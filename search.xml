<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>数据分析02：matplotlib散点图</title>
    <url>/2018/03/02/02-matplotlib%E6%95%A3%E7%82%B9%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt

'''
    散点图显示两组数据的值，每个点的坐标位置的值决定
    用户观察两种变量的相关性：
        正相关
        负相关
        不相关
        
'''

# 正相关
height = [161,170,174,165,182,175]
weight = [50,65,70,62,81,75]
plt.scatter(height,weight)
plt.show()


# 不相关
N = 1000
x = np.random.randn(N)
y = np.random.randn(N)
plt.scatter(x,y)
plt.show()


# 散点图的外观
'''
    c    颜色
    s    点（面积）大小
    alpha       透明度
        值的范围[0,1]
        通过调节透明度，来观察点的集中性
    marker      点形状
'''


# 练习
'''
    使用000001.csv的数据
    计算最高价 和开盘价之差
    绘出前后两天diff的散点图， 研究是否具有相关性
    
'''
height,open = np.loadtxt('000001.csv',delimiter=',',skiprows=1,usecols=(2,1),unpack=True)
change = height -open
tomorrow = change[2:]
yesterday = change[:-2]
plt.scatter(yesterday,tomorrow,alpha=0.2,)
plt.show()

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析01：numpy基础</title>
    <url>/2018/03/02/01-numpy%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np

# ndarray

'''
    # 三种创建方式
    1、从python的基础数据对象转化
    2、通过numpy内置的函数生成
    3、从硬盘（文件）读取数据
'''
# 创建方法一
a= [1,2,3,4]
x1 = np.array(a)
print(x1,"\n",type(x1))

# 创建方法二
x = np.arange(5)
print(x,"\n",type(x))

# # 创建方法三
# date,Open,low = np.loadtxt('..csv',delimiter="\t",skiprows=1,usecols=(1,2,4),unpack=True)
# print(date,"\n",Open,"\n",low)


# 常用函数
'''
    min     最小值
    max     最大值
    median      中值
    mean        均值
    variance        方差
    sort        
'''

c = np.random.randint(1,100,10)
print(np.sort(c))
print(np.mean(c))


# 练习
'''
    使用numpy生成100以内的随机数组
    将数组存储到文件，再从文件中读取数组
    对数据进行sort ,max ,min ,mean ,variance
'''

N1 = np.random.randint(0,100,10)
# 将N1 存储到文件中
np.savetxt("0002.cvs",N1,fmt = "%d",delimiter=",",header="number")
# 从文件中读取数组
N2 = np.loadtxt("0002.cvs",delimiter=",",skiprows=1)

print(np.sort(N2))
print(np.max(N2))


```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析04：matplotlib柱形图</title>
    <url>/2018/03/02/04-matploylib%E6%9F%B1%E5%BD%A2%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt

# 柱形图
# 例一
N =5
y =  [15,28,10,30,25]
index = np.arange(N)
p = plt.bar(index,height=y)
plt.show()

# 例2
p1 = plt.bar(0,bottom=index,width=y,height=0.5,align='edge',color='red',orientation='horizontal')
plt.show()

p2 = plt.barh(index,width= y , align='edge',color ='green',height=0.5)
plt.show()

# 例3
sales_BJ = [52,55,63,53]
sales_SH = [44,66,55,41]

index = np.arange(4)
bar_width = 0.3

# 竖着显示
plt.bar(index,sales_BJ,bar_width)
plt.bar(index+bar_width,sales_SH,bar_width,color='r')
plt.show()

# 横着显示
plt.barh(index,sales_BJ,bar_width)
plt.barh(index+bar_width,sales_SH,bar_width,color='r')
plt.show()

# 层叠图
plt.bar(index,sales_BJ,bar_width)
plt.bar(index,sales_SH,bar_width,color='r',bottom=sales_BJ)
plt.show()

# 练习
'''
    生成两组大小为5的数据；
    画出两组数据 水平的条形图；
    采用并列，层叠两种方式；
    
'''

N =5
n1 = np.random.randint(1,100,N)
n2 = np.random.randint(1,100,N)

index = np.arange(N)
bar_width = 0.3

# 并列显示
plt.bar(index,n1,bar_width)
plt.bar(index+bar_width,n2,bar_width,color='r')
plt.show()

# 层叠显示
plt.bar(index,n1,bar_width)
plt.bar(index,n2,bar_width,color='r',bottom=n1)
plt.show()

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析03：matplotlib折线图</title>
    <url>/2018/03/02/03-matplotlib%E6%8A%98%E7%BA%BF%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates


'''
    折线图，用直线段将各数据连接起来组成的图形
    常用来观察数据随时间变化的趋势
    例如：股票价格，温度变化
'''

date ,open ,close = np.loadtxt("000001.csv",delimiter=',',converters={0:mdates.bytespdate2num('%Y-%m-%d')},skiprows=1,usecols=(0,1,3),unpack=True)

plt.plot_date(date,open,linestyle='--',color="green",marker="<") plt.plot_date(date,open,linestyle="-" ,color="red" ,marker="o" ) plt.show() # 练习 ''' 画出x值为[0,10]的正弦函数图像 x="np.linspace(0,10,100)" y="np.sin(x)" plt.plot(x,y) ``` --- ### about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ - 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</")>]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析05：matplotlib直方图</title>
    <url>/2018/03/02/05-matplotlib%E7%9B%B4%E6%96%B9%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt

'''
    由于一系列不等的纵形图组成，表示数据分布的情况
    例如：某年级同学的身高分布
    需要注意与 柱形图的区别
'''

# # 例
# mu = 100    #均值
# sigma = 20    # 标准差
#
# x = mu + sigma * np.random.random(1000)
# plt.hist(x,bins=20,density=True)
# plt.show()
#
#
# # 双变量图 频率越低越暗
# # x的中心为2
# x = np.random.randn(1000) +2
# # y的中心为3
# y = np.random.randn(1000)+3
#
# plt.hist2d(x,y,bins=40)
# plt.show()


# 练习
'''
    随机生成2000个数据，均值为10， 方差3；
    绘制两个直方图， bins =10 和50 ，normed ／density 分别为True,False;
    随机生成x,y 各2000个， x均值1 ，y 均值5;
    绘制2-D直方图， bins = 40;
'''
# 均值
ava = 10
# 方差
variance = 3

sigma = np.sqrt(variance)
x = ava + sigma * np.random.random(2000)

plt.hist(x,bins=10,density=True)
plt.show()

plt.hist(x,bins=50,density=False)
plt.show()

x = np.random.randn(2000) +1
y = np.random.randn(2000) + 5
plt.hist2d(x,y,bins=40)
plt.show()

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析06：matplotlib饼状图</title>
    <url>/2018/03/02/06-matplotlib%E9%A5%BC%E7%8A%B6%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt

'''
    饼状图显示一个数据系列中各项总和的比例；
    饼状图中的数据点显示为整个饼状图的百分比；
    如：前十大品牌占市场份额图
    
'''
# 例
labels = 'A','B','C','D'
fracs = [15.0,30.0,45.0,10.0]

explode = [0,0.05,0,0.08]
plt.axes(aspect=1)
plt.pie(x=fracs,labels=labels,autopct="%.0f%%",explode=explode,shadow=True)
plt.show()

# 练习
labels = 'SH','BJ','SZ','GZ'
fracs = [20,30,25,15]
explode = [0,0,0.08,0]
plt.pie(x= fracs,labels=labels,autopct='%.00f%%',explode=explode,shadow=True)
plt.show()
```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Numpy</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析07：matplotlib箱线图</title>
    <url>/2018/03/02/07-matplotlib%E7%AE%B1%E7%BA%BF%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt

'''
    箱形图（Box-plot）又称为盒须图，盒式图，或 箱线图；
    是一种用在显示一组数据分散情况的资料统计图；
    上边缘，上四分位数，中位数，下四分位数，下边缘，异常值；
'''

np.random.seed(100)
data = np.random.normal(size=1000,loc=0,scale=1)
# sym 指定异常值的点；whis虚线的长度， 通过调整whis的大小来决定收入异常值的多少
plt.boxplot(data,sym ='o',whis=1.5)
plt.show()

# 同一张图中显示多个箱线图

# 4组 1000的数据
data = np.random.normal(size=(1000,4),loc = 0,scale=1)
# 每组的标签为ABCD
labels = ['A','B','C','D']

plt.boxplot(data,labels=labels)
plt.show()


# 练习
'''
    随机生成 100 *5 的数组；
    绘制箱线图，使用sym ,whis参数
    
'''
data = np.random.normal(size=(100,5),loc = 0,scale=1)
plt.boxplot(data,sym='o',whis=0.5)
plt.show()
```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>产品思维</title>
    <url>/2016/03/01/2016-03-01-%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 产品思维

## 设计一个产品

使用结构化思维，并优先考虑用户需求

### 1、适当提问来理解需求点

比如“设计一支笔”，“实现一个游戏类的促活活动”

需要先咨询到这支笔面向的用户群体是什么，用户的使用场景是什么，要解决用户什么样的诉求，尺寸、颜色等各类个性化的诉求，更多的咨询能更全面的捕捉用户需求，捕捉到用户的痛点需求后，可以考虑怎么来设计产品，产品的迭代计划

### 2、明确目标用户和消费者，为用户考虑

有些情况，目标用户和消费者并不是同一群人，需要了解产品的目标用户 和消费者是什么样的人。

消费者是愿为产品付费的人，用户是使用产品的人。

更多时候用户并不是单一人群，很大可能是是不同的用户群。

### 3、有哪些使用场景，用户为什么要使用这个产品

- 列出案例清单
  - 列出用户使用产品所有可能的使用目的和使用场景
- 评估案例优先级-是否解决核心痛点
- 升华考虑，用户使用这个产品的潜在动机是什么，产品可以通过激发用户的潜在动机，来满足他们的使用目的和使用场景

### 4、现有产品能否良好满足这些需求？这些产品是否存在明显的缺陷？

例如音乐软件，一直都是一个音乐播放器，国人需要好的音乐，好的音乐没有被发现，发现的效率极低。

### 5、什么功能/修改可以改进这些缺陷？

同时考虑多个用户的需求来梳理出来解决方案

### 6、结构化思维

- 产品的核心点--对标解决用户核心诉求
- 围绕核心点列出可行的周边功能点，创早意外之喜
- 根据分析得到的各个需求点，与开发、设计、测试、业务方进行方案沟通及初评，评估可行性、流程是否存在疏漏
- 进行版本排期
- 梳理完整需求文档、组织需求详评
- 跟进开发实施
- 上线准备工作
- 发布上线及生产验证
- 上线后运营维护，及数据分析
- 项目的复盘

## 产品的数据指标变化

现象：查看数据时发现数据发生变化

**分析解决思路**

归因数据，回看整个数据流和周边影响

- 检查数据测量工具，确保测量工具的正确性
- 检查基础数据，及数据埋点上报日志
- 回顾历史数据，查看历史数据情况
- 考虑最近产品进行的更改，是否因更改导致异常
- 考虑其他团队的更改、营销活动
- 考虑用户行为和客户趋势的变化
- 考虑自然条件的变化

## 产品的信息值的预估

### 明确列出问题的估值范围

明确需要估算的内容

### 创建估值的主方程

如：

中国加油站总数= 中国的城市总数* 每个城市的加油站 =   sum（每个省的城市总数）* 每个城市加油站数

### 列出主要所需的信息参数

可求证、可取值

### 考虑边缘情况

- 潜在的未知干扰因素
- 因边缘儿疏漏的统计信息

### 将估值公式的未知数分解更简单的小公式

### 计算数字

### 进行合理性复查

## 改进产品

### 描述产品

要能够理解产品的功能，方向及意图

### 明确问题的范围

理解产品后，要明确改进产品需要改进的方向是什么（是用户量，还是收入，还是其他业务目的）

### 选择一个指标

- 选择拟定到一个改进的指标
- 需要能解释清楚改进该指标的依据是什么
- 并且需要能说服对方
- 或从付费转化流程内评估考虑改动点，以优化内容完成
  - 获取新用户：怎样帮助产品获取更多用户流量
  - 用户激活：怎样更好的让户注册成为产品的用户
  - 用户留存：怎样更好的让用户持续不断的使用产品
  - 用户传播：怎么提升用户参与度，促使用户代为传播
  - 增加收入：怎么帮助产品提升收入，实习用户购买和消费， 从用户变成消费者

### 列出常见用户并选择本次改进的目标用户

- 分析并列出产品当前的用户群体
- 分析用户群特征
- 分析不同用户群体的产品诉求
- 分析得出本次改进重点是面向哪类用户群，解决的是他们的什么痛点，以达到什么样的效果

### 列出用例/痛点/并确定优先级

### 列出解决方案

### 评估解决方案

评估改进方案，制定roadmap

### 定义衡量绩效的指标

以此评估优化改进的的实际效果

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>产品思维</category>
      </categories>
      <tags>
        <tag>产品思维</tag>
        <tag>产品</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析08：matplotlib颜色与样式</title>
    <url>/2018/03/02/08-matplotlib%E9%A2%9C%E8%89%B2%E4%B8%8E%E6%A0%B7%E5%BC%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
```
import numpy as np
import matplotlib.pyplot as plt

'''
    颜色：
    - 八种内置默认颜色， 缩写
        b   :blue
        g   :green
        r   :red
        c   :cyan
        m   :magenta
        y   :yellow
        k   :black
        w   :white
    - 其它颜色的表示方法
        灰色阴影
        html   十六进制
        RGB    元组
        
'''

y = np.arange(1,5)
# 内置颜色表示
plt.plot(y,color ='g')
# 灰度表示方法
plt.plot(y+1,color = '0.5')
# html 十六进制
plt.plot(y+2,color = '#ff00ff')
# RGB 元组
plt.plot(y+3,color=(0.1,0.2,0.3))

plt.show()


'''
    线
        linestyle =''
        --      虚线
        -.      点化线
        ：      点线
        -       实线
        
    样式字符串
        可将 颜色，点型，线性 ，依次排列成一个字符串如：
            cx--
            mo:
            kp-
            
            plt.plot(y,'cx--')
'''

# 练习
'''
    使用样式字符串绘制两条线；
        1、红色，实线，圆点
        2、黄色，虚线，X点
        3、绿色，点线，三角形点
'''

y = np.arange(0,4)
plt.plot(y,'ro-',y+1,'yx--',y+2,'g>:')

plt.show()

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Python3</category>
        <category>Matplotlib</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Python3</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>AI产品视角下的ChatGPT</title>
    <url>/2023/03/04/AI%E4%BA%A7%E5%93%81%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84ChatGPT/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>

# AI产品视角下的ChatGPT
> "ChatGPT:Optimizing Language Models for Dialogue"





## ChatGPT使用体验

- 内容创作【创作小说提纲、编写小说开篇】
  
  <!-- ![](./AI产品视角下的ChatGPT/内容创作.png) -->
  <img src="/.top//内容创作.png" width="1200">




## ChatGPT使用体验

- 代码编写【生成markdown解析器】
 
  ![](./AI产品视角下的ChatGPT/生成代码.png)


## ChatGPT使用体验

- “检索问答”【知识截止于21年9月】
 
  ![](./AI产品视角下的ChatGPT/问答.png)


## ChatGPT使用体验

- “安全模型”
 
  ![](./AI产品视角下的ChatGPT/安全模型.png)



## ChatGPT主要特点

#### 主要特性
- 支持连续多轮对话，根据用户的输入连续生成回答
- 可以主动承认自身错误
  - 若用户指出其错误，模型会听取意见并优化答案
- 可以质疑不正确的问题，并给出“正能量”答复
- 可以承认自身的无知：承认对专业技术的不了解

#### “认知误区”
- <span style="color:red">不是搜索引擎</span>，是基于语言模型，推断输入意图，生成对应文本
- 模型数据输入截止21年9月，<span style="color:red">时效性</span>
- 模型本身无法确认自身输出的<span style="color:red">真实性</span>使用者需自行判断
- 可以<span style="color:red">作为人的能力的延伸</span>，但不能完全代替人类的思考
- <span style="color:red">开放领域的大模型</span>，未针对指定领域特别设计
  - 需要使用者提供足够充分的prompt【描述需求】


---
  



## ChatGPT的发展历史
#### 模型时间线


||模型发布时间|层数|头数|词向量长度|参数量|预训练数据量|论文地址|
|---|---|---|---|---|---|---|---|
|GPT-1|2018年6月|12|12|768|1.17 亿|约 5GB|[https://pa...](https://paperswithcode.com/method/gpt)|
|GPT-2|2019年2月|48|-|1600|15 亿|40GB| [https://pa...](https://paperswithcode.com/method/gpt-2)|
|GPT-3|2020年5月|96|96|12888|1,750 亿|45TB|[https://pa...](https://paperswithcode.com/method/gpt-3)|
|InstructGPT|2022年2月|-|-|-|-|-|[https://pa...](https://arxiv.org/abs/2203.02155)|
|ChatGPT|2022年11月|-|-|-|-|-|-|


 ![](./AI产品视角下的ChatGPT/chatgpt时间节点.png)





## ChatGPT的发展历史
#### 模型解读

- 👉GPT1【无监督学习】：自左向右生成式的构建预训练任务+简单的微调
- 👉GPT2【多任务学习】：使用更多参数、训练数据 >使用无监督的预训练模型做有监督的任务
  - 重要思想：“所有的有监督学习都是无监督语言模型的一个子集”，这个思想也是提示学习（Prompt Learning）的前身
- 👉GPT3【海量参数】：1759亿参数量，并且训练使用了情境学习（In-context Learning）^[1]^
  - [1]元学习（Meta-learning）的一种，元学习的核心思想在于通过少量的数据寻找一个合适的初始化范围，使得模型能够在有限的数据集上快速拟合，并获得不错的效果
#### 👉预训练模型的偏见性
- 因预训练模型都是通过海量数据在超大参数量级的模型上训练出来的[黑盒子]
- 没人能保证预训练模型不会生成一些“危险内容”，因它超大训练数据很可能包含类似的样本
#### 👉InstructGPT/ChatGPT：有用的（Helpful）、可信的（Honest）、无害的（Harmless）



## ChatGPT的简单的技术原理
#### 大参数的预训练生成语言模型
- 根据采集的SFT数据集对GPT-3.5进行有监督的微调（Supervised FineTune，SFT）
- 收集人工标注的对比数据，训练奖励模型（Reword Model，RM）
- 使用RM作为强化学习的优化目标，利用PPO算法微调SFT模型（Proximal Policy Optimization，近端策略优化）

  
  <!-- ![](./AI产品视角下的ChatGPT/ChatGPT_Diagram-技术原理.svg) -->
  <div style="height:800px;width:2000px;text-align:center">
  <img src="/.top//ChatGPT_Diagram-技术原理.svg">
  </div>
   




## 基于GPT3.5训练监督策略模型

#### SFT模型【Supervised Fine-Tuning】
  - 首先在数据集中随机抽取问题，由人类标注人员给出高质量答案
  - 然后用这些人工标注好的数据来微调GPT3.5（获得SFT模型, Supervised Fine-Tuning）
    - 使其初步具备理解指令的意图
  - 此时的SFT模型在遵循指令/对话方面已经优于 GPT-3.5，但不一定符合人类偏好

> 基于专家标注结果微调GPT模型




## 训练奖励模型
#### 主要是通过人工标注训练数据,来训练回报模型

- 在数据集中随机抽取问题，用第一阶段生成的模型,对每个问题生成多个不同回答【问题-答案对】
- 人类标注者对这些结果综合考虑给出排名顺序【这一过程类似于教练或老师辅导】
- 使用这个排序结果数据来训练奖励模型 

> 专家标注【问题-答案-排序】训练数据，调节参数使高质量回答的打分>低质量的打分





## 近端策略优化
#### 强化学习来优化策略 

- 在数据集中随机抽取问题，使用PPO模型生成回答【PPO模型用SFT初始化】
- 用训练好的RM模型给出质量分数
- 再通过强化学习的方式来更新PPO模型参数

> 指导训练对象每一步如何决策，采用什么样的"行动"可以使回答的效果更好【更新参数】




## ChatGPT原理通俗解读
---
- OpenAI使用RLHF【人类反馈强化学习】技术对【预训练语言模型】进行训练优化
- 得到大语言模型LLM
- 并基于prompting【提示】来适应不同领域的任务
- “仿真性”感知上“智力提升”，本质上是“在用人类所喜欢的方式回答”

---



## 预训练模型通俗解读

#### 之前对智能模型的认知：
  - 例如一个能分辨狗品种的Agent，需要你提供A-柴犬，B-柯基这样的数据集给他，让它学习不同品种之间的特征差异，从而学会分辨狗品种这项能力
  
#### 通过一个大一统模型先来认识这个世界。再带着对这个世界的认知对具体领域进行降维打击

- 将海量的文本语料，直接喂给模型进行学习
- 在这其中模型对词性、句法的学习自然而然会沉淀在模型的参数当中
  
#### chatgpt：拥有3000亿单词的语料基础上预训练出的拥有1750亿参数的模型

> 3000亿单词就是训练数据，1750亿参数就是AI对这个世界的理解
 一部分沉淀了Agent对各类语法、句法的学习
 另一部分参数参数则储存了AI对于事实的认知



## GPT与BERT
#### NLP任务->“猜概率”游戏

#### LLM大语言模型，演化出Bert和GPT，但理念有所不同

- BERT：
  - 预训练：Masking Input【完形填空，预测什么被盖住】
    - 双向：“结合空格两端的信息来猜测空格内应该是哪个单词” 如：“我坐__去上班”
  - 微调：fine-tuning
    - 做专业领域任务时，需收集相关的专业领域数据，做小幅模型调整更新相关参数
  - 示例：[AI情绪分析](http://ai.oceangzy.top)
- GPT：
  - 预训练：Predict Next Token【预测下一个token是什么】
    - 自回归：“从左往右做预测，不会利用文本中右侧的内容” 如：“我坐...”
  - 提示/指示：Prompting
    - 做专业领域的任务时，提供给它一些示例或引导。不用更新模型参数

---

||应用方向|应用场景|
|---|---|---|
|BERT|自然语言理解|问答系统、句子相似度、文本分类、情感分析、命名实体识别|
|GPT|自然语言生成|文本生成/续写、语言翻译、对话生成、摘要生成|


## ChatGPT的“影响”

- 加速“决策/分析AI（Discriminant/Analytical AI）”->“生成AI（Generative AI）”的演化
- 降低了非专业领域对“人工智能”的认知难度，在一定程度预示着“通用人工智能”领域的到来
- "大模型时代到来了！"
  
  <!-- ![](./AI产品视角下的ChatGPT/chatgpt影响决策AI到生成AI.png) -->
  <img src="/.top//chatgpt影响决策AI到生成AI.png">



## 大模型与AIGC

#### 【创意相关的下游产业】：图片、游戏、动画 [：600个GPT3的应用案例](https://gpt3demo.com/) 

#### 【科学技术】：编程、算法【一步到位的设计模型/给出最优解答】
[：在chatgpt内'搭建'神经网络](https://zhuanlan.zhihu.com/p/605163615)   ｜ [：CodeGeeX编程](https://gitee.com/codegeex/CodeGeeX)

#### 【编写创作】：小说、剧本、论文、周报、UGC等 [：蒲公英TracupAI](https://www.tracup.com/ai)
  
#### 【个人集成到终端智能助理】：联动语音模型、助手

#### 【知识库管理】:“类似于电脑的拓展硬盘，人类的外脑”

![](./AI产品视角下的ChatGPT/AIGC示例.png)




## 附注
#### 注册体验ChatGPT的方法
 [注册方法 -  https://note.youdao.com/s/XqoJbMJ2](https://note.youdao.com/s/XqoJbMJ2)
  
---

<div class="shows" style="display:flex;flex-deriction:row;justify-content:space-around;line-height:2">
<div class="show" style="width:40%">
<div style="background:rgba(0,0,0,0.15)">第三方体验</div>
<div style="text-align:left">
<div><a href="https://freegpt.one">https://freegpt.one</a>ps:可能已崩</div>
<div><a href="https://freechatgpt.lol">https://freechatgpt.lol</a>ps:可能已崩</div>
</div>
</div>
<div class="show" style="width:40%">
<div style="background:rgba(0,0,0,0.15)">技术资料</div>
<div style="text-align:right">
<div><a href="https://github.com/hpcaitech/ColossalAI">ColossalAI单卡复现</a></div>
<div><a href="https://platform.openai.com/docs/api-reference/chat">ChatGPT API文档</a></div>
</div>
</div>
</div>

<!-- 
#### 第三方体验

- [**基于InstructGPT的网站一**](https://freegpt.one)
- [**基于InstructGPT的网站二**](https://chatgpt.ddiu.io)
- [**Notion AI**](https://www.notion.so/)

#### 技术资料

- [**ColossalAI单卡复现**](https://github.com/hpcaitech/ColossalAI)
- [**ChatGPT API**](https://platform.openai.com/docs/api-reference/chat) -->

#### 个人站点

<!-- - [**AI情绪分析**](http://ai.oceangzy.top/#/index/motion)
  ![](./AI产品视角下的ChatGPT/ai情绪分析二维码.png)
- [**AI写诗**](http://ai.oceangzy.top/#/contentCreate/poetry)
  ![](./AI产品视角下的ChatGPT/AI写诗二维码.png)
- [**AI聊天机器人**](http://ai.oceangzy.top/generator/chat)
  ![](./AI产品视角下的ChatGPT/AI聊天机器人二维码.png) -->


<div class="shows" style="display:flex;flex-deriction:row;justify-content:center">
<div class="show">
<img src="/.top//ai情绪分析二维码.png">
</div>
<div class="show">
<img src="/.top//AI写诗二维码.png">
</div>
<div class="show">
<img src="/.top//AI聊天机器人二维码.png">
</div>
</div>




# Thanks!]]></content>
      <categories>
        <category>产品</category>
        <category>ChatGPT</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>算法</tag>
        <tag>ChatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>AI数据标注是什么</title>
    <url>/2018/11/26/AI%E6%95%B0%E6%8D%AE%E6%A0%87%E6%B3%A8%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### AI数据标注是什么

​	只要跟“监督学习”沾边的产品／技术，比如图像识别、人脸识别、自然语言处理等，都又一个必不可少的流程：

![image-20190225160952429](/Users/gaozhiyong/Desktop/image-20190225160952429.png)

不断的使用标注后的数据去训练模型，不断调整模型参数，得到指标熟知更高的模型。

#### 数据处理流程拆解

#### 数据标注

*数据质量直接影响模型质量*

- 数据标注人员角色

  - **标注员**：标注员负责标记数据
  - **审核员**：审核员负责审核被标记数据的质量
  - **管理员**：管理人员、发放任务、统计工资

  只有数据被审核员审核通过后，这批数据才能被算法同事使用

- 数据标记流程

  - 任务分配

  - 标记程序设计

- 进度跟踪
- 质量跟踪

#### 模型训练

- 示例：为提高识别精确度，可以采用的方式如：
  - 补充数据
    - 提供正例数据
    - 提供负例数据
    - 进而及提高差异度的识别
  - 优化数据
    - 修改以往的错误标注

#### 模型测试

*如无后台设计，则测试只能由人工抽样计算，繁琐且效率低下；故可以考虑后台计算*

- 模型测试需关注的指标

  - 精确率；又叫准确率

    ​	*识别为正确的样本数 ／ 识别出来的样本数*

  - 召回率；又叫查全率（Recall Rate）

    ​	*识别为正确的样本数 ／ 所有样本中的正确的数*

  - 精准率；又叫查准率

  - 真正例率（同召回率／查全率）

  - 假正例率

  - > 示例：举个栗子：全班一共30名男生、20名女生。需要机器识别出男生的数量。本次机器一共识别出20名目标对象，其中18名为男性，2名为女性。则
    >
    > - 精确率=18/（18+2）=0.9
    > - 召回率=18/30=0.6

#### 产品评估

在模型上线之前，产品需反复验证模型效果。为了用数据对比本模型和上一个模型的优劣，需要每次都记录好指标数据。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>AI时代决策效率革命</title>
    <url>/2019/02/25/AI%E6%97%B6%E4%BB%A3%E5%86%B3%E7%AD%96%E6%95%88%E7%8E%87%E9%9D%A9%E5%91%BD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


![image-20200215095521389](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215095521389.png)

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>AI时代如何提升个人认知</title>
    <url>/2019/02/25/AI%E6%97%B6%E4%BB%A3%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E4%B8%AA%E4%BA%BA%E8%AE%A4%E7%9F%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### AI时间如何提升个人认知

> 思考比学习知识更重要。

#### 外部原因

​	当今世界的知识爆炸时代，每个人的精力有限，需要思考深于学习；但当时间盈余的情况下，还是需要在思考的同时进行知识学习。

比如：

- 互联网

- 共享经济

- 大数据



#### 内部原因

> 《论思考》 、《论书籍和写作》——叔本华

> 读书和思考是相互替代的关系；读书是在思考无头绪的时候作为辅助。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>AI是什么</title>
    <url>/2018/11/25/AI%E6%98%AF%E4%BB%80%E4%B9%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### AI是什么

AI，“Artificial Intelligence”的缩写，中文“人工智能”；可以理解为让机器具备类似人的智能，从而代替人类完成某些工作和任务。

- “强人工智能”

  能够像人类一样去思考和推理，具备自我意识

- “弱人工智能”

  机器表现出来的特征是智能的，但是不具备自我意识

  - 通过相关规则编程，使机器按照程序逻辑完成特定的任务

  - 针对某一任务向机器提供大量数据，使机器自己去学习，继而挖掘出规律，从而完成任务

#### 弱人工智能

##### 机器学习

*从模型层次结构的角度可以分为浅层学习和深度学习*

###### 浅层学习（Shallow Learning）

- 模型层次较浅，通常没有隐藏层、或只有一层隐藏层

- 可以做一些预测、分类、聚类、降低数据维度、压缩数据、商品推荐系统等工作

- 常见算法：

  - 线性回归

  - 逻辑回归

  - 随机森林

  - SVM

  - K-means

  - RBM

  - AutoEncoder

  - PCA

  - SOM

  - ……

###### 深度学习（Deep Learning）

- “深”是因为通常具有较多的隐藏层，进而拥有表达更多复杂函数的能力，进而能识别更复杂的特征
- 主要集中在CNN 和RNN
- **CNN**

  - **CNN**为Convolution Neural NetWorks的缩写，也就是卷积神经网络

  - 主要应用于计算机视觉、图像分类领域

  - 应用场景示例

    - 美颜相机的滤镜

    - 交通监控识别车辆车型、车牌号

    - 商汤人脸识别

    - 无人车

    - ……
- **RNN**
  - Recurrent Neual NetWorks的缩写，递归神经网络
  - 基于**RNN**还衍生出**LSTM**（Long-Short-Term-Memerory） 和**GRU**（Gated Recurrent Unit）等
  - 具有记忆过去的能力，故用来处理一些有**时间序列属性**的数据，处理语言、文字具有优势
  - 应用场景示例：
    - Siri**对话机器人**
    - 谷歌翻译，**机器翻译**
    - 语音转文字
    - ……

### AI本质

*AI本质上都是一个函数*

*AI其实就是我们提供机器目前已有的数据，机器从数据去找出一个最能拟合这些数据的函数；当有新的数据需要预测时，机器通过之前找到的函数去预测新数据的对应结果。*

- 通用要素

  **AI = 数据+算法+模型**

- 示例讲解—分类器模型为区分A 和B

  - 数据

    - 准备大量已标注过 是A  还是B的图片
    - 只有数据量足够大，模型才能够学习足够准确的 区分A 和B的特征，在进行最终的AB任务区分上，才能表现出足够高的准确性

  - 算法

    - 网络架构设计：构建模型时，采用浅层网络还是深层网络，如为深层，则需多少层，每层油多少神经元，功能是什么等

    - 预测函数的大致结构
      $$
      Y= f(W,X,b)
      $$
      Y ，是已有的图片数据的标签；（A和B的图片）

      X，是已有的用来训练的数据；（该图是A 还是B）

      W，权重；b，偏差 ； 这两个参数通过机器学习后得出

    - 寻找W 和b 的过程，就是模型训练的过程

  - 模型

    - 将数据带入算法中训练，机器不断学习，当机器找到最优 W 权重，b 偏差；就意味着模型 train成功了

    - 函数模型
      $$
      Y=f(W,X,b)
      $$

    - 提供新的数据输入该模型，算出新的数据是A或者B，即为模型的**预测功能**



**不管是简单的线性回归，还是复杂的深度神经网络模型，本质都是寻找一个能够良好拟合目前已有数据的函数**
$$
Y=f(W，X，b)
$$
**并且这个函数在新的未知数据上也能够表现良好。**


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS MariaDB配置</title>
    <url>/2018/01/01/CentOS%20MariaDB%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 启动Mariadb

前提需安装mariadb-server
- 安装mariadb-server
	yum install -y mariadb-server
- 启动服务
	systemctl start mariadb.service
- 添加到开机启动
	systemctl enable mariadb.service
- 安全设置，以及修改数据库管理员密码
	mysql_secure_installation

- 启动MariaDB
   - 正常启动
      - systemctl start mariadb
      - service mariadb start
   - 设置开机启动
      - systemctl enable mariadb
      - chkconfig mariadb on

## 配置MariaDB的字符集

- 设置客户端：
	vim /etc/my.cnf.d/mysql-clients.cnf

	[mysql]
	default-character-set=utf8

- 设置服务端：
	vim /etc/my.cnf.d/server.cnf

	[mysqld]
	init_connect='SET collation_connection = utf8_general_ci'
	init_connect='SET NAMES utf8'
	character-set-server=utf8
	collation-server=utf8_general_ci
	skip-character-set-client-handshake

	[开启慢查询]
	slow_query_log = ON
	slow_query_log_file = /usr/local/mysql/data/slow.log
	long_query_time = 1


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>MariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Algorithm入门解读</title>
    <url>/2018/10/01/Algorithm%E5%85%A5%E9%97%A8%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 决策树
- 根据一些feature特征进行分类
- 每个节点，根据问题判断，将数据分为两类

## 随机森林
## 逻辑回归
## Support vector machines
	支持向量机
## Navie Bayes
	朴素贝叶斯 
## kNN: k-nearest neighbor classification
	K近邻算法
## K均值算法
## Adaboost
## 神经网络
## 马尔科夫

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7 防火墙控制与端口控制</title>
    <url>/2018/01/08/CentOS7%E9%98%B2%E7%81%AB%E5%A2%99%E6%8E%A7%E5%88%B6%E4%B8%8E%E7%AB%AF%E5%8F%A3%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## firewalld
- 启动： systemctl start firewalld
- 关闭： systemctl stop firewalld
- 查看状态： systemctl status firewalld 
- 开机禁用  ： systemctl disable firewalld
- 开机启用  ： systemctl enable firewalld
 
## systemctl
	systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。
- 启动一个服务：systemctl start firewalld.service
- 关闭一个服务：systemctl stop firewalld.service
- 重启一个服务：systemctl restart firewalld.service
- 显示一个服务的状态：systemctl status firewalld.service
- 在开机时启用一个服务：systemctl enable firewalld.service
- 在开机时禁用一个服务：systemctl disable firewalld.service
- 查看服务是否开机启动：systemctl is-enabled firewalld.service
- 查看已启动的服务列表：systemctl list-unit-files|grep enabled
- 查看启动失败的服务列表：systemctl --failed

## firewalld-cmd
- 查看版本： firewall-cmd --version
- 查看帮助： firewall-cmd --help
- 显示状态： firewall-cmd --state
- 查看所有打开的端口： firewall-cmd --zone=public --list-ports
- 更新防火墙规则： firewall-cmd --reload
- 查看区域信息:  firewall-cmd --get-active-zones
- 查看指定接口所属区域： firewall-cmd --get-zone-of-interface=eth0
- 拒绝所有包：firewall-cmd --panic-on
- 取消拒绝状态： firewall-cmd --panic-off
- 查看是否拒绝： firewall-cmd --query-panic
 
## 开启端口
- 添加
   - firewall-cmd --zone=public --add-port=80/tcp --permanent    （--permanent永久生效，没有此参数重启后失效）
- 重新载入
   - firewall-cmd --reload
- 查看
   - firewall-cmd --zone=public --query-port=80/tcp
- 删除
   - firewall-cmd --zone=public --remove-port=80/tcp --permanent


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS-Maven配置</title>
    <url>/2018/03/02/Centos-Maven%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# Centos-Maven配置

 配置maven镜像

```xml
<mirror>
	<id>alimaven</id>
	<name>aliyun maven</name>
  <url>http://maven.aliyun.com/nexus/content/groups/public/</url>
  <mirrorOf>central</mirrorOf>
</mirror>
```



maven配置路径 

```shell
export M2_HOME=/usr/local/maven3/apache-maven-3.6.3
export PATH=$PATH$:M2_HOME/bin

source /etc/profile
```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>服务端</tag>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN、RNN、DNN区别</title>
    <url>/2019/01/01/CNN%E3%80%81RNN%E3%80%81DNN%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## CNN、RNN、DNN区别

![img](https://img-blog.csdnimg.cn/201811232052525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpbnl1c2tp,size_16,color_FFFFFF,t_70)

### 神经网络起源

**感知机（perception），包含输入层，输出层，和一个隐藏层；**

​	输入的特征向量通过隐藏层变换达到输出层，由输出层得到分类结果。

**多层感知机，多个隐藏层；**

**神经网络NN，使用连续函数模拟神经元对激励的响应，在训练算法上使用反向传播算法；**

1、神经网络的层数直接决定了它对现实的刻画能力----利用每层更少的神经元拟合更加附加的函数。

2、神经网络层数加深，优化函数越容易陷入局部最优解，并且越来越偏离全局最优

3、利用有限的数据训练深层的网络，性能还不如浅层网络

4、网络层数的不断增加，“梯度消失”的现象更严重

### DNN

2006年，Hition提出深度学习，利用预训练的方式缓解局部最优解问题，将隐藏层增加到了7层



### CNN 卷积神经网络Convolutional Neural Networks

图像中存在固有的局部模式，故将图像处理和神经网络结合引出卷机神经网络CNN（Convolutional Neural Networks），通过卷积核将上下层进行链接![img](https://img-blog.csdnimg.cn/20181123204831338.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpbnl1c2tp,size_16,color_FFFFFF,t_70)

因每层神经元的信号智能向上一层传播，样本的处理每个时刻独立，又被称为前向神经网络（Feed-forward Neural Networks）。

### RNN 递归神经网络Recursive Neural Network

**广义上分为：**

- 结构递归神经网络

- 时间递归神经网络

**狭义上分为：**

- 递归神经网络常常指的是 结构递归神经网络
- 时间递归神经网络则成为 循环神经网络（Recurrent Neural Network）

**循环神经网络**

![img](https://img-blog.csdnimg.cn/20181123205052191.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpbnl1c2tp,size_16,color_FFFFFF,t_70)

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>神经网络</tag>
        <tag>RNN</tag>
        <tag>CNN</tag>
        <tag>DNN</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7编译安装Python3.7</title>
    <url>/2018/01/01/Centos7%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85Python3.7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 安装编译工具
- yum -y groupinstall "Development tools"
- yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel
- yum -y install libffi-devel 

## 下载安装包解压
- cd #用户目录
- wget https://www.python.org/ftp/python/3.7.0/Python-3.7.0.tar.xz
- tar -xvJf  Python-3.7.0.tar.xz

## 编译安装
- mkdir /usr/local/python3 #创建编译安装目录
- cd Python-3.7.0
- ./configure --prefix=/usr/local/python3
- make && make install

## 创建软链接
- ln -s /usr/local/python3/bin/python3 /usr/local/bin/python3
- ln -s /usr/local/python3/bin/pip3 /usr/local/bin/pip3

## 验证是否成功
- python3 -V
- pip3 -V


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Linux</category>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title>广告系统架构</title>
    <url>/2020/02/22/DSP%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 广告系统架构

- DSP
  - 需求方平台，即为广告主服务平台，广告主可以通过DSP平台设置自己想要的受众，设置愿意出资多少购买这些受众的曝光，完成广告投放需求； 面向广告购买方
- SSP
  - 供应方平台，即为媒体服务平台，媒体方通过SSP平台完成广告资源的管理，如流量分配，价格，筛选等；面向广告售卖方
- ADX
  - 广告交易平台，即为连接买方和卖方；ADX将媒体的广告流量以拍卖的方式卖给DSP
- DMP
  - 数据管理平台，整合各方数据并提供数据分析、数据管理、数据调用，用来指导广告主进行广告优化和投放决策
- RTB
  - 实时竞价，100ms内完成计算，当前谁在这个广告位上提供的广告费用更高

**实用程序的方式进行广告投放的管理，并利用算法和技术自动实现精准的目标受众定向，把广告内容投放给对的人；效果：**

- 对广告主
  - 提高流量的采购效率，更低成本，更可靠稳定的流量
  - 可融合使用多种策略，投放不同的目标人群，使得广告的投放效果更加可控
  - 减少广告浪费，提升转化率，扩大覆盖面积
- 对媒体资源
  - 实现资源的自动化售卖，提高流量的使用率
  - 有效利用优质流量和长尾流量
  - 并且能基于人员的属性、兴趣等标签对不同的流量给出不同售价，提升流量库存的收入

#### DSP投放架构

![img](https://upload-images.jianshu.io/upload_images/13280750-a2bda3e85433b72a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200)

#### RTB竞价逻辑

![img](https://upload-images.jianshu.io/upload_images/13280750-8b586f3cc9457aec.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200)

### 平台核心要素

#### 流量资源

不同的流量资源会有不同的效果，如何选择媒体和广告位是关键。

制定媒体策略首先需要分析目标受众，根据目标受众选择匹配的媒体资源。媒体策略可以从所要投放的广告位所在页面page、位置spot、流量inventory、价格price、和转化conversion五个角度制定

- 页面
  - 包括渠道、载体（PC、WAP、APP）、媒体分类、频道、URL、页面关键词
- 位置
  - 广告位所在的具体位置、尺寸的大小、广告位类型、屏次（首屏、第二屏）
- 流量
  - 总流量的大小决定着采购的流量大小
- 价格
- 转化

#### 投放策略及受众定向

##### 基础设置

- 出价上限
  - 按照CPM、CPC设置，广告主设置能承受的价格上限
- 预算控制
  - 提前设置预算避免过度消耗，分为每日预算、总预算
  - 可设置曝光次数限制、点击次数限制；每日曝光、总曝光；每日点击、总点击
- 频次控制
  - 广告主设置同一个用户在设定时间内看到特定广告的总次数
- 投放时间
  - 设置投放日期和投放时段
  - 不同的时间段都会对广告效果产生影响，比如周末、晚上高峰时段

##### 受众定向

- 地区
- 客户端定向
- 设备类型
- 人群标签定向，基于DMP系统，不同兴趣爱好的人群进行广告投放

#### 创意内容

##### 创意形式format

- 以何种形式呈现
  - 图片
  - 蚊子
  - 图文
  - 视频
  - 表单
  - ……

##### 用户交互方式engagement

### 数据指标

在广告投放过程中，必须关注广告的投放效果，以及时调整投放策略，达到效果最大化

#### 基础指标

- 请求数：包含总请求数、有效请求数、参加竞价数、赢得竞价数
- CPC：每点击成本
- CPM：每千人成本
- CTR：广告点击率，即广告点击次数/广告展示次数

#### 高阶指标

- 独立访客数
- 访问数
- 网站到达率：用户到达landingpage的数量 / 点击数 ； 用户衡量该环节的用户流失率
- 频次：离线频次、累计频次
- 网站浏览量：用户到达目标页面产生的浏览量
- 二跳率
- 平均停留时长：用户到达目标页面后的平均停留时间
- 下载、激活、注册：该次广告投放引导用户下载、激活、注册的数量
- 付款金额、付款人次

### 程序化创意

![img](https://upload-images.jianshu.io/upload_images/13280750-6b37be8f436c849b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200)

### 用户数据中心DMP

![img](https://upload-images.jianshu.io/upload_images/13280750-793b5fc068b19f6a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200)

### 反作弊

#### 常见作弊方式

- CTR异常，明显高于正常水平
- 广告访问IP异常，某些IP产生大量的展示点击
- 点击热力图异常
- 有点击展示，却没有对应的广告请求
- 广告请求，展示、点击、跳转、时间顺序异常
- 无时间定向时，某时间段的请求，展示，点击数量明显高于正常水平
- 某些设备产生了大量的展示、点击
- 重复展示、点击
- 广告请求中的参数异常，如UA，IP，机型等

#### 反作弊方法

反作弊需要事前预防、事后溯源、人工排查、智能算法等多管齐下

反作弊的最终目的是识别机器人流量和正常流量，既要能准确的过滤非正常流量，又要保证正常流量不被过滤

##### 广告来源

- 过滤爬虫IP，过滤内网IP，过滤长时间产生异常数据的IP
- 出现大量无refer的广告流量
- refer与所投放的媒体不对应

##### 用户标识

- 根据IP、cookie或者设备ID作为分辨用户的依据

##### 用户行为

对广告请求、请求频次、展示、展示频次、点击、点击频次进行分析

- 同一用户、同一时间在多个广告位产生了浏览或点击行为,或短时间内在同一广告位产生多次曝光或点击;

- 同一用户的广告浏览或点击时间间隔过于规律;

- 曝光数和点击数在某个时间点暴涨;

- 用户未浏览广告就直接产生了点击行为,通常表现为出现大量无曝光的点击;

- 用户浏览广告的面积和时长数据异常,可用广告可见度(Viewability)衡量和分析;

- 用户点击广告的位置过于规律或过于集中,一般用广告位热图来观察分析;

- 用户行为的各环节(浏览广告->点击广告->到站->转化)遵循严谨的时间先后顺序,如果点击广告的时间早于浏览广告的时间,或浏览和点击行为之间的时间间隔异常,一般可以判断为作弊

- 到站情况，综合考量用户留存、停留时间,访问深度等指标,用于分析转化用户的质量
- 关注用户的站内交互情况(点击、滚动、输入等操作)。和广告点击作弊一样,为了制造用户活跃的假象,作弊的方可能会利用机器产生大量页面点击,同样地,我们可以利用点击的区域、次数、频率、页面窗口大小等指标去伪存真

![](DSP广告系统架构/个人微信公众号二维码.png)

![](DSP广告系统架构/个人网站二维码.png)


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>广告</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>广告</tag>
        <tag>DSP</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringData JPA 表与表之间的操作</title>
    <url>/2020/02/19/JPA%E8%A1%A8%E4%B8%8E%E8%A1%A8%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 表分析

数据库表与表之间的关系

- **多对多**
  - 工程师---项目
  - 老师---学生
- **一对多**
  - 学校---班级
  - 班级---学生
- 一对一
  - 学生---学生证
  - 公民---身份证

![image-20200402202254173](C:\Users\YSilhouette\AppData\Roaming\Typora\typora-user-images\image-20200402202254173.png)

### JPA中的一对多

**一的一方为主表；多的一方为从表；从表依赖主表存在**

- 首先，确定两张表之间的关系
- 在数据库中实现两张表的关系外键
- 在实体类中描述两个实体的关系
- 配置初实体类和数据库表的关系映射

@OneToMany

### JPA中的多对多

@ManyToMany

### JPA中的一对一

@OneToOne

### **问题描述**

在利用Spring boot data JPA进行表设计的时候，表对象之间经常存在各种映射关系，如何正确将理解的映射关系转化为代码中的映射关系是关键之处。

### **解决办法**

#### **概念理解**

- 举例：在公司的权限管理中，存在公司表、部门表、员工表。
  1. 公司表和部门表的关系：
     主控方：部门表
     被控方：公司表
  2. 部门表和员工表的关系：
     由于是多对多的关系，不存在谁是主控方或被控方，两者处于平行关系。
- 一对多或多对一，用外键关联，若未设置级联删除，则删除被控方记录的时候会有外键约束。
- 多对多，用中间表关联，删除中间表的记录，不会各方的表造成影响。
- 在该四个注解中，都含有属性可设置，以下举例两个属性。
  1. fetch=FetchType.LAZY为默认的数据延迟加载，fetch=FetchType.EAGER为急加载。
  2. cascade={CascadeType.PERSIST，CascadeType.MERGE,
     CascadeType.REFRESH,CascadeType.REMOVE}.
     其中：
     CascadeType.PERSIST级联新增（又称级联保存）；
     CascadeType.MERGE:级联合并（级联更新）；
     CascadeType.REMOVE:级联删除；
     CascadeType.REFRESH:级联刷新
     CascadeType.ALL:以上四种都是；
     一般采用CascadeType.MERGE:级联合并（级联更新）即可。默认值是均不进行关联。

#### **@OneToOne**

- 在一对一的关系中，只需在主控方（数据总表）内注明@OneToOne，而被控方（员工表）只是作为外键，不需任何特殊标记。

```java
@Entity
@Table(name = "costume_all_id")
public class AllId extends AbstractEntity {
    private static final long serialVersionUID = 1L;

    @OneToOne(cascade = CascadeType.ALL)
    @JoinColumn(name = "costume_member_fk")
    private Member member;// 用户表外键
}
```

#### **@OneToMany和@ManyToOne**

- 公司（组织）表相对于部门表是被控方，只需在被控方写mappedBy,其值为主控方中引用的外键对象的名称。

```java
@Entity
@Table(name = "costume_organization")
public class Organization extends AbstractEntity {
    private static final long serialVersionUID = 1L;

    @Column(nullable = false, length = 50)
    private String name; // 组织名称

    @OneToMany(mappedBy = "organization")
    private Set<Department> departmentSet; // 部门集合
}
```

- 部门表相对于公司（组织）表是主控方，在主控方只需写@ManyToOne即可，其对象名为被控表中mappedBy中的值。
- 同时需要注意，如果需要将公司表对象或者部门表对象转为JSON数据的时候，为了防止出现无限循环包含对方，需要在部门表（多的一方）的引用公司表（少的一方）对象的set方法上写上注解@JsonBackReference

```java
@Entity
@Table(name = "costume_department")
public class Department extends AbstractEntity {
    private static final long serialVersionUID = 1L;

    @Column(nullable = false, length = 50)
    private String name; // 部门名称

    @ManyToOne(optional = false)
    private Organization organization; // 组织外键

    @ManyToMany
    private Set<Member> memberSet; // 用户表外键

    public Organization getOrganization() {
        return organization;
    }

    @JsonBackReference
    public void setOrganization(Organization organization) {
        this.organization = organization;
    }
}
```

#### **@ManyToMany**

- 在多对多的情况下，如部门表和员工表之间的关系（暂不去深究一个员工是否能有多个部门的身份）。
- 部门表和员工表只需在引用对象集合上注明@ManyToMany即可，其中部门表的写法如上段代码，员工表的写法如下段代码。
- 在多对多的映射中会生成一张中间表，其表名和字段名均有默认的命名规则，若需指定表名和字段名，只需在两者的一方或双方写上@JoinTable注解即可，详情如下代码段，表名属性name=”table_name”，与joinColumns属性是同级属性，即写在其前即可。
- 同时需要注意，如果需要将员工表对象或者部门表对象转为JSON数据的时候，为了防止出现无限循环包含对方，需要在一方的引用对方对象的set方法（Set对象的set方法）上写上注解@JsonBackReference

```java
@Entity
@Table(name = "costume_member")
public class Member extends AbstractEntity {
    private static final long serialVersionUID = 1L;

    @Column(nullable = false, length = 20)
    private String name;

    @ManyToMany
    @JoinTable(joinColumns = { @JoinColumn(name = "member_id") }, inverseJoinColumns = {
            @JoinColumn(name = "department_id") }) //被控方表字段名
    private Set<Department> departmentSet; // 部门表外键

    public Set<Department> getDepartmentSet() {
        return departmentSet;
    }

    @JsonBackReference
    public void setDepartmentSet(Set<Department> departmentSet)
    {
        this.departmentSet = departmentSet;
    }
}
```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </Department></Department></Department></Member></Department>]]></content>
      <categories>
        <category>JAVA</category>
        <category>SpringData JPA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>SpringData JPA</tag>
      </tags>
  </entry>
  <entry>
    <title>Data Management Platform 数据管理平台简介</title>
    <url>/2019/01/01/Data%20Management%20Platform%20%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## Data Management Platform 数据管理平台
- 大数据在营销中的落地解决方案和实时消费者互动的基础
- 即：利用数据管理平台实现营销层面和战略层面的多重用途

## DMP的三个层次，核心能力
### 数据整合能力
- 数据，即DMP的输入；
- 稳定可靠的数据来源是一切DMP的基础
- 建立DMP，可拿到大量非自己业务的数据，并且自己业务的数据可量化评估其他数据提供方的数据
- 对不同来源和不同结构的数据清洗 和整合

### 数据分析能力
- 用户画像是基础，即通过对用户信息的标签化，完美的抽象出一个用户信息全貌
- 用户画像的焦点：为用户打标签；一个标签 ：高度提炼的特征标识

### 行业解决方案
- DMP的输出
- 有了数据的整合分析，通过一个特定的应用场景，实现大数据的最终价值
- 即解决数据的最终如何变现的问题

## DMP分类
## 按照数据归属
### 第一方数据
- 需求方即广告主，自有用户数据，包括网站/APP监测数据，CRM数据，电商交易数据等

### 第二方数据
- 需求方服务提供者，在广告投放过程中积累的业务数据，如DSP平台业务中积累的受众 浏览广告，点击广告等相关数据

### 第三方数据
- 非直接合作方拥有的数据，如运营商数据

## 按照DMP平台归属
### 第一方DMP
- 大型广告主自己搭建或者 寻找外部技术提供商，为自己搭建的内部DMP，用户分析和管理用户数据；为营销环节提供决策支持和用户数据支撑，广泛用于电商、游戏、旅游等行业

### 第二方DMP
- 需求方服务提供者（一般指需求方平台）搭建的DMP，帮助广告主更好的进行投放，提升效果的同时，加大投放量，间接提升广告主在需求方平台的投放额度

### 第三方DMP
- 以数据交易为主要形式的DMP，为需求方提供数据交换、售卖等服务；
- 需要对接入DSP后再运用到广告投放中

## DMP作用
- 收集和处理来自各种孤岛数据源的数据，并将其提供至第三方平台
   - 如：DSP，SSP，和广告交易平台
   - 用于在营销、程序化创意、转化统计、定向广告、个性化、内容定制
- 又称为：广告技术的“管道”-以中立的方式连接许多平台，方便营销人员使用

## DMP运作方式
- 可从任一来源收集非结构化的数据

## DMP数据收集
### 数据源
- 包括：桌面、移动网络、移动应用、网络分析工具、CRM、销售点、社交、在线视频、离线视频

## DMP使用策略
### 受众分类
- DMP按照广告主需求，对受众数据分门别类
- 即，广告主可自定义数据的组织方式

### 标签细分
- 数据归类后，将数据打上不同的标签

### 洞察和受众概况报告
- 经过分类和标签后，进一步分析，生成“受众数据分析报告”

### 数据激活
- 将数据投入使用来激活数据
   - DMP通过DSP向特定群体精准投放广告
   - DMP连接到CMS，以调整特定受众群体的网站内容

## DMP建立受众

## DMP建立标签
### 标签类型
- 年龄
- 性别
- 位置或地区
- 兴趣
- 浏览记录
- 家庭收入
- 家庭规模
- 意见（如：所有喜欢/不喜欢）
- 社交网络

## DMP受益者
### SSP
- SSP ：媒体所有者，包括拥有和管理网关的任何人

### 营销人员和代理商


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>DMP</category>
      </categories>
      <tags>
        <tag>DMP</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-Character类</title>
    <url>/2016/03/02/Java-Character%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java-Character类

```
public class CharacterDemo {
    // 对单个字符进行操作

    /*
        转义序列	描述
        \t	在文中该处插入一个tab键
        \b	在文中该处插入一个后退键
        \n	在文中该处换行
        \r	在文中该处插入回车
        \f	在文中该处插入换页符
        \'	在文中该处插入单引号
        \"	在文中该处插入双引号
        \\	在文中该处插入反斜杠
     */

    //字符方法
    /*
        序号	方法与描述
        1	isLetter()
是否是一个字母
        2	isDigit()
是否是一个数字字符
        3	isWhitespace()
是否是一个空白字符
        4	isUpperCase()
是否是大写字母
        5	isLowerCase()
是否是小写字母
        6	toUpperCase()
指定字母的大写形式
        7	toLowerCase()
指定字母的小写形式
        8	toString()
返回字符的字符串形式，字符串的长度仅为1
     */
    public static void main(String[] args) {
        System.out.println("实验一个引号\"引号引号\"");
    }
}

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-FileStreamIO</title>
    <url>/2016/03/02/Java-FileStreamIO/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java-FileStreamIO

```
import java.io.*;

public class StreamFileIODemo {
    public void printChar() throws IOException {
        //使用BufferedReader从控制台读取输入
        char c;
        //使用System.in 创建BufferedReader
        BufferedReader br1 = new BufferedReader(new InputStreamReader(System.in));
        System.out.println("输入字符，按Q键退出");
        do {
            //read() 读取字符
            c = (char) br1.read();
            System.out.println(c);
        } while (c != 'Q');
    }

    public void printStr() throws IOException{
        String str1;
        //使用System.in 创建BufferedReader
        BufferedReader br1 = new BufferedReader(new InputStreamReader(System.in));
        System.out.println("输入字符 'end' 退出");
        do {
            //readLine() 读取字符串
            str1 = br1.readLine();
            System.out.println(str1);
        } while (!str1.equals("end"));

    }

    public void ReadFileDemo() throws IOException{
        //FileInputStream 从文件读取数据
        //  File f = new File("C:/java/hello");
        //  InputStream out = new FileInputStream(f);
        /*
            序号	方法及描述
            1	public void close() throws IOException{}
                关闭此文件输入流并释放与此流有关的所有系统资源。抛出IOException异常。
            2	protected void finalize()throws IOException {}
                这个方法清除与该文件的连接。确保在不再引用文件输入流时调用其 close 方法。抛出IOException异常。
            3	public int read(int r)throws IOException{}
                这个方法从 InputStream 对象读取指定字节的数据。返回为整数值。返回下一字节数据，如果已经到结尾则返回-1。
            4	public int read(byte[] r) throws IOException{}
                这个方法从输入流读取r.length长度的字节。返回读取的字节数。如果是文件结尾则返回-1。
            5	public int available() throws IOException{}
                返回下一次对此输入流调用的方法可以不受阻塞地从此输入流读取的字节数。返回一个整数值。
         */
        System.out.println("打印输出读取文件demo");
        InputStream is1 = new FileInputStream("test.txt");
        int size = is1.available();
        for (int i=0;i<size;i++) 1 2 3 4 { system.out.println((char) is1.read()); } public void writefiledemo() throws ioexception fileoutputstream 创建一个文件向文件中写数据 file f="new" file("c: java hello"); outputstream fileoutputstream(f); * 序号 方法及描述 close() ioexception{} 关闭此文件输入流并释放与此流有关的所有系统资源。抛出ioexception异常。 protected finalize()throws {} 这个方法清除与该文件的连接。确保在不再引用文件输入流时调用其 close 方法。抛出ioexception异常。 write(int w)throws 这个方法把指定的字节写到输出流中。 write(byte[] w) 把指定数组中w.length长度的字节写到outputstream中。 system.out.println("打印输出写入文件demo"); byte bwrite[]="{11,21,3,38,5};" os1="new" fileoutputstream("test.txt"); for (int i="0;i<bWrite.length;i++){" os1.write(bwrite[i]); os1.close(); createdirs(){ 文件和i o ，目录 file类 - mkdir( )方法创建一个文件夹，成功则返回true，失败则返回false。失败表明file对象指定的路径已经存在，或者由于整个路径还不存在，该文件夹不能被创建。 mkdirs()方法创建一个文件夹和它的所有父文件夹。 string dirname="/Users/gaozhiyong/Documents/GitHub/javaLearn/tmp/testdir/test" ; dir1="new" file(dirname); 创建目录 dir1.mkdirs(); readdirs(){ 一个目录其实就是一个 对象，它包含其他文件和文件夹。 如果创建一个 对象并且它是一个目录，那么调用 isdirectory() 方法会返回 true。 可以通过调用该对象上的 list() 方法，来提取它包含的文件和文件夹的列表。 dir2="new" if (dir2.isdirectory()){ system.out.println("目录"+ dirname); string[] s1="dir2.list();" file(dirname + ' s1[i]); (f.isdirectory()){ system.out.println(s1[i] "是一个目录"); }else "是一个文件"); system.out.println(dirname +"不是一个目录"); deletedirs(){ 删除文件 目录 删除文件可以使用 java.io.file.delete() 方法 当删除某一目录时，必须保证该目录下没有其他文件才能正确删除，否则将删除失败 dir3="new" file[] files="dir3.listFiles();" (files !="null){" (file f: files){ (!f.isdirectory()){ f.delete(); dir3.delete(); system.out.println("删除成功"); static main(string[] args) streamfileiodemo s="new" streamfileiodemo(); s.printchar(); s.printstr(); s.writefiledemo(); s.createdirs(); s.readdirs(); s.deletedirs(); ``` --- ### about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </size;i++)>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-StringBuffer</title>
    <url>/2016/03/02/Java-StringBuffer/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java-StringBuffer

```
public class StringBufferAndStringBuilderDemo {
    //StringBuffer  线程安全
    //StringBuilder 速度快

    /*
        序号	方法描述
1	public StringBuffer append(String s)
将指定的字符串追加到此字符序列。
2	public StringBuffer reverse()
 将此字符序列用其反转形式取代。
3	public delete(int start, int end)
移除此序列的子字符串中的字符。
4	public insert(int offset, int i)
将 int 参数的字符串表示形式插入此序列中。
5	replace(int start, int end, String str)
使用给定 String 中的字符替换此序列的子字符串中的字符。
     */

    /*
        序号	方法描述
1	int capacity()
返回当前容量。
2	char charAt(int index)
返回此序列中指定索引处的 char 值。
3	void ensureCapacity(int minimumCapacity)
确保容量至少等于指定的最小值。
4	void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)
将字符从此序列复制到目标字符数组 dst。
5	int indexOf(String str)
返回第一次出现的指定子字符串在该字符串中的索引。
6	int indexOf(String str, int fromIndex)
从指定的索引处开始，返回第一次出现的指定子字符串在该字符串中的索引。
7	int lastIndexOf(String str)
返回最右边出现的指定子字符串在此字符串中的索引。
8	int lastIndexOf(String str, int fromIndex)
返回 String 对象中子字符串最后出现的位置。
9	int length()
 返回长度（字符数）。
10	void setCharAt(int index, char ch)
将给定索引处的字符设置为 ch。
11	void setLength(int newLength)
设置字符序列的长度。
12	CharSequence subSequence(int start, int end)
返回一个新的字符序列，该字符序列是此序列的子序列。
13	String substring(int start)
返回一个新的 String，它包含此字符序列当前所包含的字符子序列。
14	String substring(int start, int end)
返回一个新的 String，它包含此序列当前所包含的字符子序列。
15	String toString()
返回此序列中数据的字符串表示形式。

     */
    public static void main(String[] args){
        StringBuffer sBuffer = new StringBuffer("oceaneyes.top");
        sBuffer.append("站点");
        System.out.println(sBuffer);
    }
}

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-Scanner类</title>
    <url>/2016/03/02/Java-Scanner%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java-Scanner类

```
import java.util.Scanner;

public class ScannerDemo {
    //Scanner类 获取用户的输入
    /*
        next() 与 nextLine() 区别
        next():
            1、一定要读取到有效字符后才可以结束输入。
            2、对输入有效字符之前遇到的空白，next() 方法会自动将其去掉。
            3、只有输入有效字符后才将其后面输入的空白作为分隔符或者结束符。
        next() 不能得到带有空格的字符串。
        nextLine()：
            1、以Enter为结束符,也就是说 nextLine()方法返回的是输入回车之前的所有字符。
            2、可以获得空白。
        如果要输入 int 或 float 类型的数据，在 Scanner 类中也有支持，但是在输入之前最好先使用 hasNextXxx() 方法进行验证，再使用 nextXxx() 来读取：
     */

    public void NextDemo() {
        //从键盘接收数据
        Scanner scan1 = new Scanner(System.in);

        //next方式接收字符串
        System.out.println("next方式接收：");
        //判断是否还有输入
        if (scan1.hasNext()) {
            String str1 = scan1.next();
            System.out.println("输入的数据为：" + str1);
        }
        scan1.close();

    }

    public void NextLineDemo() {
        //从键盘接收数据
        Scanner scan2 = new Scanner(System.in);

        //nextLine方式接收字符串
        System.out.println("nextLine方式接收：");
        //判断是否还有输入
        if (scan2.hasNext()) {
            String str2 = scan2.nextLine();
            System.out.println("输入的数据为：" + str2);
        }
        scan2.close();

    }

    public static void main(String[] args) {
        ScannerDemo s = new ScannerDemo();
//        s.NextDemo();
        s.NextLineDemo();

    }
}

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-NumberMath类</title>
    <url>/2016/03/02/Java-NumberMath%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java-NumberMath类

```
public class NumberAndMath {
    //（Integer、Long、Byte、Double、Float、Short）都是抽象类 Number 的子类
    // Math 包含了用于执行基本数学运算的属性和方法，如初等指数、对数、平方根和三角函数

    private static void test(double num) {
        System.out.println("Math.floor(" + num + ")=" + Math.floor(num));
        System.out.println("Math.round(" + num + ")=" + Math.round(num));
        System.out.println("Math.ceil(" + num + ")=" + Math.ceil(num));
    }

    public static void main(String[] args) {
        System.out.println("90度的正弦值" + Math.sin(Math.PI / 2));
        System.out.println("0度的余弦值" + Math.cos(0));
        System.out.println("60度的正切值" + Math.tan(Math.PI / 3));
        System.out.println("1的反正切值" + Math.atan(1));
        System.out.println("PI /2的角度值" + Math.toDegrees(Math.PI / 2));


        double[] nums = {1.4, 1.5, 1.6, -1.4, -1.5, -1.6};
        for (double num : nums) {
            test(num);
        }

/*
序号	    方法与描述
1	    xxxValue()
将 Number 对象转换为xxx数据类型的值并返回。
2	    compareTo()
将number对象与参数比较。
3	    equals()
判断number对象是否与参数相等。
4	    valueOf()
返回一个 Number 对象指定的内置数据类型
5	    toString()
以字符串形式返回值。
6	    parseInt()
将字符串解析为int类型。
7	    abs()
返回参数的绝对值。
8	    ceil()
返回大于等于( >= )给定参数的的最小整数，类型为双精度浮点型。
9	    floor()
返回小于等于（<=）给定参数的最大整数 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 。 rint() 返回与参数最接近的整数。返回类型为double。 round() 它表示四舍五入，算法为 math.floor(x+0.5)，即将原来的数字加上 0.5 后再向下取整，所以，math.round(11.5) 的结果为12，math.round(-11.5) 的结果为-11。 min() 返回两个参数中的最小值。 max() 返回两个参数中的最大值。 exp() 返回自然数底数e的参数次方。 log() 返回参数的自然数底数的对数值。 pow() 返回第一个参数的第二个参数次方。 sqrt() 求参数的算术平方根。 sin() 求指定double类型参数的正弦值。 cos() 求指定double类型参数的余弦值。 tan() 求指定double类型参数的正切值。 asin() 求指定double类型参数的反正弦值。 acos() 求指定double类型参数的反余弦值。 atan() 求指定double类型参数的反正切值。 atan2() 将笛卡尔坐标转换为极坐标，并返回极坐标的角度值。 todegrees() 将参数转化为角度。 toradians() 将角度转换为弧度。 random() 返回一个随机数。 * } ``` --- ### about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ - 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </=）给定参数的最大整数>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-SwitchCase语句</title>
    <url>/2016/03/02/Java-SwitchCase/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java-SwitchCase语句

```
public class SwitchCase {
    //switch case语句  判断一个变量与一系列值中某个值是否相等，每个值称为一个分支
    // switch case 执行时，一定会先进行匹配，匹配成功返回当前 case 的值，再根据是否有 break，判断是否继续输出，或是跳出判断。
    /*
        switch(expression){
            case value :
                //语句
                break; //可选
            case value :
                //语句
                break; //可选
            //你可以有任意数量的case语句
            default : //可选
                //语句   不需要break
        }
     */

    public static void main(String[]args){
        char grade ='C';
        switch (grade)
        {
            case 'A':
                System.out.println("优秀");
                break;
            case 'B':
            case 'C':
                System.out.println("良好");
                break;
            case 'D':
                System.out.println("及格");
                break;
            case 'F':
                System.out.println("你还需要继续努力");
                break;
            default:
                System.out.println("未知等级");
        }
        System.out.println("你的等级是" + grade);
    }
}

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基本数据类型</title>
    <url>/2016/03/02/Java%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java基本数据类型

```
public class DataType {
    /*
        内置数据类型
        引用数据类型
     */
    public static void main(String[] args) {
        // byte
        System.out.println("基本类型：byte 二进制位数：" + Byte.SIZE);
        System.out.println("包装类：java.lang.Byte");
        System.out.println("最小值：Byte.MIN_VALUE=" + Byte.MIN_VALUE);
        System.out.println("最大值：Byte.MAX_VALUE=" + Byte.MAX_VALUE);
        System.out.println();

        // short
        System.out.println("基本类型：short 二进制位数：" + Short.SIZE);
        System.out.println("包装类：java.lang.Short");
        System.out.println("最小值：Short.MIN_VALUE=" + Short.MIN_VALUE);
        System.out.println("最大值：Short.MAX_VALUE=" + Short.MAX_VALUE);
        System.out.println();

        // int
        System.out.println("基本类型：int 二进制位数：" + Integer.SIZE);
        System.out.println("包装类：java.lang.Integer");
        System.out.println("最小值：Integer.MIN_VALUE=" + Integer.MIN_VALUE);
        System.out.println("最大值：Integer.MAX_VALUE=" + Integer.MAX_VALUE);
        System.out.println();

        // long
        System.out.println("基本类型：long 二进制位数：" + Long.SIZE);
        System.out.println("包装类：java.lang.Long");
        System.out.println("最小值：Long.MIN_VALUE=" + Long.MIN_VALUE);
        System.out.println("最大值：Long.MAX_VALUE=" + Long.MAX_VALUE);
        System.out.println();

        // float
        System.out.println("基本类型：float 二进制位数：" + Float.SIZE);
        System.out.println("包装类：java.lang.Float");
        System.out.println("最小值：Float.MIN_VALUE=" + Float.MIN_VALUE);
        System.out.println("最大值：Float.MAX_VALUE=" + Float.MAX_VALUE);
        System.out.println();

        // double
        System.out.println("基本类型：double 二进制位数：" + Double.SIZE);
        System.out.println("包装类：java.lang.Double");
        System.out.println("最小值：Double.MIN_VALUE=" + Double.MIN_VALUE);
        System.out.println("最大值：Double.MAX_VALUE=" + Double.MAX_VALUE);
        System.out.println();

        // char
        System.out.println("基本类型：char 二进制位数：" + Character.SIZE);
        System.out.println("包装类：java.lang.Character");
        // 以数值形式而不是字符形式将Character.MIN_VALUE输出到控制台
        System.out.println("最小值：Character.MIN_VALUE="
                + (int) Character.MIN_VALUE);
        // 以数值形式而不是字符形式将Character.MAX_VALUE输出到控制台
        System.out.println("最大值：Character.MAX_VALUE="
                + (int) Character.MAX_VALUE);
    }
}

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-String类</title>
    <url>/2016/03/02/Java-String%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script># Java-String类

```
public class StringDemo {
    //String 方法
    /*
        SN(序号)	方法描述
1	char charAt(int index)
返回指定索引处的 char 值。
2	int compareTo(Object o)
把这个字符串和另一个对象比较。
3	int compareTo(String anotherString)
按字典顺序比较两个字符串。
4	int compareToIgnoreCase(String str)
按字典顺序比较两个字符串，不考虑大小写。
5	String concat(String str)
将指定字符串连接到此字符串的结尾。
6	boolean contentEquals(StringBuffer sb)
当且仅当字符串与指定的StringBuffer有相同顺序的字符时候返回真。
7	static String copyValueOf(char[] data)
返回指定数组中表示该字符序列的 String。
8	static String copyValueOf(char[] data, int offset, int count)
返回指定数组中表示该字符序列的 String。
9	boolean endsWith(String suffix)
测试此字符串是否以指定的后缀结束。
10	boolean equals(Object anObject)
将此字符串与指定的对象比较。
11	boolean equalsIgnoreCase(String anotherString)
将此 String 与另一个 String 比较，不考虑大小写。
12	byte[] getBytes()
 使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。
13	byte[] getBytes(String charsetName)
使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。
14	void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)
将字符从此字符串复制到目标字符数组。
15	int hashCode()
返回此字符串的哈希码。
16	int indexOf(int ch)
返回指定字符在此字符串中第一次出现处的索引。
17	int indexOf(int ch, int fromIndex)
返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。
18	int indexOf(String str)
 返回指定子字符串在此字符串中第一次出现处的索引。
19	int indexOf(String str, int fromIndex)
返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始。
20	String intern()
 返回字符串对象的规范化表示形式。
21	int lastIndexOf(int ch)
 返回指定字符在此字符串中最后一次出现处的索引。
22	int lastIndexOf(int ch, int fromIndex)
返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。
23	int lastIndexOf(String str)
返回指定子字符串在此字符串中最右边出现处的索引。
24	int lastIndexOf(String str, int fromIndex)
 返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索。
25	int length()
返回此字符串的长度。
26	boolean matches(String regex)
告知此字符串是否匹配给定的正则表达式。
27	boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len)
测试两个字符串区域是否相等。
28	boolean regionMatches(int toffset, String other, int ooffset, int len)
测试两个字符串区域是否相等。
29	String replace(char oldChar, char newChar)
返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。
30	String replaceAll(String regex, String replacement)
使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。
31	String replaceFirst(String regex, String replacement)
 使用给定的 replacement 替换此字符串匹配给定的正则表达式的第一个子字符串。
32	String[] split(String regex)
根据给定正则表达式的匹配拆分此字符串。
33	String[] split(String regex, int limit)
根据匹配给定的正则表达式来拆分此字符串。
34	boolean startsWith(String prefix)
测试此字符串是否以指定的前缀开始。
35	boolean startsWith(String prefix, int toffset)
测试此字符串从指定索引开始的子字符串是否以指定前缀开始。
36	CharSequence subSequence(int beginIndex, int endIndex)
 返回一个新的字符序列，它是此序列的一个子序列。
37	String substring(int beginIndex)
返回一个新的字符串，它是此字符串的一个子字符串。
38	String substring(int beginIndex, int endIndex)
返回一个新字符串，它是此字符串的一个子字符串。
39	char[] toCharArray()
将此字符串转换为一个新的字符数组。
40	String toLowerCase()
使用默认语言环境的规则将此 String 中的所有字符都转换为小写。
41	String toLowerCase(Locale locale)
 使用给定 Locale 的规则将此 String 中的所有字符都转换为小写。
42	String toString()
 返回此对象本身（它已经是一个字符串！）。
43	String toUpperCase()
使用默认语言环境的规则将此 String 中的所有字符都转换为大写。
44	String toUpperCase(Locale locale)
使用给定 Locale 的规则将此 String 中的所有字符都转换为大写。
45	String trim()
返回字符串的副本，忽略前导空白和尾部空白。
46	static String valueOf(primitive data type x)
返回给定data type类型x参数的字符串表示形式。

     */
    public static void main(String[] args) {
        char[] hello = {'g', 'z', 'y'};
        String helloString = new String(hello);
        System.out.println(helloString);
        System.out.println(helloString.length());
    }
}

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java对象和类</title>
    <url>/2016/03/02/Java%E5%AF%B9%E8%B1%A1%E5%92%8C%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java对象和类

```
public class ObjectAndClass {
    /*
    - 多态
    - 继承
    - 封装
    - 抽象
    - 类 ： 是一个模板，用来描述
    - 对象 ： 是类class的一个实例，具有状态和行为
    - 实例
    - 方法
    - 重载
     */

    //定义一个Dog类
    public static class Dog {
        //成员变量
        StringDemo color;
        int age;
        StringDemo name;

        //类方法
        void barking(){
            System.out.println("汪！汪！汪！");
        }

        void hungry(){
            System.out.println("好饿哦！");
        }

        void sleeping(){
            System.out.println("好困哦！");
        }

        void setAge(int age){
            this.age = age;
        }
    }

    public static void main(String[]args) {
        /*
            创建对象
            声明： 声明一个对象， 对象类型 和对象名称
            实例化： new创建
            初始化： 创建时调用构造方法生成
         */
        Dog dog = new Dog();
        dog.hungry();
        dog.barking();
        dog.sleeping();
        System.out.println(dog.age);
        dog.setAge(24);
        System.out.println(dog.age);

    }
}


```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java异常处理</title>
    <url>/2016/03/02/Java%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java异常处理

```
import java.lang.Exception;

public class ExceptionDemo {
    /*
        三类异常
        - 检查性异常：最具代表的检查性异常是用户错误或问题引起的异常，这是程序员无法预见的。例如要打开一个不存在文件时，一个异常就发生了，这些异常在编译时不能被简单地忽略。
        - 运行时异常： 运行时异常是可能被程序员避免的异常。与检查性异常相反，运行时异常可以在编译时被忽略。
        - 错误： 错误不是异常，而是脱离程序员控制的问题。错误在代码中通常被忽略。例如，当栈溢出时，一个错误就发生了，它们在编译也检查不到的。
     */

    /*
       内置异常类
          非检查性异常
            异常	                            描述
            ArithmeticException	            当出现异常的运算条件时，抛出此异常。例如，一个整数"除以零"时，抛出此类的一个实例。
            ArrayIndexOutOfBoundsException	用非法索引访问数组时抛出的异常。如果索引为负或大于等于数组大小，则该索引为非法索引。
            ArrayStoreException	            试图将错误类型的对象存储到一个对象数组时抛出的异常。
            ClassCastException	            当试图将对象强制转换为不是实例的子类时，抛出该异常。
            IllegalArgumentException	    抛出的异常表明向方法传递了一个不合法或不正确的参数。
            IllegalMonitorStateException	抛出的异常表明某一线程已经试图等待对象的监视器，或者试图通知其他正在等待对象的监视器而本身没有指定监视器的线程。
            IllegalStateException	        在非法或不适当的时间调用方法时产生的信号。换句话说，即 Java 环境或 Java 应用程序没有处于请求操作所要求的适当状态下。
            IllegalThreadStateException	    线程没有处于请求操作所要求的适当状态时抛出的异常。
            IndexOutOfBoundsException	    指示某排序索引（例如对数组、字符串或向量的排序）超出范围时抛出。
            NegativeArraySizeException	    如果应用程序试图创建大小为负的数组，则抛出该异常。
            NullPointerException	        当应用程序试图在需要对象的地方使用 null 时，抛出该异常
            NumberFormatException	        当应用程序试图将字符串转换成一种数值类型，但该字符串不能转换为适当格式时，抛出该异常。
            SecurityException	            由安全管理器抛出的异常，指示存在安全侵犯。
            StringIndexOutOfBoundsException	此异常由 String 方法抛出，指示索引或者为负，或者超出字符串的大小。
            UnsupportedOperationException	当不支持请求的操作时，抛出该异常。

         检查性异常类
            异常	                            描述
            ClassNotFoundException	        应用程序试图加载类时，找不到相应的类，抛出该异常。
            CloneNotSupportedException	    当调用 Object 类中的 clone 方法克隆对象，但该对象的类无法实现 Cloneable 接口时，抛出该异常。
            IllegalAccessException	        拒绝访问一个类的时候，抛出该异常。
            InstantiationException	        当试图使用 Class 类中的 newInstance 方法创建一个类的实例，而指定的类对象因为是一个接口或是一个抽象类而无法实例化时，抛出该异常。
            InterruptedException	        一个线程被另一个线程中断，抛出该异常。
            NoSuchFieldException	        请求的变量不存在
            NoSuchMethodException	        请求的方法不存在
     */
    /*
        throws/throw 关键字

        finally 关键字
          finally 关键字用来创建在 try 代码块后面执行的代码块。
          无论是否发生异常，finally 代码块中的代码总会被执行。
          在 finally 代码块中，可以运行清理类型等收尾善后性质的语句
            try{
                // 程序代码
            }catch(异常类型1 异常的变量名1){
                // 程序代码
            }catch(异常类型2 异常的变量名2){
                // 程序代码
            }finally{
                // 程序代码
            }

     */

    public void getExceptiondemo(){
        //捕获异常
        /*
                try
                {
                    // 程序代码
                }catch(ExceptionName e1)
                {
                    //Catch 块
                }
         */

        // 多重捕获异常
        /*
                try{
                    // 程序代码
                }catch(异常类型1 异常的变量名1){
                    // 程序代码
                }catch(异常类型2 异常的变量名2){
                    // 程序代码
                }catch(异常类型2 异常的变量名2){
                    // 程序代码
                }
         */
        try {
            int[] a = new int[2];
            System.out.println(a[3]);
        }catch (ArrayIndexOutOfBoundsException e){
            System.out.println("Exception thrown" +e);
        }
        System.out.println("out of the block");
    }



    public static void main(String[] args){
        ExceptionDemo exp = new ExceptionDemo();
        exp.getExceptiondemo();
    }
}

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java循环结构</title>
    <url>/2016/03/02/Java%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java循环结构

```
public class LoopStructure {
    /*
        while 循环
        do…while 循环
        for 循环
     */

    public static void main(String[] args) {
        //while循环 ，布尔表达式为true 就会一直执行下去， 不满足条件则无法进入循环
        System.out.println("while 循环");
        int x = 10;
        while (x < 20) {
            System.out.println(x);
            x++;
        }

        // do…while 循环，至少执行一次
        /*
            do {
                //代码语句
            }while(布尔表达式);
         */
        System.out.println("do…while循环");
        int y = 10;
        do {
            System.out.println(y);
            y++;
        } while (y < 10);


        // for 循环，执行前就确定执行次数
        /*
            for(初始化; 布尔表达式; 更新) {
                //代码语句
            }
         */
        System.out.println("for 循环");
        for (int z = 0; z < 20; z = z + 1) {
            System.out.println(z);
        }


        //增强for循环
        /*
            for(声明语句 : 表达式)
            {
                //代码句子
            }
         */
        System.out.println("增强for 循环");
        int[] numbers = {10, 20, 30, 40, 50};
        for (int number : numbers) {
            System.out.println(number);
        }

        String[] names = {"gzy", "g", "zy"};
        for (String name : names) {
            System.out.println(name);
        }


        //break关键字
        /*
            break 主要用在循环语句或者 switch 语句中，用来跳出整个语句块。
            break 跳出最里层的循环，并且继续执行该循环下面的语句。
         */
        System.out.println("break关键字");
        int[] numbers1 = {10, 20, 30, 40, 50};
        for (int number : numbers1) {
            if (number == 30) {
                break;
            }
            System.out.println(number);

        }


        //continue关键字
        /*
            continue 适用于任何循环控制结构中。作用是让程序立刻跳转到下一次循环的迭代。
            在 for 循环中，continue 语句使程序立即跳转到更新语句。
            在 while 或者 do…while 循环中，程序立即跳转到布尔表达式的判断语句。
         */
        System.out.println("continue关键字");
        int[] numbers2 = {10, 20, 30, 40, 50};
        for (int number : numbers2) {
            if (number == 30) {
                continue;
            }
            System.out.println(number);

        }

    }
}

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java数组</title>
    <url>/2016/03/02/Java%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java数组

```
public class ArrayDemo {
    //声明数组
    // 数据类型[] 数组名称;  dataType[] arrayName;

    //创建数组
    // 数据名称 = new dataType[arraySize];

    //dataType[] arrayName = {value0,value1,value2,...,valuek};
    public static void main(String[] args){
        //数组大小
        int size =4;
        //定义数组
        double[] TestList = new double[size];
        TestList[0] = 3.2;
        TestList[1] = 2.6;
        TestList[2] = 4.7;
        TestList[3] = 5.6;

        double total =0;
        for (int i=0; i<size; i++){ total="total" + testlist[i]; } system.out.println(total); double[] list1="{1.4,2.8,3.6,4.9};" 打印所有数组元素 for (int i="0;i<list1.length;i++){" system.out.println(list1[i]); 计算所有元素的和 double sum="0;" list1[i]; system.out.println(sum); 查找最大元素 max="list1[0];" i<list1.length;i++){ if (list1[i]> max){
                max = list1[i];
            }
        }
        System.out.println(max);
    }
}

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </size;>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java日期和时间</title>
    <url>/2016/03/02/Java%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java日期和时间

```
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.*;

public class DateTimeDemo {
    //日期时间
    public static void main(String[] args){
        //获取当前时间
        Date date = new Date();
        System.out.println(date.toString());


        //格式化日期
        /*
            日期和时间的格式化编码
时间模式字符串用来指定时间格式。在此模式中，所有的 ASCII 字母被保留为模式字母，定义如下：

字母	描述	示例
G	纪元标记	AD
y	四位年份	2001
M	月份	July or 07
d	一个月的日期	10
h	 A.M./P.M. (1~12)格式小时	12
H	一天中的小时 (0~23)	22
m	分钟数	30
s	秒数	55
S	毫秒数	234
E	星期几	Tuesday
D	一年中的日子	360
F	一个月中第几周的周几	2 (second Wed. in July)
w	一年中第几周	40
W	一个月中第几周	1
a	A.M./P.M. 标记	PM
k	一天中的小时(1~24)	24
K	 A.M./P.M. (0~11)格式小时	10
z	时区	Eastern Standard Time
'	文字定界符	Delimiter
"	单引号	`
         */
        SimpleDateFormat ft = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");
        System.out.println("SimpleDateFormat时间格式转换");
        System.out.println(ft.format(date));


        //printf格式化时间  以%t 开头
        /*
            转  换  符             说    明              示    例
                c           包括全部日期和时间信息         星期六 十月 27 14:21:20 CST 2007
                F           "年-月-日"格式               2007-10-27
                D           "月/日/年"格式               10/27/07
                r           "HH:MM:SS PM"格式（12时制）   02:25:51 下午
                T           "HH:MM:SS"格式（24时制）   14:28:16
                R           "HH:MM"格式（24时制）         14:28
         */
        System.out.println("printf时间格式转换");
        System.out.printf("全部日期和时间信息：%tc%n",date);
        System.out.printf("年-月-日格式：%tF%n",date);
        System.out.printf("月/日/年格式：%tD%n",date);
        System.out.printf("HH:MM:SS PM(12小时)：%tr%n",date);
        System.out.printf("HH:MM:SS (24小时)：%tT%n",date);
        System.out.printf("HH:MM (24小时)：%tR%n",date);


        //定义日期转换字符，抽取转换为新字符串
        System.out.println("使日期转换生成新字符串");
        //b的使用，月份简称
        String str=String.format(Locale.US,"英文月份简称：%tb",date);
        System.out.println(str);
        System.out.printf("本地月份简称：%tb%n",date);
        //B的使用，月份全称
        str=String.format(Locale.US,"英文月份全称：%tB",date);
        System.out.println(str);
        System.out.printf("本地月份全称：%tB%n",date);
        //a的使用，星期简称
        str=String.format(Locale.US,"英文星期的简称：%ta",date);
        System.out.println(str);
        //A的使用，星期全称
        System.out.printf("本地星期的简称：%tA%n",date);
        //C的使用，年前两位
        System.out.printf("年的前两位数字（不足两位前面补0）：%tC%n",date);
        //y的使用，年后两位
        System.out.printf("年的后两位数字（不足两位前面补0）：%ty%n",date);
        //j的使用，一年的天数
        System.out.printf("一年中的天数（即年的第几天）：%tj%n",date);
        //m的使用，月份
        System.out.printf("两位数字的月份（不足两位前面补0）：%tm%n",date);
        //d的使用，日（二位，不够补零）
        System.out.printf("两位数字的日（不足两位前面补0）：%td%n",date);
        //e的使用，日（一位不补零）
        System.out.printf("月份的日（前面不补0）：%te",date);

        //Calendar 对象
        /*
            常量	                    描述
            Calendar.YEAR	        年份
            Calendar.MONTH	        月份
            Calendar.DATE	        日期
            Calendar.DAY_OF_MONTH	日期，和上面的字段意义完全相同
            Calendar.HOUR	        12小时制的小时
            Calendar.HOUR_OF_DAY	24小时制的小时
            Calendar.MINUTE	        分钟
            Calendar.SECOND	        秒
            Calendar.DAY_OF_WEEK	星期几

         */
        //GregorianCalendar类
        /*
            序号	构造函数和说明
1	GregorianCalendar()
在具有默认语言环境的默认时区内使用当前时间构造一个默认的 GregorianCalendar。
2	GregorianCalendar(int year, int month, int date)
在具有默认语言环境的默认时区内构造一个带有给定日期设置的 GregorianCalendar
3	GregorianCalendar(int year, int month, int date, int hour, int minute)
为具有默认语言环境的默认时区构造一个具有给定日期和时间设置的 GregorianCalendar。
4	GregorianCalendar(int year, int month, int date, int hour, int minute, int second)
  为具有默认语言环境的默认时区构造一个具有给定日期和时间设置的 GregorianCalendar。
5	GregorianCalendar(Locale aLocale)
在具有给定语言环境的默认时区内构造一个基于当前时间的 GregorianCalendar。
6	GregorianCalendar(TimeZone zone)
在具有默认语言环境的给定时区内构造一个基于当前时间的 GregorianCalendar。
7	GregorianCalendar(TimeZone zone, Locale aLocale)
 在具有给定语言环境的给定时区内构造一个基于当前时间的 GregorianCalendar。
这里是GregorianCalendar 类提供的一些有用的方法列表：

序号	方法和说明
1	void add(int field, int amount)
根据日历规则，将指定的（有符号的）时间量添加到给定的日历字段中。
2	protected void computeFields()
转换UTC毫秒值为时间域值
3	protected void computeTime()
覆盖Calendar ，转换时间域值为UTC毫秒值
4	boolean equals(Object obj)
比较此 GregorianCalendar 与指定的 Object。
5	int get(int field)
获取指定字段的时间值
6	int getActualMaximum(int field)
返回当前日期，给定字段的最大值
7	int getActualMinimum(int field)
返回当前日期，给定字段的最小值
8	int getGreatestMinimum(int field)
 返回此 GregorianCalendar 实例给定日历字段的最高的最小值。
9	Date getGregorianChange()
获得格里高利历的更改日期。
10	int getLeastMaximum(int field)
返回此 GregorianCalendar 实例给定日历字段的最低的最大值
11	int getMaximum(int field)
返回此 GregorianCalendar 实例的给定日历字段的最大值。
12	Date getTime()
获取日历当前时间。
13	long getTimeInMillis()
获取用长整型表示的日历的当前时间
14	TimeZone getTimeZone()
获取时区。
15	int getMinimum(int field)
返回给定字段的最小值。
16	int hashCode()
重写hashCode.
17	boolean isLeapYear(int year)
确定给定的年份是否为闰年。
18	void roll(int field, boolean up)
在给定的时间字段上添加或减去（上/下）单个时间单元，不更改更大的字段。
19	void set(int field, int value)
用给定的值设置时间字段。
20	void set(int year, int month, int date)
设置年、月、日的值。
21	void set(int year, int month, int date, int hour, int minute)
设置年、月、日、小时、分钟的值。
22	void set(int year, int month, int date, int hour, int minute, int second)
设置年、月、日、小时、分钟、秒的值。
23	void setGregorianChange(Date date)
设置 GregorianCalendar 的更改日期。
24	void setTime(Date date)
用给定的日期设置Calendar的当前时间。
25	void setTimeInMillis(long millis)
用给定的long型毫秒数设置Calendar的当前时间。
26	void setTimeZone(TimeZone value)
用给定时区值设置当前时区。
27	String toString()
返回代表日历的字符串。
         */
        String months[] = {
                "Jan", "Feb", "Mar", "Apr",
                "May", "Jun", "Jul", "Aug",
                "Sep", "Oct", "Nov", "Dec"};

        int year;
        // 初始化 Gregorian 日历
        // 使用当前时间和日期
        // 默认为本地时间和时区
        GregorianCalendar gcalendar = new GregorianCalendar();
        // 显示当前时间和日期的信息
        System.out.print("Date: ");
        System.out.print(months[gcalendar.get(Calendar.MONTH)]);
        System.out.print(" " + gcalendar.get(Calendar.DATE) + " ");
        System.out.println(year = gcalendar.get(Calendar.YEAR));
        System.out.print("Time: ");
        System.out.print(gcalendar.get(Calendar.HOUR) + ":");
        System.out.print(gcalendar.get(Calendar.MINUTE) + ":");
        System.out.println(gcalendar.get(Calendar.SECOND));

        // 测试当前年份是否为闰年
        if(gcalendar.isLeapYear(year)) {
            System.out.println("当前年份是闰年");
        }
        else {
            System.out.println("当前年份不是闰年");
        }

    }
}

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java条件语句</title>
    <url>/2016/03/02/Java%E6%9D%A1%E4%BB%B6%E8%AF%AD%E5%8F%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java条件语句

```
public class IfElse {
    /*
        条件语句 - if...else
     */
    public static void main(String[] args) {
        int x = 10;
        /*
            if(布尔表达式){
                //如果布尔表达式的值为true
            }else{
                //如果布尔表达式的值为false
            }
         */
        if (x < 20) {
            System.out.println("这是一个if判断语句");
        } else {
            System.out.println("这是一个else判断语句");
        }

        /*
            if(布尔表达式 1){
                //如果布尔表达式 1的值为true执行代码
            }else if(布尔表达式 2){
                //如果布尔表达式 2的值为true执行代码
            }else if(布尔表达式 3){
                //如果布尔表达式 3的值为true执行代码
            }else if(布尔表达式 4){
                //如果布尔表达式 4的值为true执行代码
            }else if(布尔表达式 5){
                //如果布尔表达式 5的值为true执行代码
            }
            else {
                //如果以上布尔表达式都不为true执行代码
            }

         */


        //嵌套的if...else语句
        /*
            if(布尔表达式 1){
                ////如果布尔表达式 1的值为true执行代码
                if(布尔表达式 2){
                    ////如果布尔表达式 2的值为true执行代码
                }
            }
         */
    }
}

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java正则表达式</title>
    <url>/2016/03/02/Java%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java正则表达式

```
import java.util.regex.*;
public class RegularExpressionDemo {
    /*
        Pattern 类：
        pattern 对象是一个正则表达式的编译表示。
        Pattern 类没有公共构造方法。要创建一个 Pattern 对象，你必须首先调用其公共静态编译方法，它返回一个 Pattern 对象。
        该方法接受一个正则表达式作为它的第一个参数。

        Matcher 类：
        Matcher 对象是对输入字符串进行解释和匹配操作的引擎。
        与Pattern 类一样，Matcher 也没有公共构造方法。
        需要调用 Pattern 对象的 matcher 方法来获得一个 Matcher 对象。

        PatternSyntaxException：
        PatternSyntaxException 是一个非强制异常类，它表示一个正则表达式模式中的语法错误。
     */
    /*
        正则表达式语法
        字符          说明
        \             将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，"n"匹配字符"n"。"\n"匹配换行符。序列"\\\\"匹配"\\"，"\\("匹配"("。
        ^             匹配输入字符串开始的位置。如果设置了 RegExp 对象的 Multiline 属性，^ 还会与"\n"或"\r"之后的位置匹配。
        $             匹配输入字符串结尾的位置。如果设置了 RegExp 对象的 Multiline 属性，$ 还会与"\n"或"\r"之前的位置匹配。
        *             零次或多次匹配前面的字符或子表达式。例如，zo* 匹配"z"和"zoo"。* 等效于 {0,}。
        +             一次或多次匹配前面的字符或子表达式。例如，"zo+"与"zo"和"zoo"匹配，但与"z"不匹配。+ 等效于 {1,}。
        ?             零次或一次匹配前面的字符或子表达式。例如，"do(es)?"匹配"do"或"does"中的"do"。? 等效于 {0,1}。
        {n}           n 是非负整数。正好匹配 n 次。例如，"o{2}"与"Bob"中的"o"不匹配，但与"food"中的两个"o"匹配。
        {n,}          n 是非负整数。至少匹配 n 次。例如，"o{2,}"不匹配"Bob"中的"o"，而匹配"foooood"中的所有 o。"o{1,}"等效于"o+"。"o{0,}"等效于"o*"。
        {n,m}         m 和 n 是非负整数，其中 n <= m。匹配至少 n 次，至多 m 次。例如，"o{1,3}"匹配"fooooood"中的头三个 o。'o{0,1}' 等效于 'o?'。注意：您不能将空格插入逗号和数字之间。 ? 当此字符紧随任何其他限定符（*、+、?、{n}、{n,}、{n,m}）之后时，匹配模式是"非贪心的"。"非贪心的"模式匹配搜索到的、尽可能短的字符串，而默认的"贪心的"模式匹配搜索到的、尽可能长的字符串。例如，在字符串"oooo"中，"o+?"只匹配单个"o"，而"o+"匹配所有"o"。 . 匹配除"\r\n"之外的任何单个字符。若要匹配包括"\r\n"在内的任意字符，请使用诸如"[\s\s]"之类的模式。 (pattern) 匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果"匹配"集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用"\("或者"\)"。 (?:pattern) 但不捕获该匹配的子表达式，即它是一个非捕获匹配，不存储供以后使用的匹配。这对于用"or"字符 (|) 组合模式部件的情况很有用。例如，'industr(?:y|ies) 是比 'industry|industries' 更经济的表达式。 (?="pattern)" 执行正向预测先行搜索的子表达式，该表达式匹配处于匹配 的字符串的起始点的字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'windows 匹配"windows 2000"中的"windows"，但不匹配"windows 3.1"中的"windows"。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。 (?!pattern) 执行反向预测先行搜索的子表达式，该表达式匹配不处于匹配 的字符串的起始点的搜索字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'windows (?!95|98|nt|2000)' 3.1"中的 "windows"，但不匹配"windows 2000"中的"windows"。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。 x|y x 或 y。例如，'z|food' 匹配"z"或"food"。'(z|f)ood' 匹配"zood"或"food"。 [xyz] 字符集。匹配包含的任一字符。例如，"[abc]"匹配"plain"中的"a"。 [^xyz] 反向字符集。匹配未包含的任何字符。例如，"[^abc]"匹配"plain"中"p"，"l"，"i"，"n"。 [a-z] 字符范围。匹配指定范围内的任何字符。例如，"[a-z]"匹配"a"到"z"范围内的任何小写字母。 [^a-z] 反向范围字符。匹配不在指定的范围内的任何字符。例如，"[^a-z]"匹配任何不在"a"到"z"范围内的任何字符。 \b 匹配一个字边界，即字与空格间的位置。例如，"er\b"匹配"never"中的"er"，但不匹配"verb"中的"er"。 非字边界匹配。"er\b"匹配"verb"中的"er"，但不匹配"never"中的"er"。 \cx 指示的控制字符。例如，\cm control-m 或回车符。x 的值必须在 a-z 之间。如果不是这样，则假定 c 就是"c"字符本身。 \d 数字字符匹配。等效于 [0-9]。 非数字字符匹配。等效于 [^0-9]。 \f 换页符匹配。等效于 \x0c 和 \cl。 \n 换行符匹配。等效于 \x0a \cj。 \r 匹配一个回车符。等效于 \x0d \cm。 \s 匹配任何空白字符，包括空格、制表符、换页符等。与 [ \f\n\r\t\v] 等效。 匹配任何非空白字符。与 [^ \t 制表符匹配。与 \x09 \ci \v 垂直制表符匹配。与 \x0b \ck \w 匹配任何字类字符，包括下划线。与"[a-za-z0-9_]"等效。 与任何非单词字符匹配。与"[^a-za-z0-9_]"等效。 \xn n，此处的 是一个十六进制转义码。十六进制转义码必须正好是两位数长。例如，"\x41"匹配"a"。"\x041"与"\x04"&"1"等效。允许在正则表达式中使用 ascii 代码。 \num num，此处的 num 是一个正整数。到捕获匹配的反向引用。例如，"(.)\1"匹配两个连续的相同字符。 标识一个八进制转义码或反向引用。如果 前面至少有 个捕获子表达式，那么 是反向引用。否则，如果 是八进制数 (0-7)，那么 是八进制转义码。 \nm nm 是反向引用。如果 个捕获，则 是反向引用，后面跟有字符 m。如果两种前面的情况都不存在，则 匹配八进制值 nm，其中 是八进制数字 (0-7)。 \nml 当 (0-3)，m l (0-7) 时，匹配八进制转义码 nml。 * } ``` --- ### about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ - 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </=>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java运算符</title>
    <url>/2016/03/02/Java%E8%BF%90%E7%AE%97%E7%AC%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Java运算符

```
public class Operator {
    /*
        运算符
        - 算术运算符
        - 关系运算符
        - 位运算符
        - 逻辑运算符
        - 赋值运算符
        - 其他运算符
     */
    public static void main(String[] args) {
        int a = 10;
        int b = 20;
        int c = 25;
        int d = 25;

        //算数运算符
        //前缀自增自减法(++a,--a): 先进行自增或者自减运算，再进行表达式运算。
        //后缀自增自减法(a++,a--): 先进行表达式运算，再进行自增或者自减运算
        System.out.println("a + b = " + (a + b));
        System.out.println("a - b = " + (a - b));
        System.out.println("a * b = " + (a * b));
        System.out.println("b / a = " + (b / a));
        System.out.println("b % a = " + (b % a));
        System.out.println("c % a = " + (c % a));
        System.out.println("a++   = " + (a++));
        System.out.println("a--   = " + (a--));
        // 查看  d++ 与 ++d 的不同
        System.out.println("d++   = " + (d++));
        System.out.println("++d   = " + (++d));


        //关系运算符
        System.out.println("a == b = " + (a == b));
        System.out.println("a != b = " + (a != b));
        System.out.println("a > b = " + (a > b));
        System.out.println("a < b = " + (a < b));
        System.out.println("b >= a = " + (b >= a));
        System.out.println("b <= 20 a=" + (b <= a));


        //位运算符
        /*
            操作符	描述	                                                例子
            &	    如果相对应位都是1，则结果为1，否则为0	                    （A＆B），得到12，即0000 1100
            /	    如果相对应位都是 0，则结果为 0，否则为 1	                （A | B）得到61，即 0011 1101
            ^	    如果相对应位值相同，则结果为0，否则为1	                    （A ^ B）得到49，即 0011 0001
            〜	    按位取反运算符翻转操作数的每一位，即0变成1，1变成0。	    （〜A）得到-61，即1100 0011
            <<  	按位左移运算符。左操作数按位左移右操作数指定的位数。	      A << 2得到240，即 1111 0000
            >> 	    按位右移运算符。左操作数按位右移右操作数指定的位数。	      A >> 2得到15即 1111
            >>> 	按位右移补零操作符。左操作数的值按右操作数指定的位数右移，移动得到的空位以零填充。	A>>>2得到15即0000 1111
         */


        //逻辑运算符
        /*
            操作符	       描述	                                                    例子
            &&	        称为逻辑与运算符。当且仅当两个操作数都为真，条件才为真。	    （A && B）为假。
            //	        称为逻辑或操作符。如果任何两个操作数任何一个为真，条件为真。	（A | | B）为真。
            !	        称为逻辑非运算符。用来反转操作数的逻辑状态。如果条件为true，
                        则逻辑非运算符将得到false。	                                !(A && B)为真。
         */


        //赋值运算符
        /*
            操作符	                描述	                                                例子
               =	           简单的赋值运算符，将右操作数的值赋给左侧操作数	                C = A + B将把A + B得到的值赋给C
               + =	           加和赋值操作符，它把左操作数和右操作数相加赋值给左操作数	        C + = A等价于C = C + A
               - =	           减和赋值操作符，它把左操作数和右操作数相减赋值给左操作数	        C - = A等价于C = C - A
               * =	           乘和赋值操作符，它把左操作数和右操作数相乘赋值给左操作数	        C * = A等价于C = C * A
               / =	           除和赋值操作符，它把左操作数和右操作数相除赋值给左操作数	        C / = A，C 与 A 同类型时等价于 C = C / A
               (%)=	           取模和赋值操作符，它把左操作数和右操作数取模后赋值给左操作数	    C％= A等价于C = C％A
               << =	           左移位赋值运算符	C << = 2等价于C = C << 2
               >> =	           右移位赋值运算符	C >> = 2等价于C = C >> 2
               &=	           按位与赋值运算符	C＆= 2等价于C = C＆2
               ^ =	           按位异或赋值操作符	C ^ = 2等价于C = C ^ 2
               | =	           按位或赋值操作符	C | = 2等价于C = C | 2
         */


        //条件运算符
        /*
            三元运算符。该运算符有3个操作数，并且需要判断布尔表达式的值
            variable x = (expression) ? value if true : value if false
         */
        int x, y;
        x = 10;
        y = (x == 5) ? 20 : 30;
        System.out.println(" value of y is " + y); =="10)" ? : 30; system.out.println("value 运算符优先级 * 类别 操作符 关联性 后缀 () [] . (点操作符) 左到右 一元 - !〜 从右到左 乘性 % 加性 移位>> >>>  << 	                    左到右
            关系 	    >> = << = 	                    左到右
            相等 	    ==  !=	                        左到右
            按位与	    &	                            左到右
            按位异或    	^	                            左到右
            按位或	    /	                            左到右
            逻辑与	    &&	                            左到右
            逻辑或	    //                              左到右
            条件	    ？：	                        从右到左
            赋值	    = + = - = * = / =％= >> = << =＆= ^ = | =	从右到左
            逗号	    ，	                            左到右
         */

    }
}

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </=>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown基本语法</title>
    <url>/2016/01/01/Markdown%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Markdown基本语法

# 一、标题

一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。

注：标准语法一般在#后跟个空格再写文字

```bash
# 这是一级标题
## 这是二级标题
### 这是三级标题
#### 这是四级标题
##### 这是五级标题
###### 这是六级标题
```

效果如下：

# 这是一级标题

## 这是二级标题

### 这是三级标题

#### 这是四级标题

##### 这是五级标题

###### 这是六级标题

------

# 二、字体

- ##### 加粗

要加粗的文字左右分别用两个*号包起来

- ##### 斜体

要倾斜的文字左右分别用一个*号包起来

- ##### 斜体加粗

要倾斜和加粗的文字左右分别用三个*号包起来

- ##### 删除线

要加删除线的文字左右分别用两个~~号包起来

示例：

```undefined
**这是加粗的文字**
*这是倾斜的文字*`
***这是斜体加粗的文字***
~~这是加删除线的文字~~
```

效果如下：

**这是加粗的文字**
 *这是倾斜的文字*
 ***这是斜体加粗的文字\***
 ~~这是加删除线的文字~~

------

# 三、引用

在引用的文字前加>即可。引用也可以嵌套，如加两个>>三个>>>
 n个...
 貌似可以一直加下去，但没神马卵用

示例：

```ruby
>这是引用的内容
>>这是引用的内容
>>>>>>>>>>这是引用的内容
```

效果如下：

> 这是引用的内容
>
> > 这是引用的内容
> >
> > > > > > > > > > 这是引用的内容

# 四、分割线

三个或者三个以上的 - 或者 * 都可以。

示例：

```undefined
---
----
***
*****
```

效果如下：
 可以看到，显示效果是一样的。

------

------

------

------

# 五、图片

语法：

```bash
![图片alt](图片地址 ''图片title'')

图片alt就是显示在图片下面的文字，相当于对图片内容的解释。
图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加
```

示例：

![]("图片地址")

**上传本地图片直接点击导航栏的图片标志，选择图片即可**

# 六、超链接

语法：

```csharp
[超链接名](超链接地址 "超链接title")
title可加可不加
```

示例：

```csharp
[简书](http://jianshu.com)
[百度](http://baidu.com)
```

效果如下：

[简书](https://www.jianshu.com/u/1f5ac0cf6a8b)
 [百度](http://baidu.com)

注：Markdown本身语法不支持链接在新页面中打开，貌似简书做了处理，是可以的。别的平台可能就不行了，如果想要在新页面中打开的话可以用html语言的a标签代替。

示例：

```xml
<a href="超链接地址" target="_blank">超链接名</a>
```

<a href="https://www.jianshu.com/u/1f5ac0cf6a8b" target="_blank">简书</a>

------

# 七、列表

- ##### 无序列表

语法：
 无序列表用 - + * 任何一种都可以

```undefined
- 列表内容
+ 列表内容
* 列表内容
注意：- + * 跟内容之间都要有一个空格
```

效果如下：

- 列表内容

- 列表内容

- 列表内容

- ##### 有序列表

语法：
 数字加点

```undefined
1. 列表内容
2. 列表内容
3. 列表内容

注意：序号跟内容之间要有空格
```

效果如下：

1. 列表内容
2. 列表内容
3. 列表内容

- ##### 列表嵌套

**上一级和下一级之间敲三个空格即可**

- 一级无序列表内容
  - 二级无序列表内容
  - 二级无序列表内容
  - 二级无序列表内容
- 一级无序列表内容
  1. 二级有序列表内容
  2. 二级有序列表内容
  3. 二级有序列表内容

1. 一级有序列表内容
   - 二级无序列表内容
   - 二级无序列表内容
   - 二级无序列表内容
2. 一级有序列表内容
   1. 二级有序列表内容
   2. 二级有序列表内容
   3. 二级有序列表内容

------

# 八、表格

语法：

```ruby
表头|表头|表头
---|:--:|---:
内容|内容|内容
内容|内容|内容

第二行分割表头和内容。
- 有一个就行，为了对齐，多加了几个
文字默认居左
-两边加：表示文字居中
-右边加：表示文字居右
注：原生的语法两边都要用 | 包起来。此处省略
```

示例：

```ruby
姓名|技能|排行
--|:--:|--:
刘备|哭|大哥
关羽|打|二哥
张飞|骂|三弟
```

效果如下：

| 姓名 | 技能 | 排行 |
| ---- | :--: | ---: |
| 刘备 |  哭  | 大哥 |
| 关羽 |  打  | 二哥 |
| 张飞 |  骂  | 三弟 |

# 九、代码

语法：
 单行代码：代码之间分别用一个反引号包起来

```go
    `代码内容`
```

代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行

```go
(```)
  代码...
  代码...
  代码...
(```)
```

> 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。

示例：

单行代码

```go
`create database hero;`
```

代码块

```kotlin
(```)
    function fun(){
         echo "这是一句非常牛逼的代码";
    }
    fun();
(```)
```

效果如下：

单行代码

```
create database hero;
```

代码块

```kotlin
function fun(){
  echo "这是一句非常牛逼的代码";
}
fun();
```

# 十、流程图

~~~php
```flow
st=>start: 开始
op=>operation: My Operation
cond=>condition: Yes or No?
e=>end
st->op->cond
cond(yes)->e
cond(no)->op
&```
~~~

```flow
st=>start: 开始
op=>operation: My Operation
cond=>condition: Yes or No?
e=>end
st->op->cond
cond(yes)->e
cond(no)->op
&```
```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Markdownd</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown数学公式语法</title>
    <url>/2016/01/01/Markdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# Markdown数学公式语法

## 行内与独行

1. 行内公式：将公式插入到本行内，符号：`$公式内容$`，如：$xyz$
2. 独行公式：将公式插入到新的一行内，并且居中，符号：`$$公式内容$$`，如：$$xyz$$

## 上标、下标与组合

1. 上标符号，符号：`^`，如：$x^4$
2. 下标符号，符号：`_`，如：$x_1$
3. 组合符号，符号：`{}`，如：${16}_{8}O{2+}_{2}$

## 汉字、字体与格式

1. 汉字形式，符号：`\mbox{}`，如：$V_{\mbox{初始}}$
2. 字体控制，符号：`\displaystyle`，如：$\displaystyle \frac{x+y}{y+z}$
3. 下划线符号，符号：`\underline`，如：$\underline{x+y}$
4. 标签，符号`\tag{数字}`，如：$\tag{11}$
5. 上大括号，符号：`\overbrace{算式}`，如：$\overbrace{a+b+c+d}^{2.0}$
6. 下大括号，符号：`\underbrace{算式}`，如：$a+\underbrace{b+c}_{1.0}+d$
7. 上位符号，符号：`\stacrel{上位符号}{基位符号}`，如：$\vec{x}\stackrel{\mathrm{def}}{=}{x_1,\dots,x_n}$

## 占位符

1. 两个quad空格，符号：`\qquad`，如：$x \qquad y$
2. quad空格，符号：`\quad`，如：$x \quad y$
3. 大空格，符号`\`，如：$x \  y$
4. 中空格，符号`\:`，如：$x : y$
5. 小空格，符号`\,`，如：$x , y$
6. 没有空格，符号``，如：$xy$
7. 紧贴，符号`\!`，如：$x ! y$

## 定界符与组合

1. 括号，符号：`（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)`，如：$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$
2. 中括号，符号：`[]`，如：$[x+y]$
3. 大括号，符号：`\{ \}`，如：${x+y}$
4. 自适应括号，符号：`\left \right`，如：$\left(x\right)$，$\left(x{yz}\right)$
5. 组合公式，符号：`{上位公式 \choose 下位公式}`，如：${n+1 \choose k}={n \choose k}+{n \choose k-1}$
6. 组合公式，符号：`{上位公式 \atop 下位公式}`，如：$\sum_{k_0,k_1,\ldots>0 \atop k_0+k_1+\cdots=n}A_{k_0}A_{k_1}\cdots$

## 四则运算

1. 加法运算，符号：`+`，如：$x+y=z$
2. 减法运算，符号：`-`，如：$x-y=z$
3. 加减运算，符号：`\pm`，如：$x \pm y=z$
4. 减甲运算，符号：`\mp`，如：$x \mp y=z$
5. 乘法运算，符号：`\times`，如：$x \times y=z$
6. 点乘运算，符号：`\cdot`，如：$x \cdot y=z$
7. 星乘运算，符号：`\ast`，如：$x \ast y=z$
8. 除法运算，符号：`\div`，如：$x \div y=z$
9. 斜法运算，符号：`/`，如：$x/y=z$
10. 分式表示，符号：`\frac{分子}{分母}`，如：$\frac{x+y}{y+z}$
11. 分式表示，符号：`{分子} \voer {分母}`，如：${x+y} \over {y+z}$
12. 绝对值表示，符号：`||`，如：$|x+y|$

## 高级运算

1. 平均数运算，符号：`\overline{算式}`，如：$\overline{xyz}$
2. 开二次方运算，符号：`\sqrt`，如：$\sqrt x$
3. 开方运算，符号：`\sqrt[开方数]{被开方数}`，如：$\sqrt[3]{x+y}$
4. 对数运算，符号：`\log`，如：$\log(x)$
5. 极限运算，符号：`\lim`，如：$\lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$
6. 极限运算，符号：`\displaystyle \lim`，如：$\displaystyle \lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$
7. 求和运算，符号：`\sum`，如：$\sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$
8. 求和运算，符号：`\displaystyle \sum`，如：$\displaystyle \sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$
9. 积分运算，符号：`\int`，如：$\int^{\infty}_{0}{xdx}$
10. 积分运算，符号：`\displaystyle \int`，如：$\displaystyle \int^{\infty}_{0}{xdx}$
11. 微分运算，符号：`\partial`，如：$\frac{\partial x}{\partial y}$
12. 矩阵表示，符号：`\begin{matrix} \end{matrix}`，如：$\left[ \begin{matrix} 1 &2 &\cdots &4\5 &6 &\cdots &8\\vdots &\vdots &\ddots &\vdots\13 &14 &\cdots &16\end{matrix} \right]$

## 逻辑运算

1. 等于运算，符号：`=`，如：$x+y=z$
2. 大于运算，符号：`>`，如：$x+y>z$
3. 小于运算，符号：`<`，如：$x+y<z$ 4. 大于等于运算，符号：`\geq`，如：$x+y \geq z$ 5. 小于等于运算，符号：`\leq`，如：$x+y \leq 6. 不等于运算，符号：`\neq`，如：$x+y \neq 7. 不大于等于运算，符号：`\ngeq`，如：$x+y \ngeq 8. 不大于等于运算，符号：`\not\geq`，如：$x+y \not\geq 9. 不小于等于运算，符号：`\nleq`，如：$x+y \nleq 10. 不小于等于运算，符号：`\not\leq`，如：$x+y \not\leq 11. 约等于运算，符号：`\approx`，如：$x+y \approx 12. 恒定等于运算，符号：`\equiv`，如：$x+y \equiv ## 集合运算 1. 属于运算，符号：`\in`，如：$x \in y$ 2. 不属于运算，符号：`\notin`，如：$x \notin 3. 不属于运算，符号：`\not\in`，如：$x \not\in 子集运算，符号：`\subset`，如：$x \subset 子集运算，符号：`\supset`，如：$x \supset 真子集运算，符号：`\subseteq`，如：$x \subseteq 非真子集运算，符号：`\subsetneq`，如：$x \subsetneq 真子集运算，符号：`\supseteq`，如：$x \supseteq 非真子集运算，符号：`\supsetneq`，如：$x \supsetneq 非子集运算，符号：`\not\subset`，如：$x \not\subset 非子集运算，符号：`\not\supset`，如：$x \not\supset 并集运算，符号：`\cup`，如：$x \cup 13. 交集运算，符号：`\cap`，如：$x \cap 14. 差集运算，符号：`\setminus`，如：$x \setminus 15. 同或运算，符号：`\bigodot`，如：$x \bigodot 16. 同与运算，符号：`\bigotimes`，如：$x \bigotimes 17. 实数集合，符号：`\mathbb{r}`，如：`\mathbb{r}` 18. 自然数集合，符号：`\mathbb{z}`，如：`\mathbb{z}` 19. 空集，符号：`\emptyset`，如：$\emptyset$ 数学符号 无穷，符号：`\infty`，如：$\infty$ 虚数，符号：`\imath`，如：$\imath$ 虚数，符号：`\jmath`，如：$\jmath$ 数学符号，符号`\hat{a}`，如：$\hat{a}$ 数学符号，符号`\check{a}`，如：$\check{a}$ 数学符号，符号`\breve{a}`，如：$\breve{a}$ 数学符号，符号`\tilde{a}`，如：$\tilde{a}$ 数学符号，符号`\bar{a}`，如：$\bar{a}$ 矢量符号，符号`\vec{a}`，如：$\vec{a}$ 数学符号，符号`\acute{a}`，如：$\acute{a}$ 数学符号，符号`\grave{a}`，如：$\grave{a}$ 数学符号，符号`\mathring{a}`，如：$\mathring{a}$ 一阶导数符号，符号`\dot{a}`，如：$\dot{a}$ 二阶导数符号，符号`\ddot{a}`，如：$\ddot{a}$ 上箭头，符号：`\uparrow`，如：$\uparrow$ 下箭头，符号：`\downarrow`，如：$\downarrow$ 左箭头，符号：`\leftarrow`，如：$\leftarrow$ 20. 21. 右箭头，符号：`\rightarrow`，如：$\rightarrow$ 22. 23. 底端对齐的省略号，符号：`\ldots`，如：$1,2,\ldots,n$ 24. 中线对齐的省略号，符号：`\cdots`，如：$x_1^2 + x_2^2 \cdots x_n^2$ 25. 竖直对齐的省略号，符号：`\vdots`，如：$\vdots$ 26. 斜对齐的省略号，符号：`\ddots`，如：$\ddots$ 希腊字母 | 字母 实现 ---- ---------- a `a` α `\alhpa` b `b` β `\beta` γ `\gamma` δ `\delta` e `e` ϵ `\epsilon` z `z` ζ `\zeta` h `h` η `\eta` θ `\theta` i `i` ι `\iota` k `k` κ `\kappa` λ `\lambda` m `m` μ `\mu` n `n` ν `\nu` ξ `\xi` o `o` ο `\omicron` π `\pi` p `p` ρ `\rho` σ `\sigma` t `t` τ `\tau` υ `\upsilon` φ `\phi` ϕ x `x` χ `\chi` ψ `\psi` ω `\v` `\omega` --- ### about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ - 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </`，如：$x+y<z$>]]></content>
      <categories>
        <category>Markdownd</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL基础语法</title>
    <url>/2017/11/23/MySQL%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
SQL 对大小写不敏感；SQL 语句后面的分号

## MySQL基础语法

### DML 数据操作语言

- SELECT  从数据获取数据
   - SELECT 列名称 FROM 表名称;
   - SELECT 语句用于从表中选取数据,结果被存储在一个结果表中（称为结果集）。
   - SELECT DISTINCT 列名称 FROM 表名称;
		去重查询
   - SELECT 列名称 FROM 表名称 WHERE 列 运算符 值;
		有条件地从表中选取数据 			    
		SELECT * FROM Persons WHERE FirstName='Bush'
		

     | 操作符  | 描述         |
     | ------- | ------------ |
     | =       | 等于         |
     | <>      | 不等于       |
     | >       | 大于         |
     | <       | 小于         |
     | >=      | 大于等于     |
     | <= | 小于等于 between 在某个范围内 like 搜索某种模式 注释：在某些版本的 sql 中，操作符 <> 可以写为 !=。

   - SELECT 列名称 FROM 表名称 WHERE 列 运算符 值 AND/OR 列 运算符 值;

   - AND 和 OR 可在 WHERE 子语句中把两个或多个条件结合起来

      - 如果第一个条件和第二个条件都成立，则 AND 运算符显示一条记录

      - 如果第一个条件和第二个条件中只要有一个成立，则 OR 运算符显示一条记录 

   - SELECT 列名称 FROM 表名称 ORDER BY 列名 ;

      - ORDER BY 语句用于根据指定的列对结果集进行排序。

      - ORDER BY 语句默认按照升序对记录进行排序。可以使用 DESC 关键字（降序）。


- UPDATE  更新数据库表的数据

   - UPDATE 表名称  SET 列名称  = 新值  WHERE 列表 = 某值;

   - UPDATE Person SET FirstName = 'Fred' WHERE LastName = 'Wilson' 


- DELETE  从数据库表中删除数据

   - DELETE FROM 表名称 WHERE 列名称 = 值;

	删除表中的行，

   - DELETE FROM Person WHERE LastName = 'Wilson' ;

      - DELETE FROM table_name; 删除所有行,表结构、属性和索引是完整的

      - DELETE * FROM table_name;


- INSERT INTO  向数据库表中插入数据

   - INSERT INTO 表名称 VALUES (值1 ，值2， .....);

   - INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....);


### DDL 数据定义语言

- CREATE DATABASE   创建新数据库
- ALTER DATABASE     修改数据库
- CREATE TABLE         创建新表
- DROP TABLE           改变（变更）数据库表
- CREATE INDEX       创建索引（搜索键）
- DROP INDEX         删除索引


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </=>]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL学习-初涉MySQL</title>
    <url>/2017/09/20/MySQL%E5%AD%A6%E4%B9%A0--%E5%88%9D%E6%B6%89MySQL/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### MySQL登录/退出

- 登录

```mysql
mysql -u root -p -P3306 -h127.0.0.1

-D 数据库名称             打开指定数据库
--delimiter = name       指定分割符
-h 服务器名               服务器名称        
-p 密码				  密码
-P 端口号				 端口号
-u 用户名				 用户名
--prompt = name 		设置提示符
-V 输出版本信息并退出
```

- 退出

```mysql
exit;
quit;
\q;
```

### 修改MySQL提示符

```mysql
- 连接客户端时候通过prompt命令参数指定
 mysql -u root -p root --prompt 提示符 
示例： mysql -u root -p root --prompt \h

- 连接客户端后，通过prompt命令修改
prompt 提示符;
示例： prompt mysql>;
执行结果 PROMPT set to 'mysql>'
示例： prompt \D;

- 提示符
\D				完整的日期
\d				当前数据库
\h				服务器名称
\u				当前用户
示例：
1、设置当前用户+服务器+数据库名称
prompt \u@\h \d>
执行结果： PROMPT set to '\u@\h \d>'
	
```

### MySQL常用命令

```mysql
- 显示当前服务器版本
SELECT VERSION();
- 显示当前日期时间
SELECT NOW();
- 显示当前用户
SELECT USER();
```

### MySQL语句规范

- 关键字与函数名称全部大写

- 数据库名称、表名称、字段名称全部小写

- SQL语句必须以分号结尾

### 操作数据库

```mysql
- 创建数据库
CREATE { DATABASE | SCHEMA } [IF NOT EXISTS] db_name [DEFAULT] CHARACTER SET [=] charset_name;

- 查看当前服务器下的数据库列表
SHOW { DATABASES | SCHEMAS } [LIKE 'pattern' | WHERE expr];

- 修改数据库
ALTER { DATABASE | SCHEMA } [db_name] [DEFAULT] CHARACTER SET [=] charset_name;

- 删除数据库
DROP { DATABASE | SCHEMA } [IF EXISTS] db_name；

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL学习-数据类型与操作数据表</title>
    <url>/2017/09/21/MySQL%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E8%A1%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### MySQL数据类型

- 整型

```mysql
TINYINT   	1字节
	有符号值	-128到127 （- 2^7 到 2^7-1）
	无符号值	0 到 255  （0 到 2^8-1）
SMALLINT		2字节
	有符号值	-3278 到 32767	（- 2^15 到 2^15-1）
	无符号值	0 到 65535		（0 到 2^16-1）
MEDIUMINT		3字节
	有符号值	-8388608 到 8388607	（- 2^23 到 2^23-1）
	无符号值	0 到 16777215		（0 到 2^24-1）	
INT			4字节
	有符号值			（- 2^31 到 2^31-1）	
	无符号值			（0 到 2^32-1）
BIGINT		8字节
	有符号值			（- 2^63 到 2^63-1）
	无符号值			（0 到 2^64-1）
	
	1个字节 = 8 bit ,（8位）
```

- 浮点类型

```MYSQL
FLOAT[(M,D)]
	M,是数字总位数，
	D，是小数点后面的位数，
	如果M,D被省略，根据硬件允许的限制来保存值，
	单精度浮点数精确到大约7位小数位，

DOUBLE[(M,D)]
```

- 日期时间型

```mysql
类型			存储需求
YEAR			1
TIME			3
DATE			3
DATETIME		8
TIMESTAMP		4
```

- 字符型

```mysql
列类型							存储需求					
CHAR(M)		 定长类型		M个字节，0<= m <="255" varchar(m) 变长类型 l+1个字节，l<="M且0<=" tinytext l+1个字节， l< 2^8 text 2^16 mediumtext 2^24 longtext 2^32 enum('value1','value2',...) 1或2个字节，取决于枚举值的个数，最多65535个值 set('value1','value2'...) 1、2、3、4或者8个字节，取决于set集合成员的排列组合 ``` ### mysql数据表 - 创建数据表 ```mysql 打开数据库 mysql -u root -p; use 数据库名称; test01; create table [if not exists] table_name ( column_name1 data_type, column_name2 ... ); 查看数据表 查看数据表列表 show tables [from db_name] [like 'pattern' | where expr]; 查看数据表结构 columns from tbl_name; 插入记录 insert [into] tbl_name [(col_name,...)] values (val,...); 记录查找 select expr,... 空值与非空 null ,字段值可以为空 ,字段值禁止为空 约束的使用 非空约束 auto_increment 自动编号 且必须与主键组合使用 默认情况下，起始值为1，每次增量为1 primary key 主键 约束 每张数据表只能存在一个主键 主键保证记录的唯一性 主键自动为 unique 唯一约束 唯一约束可以保证记录的唯一性 唯一约束的字段端可以为空值（null） 每张数据表可以存在多个唯一约束 default 默认约束 foreign 外键约束 --- about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</=>]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL学习-约束及修改数据表</title>
    <url>/2017/09/22/MySQL%E5%AD%A6%E4%B9%A0-%E7%BA%A6%E6%9D%9F%E5%8F%8A%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E8%A1%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 约束

1. 约束保证数据 完整性和一致性

2. 约束分为表级约束和列级约束

3. 约束类型包括：


​	NOT NULL		非空约束

​	PRIMARY KEY	主键约束

​	UNIQUE KEY		唯一约束

​	DEFAULT		默认约束

​	FOREIGN KEY	外键约束



#### 外键约束

1. 父表和子表必须使用相同的存储引擎，而且禁止使用临时表；
2. 数据表的存储引擎只能为InnoDB；
3. 外键列和参照列 必须具有相似的数据类型，其中数字的长度/是否有符号位 必须相同；而字符长度则可以不同；
4. 外键列和参照列 必须创建索引，如果外键列不存在索引的话，MySQL将自动创建索引




```mysql
- 编辑数据表的默认存储引擎
- MySQL配置文件
default-storage-engine = INNODB

- 
```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL深入浅出--MySQL中数据类型</title>
    <url>/2017/10/25/MySQL%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--MySQL%E4%B8%AD%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### MySQL数据类型

#### 数值型

##### 整数型

- INT
- TINYINT
- BIGINT
- BOOL,BOOLEAN
- SMALLINT
- MEDIUMINT

##### 浮点型

- FLOAT
- DOUBLE
- DECIMAL

#### 字符串类型

```
说明：
1、CHAR效率高于VARCHAR,CHAR相当于拿空间换时间，VARCHAR拿时间换空间
2、CHAR默认存储数据的时候，后面会用空格填充到指定长度；而在检索的时候会去掉后面空格；VARCHAR在保存的时候不进行填充，尾部的空格会留下
3、TEXT列不能有默认值,检索的时候不存在大小写转换
```

- CHAR
- VARCHAR
- TINYTEXT
- TEXT
- MEDIUMTEXT
- LONGTEXT
- EMUM('value1','value2',...)
- SET('value1','value2',...)

#### 日期时间类型

#### 二进制类型


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL深入浅出--数据库相关操作</title>
    <url>/2017/10/25/MySQL%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 数据库相关操作

- 创建数据库   

  ```mysql
  CREATE {DATABASE|SCHEMA} db_name;
  ```

  - 检测数据库名称是否存在，不存在则创建

    ```mysql
    CREATE DATABASE [IF NOT EXISTS] db_name;
    ```

  - 创建数据库同时指定编码方式

    ```mysql
    CREATE DATABASE [IF NOT EXISTS] db_name [DEFAULT] CHARACTER SET [=] charset;
    ```

- 查看当前服务器下全部数据库

  ```mysql
  SHOW DATABASES|SCHEMAS;
  ```

- 查看指定数据库详细信息

  ```mysql
  SHOW CREATE DATABASE db_name;
  ```

- 修改指定数据库的编码方式

  ```mysql
  ALTER DATABASE db_name [DEFAULT] CHARACTER SET [=] charset;
  ```

- 打开指定数据库

  ```mysql
  USE db_name;
  ```

- 得到当前打开的数据库

  ```mysql
  SELECT DATABASE()|SCHEMA();
  ```

- 删除指定的数据库

  ```mysql
  DROP DATABASE db_name;
  ```

  - 如果数据库存在则删除

    ```mysql
    DROP DATABASE [IF EXISTS] db_name;
    ```

    
---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL深入浅出--MySQL相关操作</title>
    <url>/2017/10/25/MySQL%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--MySQL%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### MySQL 操作

#### 配置文件

​	my.cnf  是 MySQL 的配置文件

#### 登录/退出MySQL

注意：

​	1、命令行结束符号使用英文分号;   或者 \g

​	2、通过help 或者\h 或者?加上相关关键字 来查看手册

​	3、\c可以取消当前命令的执行

##### 登录

- mysql -uroot -p
- mysql -uroot -proot
- mysql -hlocalhost -uroot -p -P3306
- 登录同时修改命令提示符
  - mysql -uroot -p --prompt=命令提示符
- 获取版本号
  - mysql -V
  - mysql --version
- 登录同时打开指定数据库
  - mysql -uroot -p -D db_name

##### 退出

- exit
- quit
- \q
- ctrl + c

#### SQL语句语法规范

- 常用MySQL的关键字需要大写
- 库名、表名、字段名称等使用小写
- SQL语句支持折行操作，拆分的时候不能把完整单词拆开
- 数据库名称、表名称、字段名称不要使用MySQL的保留字，如果必须要使用，需要用反引号``将其括起来

#### 常用SQL语句

- SELECT USER()     得到登录的用户
- SELECT VERSION()     得到MySQL的版本信息
- SELECT NOW()         得到当前的日期时间
- SELECT DATABASE()     得到当前打开的数据库


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL深入浅出--数据表相关操作</title>
    <url>/2017/10/25/MySQL%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E6%95%B0%E6%8D%AE%E8%A1%A8%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 数据表相关操作

#### 数据表

- 描述

   	1、是数据库最重要的组成部分之一，数据是保存在数据表中
   	2、数据表由 行row 和 列column组成
   	3、表名要求唯一，不要包含特殊字符，最好语义明确
   	4、每个数据表至少有一列，行可有0 行，1行 或多行

#### 创建表

- ```mysql
  CREATE TABLE [IF NOT EXISTS] tbl_name(
      字段名称 字段类型 [完整性约束条件],
      字段名称 字段类型 [完整性约束条件],
  	...
  )ENGINE=存储引擎 CHARSET=编码方式;
  ```

  - UNSIGNED        

    无符号，没有负数，从0开始

  - ZEROFILL

    零填充，当数据的显示长度不够的时候可以使用前补0的效果填充至指定长度,字段会自动添加UNSIGNED

  - NOT NULL

    非空约束，也就是插入值的时候这个字段必须要给值,值不能为空

  - DEFAULT

    默认值，如果插入记录的时候没有给字段赋值，则使用默认值

  - PRIMARY KEY

    主键，标识记录的唯一性，值不能重复，一个表只能有一个主键，自动禁止为空

  - AUTO_INCREMENT

    自动增长，只能用于数值列，而且配合索引使用,默认起始值从1开始，每次增长1

  - UNIQUE KEY

    唯一性，一个表中可以有多个字段是唯一索引，同样的值不能重复，但是NULL值除外

  - FOREIGN KEY

    外键约束

#### 删除指定的数据表

```mysql
DROP TABLE [IF EXISTS] tb_name;
```

#### 查看表结构

 ```mysql
  DESC tbl_name;
  DESCRIBE tbl_name;
  SHOW COLUMNS FROM tbl_name;
 ```

#### 查看指定数据表的详细信息

```mysql
SHOW CREATE TABLE tb_name;
```

#### 查看当前数据库下已有数据表

```mysql
SHOW TABLES;
SHOW [FULL] TABLES [{FROM | IN} db_name] [LIKE 'pattern' | WHERE expr];
```

#### 表结构相关操作

- 添加字段

    ```mysql
     ALTER TABLE tbl_name ADD 字段名称 字段属性 [完整性约束条件;][FIRST|AFTER 字段名称];
    ```

- 删除字段

  ```mysql
     ALTER TABLE tbl_name DROP 字段名称;
  ```

- 添加默认值

    ```mysql
     ALTER TABLE tbl_name ALTER 字段名称 SET DEFAULT 默认值; 
    ```

- 删除默认值

    ```mysql
     ALTER TABLE tbl_name ALTER 字段名称 DROP DEFAULT;
    ```

- 修改字段类型、字段属性

    ```mysql
     ALTER TABLE tbl_name MODIFY 字段名称 字段类型 [字段属性][FIRST | AFTER 字段名称]; 
    ```

- 修改字段名称、字段类型、字段属性

   ```mysql
   ALTER TABLE tbl_name CHANGE 原字段名称 新字段名称 字段类型 字段属性 [FIRST | AFTER 字段名称];
   ```

- 添加主键

   ```mysql
   ALTER TABLE tbl_name ADD PRIMARY KEY(字段名称);
   ```

- 删除主键

   ```mysql
   ALTER TABLE tbl_name DROP PRIMARY KEY;
   ```

- 添加唯一

   ```mysql
   ALTER TABLE tbl_name ADD UNIQUE KEY|INDEX [index_name] (字段名称);
   ```

- 删除唯一

   ```mysql
   ALTER TABLE tbl_name  DROP index_name;
   ```

- 修改数据表名称

   ```mysql
   ALTER TABLE tbl_name  RENAME [TO|AS] new_tbl_name;
   RENAME TABLE tbl_name TO new_tbl_name;
   ```

- 修改AUTO_INCREMENT的值

   ```mysql
   ALTER TABLE tbl_name AUTO_INCREMENT=值;
   ```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL深入浅出--什么是数据库</title>
    <url>/2017/10/25/MySQL%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA--%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 什么是数据库

​	数据库（Database）是按照数据结构来组织、储存和管理数据的仓库

#### 常见数据库

- Oracle
- DB2
- SQL Server
- Postgre SQL
- MySQL

#### 相关术语

##### 数据库系统（Database System） DBS 

- 数据库 (Database)
- 数据库管理系统 (Database Management System) : DBMS
- 应用开发工具
- 管理员及用户

##### SQL语言 （Structured Query Language）:结构化查询语言

- DDL (数据定义语言)
- DML (数据操作语言)
- DQL (数据查询语言)
- DCL (数据控制语言)

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL高级语法</title>
    <url>/2017/11/25/MySQL%E9%AB%98%E7%BA%A7%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## MySQL高级语法
### SQL TOP子句
TOP 子句用于规定要返回的记录的数目。

- SELECT TOP number | percent column_name(s) FROM table_name;
- SELECT column_name(s) FROM table_name LIMIT number;

### SQL LIKE 操作符
LIKE 操作符用于在 WHERE 子句中搜索列中的指定模式。
- SELECT column_name(s) FROM table_name WHERE column_name LIKE pattern;

### SQL 通配符
SQL 通配符必须与 LIKE 运算符一起使用
| 通配符                     | 描述                       |
| -------------------------- | -------------------------- |
| %                          | 替代一个或多个字符         |
| _                          | 仅替代一个字符             |
| [charlist]                 | 字符列中的任何单一字符     |
| [^charlist]或者[!charlist] | 不在字符列中的任何单一字符 |

### SQL IN 操作符
- SELECT column_name(s) FROM table_name WHERE column_name IN (value1,value2,...);

### SQL CREATE DATABASE 语句
- CREATE DATABASE database_name

### SQL CREATE TABLE 语句
- CREATE TABLE 表名称 ( 列名称1 数据类型, 列名称2 数据类型, 列名称3 数据类型, .... );
   - 数据类型（data_type）规定了列可容纳何种数据类型。下面的表格包含了SQL中最常用的数据类型：

   | 数据类型                                          | 描述                                                         |
   | ------------------------------------------------- | ------------------------------------------------------------ |
   | integer(size)int(size)smallint(size)tinyint(size) | 仅容纳整数。在括号内规定数字的最大位数。                     |
   | decimal(size,d)numeric(size,d)                    | 容纳带有小数的数字。"size" 规定数字的最大位数。"d" 规定小数点右侧的最大位数。 |
   | char(size)                                        | 容纳固定长度的字符串（可容纳字母、数字以及特殊字符）。在括号中规定字符串的长度。 |
   | varchar(size)                                     | 容纳可变长度的字符串（可容纳字母、数字以及特殊的字符）。在括号中规定字符串的最大长度。 |
   | date(yyyymmdd)                                    | 容纳日期。                                                   |

### SQL约束（Constraints）
约束用于限制加入表的数据的类型；
在创建表时规定约束（通过 CREATE TABLE 语句）；
在表创建之后也可以（通过 ALTER TABLE 语句）

- NOT NULL
	如果不向字段添加值，就无法插入新记录或者更新记录
   - NOT NULL 约束强制列不接受 NULL 值;
   - NOT NULL 约束强制字段始终包含值;

- UNIQUE
    - UNIQUE 约束唯一标识数据库表中的每条记录。
    - UNIQUE 和 PRIMARY KEY 约束均为列或列集合提供了唯一性的保证。
    - PRIMARY KEY 拥有自动定义的 UNIQUE 约束。
		注意 每个表可以有多个 UNIQUE 约束，但每个表只能有一个 PRIMARY KEY 约束。

- PRIMARY KEY
    - RIMARY KEY 约束唯一标识数据库表中的每条记录。
    - 主键必须包含唯一的值。
    - 主键列不能包含 NULL 值。
- FOREIGN KEY
	一个表中的 FOREIGN KEY 指向另一个表中的 PRIMARY KEY。
- CHECK
- DEFAULT

### SQL CREATE INDEX 语句
用于在表中创建索引
### SQL DROP 语句
### SQL ALTER TABLE 语句
ALTER TABLE 语句用于在已有的表中添加、修改或删除列。





---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Linux</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP-Bert语义情感分类</title>
    <url>/2021/01/03/NLP-Bert%E8%AF%AD%E4%B9%89%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
#### 评论情感分类数据处理

```python
# 评论情感分类数据处理
# labels： 0负面、1中性、2正面
class CommentProcessor(DataProcessor):
    def get_train_examples(self, data_dir):
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir,"train.tsv")),"train"
        )
    def get_dev_examples(self, data_dir):
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir, "dev.tsv")), "dev"
        )
    def get_test_examples(self, data_dir):
        return self._create_examples(
            self._read_tsv(os.path.join(data_dir, "test.tsv")), "test"
        )
    def get_labels(self):
        return ["0","1","2"]
    def _create_examples(self,lines,set_type):
        examples=[]
        for (i ,line) in enumerate(lines):
            if i == 0:
                continue
            guid = "%s-%s" % (set_type,i)
            try:
                text_a = tokenization.convert_to_unicode(line[1])
            except:
                continue
            if set_type == "test":
                label = "0"
            else:
                label = tokenization.convert_to_unicode(line[0])
            examples.append(
                InputExample(guid=guid,text_a = text_a, label=label)
            )
        return examples

```

#### 将Bert模型ckpt文件转为 tfserving部署所需的pb

```python
#!/usr/bin/python3.6
'''
BERT模型ckpt文件转为部署tfserving所需的文件
'''
import json
import os
from enum import Enum
import sys
import modeling
from termcolor import colored
import logging
import tensorflow as tf
import argparse
import pickle

tf.app.flags.DEFINE_string('export_model_dir', "./output/comment_0/versions", 'Directory where the model exported files should be placed.')
tf.app.flags.DEFINE_integer('model_version', 10001, 'Models version number.')
FLAGS = tf.app.flags.FLAGS

def create_classification_model(bert_config, is_training, input_ids, input_mask, segment_ids, labels, num_labels):
    """
    :param bert_config:
    :param is_training:
    :param input_ids:
    :param input_mask:
    :param segment_ids:
    :param labels:
    :param num_labels:
    :param use_one_hot_embedding:
    :return:
    """

    #import tensorflow as tf
    #import modeling

    # 通过传入的训练数据，进行representation
    model = modeling.BertModel(
        config=bert_config,
        is_training=is_training,
        input_ids=input_ids,
        input_mask=input_mask,
        token_type_ids=segment_ids,
    )

    output_layer = model.get_pooled_output()
    hidden_size = output_layer.shape[-1].value

    output_weights = tf.get_variable(
        "output_weights", [num_labels, hidden_size],
        initializer=tf.truncated_normal_initializer(stddev=0.02))

    output_bias = tf.get_variable(
        "output_bias", [num_labels], initializer=tf.zeros_initializer())

    with tf.variable_scope("loss"):
        if is_training:
            # I.e., 0.1 dropout
            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)

        logits = tf.matmul(output_layer, output_weights, transpose_b=True)
        logits = tf.nn.bias_add(logits, output_bias)
        probabilities = tf.nn.softmax(logits, axis=-1)
        log_probs = tf.nn.log_softmax(logits, axis=-1)

        if labels is not None:
            one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)

            per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)
            loss = tf.reduce_mean(per_example_loss)
        else:
            loss, per_example_loss = None, None
    return (loss, per_example_loss, logits, probabilities)

def main(max_seq_len, model_dir, num_labels):

    with tf.Session() as sess:
        #输入占位符
        input_ids = tf.placeholder(tf.int32, (None, max_seq_len), 'input_ids')
        input_mask = tf.placeholder(tf.int32, (None, max_seq_len), 'input_mask')
        #模型前向传播
        bert_config = modeling.BertConfig.from_json_file('./uncased_L-2_H-128_A-2/bert_config.json')
        loss, per_example_loss, logits, probabilities = create_classification_model(bert_config=bert_config, is_training=False,
            input_ids=input_ids, input_mask=input_mask, segment_ids=None, labels=None, num_labels=num_labels)
        #转换结果格式
        logits = tf.argmax(logits, 1)
        probabilities = tf.identity(probabilities, 'pred_prob')
        #模型保存的对象
        saver = tf.train.Saver()
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        latest_checkpoint = tf.train.latest_checkpoint(model_dir)
        saver.restore(sess,latest_checkpoint )
        # Create SavedModelBuilder class
        # defines where the model will be exported
        export_path_base = FLAGS.export_model_dir
        export_path = os.path.join(
            tf.compat.as_bytes(export_path_base),
            tf.compat.as_bytes(str(FLAGS.model_version)))
        print('Exporting trained model to', export_path)
        builder = tf.saved_model.builder.SavedModelBuilder(export_path)
        # Creates the TensorInfo protobuf objects that encapsulates the input/output tensors
        input_ids_tensor = tf.saved_model.utils.build_tensor_info(input_ids)
        input_mask_tensor = tf.saved_model.utils.build_tensor_info(input_mask)
        # output tensor info
        logits_output = tf.saved_model.utils.build_tensor_info(logits)
        print("logits_output")
        print(logits_output)
        probabilities_output = tf.saved_model.utils.build_tensor_info(probabilities)
        print("probabilities_output")
        print(probabilities_output)

        # Defines the DeepLab signatures, uses the TF Predict API
        # It receives an image and its dimensions and output the segmentation mask
        labels_map = ['0','1','2']
        prediction_signature = (
            tf.saved_model.signature_def_utils.build_signature_def(
                inputs={'input_ids': input_ids_tensor, 'input_mask': input_mask_tensor},
                outputs={'pred_label': logits_output , 'score':probabilities_output},
                method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))

        builder.add_meta_graph_and_variables(
            sess, [tf.saved_model.tag_constants.SERVING],
            signature_def_map={
                'result':
                    prediction_signature,
            })
        # export the model
        builder.save(as_text=True)
        print('Done exporting!')

if __name__ == '__main__':
    max_seq_len = 128
    num_labels = 3
    model_dir = './output/comment_0'
    main(max_seq_len, model_dir, num_labels)

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
        <category>NLP</category>
        <category>Bert</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>NLP</tag>
        <tag>Bert</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据挖掘——数据预处理</title>
    <url>/2018/11/20/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## Python数据挖掘——数据预处理

- 数据预处理
  - 数据质量
    - 准确性、完整性、一致性、时效性、可信性、可解释性
  - 数据预处理的主要任务
    - 数据清理
    - 数据集成
    - 数据归约
      - 维归约
      - 数值归约
    - 数据变换
      - 规范化
      - 数据离散化
      - 概念分层产生
- 数据清理（试图填充缺失的值，光滑噪声并识别离群点，纠正数据的不一致）
  - 缺失值
    - 忽略元组
    - 人工填写缺失值
    - 使用一个全局常量填充缺失值
    - 使用属性的中心度量（均值／中位数）填充缺失值
    - 使用与给定元组属于同一类的所有样本的均值／中位数
    - 使用最可能的值 填充缺失值
    - 注：某些情况，缺失值并不代表错误
  - 噪声数据（噪声是被测量的变量的随机误差或方差）
    - 分箱（通过考察数据的近邻，来光滑有序数据值）
      - 用箱均值
      - 用箱中位数
      - 用箱边界
    - 回归
    - 离群点分析（通过聚类来检测离群点）
  - 数据清理化为一个过程
    - 首先进行偏差检测，还要防止字段过载
      - 唯一性规则
      - 连续性规则
      - 空值规则
    - 偏差检测商业工具
      - 数据清洗工具
      - 数据审计工具
    - 数据迁移工具
      - EIL工具
- 数据集成
  - 实体识别问题
  - 冗余和相关分析
  - 元组重复
  - 数据值冲突的检测与处理
- 数据归约
  - 数据变换与数据离散化



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据挖掘——基础知识</title>
    <url>/2018/11/20/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## Python数据挖掘——基础知识

- 数据挖掘又称从数据中 挖掘知识、知识提取、数据／模式分析
- 即为：从数据中发现知识的过程
  - 1、数据清理 （消除噪声，删除不一致数据）
  - 2、数据集成 （多种数据源 组合在一起）
  - 3、数据选择 （从数据库中提取和分析任务相关的数据）
  - 4、数据变换 （通过汇总或聚焦操作，把数据变换和统一成适合挖掘的形式）
  - 5、数据挖掘 （基本步骤，使用智能化方法提取数据）
  - 6、模式评估 （根据某种兴趣度量，识别代表知识的真正的有趣模式）
  - 7、知识表示 （使用可视化和知识表示技术，向用户提供数据挖掘的知识）
- 广义：从大量的数据中挖掘有趣模式和知识的过程
- 数据挖掘的模式：
  - 描述性：描述性挖掘任务刻画目标数据中数据的一般性质
  - 预测性：预测性挖掘任务在当前数据上进行归纳，以便作出预测
- 数据挖掘功能
  - 离群点分析
  - 特征化与区分
    - 数据特征化 是目标类数据的一般性／特性的汇总
    - 数据区分是将目标数据对象的一般性 与一个／多个对比类对象的一般性进行比较
  - 频繁模式、关联和相关性
    - 频繁模式包括频繁项集、序列模式和频繁子结构
    - 频繁项集挖掘是频繁模式的基础
  - 聚类分析
    - 最大化类内相似性
    - 最小化类间相似性
  - 分类与回归
- 数据挖掘使用的技术
  - 统计学
  - 数据库系统
  - 数据仓库
  - 信息检索
  - 机器学习
  - 模式识别
  - 可视化
  - 算法
  - 高性能计算
  - 应用
- 数据挖掘的主要问题
  - 挖掘方法
  - 用户交互
  - 有效性与伸缩性
  - 数据类型的多样性
  - 数据挖掘与社会


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据挖掘——数据概述</title>
    <url>/2018/11/19/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## Python数据挖掘——数据概述

- 数据集由数据对象组成；
- 数据的基本统计描述
  - 中心趋势度量
    - 均值
    - 中位数
    - 众数
    - 中列数
      - 数据集的最大值和最小值的平均
  - 度量数据分布
    - 极差
      - 最大值与最小值的差
    - 四分位数
    - 方差
    - 四分位数极差
- 数据基本统计描述的图形显示
  - 一元分布
    - 分位数图
    - 分位数-分位数图（q-q图）
    - 直方图
  - 二元分布
    - 散点图
- 数据可视化
  - 1、基于像素的可视化技术
  - 2、几何投影可视化技术
  - 3、基于图符的可视化技术
  - 4、层次可视化技术
- 度量数据的相似性和相异性
  - 相似 和相异 都称 邻近性
  - 如果不相似，则称 相似性度量为0



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title>Python数据挖掘——概要</title>
    <url>/2019/01/04/Python%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E2%80%94%E2%80%94%E6%A6%82%E8%A6%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 一、数据挖掘过程

1.数据选择

分析业务需求后，选择应用于需求业务相关的数据：业务原始数据、公开的数据集、也可通过爬虫采集网站结构化的数据。明确业务需求并选择好针对性的数据是数据挖掘的先决条件。

2.数据预处理

通常选择好的数据会有噪音，不完整等缺陷，需要对数据进行清洗，缺失项处理，集成，转换以及归纳：
python字符串处理（相当方便）、正则式匹配、pandas、beautifulsoup处理Html标签等等工具。

3.特征工程/数据转换

根据选择的算法，对预处理好的数据提取特征，并转换为特定数据挖掘算法的分析模型。

4.数据挖掘

使用选择好的数据挖掘算法对数据进行处理后得到信息。

5.解释与评价

对数据挖掘后的信息加以分析解释，并应用于实际的工作领域。

## 二、数据挖掘常用算法简介

### 1.关联分析算法

关联规则在于找出具有最小支持度阈值和最小置信度阈值的不同域的数据之间的关联。在关联规则的分析算法研究中，算法的效率是核心的问题。
经典的算法有：Apriori算法，AprioriTid算法，FP-growth算法；

### 2.分类算法

决策树算法：以树形结构表示分类或者决策集合，产生规则或者发现规律。主要有ID3算法，C4.5算法， SLIQ算法， SPRINT算法， RainForest算法；

朴素Bayes分类算法：利用Bayes定理概率统计的方法，选择其中概率比较大的类别进行分类；

CBA(Classification Based on Association)算法：基于关联规则的分类算法；

MIND(Mining in Database)算法 ：采用数据库中用户定义的函数(user-definedfunction，简称UDF)来实现分类的算法；

神经网络分类算法：利用训练集对多个神经的网络进行训练，并用训练好的模型对样本进行分类；

粗集理论：粗集理论的特点是不需要预先给定某些特征或属性的数量描述，而是直接从给定问题出发，通过不可分辨关系和不可分辨类确定问题的近似域,从而找出问题中的内在规律；

遗传算法：遗传算法是模拟生物进化过程，利用复制(选择)、交叉(重组)和变异(突变)3个基本方法优化求解的技术；

### 3.聚类算法

聚类分析与分类不同，聚类分析处理的数据对象的类是未知的。聚类分析就是将对象集合分组为由类似的对象组成 的多个簇的过程。分为3类方法：

Ipartitioning method(划分方法) 给定1个N个对象或者元组的数据库，1个划分方法构建数据的K个划分，每1个划分表示1个聚簇，并且K<N。经典算法是K-MEAN(K平均值)； 6 7 9 10 12 13 20 2018 hierarchical method(层次方法) 对给定数据对象集合进行层次的分解，经典算法是birth算法； grid based method(基于网格的方法) 这种方法采用一个多分辨率的网格数据结构。将空间量化为有限数目的单元，这些单元形成了网格结构，所有聚类分析都在网格上进行。常用的算法有sting，skwavecluster和 clique； ### 小结 随着数据量的日益积累以及数据库种类的多样化，各种数据挖掘方法作用范围有限，都有局限性，因此采用单一方法难以得到决策所需的各种知识。但它们的有机组合具有互补性，多方法融合将成为数据挖掘算法的发展趋势。 ## 三、数据挖掘算法实现 1、相关知识 #### (1)距离度量：在数据挖掘中需要明确样本数据相似度，通常可以计算样本间的距离，如下为常用距离度量的介绍。 样本数据以： ![样本数据](https: user-gold-cdn.xitu.io 165acaff8aac01cf?w="605&h=362&f=png&s=12159)" ![坐标](https: 165ad72a029f3d22?w="605&h=362&f=png&s=12159)" **曼哈顿距离：** 也称曼哈顿街区距离，就如从街区的一个十字路口点到另一个十字路口点的距离， 二维空间（多维空间按同理扩展）用公式表示为 ![img](https: 165af852e320fea3?w="300&h=30&f=png&s=500)" 165af7c0321440e0?w="605&h=356&f=png&s=15230)" **欧氏距离**：表示为点到点的距离。二维空间（多维空间按同理扩展）的公式表示为 165af8375b661141?w="846&h=99&f=png&s=23089)" 165af84b783a086b?w="596&h=356&f=png&s=15492)" **闵可夫斯基距离**：是一组距离方法的概括，当 p="1" 既是曼哈顿距离，当 既是欧氏距离。当p越大，单一维度的差值对整体的影响就越大。 165af8eebd55abee?w="155&h=57&f=png&s=2367)" 闵可夫斯基距离（包括欧氏距离，曼哈顿距离）的优缺点： 优点：应用广泛。 缺点：无法考虑各分量的单位以及各分量分布（方差，期望）的差异性。（其中个分量的单位差异可以使用数据的标准化来消除，下面会有介绍。） **余弦相关系数**：样本数据视为向量，通过两向量间的夹角余弦值确认相关性，数值范围[-1，1]。 -1表示负相关，0表示无关，1表示正相关。 165b211e1adf40e8?w="353&h=48&f=png&s=3937)" 余弦相关系数的优缺点： 优点：余弦相似度与向量的幅值无关，只与向量的方向相关，在文档相似度（tf-idf）和图片相似性（histogram）计算上都有它的身影； 而且在样本数值稀疏的时候仍可以使用。 缺点：余弦相似度受到向量的平移影响，上式如果将 x 平移到 x+1, 余弦值就会改变。(可以理解为受样本的起始标准的影响，接下来介绍的皮尔逊相关系数可以消除这个影响) **皮尔逊相关系数**：计算出了样本向量间的相关性，数值范围[-1，1]。 165b29dfceee4ae8?w="704&h=68&f=png&s=6525)" 考虑计算的遍历的次数，有一个替代公式可以近似计算皮尔逊相关系数： 165b2a5756a5a4a3?w="533&h=189&f=png&s=25601)" 皮尔逊相关系数优点：可消除每个分量标准不同（分数膨胀）的影响，具有平移不变性和尺度不变性。 (2)数据标准化：[参考文章](https: blog.csdn.net zenghaitao0128 article details 78361038) 各分量计算距离而各分量的单位尺度差异很大，可以使用数据标准化消除不同分量间单位尺度的影响，，加速模型收敛的效率，常用的方法有三种： **min-max 标准化**：将数值范围缩放到（0,1）,但没有改变数据分布。max为样本最大值，min为样本最小值。 165b2bdd4a7cd845?w="128&h=62&f=png&s=1391)" **z-score 标准化**：将数值范围缩放到0附近, 经过处理的数据符合标准正态分布。u是平均值，σ是标准差。 165b2bc6bd1995f7?w="95&h=47&f=png&s=1114)" **修正的标准z-score**：修正后可以减少样本数据异常值的影响。将z-score标准化公式中的均值改为中位数，将标准差改为绝对偏差。 165d1d0e453e3047?w="173&h=99&f=png&s=5152)" 其中asd绝对偏差：u为中位数，card(x)为样本个数 165d19a89ad874e4?w="231&h=75&f=png&s=8321)" (3) 算法的效果评估： 十折交叉验证：将数据集随机分割成十个等份，每次用9份数据做训练集，1份数据做测试集，如此迭代10次。十折交叉验证的关键在于较平均地分为10份。 n折交叉验证又称为留一法：用几乎所有的数据进行训练，然后留一个数据进行测试，并迭代每一数据测试。留一法的优点是：确定性。 2、协同过滤推荐算法 代码实现、数据集及参考论文 [电影推荐——基于用户、物品的协同过滤算法](https: github.com liaoyongyu datamining tree master recommendation_algorithms) ``` ... 示例： r="Recommendor()" print("items base协同推荐 slope one") #items base协同推荐算法 one r.slope_one_recommendation('lyy') cos") 修正余弦相似度 r.cos_recommendation('lyy') print("users base协同推荐") #userbase协同推荐算法 r.user_base_recommendation("lyy") (1)基于用户的协同推荐算法 这个方法是利用相似用户的喜好来进行推荐：如果要推荐一个乐队给你，会查找一个和你类似的用户，然后将他喜欢的乐队推荐给你。 算法的关键在于找到相似的用户，迭代计算你与每个用户对相同乐队的评分距离，来确定谁是你最相似的用户，距离计算可以用曼哈顿距离，皮尔斯相关系数等等。 165b33cfd31f1d8a?w="648&h=257&f=png&s=58602)" 基于用户的协同推荐算法算法的缺点： 扩展性：随着用户数量的增加，其计算量也会增加。这种算法在只有几千个用户的情况下能够工作得很好，但达到一百万个用户时就会出现瓶颈。稀疏性：大多数推荐系统中，物品的数量要远大于用户的数量，因此用户仅仅对一小部分物品进行了评价，这就造成了数据的稀疏性。比如亚马逊有上百万本书，但用户只评论了很少一部分，于是就很难找到两个相似的用户了。 (2)基于物品的协同推荐算法 基于用户的协同过滤是通过计算用户之间的距离找出最相似的用户（需要将所有的评价数据在读取在内存中处理进行推荐），并将相似用户评价过的物品推荐给目标用户。而基于物品的协同过滤则是找出最相似的物品（通过构建一个物品的相似度模型来做推荐），再结合用户的评价来给出推荐结果。 基于物品的协同推荐算法常用有如下两种： 修正余弦相似度算法： 以物品的评分作为物品的属性值，通过对比物品i,j的工有的用户相对评分的计算相关性s(i,j)。与皮尔逊相关系数的原理相同，共有用户对物品的每一评分r(u,j)，r(u,i)需要减去该用户评分的平均值r(`u)而消除分数膨胀。 165b4596a0bf0e1f?w="399&h=128&f=png&s=17472)" 修正余弦相似度的优点：通过构建物品模型的方式，扩展性好，占用内存小；消除分数膨胀的影响； 修正余弦相似度的缺点：稀疏性，需要基于用户的评分数据； one推荐算法： 第一步，计算平均差值： dev(i,j)为遍历所有共有物品i，j的共有用户u的评分平均差异。 card(sj,i(x))则表示同时评价过物品j和i的用户数。 ![slopeone](https: 165b456e6ef82636?w="276&h=74&f=png&s=9386)" 第二歩，使用加权的slope one算法： pws1(u)j表示我们将预测用户u对物品j的评分。 求合集i属于s(u)-j,用户u所含的所有物品i（除了j以外）。 c(ji)也就是card(sj,i(x))表示同时评价过物品j和i的用户数。 165bd05c5b75f331?w="320&h=116&f=png&s=12784)" one算法优点：算法简单；扩展性好，只需要更新共有属性的用户评价，而不需要重新载入整个数据集。 one算法的缺点：稀疏性，需要基于用户的评分数据； 3、分类算法 (1)基于物品特征值的knn分类算法 代码实现 [鸢尾花knn分类算法](https: classify knn ) # knn算法 def knn(self, oj_list): weight_dict="{"Iris-setosa":0.0," "iris-versicolor":0.0, "iris-virginica":0.0} for atuple in oj_list: weight_dict[atuple[1]] +="(1.0" atuple[0]) rel_class="[(key," value) key, value weight_dict.items()] #print(sorted(rel_class, key="lambda" x:x[1], reverse="True))" return 前面我们讨论的协同推荐算法需要在用户产生的各种数据上面进行分析，因此也称为社会化过滤算法，而这种算法通常有数据的稀疏性，算法可扩展性以及依赖于用户的数据的缺点，而基于物品特征值分类算法可以改善这些问题。算法分为两步： 第一步、选取特征值 算法的关键在于挑取有代表区分意义的特征及分值。以iris花的示例，选取花萼长度， 花萼宽度，花瓣长度，花瓣宽度特征值。 165c3bc0f875a4f2?w="468&h=193&f=png&s=13889)" 第二歩、计算距离 比如计算测试集与训练集特征值之间的曼哈顿距离，得到k个最近邻后并通过加权后的结果预测分类。 knn分类算法的缺点：无法对分类结果的置信度进行量化；是被动学习的算法，每次测试需要需要遍历所有的训练集后才能分类。 (2)贝叶斯分类算法 [区分新闻类别朴素贝叶斯分类算法](https: blob bayes train_data(self): #训练组的条件概率 word self.vocabulary: category,value self.prob.items(): if not self.prob[category]: count="0" else : #优化条件概率公式 self.prob[category][word]="(count" 1) (self.total[category] len(self.vocabulary)) 贝叶斯分类算法是基于概率的分类算法。相比于knn分类算法，它是主动学习的算法，它会根据训练集建立一个模型，并用这个模型对新样本进行分类，速度也会快很多。 贝叶斯分类算法的理论基础是基于条件概率的公式（应用于现实中p(x|y&z)不直观得出，而p(y|x)*p(z|x)比较直观得出），并假设已存在的子事件(y,z...实际应用中会有多个)间是相互独立的（因此也称为朴素贝叶斯），当y，z事件假设为独立便有： 165cb97ac388a376?w="308&h=47&f=png&s=2796)" 如下举例推测买牛奶和有机食品，再会买绿茶的概率： 165d1ff2e5208d1e?w="1546&h=38&f=png&s=11379)" 第一步：计算先验概率及条件概率 先验概率：为单独事件发生的概率，如p(买绿茶)，p(有机食品) 条件概率（后验概率）：y事件已经发生，观察y数据集后得出x发生的概率。如p(买有机食品|买绿茶)，通过以下公式计算（nc表示y数据集下x的发生频数，n为y数据集的总数）： 165cb8547529dd0e?w="109&h=53&f=png&s=2600)" 上式存在一个缺陷，当一个条件概率 p(y|x)为0时，整体的预测结果p(x) *p(y|x)* p(z|x)只能为0，这样便不能更全面地预测。 修正后的条件概率：（公式摘自tom mitchell《机器学习》。m是一个常数，表示等效样本大小。决定常数m的方法有很多，我们这里可以使用预测结果的类别来作为m，比如投票有赞成和否决两种类别，所以m就为2。p则是相应的先验概率，比如说赞成概率是0.5，那p(赞成)就是0.5。）： 165cb83cfc13aaf1?w="152&h=60&f=png&s=4167)" 第二歩：根据贝叶斯公式做出预测 165cb98290a241b9?w="308&h=47&f=png&s=2796)" 由公式计算比较y&z事件发生下，不同x事件发生的概率差异，如得出p（x="喜欢），P（x=不喜欢）" 的概率大小，预测为概率比较大的事件。 因为p(y)*p(z)在上式都一样，因此公式可以简化为计算概率最大项而预测分类： 165cba5c9f486819?w="308&h=31&f=png&s=2113)" 贝叶斯算法的优点：能够给出分类结果的置信度；它是一种主动学习算法，速度更快。 贝叶斯算法的缺点：需要特定格式；数值型数据需要转换为类别计算概率或用高斯分布计算概率； (2)逻辑回归分类算法 [区分猫的图片](https: neutralnetwork) 注：逻辑回归分类算法待后续加入网络层，更新为神经网络分类算法。 cost函数，计算梯度 propagate(w, b, x, y): m="X.shape[1]" a="sigmoid(np.dot(w.T," x) b) cost="-1" * np.sum(y np.log(a) (1 - y) np.log(1 a)) dw="1" np.dot(x, (a y).t) db="1" np.sum(a 逻辑回归分类算法实现了输入特征向量x，而输出y（范围0~1）预测x的分类。 第一步，得到关于x线性回归函数 可以通过线性回归得到wx b，其中w是权重，b是偏差值。但不能用本式表述预测的值，因为输出y的值需要在（0~1）区间； 第二歩，通过激活函数转换 激活函数的特点是可以将线性函数转换为非线性函数，并且有输出值有限，可微分，单调性的特点。本例使用sigmoid，使输出为预测值y="sigmoid（WX+b）；" 第三歩，构建cost函数 训练w，b更好的预测真实的类别需要构建cost代价函数，y^为sigmoid(wx+b)的预测分类值，y为实际分类值（0或者1）： 165cdb16135ada50?w="621&h=73&f=png&s=19581)" 其中l(y^,y)称为损失函数 165cdba3f27220e1?w="321&h=39&f=png&s=8091)" 训练的目的就是为了让l(y^,y)足够小，也就是当y实际分类值为1时，y^要尽量偏向1。y实际分类值为0时，y^尽量小接近0。 第四步，梯度下降得到cost函数的极小值 165cdc1436948f7a?w="364&h=230&f=png&s=48409)" 通过对w,b两个参数求偏导，不断迭代往下坡的的位置移动（对w，b值往极小值方向做优化，其中α为学习率控制下降的幅度），全局最优解也就是代价函数（成本函数）j (w,b)这个凸函数的极小值点。 165cdc3fca61705f?w="275&h=154&f=png&s=10722)" 第五步、通过训练好的w,b预测分类。 165cd7df7fd9b48c?w="1036&h=804&f=png&s=175335)" 4、聚类算法 (1)层次聚类 [狗的种类层次聚类](https: cluster hierarchical%20method) 层次聚类将每条数据都当作是一个分类，每次迭代的时候合并距离最近的两个分类，直到剩下一个分类为止。 (2)k-means++聚类 [kmean++聚类](https: ipartitioning%20method kmeanpp.py) 注：kmean算法与kmean++区别在于初始的中心点是直接随机选取k各点。 #kmean初始化随机k个中心点 #random.seed(1) #center="[[self.data[i][r]" i range(1, len((self.data)))] #for random.sample(range(len(self.data)), k)] kmean ++ 初始化基于距离份量随机选k个中心点 1.随机选择一个点 center="[]" center.append(random.choice(range(len(self.data[0])))) 2.根据距离的概率选择其他中心点 range(self.k 1): weights="[self.distance_closest(self.data[0][x]," center) range(len(self.data[0])) center] dp="[x" total="sum(weights)" #基于距离设定权重 weight weights] num="random.random()" while < center.append(dp[x]) k-means++算法可概括为： （1）基于各点到中心点得距离分量，依次随机选取到k个元素作为中心点： 先随机选择一个点。重复以下步骤，直到选完k个点。 计算每个数据点dp(n)到各个中心点的距离（d），选取最小的值d(dp)； 165f5eafc5c036a9?w="145&h=202&f=png&s=6769)" 根据d(dp)距离所占的份量来随机选取下一个点作为中心点。 165f5eb1eb0f4f7e?w="150&h=233&f=png&s=9001)" （2）根据各点到中心点的距离分类； （3）计算各个分类新的中心点。 重复(2、3)，直至满足条件。 原文转自 https: segmentfault.com 1190000017808525 --- about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</N。经典算法是K-MEAN(K平均值)；>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Data Mining</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>Data Mining</tag>
      </tags>
  </entry>
  <entry>
    <title>RWW产品概念评估法学习</title>
    <url>/2019/01/01/RWW%E4%BA%A7%E5%93%81%E6%A6%82%E5%BF%B5%E8%AF%84%E4%BC%B0%E6%B3%95%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### RWW概述

Real-Win-Worth，简称RWW，起源于3M大厂。通过Real-Win-Worth来评估市场机会／产品概念的商业潜力和风险大小。

- **Real-这是真实的吗？**
  潜在市场是否真实存在？
  能满足市场需求的产品技术可行性？
- **Win-我们能赢吗？**
  企业和产品是否具备获取市场份额的能力？
  产品能否在市场中具备竞争优势？	
- **Worth-这个值得做吗？**
  从盈利能力、风险承受能力以及企业战略层面对市场机会进行更深入评估。

| *R-Is It Real? 这是真实的吗？*                 |                                      |
| :--------------------------------------------- | ------------------------------------ |
| **市场真实存在吗**                             | **产品是否真的可以实现出来？**       |
| 1、用户是否想要／需要产品？                    | 5、是否有一个明确的产品概念？        |
| 2、用户是否可以使用／购买产品？                | 6、产品是否可以造出来？              |
| 3、潜在市场的规模是否足够大？                  | 7、最终产品是否满足市场需求？        |
| 4、用户会购买产品吗？                          |                                      |
| ***W-Can We Win? 我们能赢吗？***               |                                      |
| **产品是否具备竞争力？**                       | **企业是否具有竞争力？**             |
| 8、产品是否具备竞争优势                        | 11、企业有优质资源吗？               |
| 9、产品优势能否持续维持下去？                  | 12、企业有能够取胜的经营管理吗？     |
| 10、怎样应对竞争对手的反击回应？               | 13、企业能否理解并回应市场？         |
|                                                | 14、企业是否具有竞争                 |
| ***W-Is It Worth Doing? 是否值得做？***        |                                      |
| **能否在风险可控可接受的情况下保证产品回报？** | **推出新产品是否具有战略意义？**     |
| 15、预期收益是否大于成本？                     | 17、产品是否符合企业的整体增长策略？ |
| 16、当前风险是否可以接受？                     | 18、高层管理人员会支持它吗？         |



RWW 无法消除风险和问题，但能告诉团队风险和问题在哪里，以便选出最佳的市场机会／产品概念；在推出创新产品时也可更好的降低风险。



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot-WebSocket聊天室</title>
    <url>/2018/03/02/SpringBoot-WebSocket%20%E8%81%8A%E5%A4%A9%E5%AE%A4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# SpringBoot-WebSocket 聊天室

## 配置类Config

```java
// websocket配置
@Bean
    public ServerEndpointExporter serverEndpointExporter() {
        return new ServerEndpointExporter();
    }

```

## 业务类Controller

```java
import org.springframework.stereotype.Component;
 
import javax.websocket.*;
import javax.websocket.server.PathParam;
import javax.websocket.server.ServerEndpoint;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.CopyOnWriteArraySet;
 
/**
 *  * @Description: websocket的具体实现类
 *  * 使用springboot的唯一区别是要@Component声明下，而使用独立容器是由容器自己管理websocket的，
 *  * 但在springboot中连容器都是spring管理的。
 *     虽然@Component默认是单例模式的，但springboot还是会为每个websocket连接初始化一个bean，
 *     所以可以用一个静态set保存起来。
*/
@ServerEndpoint(value = "/websocket/{nickName}")
@Component
public class MyWebSocket {
    //用来存放每个客户端对应的MyWebSocket对象。
    private static CopyOnWriteArraySet<MyWebSocket> webSocketSet = new CopyOnWriteArraySet<MyWebSocket>();
    private static Map<Session, userinfo> connectmap = new HashMap<>();//用session作为key，保存用户信息
    //与某个客户端的连接会话，需要通过它来给客户端发送数据
    private Session session;
    /**
     * 连接建立成功调用的方法
     */
    @OnOpen
    public void onOpen(Session session, @PathParam("nickName") String nickName) {
        this.session = session;
        UserInfo userInfo = new UserInfo(session.getId(),nickName);
        connectmap.put(session,userInfo);
        webSocketSet.add(this);     //加入set中
        System.out.println(nickName+" 上线了！当前在线人数为" + webSocketSet.size());
        //群发消息，告诉每一位
        broadcast(nickName+" 上线了！-->当前在线人数为："+webSocketSet.size());
    }
    /**
     * 连接关闭调用的方法
     */
    @OnClose
    public void onClose() {
        String nickName=connectmap.get(session).getNickName();
        connectmap.remove(session);
        webSocketSet.remove(this);  //从set中删除
        System.out.println(nickName+" 下线了！当前在线人数为" + webSocketSet.size());
        //群发消息，告诉每一位
        broadcast(nickName+" 下线，当前在线人数为："+webSocketSet.size());
    }
    /**
     * 收到客户端消息后调用的方法
     *
     * @param message 客户端发送过来的消息
     * */
    @OnMessage
    public void onMessage(String message, Session session) {
        System.out.println("来自客户端的消息:" + message);
        //群发消息
        String nickName=connectmap.get(session).getNickName();
        broadcast(nickName+" 说："+message);
    }
    /**
     * 发生错误时调用
     *
     */
    @OnError
    public void onError(Session session, Throwable error) {
        System.out.println("发生错误");
        error.printStackTrace();
    }
    /**
     * 群发自定义消息
     * */
    public  void broadcast(String message){
        for (MyWebSocket item : webSocketSet) {
            //同步异步说明参考：http://blog.csdn.net/who_is_xiaoming/article/details/53287691
            //this.session.getBasicRemote().sendText(message);
            item.session.getAsyncRemote().sendText(message);//异步发送消息.
        }
    }
}
```

## 实体类Entity

```java
public class UserInfo {
    private String id;
    private String nickName;
    private String password;
 
    public UserInfo() {
    }
 
    public UserInfo(String id, String nickName) {
        this.id = id;
        this.nickName = nickName;
    }
 
    public String getId() {
        return id;
    }
 
    public void setId(String id) {
        this.id = id;
    }
 
    public String getNickName() {
        return nickName;
    }
 
    public void setNickName(String nickName) {
        this.nickName = nickName;
    }
 
    public String getPassword() {
        return password;
    }
 
    public void setPassword(String password) {
        this.password = password;
    }
}
```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</Session,></MyWebSocket></MyWebSocket>]]></content>
      <categories>
        <category>Java</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>服务端</tag>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
        <tag>WebSocket</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot-自动配置原理</title>
    <url>/2016/12/23/Springboot-%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# SpringBoot-自动配置原理

#### 自动配置原理

1. springboot启动的时候加载朱配置类，开起了自动配置功能@EnableAutoConfiguration
2. @EnableAutoConfiguration的作用




---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 


]]></content>
      <categories>
        <category>Java</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>服务端</tag>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot数据访问JPA</title>
    <url>/2018/03/02/SpringBoot%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE-%E6%95%B4%E5%90%88JPA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# SpringBoot数据访问-整合JPA

- Entity --定义实体类，与数据表映射
- Repository ---定义操作，操作实体类中的数据表


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Java</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>服务端</tag>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot启动自定义方法</title>
    <url>/2018/03/02/SpringBoot%E5%90%AF%E5%8A%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# SpringBoot启动自定义方法

## 一、实现CommandLineRunner接口，重写run方法

```java
import org.springframework.boot.CommandLineRunner;
import org.springframework.stereotype.Component;

import com.gzy.demo.NettyClient;

@Component
public class MyStart1 implements CommandLineRunner{

    @Override
    public void run(String... args) throws Exception {
    	NettyClient.connect(10007, "127.0.0.1");
    }
}

```

## 二、实现ApplicationRunner接口，重写un方法

```java
import org.springframework.boot.ApplicationArguments;
import org.springframework.boot.ApplicationRunner;
import org.springframework.stereotype.Component;

import com.gzy.demo.NettyClient;

@Component
public class MyStart2 implements ApplicationRunner {
	@Override
	public void run(ApplicationArguments args) throws Exception {
		NettyClient.connect(10007, "127.0.0.1");
	}

}

```

## 三、初始化方法加上@PostConstruct注解

```java
import javax.annotation.PostConstruct;

import org.springframework.stereotype.Component;

import com.gzy.demo.NettyClient;

@Component
public class MyStart3{
	@PostConstruct
	public void test() throws Exception {
		NettyClient.connect(10007, "127.0.0.1");
	}
}
```

#### 四、其他实现思路

```java
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import com.gzy.demo.NettyClient;

@Configuration
public class MyStart4 {
	@Bean
	public String startNetty() {
		try {
			NettyClient.connect(10007, "127.0.0.1");
		} catch (Exception e) {
			e.printStackTrace();
		}
		return "startNetty";
	}
}
```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Java</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>服务端</tag>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Bert-TF-2.6修改-自调适配版</title>
    <url>/2021/08/01/bert-tf2-6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# Bert-TF-2.6修改-自调适配版

#### 背景

bert开源版适配的为tf1版本，当机器的tf环境为2以上版本时，会出现各种异常。

因此我根据tf的函数库，进行了bert适配tf2.6的修改适配。

#### 代码

##### run_classifier.py

```python3
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import collections
import csv
import os
import modeling
import optimization
import tokenization
import tensorflow as tf
from absl import flags
from absl import app
import pickle

# flags = tf.flags

FLAGS = flags.FLAGS

## Required parameters
flags.DEFINE_string(
    "data_dir", None,
    "The input data dir. Should contain the .tsv files (or other data files) "
    "for the task.")

flags.DEFINE_string(
    "bert_config_file", None,
    "The config json file corresponding to the pre-trained BERT model. "
    "This specifies the model architecture.")

flags.DEFINE_string("task_name", None, "The name of the task to train.")

flags.DEFINE_string("vocab_file", None,
                    "The vocabulary file that the BERT model was trained on.")

flags.DEFINE_string(
    "output_dir", None,
    "The output directory where the model checkpoints will be written.")

flags.DEFINE_string(
    "trans_model_dir", None,
    "The trans_model_dir directory where the model will be written.")


## Other parameters

flags.DEFINE_string(
    "init_checkpoint", None,
    "Initial checkpoint (usually from a pre-trained BERT model).")

flags.DEFINE_bool(
    "do_lower_case", True,
    "Whether to lower case the input text. Should be True for uncased "
    "models and False for cased models.")

flags.DEFINE_integer(
    "max_seq_length", 128,
    "The maximum total input sequence length after WordPiece tokenization. "
    "Sequences longer than this will be truncated, and sequences shorter "
    "than this will be padded.")

flags.DEFINE_bool("do_train", False, "Whether to run training.")

flags.DEFINE_bool("do_eval", False, "Whether to run eval on the dev set.")

flags.DEFINE_bool(
    "do_predict", False,
    "Whether to run the model in inference mode on the test set.")

flags.DEFINE_integer("train_batch_size", 32, "Total batch size for training.")

flags.DEFINE_integer("eval_batch_size", 8, "Total batch size for eval.")

flags.DEFINE_integer("predict_batch_size", 8, "Total batch size for predict.")

flags.DEFINE_float("learning_rate", 5e-5, "The initial learning rate for Adam.")

flags.DEFINE_float("num_train_epochs", 3.0,
                   "Total number of training epochs to perform.")

flags.DEFINE_float(
    "warmup_proportion", 0.1,
    "Proportion of training to perform linear learning rate warmup for. "
    "E.g., 0.1 = 10% of training.")

flags.DEFINE_integer("save_checkpoints_steps", 1000,
                     "How often to save the model checkpoint.")

flags.DEFINE_integer("iterations_per_loop", 1000,
                     "How many steps to make in each estimator call.")

flags.DEFINE_bool("use_tpu", False, "Whether to use TPU or GPU/CPU.")

flags.DEFINE_string(
    "tpu_name", None,
    "The Cloud TPU to use for training. This should be either the name "
    "used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 "
    "url.")

flags.DEFINE_string(
    "tpu_zone", None,
    "[Optional] GCE zone where the Cloud TPU is located in. If not "
    "specified, we will attempt to automatically detect the GCE project from "
    "metadata.")

flags.DEFINE_string(
    "gcp_project", None,
    "[Optional] Project name for the Cloud TPU-enabled project. If not "
    "specified, we will attempt to automatically detect the GCE project from "
    "metadata.")

flags.DEFINE_string("master", None, "[Optional] TensorFlow master URL.")

flags.DEFINE_integer(
    "num_tpu_cores", 8,
    "Only used if `use_tpu` is True. Total number of TPU cores to use.")


class InputExample(object):
  """A single training/test example for simple sequence classification."""

  def __init__(self, guid, text_a, text_b=None, label=None):
    """Constructs a InputExample.

    Args:
      guid: Unique id for the example.
      text_a: string. The untokenized text of the first sequence. For single
        sequence tasks, only this sequence must be specified.
      text_b: (Optional) string. The untokenized text of the second sequence.
        Only must be specified for sequence pair tasks.
      label: (Optional) string. The label of the example. This should be
        specified for train and dev examples, but not for test examples.
    """
    self.guid = guid
    self.text_a = text_a
    self.text_b = text_b
    self.label = label


class PaddingInputExample(object):
  """Fake example so the num input examples is a multiple of the batch size.

  When running eval/predict on the TPU, we need to pad the number of examples
  to be a multiple of the batch size, because the TPU requires a fixed batch
  size. The alternative is to drop the last batch, which is bad because it means
  the entire output data won't be generated.

  We use this class instead of `None` because treating `None` as padding
  battches could cause silent errors.
  """


class InputFeatures(object):
  """A single set of features of data."""

  def __init__(self,
               input_ids,
               input_mask,
               segment_ids,
               label_id,
               is_real_example=True):
    self.input_ids = input_ids
    self.input_mask = input_mask
    self.segment_ids = segment_ids
    self.label_id = label_id
    self.is_real_example = is_real_example


class DataProcessor(object):
  """Base class for data converters for sequence classification data sets."""

  def get_train_examples(self, data_dir):
    """Gets a collection of `InputExample`s for the train set."""
    raise NotImplementedError()

  def get_dev_examples(self, data_dir):
    """Gets a collection of `InputExample`s for the dev set."""
    raise NotImplementedError()

  def get_test_examples(self, data_dir):
    """Gets a collection of `InputExample`s for prediction."""
    raise NotImplementedError()

  def get_labels(self):
    """Gets the list of labels for this data set."""
    raise NotImplementedError()

  @classmethod
  def _read_tsv(cls, input_file, quotechar=None):
    """Reads a tab separated value file."""
    with tf.io.gfile.GFile(input_file, "r") as f:
      reader = csv.reader(f, delimiter="\t", quotechar=quotechar)
      lines = []
      for line in reader:
        lines.append(line)
      return lines


class XnliProcessor(DataProcessor):
  """Processor for the XNLI data set."""

  def __init__(self):
    self.language = "zh"

  def get_train_examples(self, data_dir):
    """See base class."""
    lines = self._read_tsv(
        os.path.join(data_dir, "multinli",
                     "multinli.train.%s.tsv" % self.language))
    examples = []
    for (i, line) in enumerate(lines):
      if i == 0:
        continue
      guid = "train-%d" % (i)
      text_a = tokenization.convert_to_unicode(line[0])
      text_b = tokenization.convert_to_unicode(line[1])
      label = tokenization.convert_to_unicode(line[2])
      if label == tokenization.convert_to_unicode("contradictory"):
        label = tokenization.convert_to_unicode("contradiction")
      examples.append(
          InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))
    return examples

  def get_dev_examples(self, data_dir):
    """See base class."""
    lines = self._read_tsv(os.path.join(data_dir, "xnli.dev.tsv"))
    examples = []
    for (i, line) in enumerate(lines):
      if i == 0:
        continue
      guid = "dev-%d" % (i)
      language = tokenization.convert_to_unicode(line[0])
      if language != tokenization.convert_to_unicode(self.language):
        continue
      text_a = tokenization.convert_to_unicode(line[6])
      text_b = tokenization.convert_to_unicode(line[7])
      label = tokenization.convert_to_unicode(line[1])
      examples.append(
          InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))
    return examples

  def get_labels(self):
    """See base class."""
    return ["contradiction", "entailment", "neutral"]


class MnliProcessor(DataProcessor):
  """Processor for the MultiNLI data set (GLUE version)."""

  def get_train_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "train.tsv")), "train")

  def get_dev_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "dev_matched.tsv")),
        "dev_matched")

  def get_test_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "test_matched.tsv")), "test")

  def get_labels(self):
    """See base class."""
    return ["contradiction", "entailment", "neutral"]

  def _create_examples(self, lines, set_type):
    """Creates examples for the training and dev sets."""
    examples = []
    for (i, line) in enumerate(lines):
      if i == 0:
        continue
      guid = "%s-%s" % (set_type, tokenization.convert_to_unicode(line[0]))
      text_a = tokenization.convert_to_unicode(line[8])
      text_b = tokenization.convert_to_unicode(line[9])
      if set_type == "test":
        label = "contradiction"
      else:
        label = tokenization.convert_to_unicode(line[-1])
      examples.append(
          InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))
    return examples


class MrpcProcessor(DataProcessor):
  """Processor for the MRPC data set (GLUE version)."""

  def get_train_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "train.tsv")), "train")

  def get_dev_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "dev.tsv")), "dev")

  def get_test_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "test.tsv")), "test")

  def get_labels(self):
    """See base class."""
    return ["0", "1"]

  def _create_examples(self, lines, set_type):
    """Creates examples for the training and dev sets."""
    examples = []
    for (i, line) in enumerate(lines):
      if i == 0:
        continue
      guid = "%s-%s" % (set_type, i)
      text_a = tokenization.convert_to_unicode(line[3])
      text_b = tokenization.convert_to_unicode(line[4])
      if set_type == "test":
        label = "0"
      else:
        label = tokenization.convert_to_unicode(line[0])
      examples.append(
          InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))
    return examples


class ColaProcessor(DataProcessor):
  """Processor for the CoLA data set (GLUE version)."""

  def get_train_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "train.tsv")), "train")

  def get_dev_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "dev.tsv")), "dev")

  def get_test_examples(self, data_dir):
    """See base class."""
    return self._create_examples(
        self._read_tsv(os.path.join(data_dir, "test.tsv")), "test")

  def get_labels(self):
    """See base class."""
    return ["0", "1"]

  def _create_examples(self, lines, set_type):
    """Creates examples for the training and dev sets."""
    examples = []
    for (i, line) in enumerate(lines):
      # Only the test set has a header
      if set_type == "test" and i == 0:
        continue
      guid = "%s-%s" % (set_type, i)
      if set_type == "test":
        text_a = tokenization.convert_to_unicode(line[1])
        label = "0"
      else:
        text_a = tokenization.convert_to_unicode(line[3])
        label = tokenization.convert_to_unicode(line[1])
      examples.append(
          InputExample(guid=guid, text_a=text_a, text_b=None, label=label))
    return examples


def convert_single_example(ex_index, example, label_list, max_seq_length,
                           tokenizer):
  """Converts a single `InputExample` into a single `InputFeatures`."""

  if isinstance(example, PaddingInputExample):
    return InputFeatures(
        input_ids=[0] * max_seq_length,
        input_mask=[0] * max_seq_length,
        segment_ids=[0] * max_seq_length,
        label_id=0,
        is_real_example=False)

  label_map = {}
  for (i, label) in enumerate(label_list):
    label_map[label] = i

  output_label2id_file = os.path.join(FLAGS.trans_model_dir, "label2id.pkl")
  if not os.path.exists(output_label2id_file):
    with open(output_label2id_file, 'wb') as w:
        pickle.dump(label_map, w)

  tokens_a = tokenizer.tokenize(example.text_a)
  tokens_b = None
  if example.text_b:
    tokens_b = tokenizer.tokenize(example.text_b)

  if tokens_b:
    # Modifies `tokens_a` and `tokens_b` in place so that the total
    # length is less than the specified length.
    # Account for [CLS], [SEP], [SEP] with "- 3"
    _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)
  else:
    # Account for [CLS] and [SEP] with "- 2"
    if len(tokens_a) > max_seq_length - 2:
      tokens_a = tokens_a[0:(max_seq_length - 2)]

  # The convention in BERT is:
  # (a) For sequence pairs:
  #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]
  #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1
  # (b) For single sequences:
  #  tokens:   [CLS] the dog is hairy . [SEP]
  #  type_ids: 0     0   0   0  0     0 0
  #
  # Where "type_ids" are used to indicate whether this is the first
  # sequence or the second sequence. The embedding vectors for `type=0` and
  # `type=1` were learned during pre-training and are added to the wordpiece
  # embedding vector (and position vector). This is not *strictly* necessary
  # since the [SEP] token unambiguously separates the sequences, but it makes
  # it easier for the model to learn the concept of sequences.
  #
  # For classification tasks, the first vector (corresponding to [CLS]) is
  # used as the "sentence vector". Note that this only makes sense because
  # the entire model is fine-tuned.
  tokens = []
  segment_ids = []
  tokens.append("[CLS]")
  segment_ids.append(0)
  for token in tokens_a:
    tokens.append(token)
    segment_ids.append(0)
  tokens.append("[SEP]")
  segment_ids.append(0)

  if tokens_b:
    for token in tokens_b:
      tokens.append(token)
      segment_ids.append(1)
    tokens.append("[SEP]")
    segment_ids.append(1)

  input_ids = tokenizer.convert_tokens_to_ids(tokens)

  # The mask has 1 for real tokens and 0 for padding tokens. Only real
  # tokens are attended to.
  input_mask = [1] * len(input_ids)

  # Zero-pad up to the sequence length.
  while len(input_ids) < max_seq_length:
    input_ids.append(0)
    input_mask.append(0)
    segment_ids.append(0)

  assert len(input_ids) == max_seq_length
  assert len(input_mask) == max_seq_length
  assert len(segment_ids) == max_seq_length

  label_id = label_map[example.label]
  if ex_index < 5:
    tf.compat.v1.logging.info("*** Example ***")
    tf.compat.v1.logging.info("guid: %s" % (example.guid))
    tf.compat.v1.logging.info("tokens: %s" % " ".join(
        [tokenization.printable_text(x) for x in tokens]))
    tf.compat.v1.logging.info("input_ids: %s" % " ".join([str(x) for x in input_ids]))
    tf.compat.v1.logging.info("input_mask: %s" % " ".join([str(x) for x in input_mask]))
    tf.compat.v1.logging.info("segment_ids: %s" % " ".join([str(x) for x in segment_ids]))
    tf.compat.v1.logging.info("label: %s (id = %d)" % (example.label, label_id))

  feature = InputFeatures(
      input_ids=input_ids,
      input_mask=input_mask,
      segment_ids=segment_ids,
      label_id=label_id,
      is_real_example=True)
  return feature


def file_based_convert_examples_to_features(
    examples, label_list, max_seq_length, tokenizer, output_file):
  """Convert a set of `InputExample`s to a TFRecord file."""

  writer = tf.io.TFRecordWriter(output_file)

  for (ex_index, example) in enumerate(examples):
    if ex_index % 10000 == 0:
      tf.compat.v1.logging.info("Writing example %d of %d" % (ex_index, len(examples)))

    feature = convert_single_example(ex_index, example, label_list,
                                     max_seq_length, tokenizer)

    def create_int_feature(values):
      f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))
      return f

    features = collections.OrderedDict()
    features["input_ids"] = create_int_feature(feature.input_ids)
    features["input_mask"] = create_int_feature(feature.input_mask)
    features["segment_ids"] = create_int_feature(feature.segment_ids)
    features["label_ids"] = create_int_feature([feature.label_id])
    features["is_real_example"] = create_int_feature(
        [int(feature.is_real_example)])

    tf_example = tf.train.Example(features=tf.train.Features(feature=features))
    writer.write(tf_example.SerializeToString())
  writer.close()


def file_based_input_fn_builder(input_file, seq_length, is_training,
                                drop_remainder):
  """Creates an `input_fn` closure to be passed to TPUEstimator."""

  name_to_features = {
      "input_ids": tf.io.FixedLenFeature([seq_length], tf.int64),
      "input_mask": tf.io.FixedLenFeature([seq_length], tf.int64),
      "segment_ids": tf.io.FixedLenFeature([seq_length], tf.int64),
      "label_ids": tf.io.FixedLenFeature([], tf.int64),
      "is_real_example": tf.io.FixedLenFeature([], tf.int64),
  }

  def _decode_record(record, name_to_features):
    """Decodes a record to a TensorFlow example."""
    example = tf.io.parse_single_example(record, name_to_features)

    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.
    # So cast all int64 to int32.
    for name in list(example.keys()):
      t = example[name]
      if t.dtype == tf.int64:
        t = tf.compat.v1.to_int32(t)
      example[name] = t

    return example

  def input_fn(params):
    """The actual input function."""
    batch_size = params["batch_size"]

    # For training, we want a lot of parallel reading and shuffling.
    # For eval, we want no shuffling and parallel reading doesn't matter.
    d = tf.data.TFRecordDataset(input_file)
    if is_training:
      d = d.repeat()
      d = d.shuffle(buffer_size=100)

    d = d.apply(
        tf.data.experimental.map_and_batch(
            lambda record: _decode_record(record, name_to_features),
            batch_size=batch_size,
            drop_remainder=drop_remainder))


    return d

  return input_fn


def _truncate_seq_pair(tokens_a, tokens_b, max_length):
  """Truncates a sequence pair in place to the maximum length."""

  # This is a simple heuristic which will always truncate the longer sequence
  # one token at a time. This makes more sense than truncating an equal percent
  # of tokens from each, since if one sequence is very short then each token
  # that's truncated likely contains more information than a longer sequence.
  while True:
    total_length = len(tokens_a) + len(tokens_b)
    if total_length <= max_length: break if len(tokens_a)> len(tokens_b):
      tokens_a.pop()
    else:
      tokens_b.pop()


def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,
                 labels, num_labels, use_one_hot_embeddings):
  """Creates a classification model."""
  model = modeling.BertModel(
      config=bert_config,
      is_training=is_training,
      input_ids=input_ids,
      input_mask=input_mask,
      token_type_ids=segment_ids,
      use_one_hot_embeddings=use_one_hot_embeddings)

  # In the demo, we are doing a simple classification task on the entire
  # segment.
  #
  # If you want to use the token-level output, use model.get_sequence_output()
  # instead.
  output_layer = model.get_pooled_output()

  hidden_size = output_layer.shape[-1]

  output_weights = tf.compat.v1.get_variable(
      "output_weights", [num_labels, hidden_size],
      initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))

  output_bias = tf.compat.v1.get_variable(
      "output_bias", [num_labels], initializer=tf.zeros_initializer())

  with tf.compat.v1.variable_scope("loss"):
    if is_training:
      # I.e., 0.1 dropout
      output_layer = tf.compat.v1.nn.dropout(output_layer, keep_prob=0.9)

    logits = tf.matmul(output_layer, output_weights, transpose_b=True)
    logits = tf.nn.bias_add(logits, output_bias)
    probabilities = tf.nn.softmax(logits, axis=-1)
    log_probs = tf.nn.log_softmax(logits, axis=-1)

    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)

    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)
    loss = tf.reduce_mean(per_example_loss)

    return (loss, per_example_loss, logits, probabilities)


def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,
                     num_train_steps, num_warmup_steps, use_tpu,
                     use_one_hot_embeddings):
  """Returns `model_fn` closure for TPUEstimator."""

  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument
    """The `model_fn` for TPUEstimator."""

    tf.compat.v1.logging.info("*** Features ***")
    for name in sorted(features.keys()):
      tf.compat.v1.logging.info("  name = %s, shape = %s" % (name, features[name].shape))

    input_ids = features["input_ids"]
    input_mask = features["input_mask"]
    segment_ids = features["segment_ids"]
    label_ids = features["label_ids"]
    is_real_example = None
    if "is_real_example" in features:
      is_real_example = tf.cast(features["is_real_example"], dtype=tf.float32)
    else:
      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)

    is_training = (mode == tf.estimator.ModeKeys.TRAIN)

    (total_loss, per_example_loss, logits, probabilities) = create_model(
        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,
        num_labels, use_one_hot_embeddings)

    tvars = tf.compat.v1.trainable_variables()
    initialized_variable_names = {}
    scaffold_fn = None
    if init_checkpoint:
      (assignment_map, initialized_variable_names
      ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)
      if use_tpu:

        def tpu_scaffold():
          tf.compat.v1.train.init_from_checkpoint(init_checkpoint, assignment_map)
          return tf.compat.v1.train.Scaffold()

        scaffold_fn = tpu_scaffold
      else:
        tf.compat.v1.train.init_from_checkpoint(init_checkpoint, assignment_map)

    tf.compat.v1.logging.info("**** Trainable Variables ****")
    for var in tvars:
      init_string = ""
      if var.name in initialized_variable_names:
        init_string = ", *INIT_FROM_CKPT*"
      tf.compat.v1.logging.info("  name = %s, shape = %s%s", var.name, var.shape,
                      init_string)

    output_spec = None
    if mode == tf.estimator.ModeKeys.TRAIN:

      train_op = optimization.create_optimizer(
          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)

      output_spec = tf.compat.v1.estimator.tpu.TPUEstimatorSpec(
          mode=mode,
          loss=total_loss,
          train_op=train_op,
          scaffold_fn=scaffold_fn)
    elif mode == tf.estimator.ModeKeys.EVAL:

      def metric_fn(per_example_loss, label_ids, logits, is_real_example):
        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)
        accuracy = tf.compat.v1.metrics.accuracy(
            labels=label_ids, predictions=predictions, weights=is_real_example)
        loss = tf.compat.v1.metrics.mean(values=per_example_loss, weights=is_real_example)
        return {
            "eval_accuracy": accuracy,
            "eval_loss": loss,
        }

      eval_metrics = (metric_fn,
                      [per_example_loss, label_ids, logits, is_real_example])
      output_spec = tf.compat.v1.estimator.tpu.TPUEstimatorSpec(
          mode=mode,
          loss=total_loss,
          eval_metrics=eval_metrics,
          scaffold_fn=scaffold_fn)
    else:
      output_spec = tf.compat.v1.estimator.tpu.TPUEstimatorSpec(
          mode=mode,
          predictions={"probabilities": probabilities},
          scaffold_fn=scaffold_fn)
    return output_spec

  return model_fn


# This function is not used by this file but is still used by the Colab and
# people who depend on it.
def input_fn_builder(features, seq_length, is_training, drop_remainder):
  """Creates an `input_fn` closure to be passed to TPUEstimator."""

  all_input_ids = []
  all_input_mask = []
  all_segment_ids = []
  all_label_ids = []

  for feature in features:
    all_input_ids.append(feature.input_ids)
    all_input_mask.append(feature.input_mask)
    all_segment_ids.append(feature.segment_ids)
    all_label_ids.append(feature.label_id)

  def input_fn(params):
    """The actual input function."""
    batch_size = params["batch_size"]

    num_examples = len(features)

    # This is for demo purposes and does NOT scale to large data sets. We do
    # not use Dataset.from_generator() because that uses tf.py_func which is
    # not TPU compatible. The right way to load data is with TFRecordReader.
    d = tf.data.Dataset.from_tensor_slices({
        "input_ids":
            tf.constant(
                all_input_ids, shape=[num_examples, seq_length],
                dtype=tf.int32),
        "input_mask":
            tf.constant(
                all_input_mask,
                shape=[num_examples, seq_length],
                dtype=tf.int32),
        "segment_ids":
            tf.constant(
                all_segment_ids,
                shape=[num_examples, seq_length],
                dtype=tf.int32),
        "label_ids":
            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),
    })

    if is_training:
      d = d.repeat()
      d = d.shuffle(buffer_size=100)

    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)
    return d

  return input_fn


# This function is not used by this file but is still used by the Colab and
# people who depend on it.
def convert_examples_to_features(examples, label_list, max_seq_length,
                                 tokenizer):
  """Convert a set of `InputExample`s to a list of `InputFeatures`."""

  features = []
  for (ex_index, example) in enumerate(examples):
    if ex_index % 10000 == 0:
      tf.compat.v1.logging.info("Writing example %d of %d" % (ex_index, len(examples)))

    feature = convert_single_example(ex_index, example, label_list,
                                     max_seq_length, tokenizer)

    features.append(feature)
  return features


def serving_input_fn():
    # 保存模型为SaveModel格式
    # 采用最原始的feature方式，输入是feature Tensors。
    # 如果采用build_parsing_serving_input_receiver_fn，则输入是tf.Examples

    label_ids = tf.compat.v1.placeholder(tf.int32, [None, 3], name='label_ids')
    input_ids = tf.compat.v1.placeholder(tf.int32, [None, 200], name='input_ids')
    input_mask = tf.compat.v1.placeholder(tf.int32, [None, 200], name='input_mask')
    segment_ids = tf.compat.v1.placeholder(tf.int32, [None, 200], name='segment_ids')
    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({
        'label_ids': label_ids,
        'input_ids': input_ids,
        'input_mask': input_mask,
        'segment_ids': segment_ids,
    })()
    return input_fn

def main(_):
  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)

  processors = {
      "cola": ColaProcessor,
      "mnli": MnliProcessor,
      "mrpc": MrpcProcessor,
      "xnli": XnliProcessor,
  }

  tokenization.validate_case_matches_checkpoint(FLAGS.do_lower_case,
                                                FLAGS.init_checkpoint)

  if not FLAGS.do_train and not FLAGS.do_eval and not FLAGS.do_predict:
    raise ValueError(
        "At least one of `do_train`, `do_eval` or `do_predict' must be True.")

  bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)

  if FLAGS.max_seq_length > bert_config.max_position_embeddings:
    raise ValueError(
        "Cannot use sequence length %d because the BERT model "
        "was only trained up to sequence length %d" %
        (FLAGS.max_seq_length, bert_config.max_position_embeddings))

  tf.io.gfile.makedirs(FLAGS.output_dir)
  tf.io.gfile.makedirs(FLAGS.trans_model_dir)

  task_name = FLAGS.task_name.lower()

  if task_name not in processors:
    raise ValueError("Task not found: %s" % (task_name))

  processor = processors[task_name]()

  label_list = processor.get_labels()

  tokenizer = tokenization.FullTokenizer(
      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)

  tpu_cluster_resolver = None
  if FLAGS.use_tpu and FLAGS.tpu_name:
    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
        FLAGS.tpu_name, zone=FLAGS.tpu_zone, project=FLAGS.gcp_project)

  is_per_host = tf.compat.v1.estimator.tpu.InputPipelineConfig.PER_HOST_V2
  run_config = tf.compat.v1.estimator.tpu.RunConfig(
      cluster=tpu_cluster_resolver,
      master=FLAGS.master,
      model_dir=FLAGS.output_dir,
      save_checkpoints_steps=FLAGS.save_checkpoints_steps,
      tpu_config=tf.compat.v1.estimator.tpu.TPUConfig(
          iterations_per_loop=FLAGS.iterations_per_loop,
          num_shards=FLAGS.num_tpu_cores,
          per_host_input_for_training=is_per_host))

  train_examples = None
  num_train_steps = None
  num_warmup_steps = None
  if FLAGS.do_train:
    train_examples = processor.get_train_examples(FLAGS.data_dir)
    num_train_steps = int(
        len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)
    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)

  model_fn = model_fn_builder(
      bert_config=bert_config,
      num_labels=len(label_list),
      init_checkpoint=FLAGS.init_checkpoint,
      learning_rate=FLAGS.learning_rate,
      num_train_steps=num_train_steps,
      num_warmup_steps=num_warmup_steps,
      use_tpu=FLAGS.use_tpu,
      use_one_hot_embeddings=FLAGS.use_tpu)

  # If TPU is not available, this will fall back to normal Estimator on CPU
  # or GPU.
  estimator = tf.compat.v1.estimator.tpu.TPUEstimator(
      use_tpu=FLAGS.use_tpu,
      model_fn=model_fn,
      config=run_config,
      train_batch_size=FLAGS.train_batch_size,
      eval_batch_size=FLAGS.eval_batch_size,
      predict_batch_size=FLAGS.predict_batch_size)

  if FLAGS.do_train:
    train_file = os.path.join(FLAGS.output_dir, "train.tf_record")
    file_based_convert_examples_to_features(
        train_examples, label_list, FLAGS.max_seq_length, tokenizer, train_file)
    tf.compat.v1.logging.info("***** Running training *****")
    tf.compat.v1.logging.info("  Num examples = %d", len(train_examples))
    tf.compat.v1.logging.info("  Batch size = %d", FLAGS.train_batch_size)
    tf.compat.v1.logging.info("  Num steps = %d", num_train_steps)
    train_input_fn = file_based_input_fn_builder(
        input_file=train_file,
        seq_length=FLAGS.max_seq_length,
        is_training=True,
        drop_remainder=True)
    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)

  if FLAGS.do_eval:
    eval_examples = processor.get_dev_examples(FLAGS.data_dir)
    num_actual_eval_examples = len(eval_examples)
    if FLAGS.use_tpu:
      # TPU requires a fixed batch size for all batches, therefore the number
      # of examples must be a multiple of the batch size, or else examples
      # will get dropped. So we pad with fake examples which are ignored
      # later on. These do NOT count towards the metric (all tf.metrics
      # support a per-instance weight, and these get a weight of 0.0).
      while len(eval_examples) % FLAGS.eval_batch_size != 0:
        eval_examples.append(PaddingInputExample())

    eval_file = os.path.join(FLAGS.output_dir, "eval.tf_record")
    file_based_convert_examples_to_features(
        eval_examples, label_list, FLAGS.max_seq_length, tokenizer, eval_file)

    tf.compat.v1.logging.info("***** Running evaluation *****")
    tf.compat.v1.logging.info("  Num examples = %d (%d actual, %d padding)",
                    len(eval_examples), num_actual_eval_examples,
                    len(eval_examples) - num_actual_eval_examples)
    tf.compat.v1.logging.info("  Batch size = %d", FLAGS.eval_batch_size)

    # This tells the estimator to run through the entire set.
    eval_steps = None
    # However, if running eval on the TPU, you will need to specify the
    # number of steps.
    if FLAGS.use_tpu:
      assert len(eval_examples) % FLAGS.eval_batch_size == 0
      eval_steps = int(len(eval_examples) // FLAGS.eval_batch_size)

    eval_drop_remainder = True if FLAGS.use_tpu else False
    eval_input_fn = file_based_input_fn_builder(
        input_file=eval_file,
        seq_length=FLAGS.max_seq_length,
        is_training=False,
        drop_remainder=eval_drop_remainder)

    result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)

    # trans_model_dir模型转换后输出目录，将模型转换为saved model
    estimator._export_to_tpu = False
    estimator.export_savedmodel(FLAGS.trans_model_dir, serving_input_fn)

    output_eval_file = os.path.join(FLAGS.output_dir, "eval_results.txt")
    with tf.io.gfile.GFile(output_eval_file, "w") as writer:
      tf.compat.v1.logging.info("***** Eval results *****")
      for key in sorted(result.keys()):
        tf.compat.v1.logging.info("  %s = %s", key, str(result[key]))
        writer.write("%s = %s\n" % (key, str(result[key])))

  if FLAGS.do_predict:
    predict_examples = processor.get_test_examples(FLAGS.data_dir)
    num_actual_predict_examples = len(predict_examples)
    if FLAGS.use_tpu:
      # TPU requires a fixed batch size for all batches, therefore the number
      # of examples must be a multiple of the batch size, or else examples
      # will get dropped. So we pad with fake examples which are ignored
      # later on.
      while len(predict_examples) % FLAGS.predict_batch_size != 0:
        predict_examples.append(PaddingInputExample())

    predict_file = os.path.join(FLAGS.output_dir, "predict.tf_record")
    file_based_convert_examples_to_features(predict_examples, label_list,
                                            FLAGS.max_seq_length, tokenizer,
                                            predict_file)

    tf.compat.v1.logging.info("***** Running prediction*****")
    tf.compat.v1.logging.info("  Num examples = %d (%d actual, %d padding)",
                    len(predict_examples), num_actual_predict_examples,
                    len(predict_examples) - num_actual_predict_examples)
    tf.compat.v1.logging.info("  Batch size = %d", FLAGS.predict_batch_size)

    predict_drop_remainder = True if FLAGS.use_tpu else False
    predict_input_fn = file_based_input_fn_builder(
        input_file=predict_file,
        seq_length=FLAGS.max_seq_length,
        is_training=False,
        drop_remainder=predict_drop_remainder)

    result = estimator.predict(input_fn=predict_input_fn)

    output_predict_file = os.path.join(FLAGS.output_dir, "test_results.tsv")
    with tf.io.gfile.GFile(output_predict_file, "w") as writer:
      num_written_lines = 0
      tf.compat.v1.logging.info("***** Predict results *****")
      for (i, prediction) in enumerate(result):
        probabilities = prediction["probabilities"]
        if i >= num_actual_predict_examples:
          break
        output_line = "\t".join(
            str(class_probability)
            for class_probability in probabilities) + "\n"
        writer.write(output_line)
        num_written_lines += 1
    assert num_written_lines == num_actual_predict_examples


if __name__ == "__main__":
  flags.mark_flag_as_required("data_dir")
  flags.mark_flag_as_required("task_name")
  flags.mark_flag_as_required("vocab_file")
  flags.mark_flag_as_required("bert_config_file")
  flags.mark_flag_as_required("output_dir")
  flags.mark_flag_as_required("trans_model_dir")
  app.run(main)
```

##### optimization.py

```python3
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import re
import tensorflow as tf


def create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu):
  """Creates an optimizer training op."""
  global_step = tf.compat.v1.train.get_or_create_global_step()

  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)

  # Implements linear decay of the learning rate.
  learning_rate = tf.compat.v1.train.polynomial_decay(
      learning_rate,
      global_step,
      num_train_steps,
      end_learning_rate=0.0,
      power=1.0,
      cycle=False)

  # Implements linear warmup. I.e., if global_step < num_warmup_steps, the
  # learning rate will be `global_step/num_warmup_steps * init_lr`.
  if num_warmup_steps:
    global_steps_int = tf.cast(global_step, tf.int32)
    warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)

    global_steps_float = tf.cast(global_steps_int, tf.float32)
    warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)

    warmup_percent_done = global_steps_float / warmup_steps_float
    warmup_learning_rate = init_lr * warmup_percent_done

    is_warmup = tf.cast(global_steps_int < warmup_steps_int, tf.float32)
    learning_rate = (
        (1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)

  # It is recommended that you use this optimizer for fine tuning, since this
  # is how the model was trained (note that the Adam m/v variables are NOT
  # loaded from init_checkpoint.)
  optimizer = AdamWeightDecayOptimizer(
      learning_rate=learning_rate,
      weight_decay_rate=0.01,
      beta_1=0.9,
      beta_2=0.999,
      epsilon=1e-6,
      exclude_from_weight_decay=["LayerNorm", "layer_norm", "bias"])

  if use_tpu:
    optimizer = tf.compat.v1.estimator.tpu.CrossShardOptimizer(optimizer)

  tvars = tf.compat.v1.trainable_variables()
  grads = tf.gradients(loss, tvars)

  # This is how the model was pre-trained.
  (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)

  train_op = optimizer.apply_gradients(
      zip(grads, tvars), global_step=global_step)

  # Normally the global step update is done inside of `apply_gradients`.
  # However, `AdamWeightDecayOptimizer` doesn't do this. But if you use
  # a different optimizer, you should probably take this line out.
  new_global_step = global_step + 1
  train_op = tf.group(train_op, [global_step.assign(new_global_step)])
  return train_op


class AdamWeightDecayOptimizer(tf.keras.optimizers.Optimizer):
  """A basic Adam optimizer that includes "correct" L2 weight decay."""

  def __init__(self,
               learning_rate,
               weight_decay_rate=0.0,
               beta_1=0.9,
               beta_2=0.999,
               epsilon=1e-6,
               exclude_from_weight_decay=None,
               name="AdamWeightDecayOptimizer"):
    """Constructs a AdamWeightDecayOptimizer."""
    super(AdamWeightDecayOptimizer, self).__init__(False, name)

    self.learning_rate = learning_rate
    self.weight_decay_rate = weight_decay_rate
    self.beta_1 = beta_1
    self.beta_2 = beta_2
    self.epsilon = epsilon
    self.exclude_from_weight_decay = exclude_from_weight_decay

  def apply_gradients(self, grads_and_vars, global_step=None, name=None):
    """See base class."""
    assignments = []
    for (grad, param) in grads_and_vars:
      if grad is None or param is None:
        continue

      param_name = self._get_variable_name(param.name)

      m = tf.compat.v1.get_variable(
          name=param_name + "/adam_m",
          shape=param.shape.as_list(),
          dtype=tf.float32,
          trainable=False,
          initializer=tf.zeros_initializer())
      v = tf.compat.v1.get_variable(
          name=param_name + "/adam_v",
          shape=param.shape.as_list(),
          dtype=tf.float32,
          trainable=False,
          initializer=tf.zeros_initializer())

      # Standard Adam update.
      next_m = (
          tf.multiply(self.beta_1, m) + tf.multiply(1.0 - self.beta_1, grad))
      next_v = (
          tf.multiply(self.beta_2, v) + tf.multiply(1.0 - self.beta_2,
                                                    tf.square(grad)))

      update = next_m / (tf.sqrt(next_v) + self.epsilon)

      # Just adding the square of the weights to the loss function is *not*
      # the correct way of using L2 regularization/weight decay with Adam,
      # since that will interact with the m and v parameters in strange ways.
      #
      # Instead we want ot decay the weights in a manner that doesn't interact
      # with the m/v parameters. This is equivalent to adding the square
      # of the weights to the loss with plain (non-momentum) SGD.
      if self._do_use_weight_decay(param_name):
        update += self.weight_decay_rate * param

      update_with_lr = self.learning_rate * update

      next_param = param - update_with_lr

      assignments.extend(
          [param.assign(next_param),
           m.assign(next_m),
           v.assign(next_v)])
    return tf.group(*assignments, name=name)

  def _do_use_weight_decay(self, param_name):
    """Whether to use L2 weight decay for `param_name`."""
    if not self.weight_decay_rate:
      return False
    if self.exclude_from_weight_decay:
      for r in self.exclude_from_weight_decay:
        if re.search(r, param_name) is not None:
          return False
    return True

  def _get_variable_name(self, param_name):
    """Get the variable name from the tensor name."""
    m = re.match("^(.*):\\d+$", param_name)
    if m is not None:
      param_name = m.group(1)
    return param_name

```

##### tokenization.py

```python3

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import collections
import re
import unicodedata
import six
import tensorflow as tf


def validate_case_matches_checkpoint(do_lower_case, init_checkpoint):
  """Checks whether the casing config is consistent with the checkpoint name."""

  # The casing has to be passed in by the user and there is no explicit check
  # as to whether it matches the checkpoint. The casing information probably
  # should have been stored in the bert_config.json file, but it's not, so
  # we have to heuristically detect it to validate.

  if not init_checkpoint:
    return

  m = re.match("^.*?([A-Za-z0-9_-]+)/bert_model.ckpt", init_checkpoint)
  if m is None:
    return

  model_name = m.group(1)

  lower_models = [
      "uncased_L-24_H-1024_A-16", "uncased_L-12_H-768_A-12",
      "multilingual_L-12_H-768_A-12", "chinese_L-12_H-768_A-12"
  ]

  cased_models = [
      "cased_L-12_H-768_A-12", "cased_L-24_H-1024_A-16",
      "multi_cased_L-12_H-768_A-12"
  ]

  is_bad_config = False
  if model_name in lower_models and not do_lower_case:
    is_bad_config = True
    actual_flag = "False"
    case_name = "lowercased"
    opposite_flag = "True"

  if model_name in cased_models and do_lower_case:
    is_bad_config = True
    actual_flag = "True"
    case_name = "cased"
    opposite_flag = "False"

  if is_bad_config:
    raise ValueError(
        "You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. "
        "However, `%s` seems to be a %s model, so you "
        "should pass in `--do_lower_case=%s` so that the fine-tuning matches "
        "how the model was pre-training. If this error is wrong, please "
        "just comment out this check." % (actual_flag, init_checkpoint,
                                          model_name, case_name, opposite_flag))


def convert_to_unicode(text):
  """Converts `text` to Unicode (if it's not already), assuming utf-8 input."""
  if six.PY3:
    if isinstance(text, str):
      return text
    elif isinstance(text, bytes):
      return text.decode("utf-8", "ignore")
    else:
      raise ValueError("Unsupported string type: %s" % (type(text)))
  elif six.PY2:
    if isinstance(text, str):
      return text.decode("utf-8", "ignore")
    elif isinstance(text, unicode):
      return text
    else:
      raise ValueError("Unsupported string type: %s" % (type(text)))
  else:
    raise ValueError("Not running on Python2 or Python 3?")


def printable_text(text):
  """Returns text encoded in a way suitable for print or `tf.logging`."""

  # These functions want `str` for both Python2 and Python3, but in one case
  # it's a Unicode string and in the other it's a byte string.
  if six.PY3:
    if isinstance(text, str):
      return text
    elif isinstance(text, bytes):
      return text.decode("utf-8", "ignore")
    else:
      raise ValueError("Unsupported string type: %s" % (type(text)))
  elif six.PY2:
    if isinstance(text, str):
      return text
    elif isinstance(text, unicode):
      return text.encode("utf-8")
    else:
      raise ValueError("Unsupported string type: %s" % (type(text)))
  else:
    raise ValueError("Not running on Python2 or Python 3?")


def load_vocab(vocab_file):
  """Loads a vocabulary file into a dictionary."""
  vocab = collections.OrderedDict()
  index = 0
  with tf.io.gfile.GFile(vocab_file, "r") as reader:
    while True:
      token = convert_to_unicode(reader.readline())
      if not token:
        break
      token = token.strip()
      vocab[token] = index
      index += 1
  return vocab


def convert_by_vocab(vocab, items):
  """Converts a sequence of [tokens|ids] using the vocab."""
  output = []
  for item in items:
    output.append(vocab[item])
  return output


def convert_tokens_to_ids(vocab, tokens):
  return convert_by_vocab(vocab, tokens)


def convert_ids_to_tokens(inv_vocab, ids):
  return convert_by_vocab(inv_vocab, ids)


def whitespace_tokenize(text):
  """Runs basic whitespace cleaning and splitting on a piece of text."""
  text = text.strip()
  if not text:
    return []
  tokens = text.split()
  return tokens


class FullTokenizer(object):
  """Runs end-to-end tokenziation."""

  def __init__(self, vocab_file, do_lower_case=True):
    self.vocab = load_vocab(vocab_file)
    self.inv_vocab = {v: k for k, v in self.vocab.items()}
    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)
    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)

  def tokenize(self, text):
    split_tokens = []
    for token in self.basic_tokenizer.tokenize(text):
      for sub_token in self.wordpiece_tokenizer.tokenize(token):
        split_tokens.append(sub_token)

    return split_tokens

  def convert_tokens_to_ids(self, tokens):
    return convert_by_vocab(self.vocab, tokens)

  def convert_ids_to_tokens(self, ids):
    return convert_by_vocab(self.inv_vocab, ids)


class BasicTokenizer(object):
  """Runs basic tokenization (punctuation splitting, lower casing, etc.)."""

  def __init__(self, do_lower_case=True):
    """Constructs a BasicTokenizer.

    Args:
      do_lower_case: Whether to lower case the input.
    """
    self.do_lower_case = do_lower_case

  def tokenize(self, text):
    """Tokenizes a piece of text."""
    text = convert_to_unicode(text)
    text = self._clean_text(text)

    # This was added on November 1st, 2018 for the multilingual and Chinese
    # models. This is also applied to the English models now, but it doesn't
    # matter since the English models were not trained on any Chinese data
    # and generally don't have any Chinese data in them (there are Chinese
    # characters in the vocabulary because Wikipedia does have some Chinese
    # words in the English Wikipedia.).
    text = self._tokenize_chinese_chars(text)

    orig_tokens = whitespace_tokenize(text)
    split_tokens = []
    for token in orig_tokens:
      if self.do_lower_case:
        token = token.lower()
        token = self._run_strip_accents(token)
      split_tokens.extend(self._run_split_on_punc(token))

    output_tokens = whitespace_tokenize(" ".join(split_tokens))
    return output_tokens

  def _run_strip_accents(self, text):
    """Strips accents from a piece of text."""
    text = unicodedata.normalize("NFD", text)
    output = []
    for char in text:
      cat = unicodedata.category(char)
      if cat == "Mn":
        continue
      output.append(char)
    return "".join(output)

  def _run_split_on_punc(self, text):
    """Splits punctuation on a piece of text."""
    chars = list(text)
    i = 0
    start_new_word = True
    output = []
    while i < len(chars):
      char = chars[i]
      if _is_punctuation(char):
        output.append([char])
        start_new_word = True
      else:
        if start_new_word:
          output.append([])
        start_new_word = False
        output[-1].append(char)
      i += 1

    return ["".join(x) for x in output]

  def _tokenize_chinese_chars(self, text):
    """Adds whitespace around any CJK character."""
    output = []
    for char in text:
      cp = ord(char)
      if self._is_chinese_char(cp):
        output.append(" ")
        output.append(char)
        output.append(" ")
      else:
        output.append(char)
    return "".join(output)

  def _is_chinese_char(self, cp):
    """Checks whether CP is the codepoint of a CJK character."""
    # This defines a "chinese character" as anything in the CJK Unicode block:
    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)
    #
    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,
    # despite its name. The modern Korean Hangul alphabet is a different block,
    # as is Japanese Hiragana and Katakana. Those alphabets are used to write
    # space-separated words, so they are not treated specially and handled
    # like the all of the other languages.
    if ((cp >= 0x4E00 and cp <= 0x9fff) or # (cp>= 0x3400 and cp <= 0x4dbf) or # (cp>= 0x20000 and cp <= 0x2a6df) or # (cp>= 0x2A700 and cp <= 0x2b73f) or # (cp>= 0x2B740 and cp <= 0x2b81f) or # (cp>= 0x2B820 and cp <= 0x2ceaf) or (cp>= 0xF900 and cp <= 0xfaff) or # (cp>= 0x2F800 and cp <= 0 0x2fa1f)): # return true false def _clean_text(self, text): """performs invalid character removal and whitespace cleanup on text.""" output="[]" for char in text: cp="ord(char)" if or 0xfffd _is_control(char): continue _is_whitespace(char): output.append(" ") else: output.append(char) "".join(output) class wordpiecetokenizer(object): """runs wordpiece tokenziation.""" __init__(self, vocab, unk_token="[UNK]" , max_input_chars_per_word="200):" self.vocab="vocab" self.unk_token="unk_token" self.max_input_chars_per_word="max_input_chars_per_word" tokenize(self, """tokenizes a piece of text into its word pieces. this uses greedy longest-match-first algorithm to perform tokenization using the given vocabulary. example: input="unaffable" "##aff", "##able"] args: single token separated tokens. should have already been passed through `basictokenizer. returns: list """ output_tokens="[]" whitespace_tokenize(text): chars="list(token)" len(chars)> self.max_input_chars_per_word:
        output_tokens.append(self.unk_token)
        continue

      is_bad = False
      start = 0
      sub_tokens = []
      while start < len(chars):
        end = len(chars)
        cur_substr = None
        while start < end:
          substr = "".join(chars[start:end])
          if start > 0:
            substr = "##" + substr
          if substr in self.vocab:
            cur_substr = substr
            break
          end -= 1
        if cur_substr is None:
          is_bad = True
          break
        sub_tokens.append(cur_substr)
        start = end

      if is_bad:
        output_tokens.append(self.unk_token)
      else:
        output_tokens.extend(sub_tokens)
    return output_tokens


def _is_whitespace(char):
  """Checks whether `chars` is a whitespace character."""
  # \t, \n, and \r are technically contorl characters but we treat them
  # as whitespace since they are generally considered as such.
  if char == " " or char == "\t" or char == "\n" or char == "\r":
    return True
  cat = unicodedata.category(char)
  if cat == "Zs":
    return True
  return False


def _is_control(char):
  """Checks whether `chars` is a control character."""
  # These are technically control characters but we count them as whitespace
  # characters.
  if char == "\t" or char == "\n" or char == "\r":
    return False
  cat = unicodedata.category(char)
  if cat in ("Cc", "Cf"):
    return True
  return False


def _is_punctuation(char):
  """Checks whether `chars` is a punctuation character."""
  cp = ord(char)
  # We treat all non-letter/number ASCII as punctuation.
  # Characters such as "^", "$", and "`" are not in the Unicode
  # Punctuation class but we treat them as punctuation anyways, for
  # consistency.
  if ((cp >= 33 and cp <= 47) or (cp>= 58 and cp <= 64) or (cp>= 91 and cp <= 96) or (cp>= 123 and cp <= 512 1024 126)): return true cat="unicodedata.category(char)" if cat.startswith("p"): false ``` ##### modeling.py ```python3 from __future__ import absolute_import division print_function collections copy json math re numpy as np six tensorflow tf class bertconfig(object): """configuration for `bertmodel`.""" def __init__(self, vocab_size, hidden_size="768," num_hidden_layers="12," num_attention_heads="12," intermediate_size="3072," hidden_act="gelu" , hidden_dropout_prob="0.1," attention_probs_dropout_prob="0.1," max_position_embeddings="512," type_vocab_size="16," initializer_range="0.02):" """constructs bertconfig. args: vocab_size: vocabulary size of `inputs_ids` in `bertmodel`. hidden_size: the encoder layers and pooler layer. num_hidden_layers: number hidden transformer encoder. num_attention_heads: attention heads each layer intermediate_size: "intermediate" (i.e., feed-forward) hidden_act: non-linear activation function (function or string) pooler. hidden_dropout_prob: dropout probability all fully connected embeddings, encoder, attention_probs_dropout_prob: ratio probabilities. max_position_embeddings: maximum sequence length that this model might ever be used with. typically set to something large just case (e.g., 2048). type_vocab_size: `token_type_ids` passed into initializer_range: stdev truncated_normal_initializer initializing weight matrices. """ self.vocab_size="vocab_size" self.hidden_size="hidden_size" self.num_hidden_layers="num_hidden_layers" self.num_attention_heads="num_attention_heads" self.hidden_act="hidden_act" self.intermediate_size="intermediate_size" self.hidden_dropout_prob="hidden_dropout_prob" self.attention_probs_dropout_prob="attention_probs_dropout_prob" self.max_position_embeddings="max_position_embeddings" self.type_vocab_size="type_vocab_size" self.initializer_range="initializer_range" @classmethod from_dict(cls, json_object): a `bertconfig` python dictionary parameters.""" config="BertConfig(vocab_size=None)" (key, value) six.iteritems(json_object): config.__dict__[key]="value" from_json_file(cls, json_file): file with tf.io.gfile.gfile(json_file, "r") reader: text="reader.read()" cls.from_dict(json.loads(text)) to_dict(self): """serializes instance dictionary.""" output="copy.deepcopy(self.__dict__)" to_json_string(self): string.""" json.dumps(self.to_dict(), indent="2," sort_keys="True)" + "\n" bertmodel(object): """bert ("bidirectional representations transformers"). example usage: ```python # already been converted wordpiece token ids input_ids="tf.constant([[31," 51, 99], [15, 5, 0]]) input_mask="tf.constant([[1," 1, 1], [1, token_type_ids="tf.constant([[0," 0, [0, 2, is_training="True," label_embeddings="tf.compact.v1.get_variable(...)" pooled_output="model.get_pooled_output()" logits="tf.matmul(pooled_output," label_embeddings) ... config, is_training, input_ids, use_one_hot_embeddings="False," scope="None):" """constructor bertmodel. config: instance. is_training: bool. training model, eval model. controls whether will applied. input_ids: int32 tensor shape [batch_size, seq_length]. input_mask: (optional) token_type_ids: use_one_hot_embeddings: use one-hot word embeddings tf.embedding_lookup() embeddings. scope: variable scope. defaults "bert". raises: valueerror: is invalid one input shapes invalid. not config.hidden_dropout_prob="0.0" config.attention_probs_dropout_prob="0.0" input_shape="get_shape_list(input_ids," expected_rank="2)" batch_size="input_shape[0]" seq_length="input_shape[1]" none: seq_length], dtype="tf.int32)" tf.compat.v1.variable_scope(scope, default_name="bert" ): tf.compat.v1.variable_scope("embeddings"): perform embedding lookup on ids. (self.embedding_output, self.embedding_table)="embedding_lookup(" vocab_size="config.vocab_size," embedding_size="config.hidden_size," word_embedding_name="word_embeddings" add positional type then normalize dropout. self.embedding_output="embedding_postprocessor(" input_tensor="self.embedding_output," use_token_type="True," token_type_vocab_size="config.type_vocab_size," token_type_embedding_name="token_type_embeddings" use_position_embeddings="True," position_embedding_name="position_embeddings" dropout_prob="config.hidden_dropout_prob)" tf.compat.v1.variable_scope("encoder"): converts 2d mask seq_length] 3d seq_length, which scores. attention_mask="create_attention_mask_from_input_mask(" input_mask) run stacked transformer. `sequence_output` hidden_size]. self.all_encoder_layers="transformer_model(" intermediate_act_fn="get_activation(config.hidden_act)," do_return_all_layers="True)" self.sequence_output="self.all_encoder_layers[-1]" "pooler" encoded hidden_size] necessary segment-level (or segment-pair-level) classification tasks where we need fixed dimensional representation segment. tf.compat.v1.variable_scope("pooler"): "pool" by simply taking state corresponding first token. assume has pre-trained first_token_tensor="tf.squeeze(self.sequence_output[:," 0:1, :], axis="1)" self.pooled_output="tf.compat.v1.layers.dense(" first_token_tensor, config.hidden_size, kernel_initializer="create_initializer(config.initializer_range))" get_pooled_output(self): get_sequence_output(self): """gets final returns: float get_all_encoder_layers(self): get_embedding_output(self): transformer). layer, after summing performing normalization. get_embedding_table(self): self.embedding_table gelu(x): """gaussian error linear unit. smoother version relu. original paper: https: arxiv.org abs 1606.08415 x: activation. `x` gelu cdf="0.5" * (1.0 tf.tanh( (np.sqrt(2 np.pi) (x 0.044715 tf.pow(x, 3))))) x get_activation(activation_string): """maps string function, e.g., "relu"> `tf.nn.relu`.

  Args:
    activation_string: String name of the activation function.

  Returns:
    A Python function corresponding to the activation function. If
    `activation_string` is None, empty, or "linear", this will return None.
    If `activation_string` is not a string, it will return `activation_string`.

  Raises:
    ValueError: The `activation_string` does not correspond to a known
      activation.
  """

  # We assume that anything that"s not a string is already an activation
  # function, so we just return it.
  if not isinstance(activation_string, six.string_types):
    return activation_string

  if not activation_string:
    return None

  act = activation_string.lower()
  if act == "linear":
    return None
  elif act == "relu":
    return tf.nn.relu
  elif act == "gelu":
    return gelu
  elif act == "tanh":
    return tf.tanh
  else:
    raise ValueError("Unsupported activation: %s" % act)


def get_assignment_map_from_checkpoint(tvars, init_checkpoint):
  """Compute the union of the current variables and checkpoint variables."""
  assignment_map = {}
  initialized_variable_names = {}

  name_to_variable = collections.OrderedDict()
  for var in tvars:
    name = var.name
    m = re.match("^(.*):\\d+$", name)
    if m is not None:
      name = m.group(1)
    name_to_variable[name] = var

  init_vars = tf.compat.v1.train.list_variables(init_checkpoint)

  assignment_map = collections.OrderedDict()
  for x in init_vars:
    (name, var) = (x[0], x[1])
    if name not in name_to_variable:
      continue
    assignment_map[name] = name
    initialized_variable_names[name] = 1
    initialized_variable_names[name + ":0"] = 1

  return (assignment_map, initialized_variable_names)


def dropout(input_tensor, dropout_prob):
  """Perform dropout.

  Args:
    input_tensor: float Tensor.
    dropout_prob: Python float. The probability of dropping out a value (NOT of
      *keeping* a dimension as in `tf.nn.dropout`).

  Returns:
    A version of `input_tensor` with dropout applied.
  """
  if dropout_prob is None or dropout_prob == 0.0:
    return input_tensor

  output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)
  return output


def layer_norm(input_tensor, name=None):
  """Run layer normalization on the last dimension of the tensor."""
  layernorm = tf.keras.layers.LayerNormalization(axis=-1)
  return layernorm(input_tensor)


def layer_norm_and_dropout(input_tensor, dropout_prob, name=None):
  """Runs layer normalization followed by dropout."""
  output_tensor = layer_norm(input_tensor, name)
  output_tensor = dropout(output_tensor, dropout_prob)
  return output_tensor


def create_initializer(initializer_range=0.02):
  """Creates a `truncated_normal_initializer` with the given range."""
  return tf.compat.v1.truncated_normal_initializer(stddev=initializer_range)


def embedding_lookup(input_ids,
                     vocab_size,
                     embedding_size=128,
                     initializer_range=0.02,
                     word_embedding_name="word_embeddings",
                     use_one_hot_embeddings=False):
  """Looks up words embeddings for id tensor.

  Args:
    input_ids: int32 Tensor of shape [batch_size, seq_length] containing word
      ids.
    vocab_size: int. Size of the embedding vocabulary.
    embedding_size: int. Width of the word embeddings.
    initializer_range: float. Embedding initialization range.
    word_embedding_name: string. Name of the embedding table.
    use_one_hot_embeddings: bool. If True, use one-hot method for word
      embeddings. If False, use `tf.gather()`.

  Returns:
    float Tensor of shape [batch_size, seq_length, embedding_size].
  """
  # This function assumes that the input is of shape [batch_size, seq_length,
  # num_inputs].
  #
  # If the input is a 2D tensor of shape [batch_size, seq_length], we
  # reshape to [batch_size, seq_length, 1].
  if input_ids.shape.ndims == 2:
    input_ids = tf.expand_dims(input_ids, axis=[-1])

  embedding_table = tf.compat.v1.get_variable(
      name=word_embedding_name,
      shape=[vocab_size, embedding_size],
      initializer=create_initializer(initializer_range))

  flat_input_ids = tf.reshape(input_ids, [-1])
  if use_one_hot_embeddings:
    one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size)
    output = tf.matmul(one_hot_input_ids, embedding_table)
  else:
    output = tf.gather(embedding_table, flat_input_ids)

  input_shape = get_shape_list(input_ids)

  output = tf.reshape(output,
                      input_shape[0:-1] + [input_shape[-1] * embedding_size])
  return (output, embedding_table)


def embedding_postprocessor(input_tensor,
                            use_token_type=False,
                            token_type_ids=None,
                            token_type_vocab_size=16,
                            token_type_embedding_name="token_type_embeddings",
                            use_position_embeddings=True,
                            position_embedding_name="position_embeddings",
                            initializer_range=0.02,
                            max_position_embeddings=512,
                            dropout_prob=0.1):
  """Performs various post-processing on a word embedding tensor.

  Args:
    input_tensor: float Tensor of shape [batch_size, seq_length,
      embedding_size].
    use_token_type: bool. Whether to add embeddings for `token_type_ids`.
    token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length].
      Must be specified if `use_token_type` is True.
    token_type_vocab_size: int. The vocabulary size of `token_type_ids`.
    token_type_embedding_name: string. The name of the embedding table variable
      for token type ids.
    use_position_embeddings: bool. Whether to add position embeddings for the
      position of each token in the sequence.
    position_embedding_name: string. The name of the embedding table variable
      for positional embeddings.
    initializer_range: float. Range of the weight initialization.
    max_position_embeddings: int. Maximum sequence length that might ever be
      used with this model. This can be longer than the sequence length of
      input_tensor, but cannot be shorter.
    dropout_prob: float. Dropout probability applied to the final output tensor.

  Returns:
    float tensor with same shape as `input_tensor`.

  Raises:
    ValueError: One of the tensor shapes or input values is invalid.
  """
  input_shape = get_shape_list(input_tensor, expected_rank=3)
  batch_size = input_shape[0]
  seq_length = input_shape[1]
  width = input_shape[2]

  output = input_tensor

  if use_token_type:
    if token_type_ids is None:
      raise ValueError("`token_type_ids` must be specified if"
                       "`use_token_type` is True.")
    token_type_table = tf.compat.v1.get_variable(
        name=token_type_embedding_name,
        shape=[token_type_vocab_size, width],
        initializer=create_initializer(initializer_range))
    # This vocab will be small so we always do one-hot here, since it is always
    # faster for a small vocabulary.
    flat_token_type_ids = tf.reshape(token_type_ids, [-1])
    one_hot_ids = tf.one_hot(flat_token_type_ids, depth=token_type_vocab_size)
    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)
    token_type_embeddings = tf.reshape(token_type_embeddings,
                                       [batch_size, seq_length, width])
    output += token_type_embeddings

  if use_position_embeddings:
    assert_op = tf.debugging.assert_less_equal(seq_length, max_position_embeddings)
    with tf.control_dependencies([assert_op]):
      full_position_embeddings = tf.compat.v1.get_variable(
          name=position_embedding_name,
          shape=[max_position_embeddings, width],
          initializer=create_initializer(initializer_range))
      # Since the position embedding table is a learned variable, we create it
      # using a (long) sequence length `max_position_embeddings`. The actual
      # sequence length might be shorter than this, for faster training of
      # tasks that do not have long sequences.
      #
      # So `full_position_embeddings` is effectively an embedding table
      # for position [0, 1, 2, ..., max_position_embeddings-1], and the current
      # sequence has positions [0, 1, 2, ... seq_length-1], so we can just
      # perform a slice.
      position_embeddings = tf.slice(full_position_embeddings, [0, 0],
                                     [seq_length, -1])
      num_dims = len(output.shape.as_list())

      # Only the last two dimensions are relevant (`seq_length` and `width`), so
      # we broadcast among the first dimensions, which is typically just
      # the batch size.
      position_broadcast_shape = []
      for _ in range(num_dims - 2):
        position_broadcast_shape.append(1)
      position_broadcast_shape.extend([seq_length, width])
      position_embeddings = tf.reshape(position_embeddings,
                                       position_broadcast_shape)
      output += position_embeddings

  output = layer_norm_and_dropout(output, dropout_prob)
  return output


def create_attention_mask_from_input_mask(from_tensor, to_mask):
  """Create 3D attention mask from a 2D tensor mask.

  Args:
    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].
    to_mask: int32 Tensor of shape [batch_size, to_seq_length].

  Returns:
    float Tensor of shape [batch_size, from_seq_length, to_seq_length].
  """
  from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])
  batch_size = from_shape[0]
  from_seq_length = from_shape[1]

  to_shape = get_shape_list(to_mask, expected_rank=2)
  to_seq_length = to_shape[1]

  to_mask = tf.cast(
      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)

  # We don't assume that `from_tensor` is a mask (although it could be). We
  # don't actually care if we attend *from* padding tokens (only *to* padding)
  # tokens so we create a tensor of all ones.
  #
  # `broadcast_ones` = [batch_size, from_seq_length, 1]
  broadcast_ones = tf.ones(
      shape=[batch_size, from_seq_length, 1], dtype=tf.float32)

  # Here we broadcast along two dimensions to create the mask.
  mask = broadcast_ones * to_mask

  return mask


def attention_layer(from_tensor,
                    to_tensor,
                    attention_mask=None,
                    num_attention_heads=1,
                    size_per_head=512,
                    query_act=None,
                    key_act=None,
                    value_act=None,
                    attention_probs_dropout_prob=0.0,
                    initializer_range=0.02,
                    do_return_2d_tensor=False,
                    batch_size=None,
                    from_seq_length=None,
                    to_seq_length=None):
  """Performs multi-headed attention from `from_tensor` to `to_tensor`.

  This is an implementation of multi-headed attention based on "Attention
  is all you Need". If `from_tensor` and `to_tensor` are the same, then
  this is self-attention. Each timestep in `from_tensor` attends to the
  corresponding sequence in `to_tensor`, and returns a fixed-with vector.

  This function first projects `from_tensor` into a "query" tensor and
  `to_tensor` into "key" and "value" tensors. These are (effectively) a list
  of tensors of length `num_attention_heads`, where each tensor is of shape
  [batch_size, seq_length, size_per_head].

  Then, the query and key tensors are dot-producted and scaled. These are
  softmaxed to obtain attention probabilities. The value tensors are then
  interpolated by these probabilities, then concatenated back to a single
  tensor and returned.

  In practice, the multi-headed attention are done with transposes and
  reshapes rather than actual separate tensors.

  Args:
    from_tensor: float Tensor of shape [batch_size, from_seq_length,
      from_width].
    to_tensor: float Tensor of shape [batch_size, to_seq_length, to_width].
    attention_mask: (optional) int32 Tensor of shape [batch_size,
      from_seq_length, to_seq_length]. The values should be 1 or 0. The
      attention scores will effectively be set to -infinity for any positions in
      the mask that are 0, and will be unchanged for positions that are 1.
    num_attention_heads: int. Number of attention heads.
    size_per_head: int. Size of each attention head.
    query_act: (optional) Activation function for the query transform.
    key_act: (optional) Activation function for the key transform.
    value_act: (optional) Activation function for the value transform.
    attention_probs_dropout_prob: (optional) float. Dropout probability of the
      attention probabilities.
    initializer_range: float. Range of the weight initializer.
    do_return_2d_tensor: bool. If True, the output will be of shape [batch_size
      * from_seq_length, num_attention_heads * size_per_head]. If False, the
      output will be of shape [batch_size, from_seq_length, num_attention_heads
      * size_per_head].
    batch_size: (Optional) int. If the input is 2D, this might be the batch size
      of the 3D version of the `from_tensor` and `to_tensor`.
    from_seq_length: (Optional) If the input is 2D, this might be the seq length
      of the 3D version of the `from_tensor`.
    to_seq_length: (Optional) If the input is 2D, this might be the seq length
      of the 3D version of the `to_tensor`.

  Returns:
    float Tensor of shape [batch_size, from_seq_length,
      num_attention_heads * size_per_head]. (If `do_return_2d_tensor` is
      true, this will be of shape [batch_size * from_seq_length,
      num_attention_heads * size_per_head]).

  Raises:
    ValueError: Any of the arguments or tensor shapes are invalid.
  """

  def transpose_for_scores(input_tensor, batch_size, num_attention_heads,
                           seq_length, width):
    output_tensor = tf.reshape(
        input_tensor, [batch_size, seq_length, num_attention_heads, width])

    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])
    return output_tensor

  from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])
  to_shape = get_shape_list(to_tensor, expected_rank=[2, 3])

  if len(from_shape) != len(to_shape):
    raise ValueError(
        "The rank of `from_tensor` must match the rank of `to_tensor`.")

  if len(from_shape) == 3:
    batch_size = from_shape[0]
    from_seq_length = from_shape[1]
    to_seq_length = to_shape[1]
  elif len(from_shape) == 2:
    if (batch_size is None or from_seq_length is None or to_seq_length is None):
      raise ValueError(
          "When passing in rank 2 tensors to attention_layer, the values "
          "for `batch_size`, `from_seq_length`, and `to_seq_length` "
          "must all be specified.")

  # Scalar dimensions referenced here:
  #   B = batch size (number of sequences)
  #   F = `from_tensor` sequence length
  #   T = `to_tensor` sequence length
  #   N = `num_attention_heads`
  #   H = `size_per_head`

  from_tensor_2d = reshape_to_matrix(from_tensor)
  to_tensor_2d = reshape_to_matrix(to_tensor)

  # `query_layer` = [B*F, N*H]
  query_layer = tf.compat.v1.layers.dense(
      from_tensor_2d,
      num_attention_heads * size_per_head,
      activation=query_act,
      name="query",
      kernel_initializer=create_initializer(initializer_range))

  # `key_layer` = [B*T, N*H]
  key_layer = tf.compat.v1.layers.dense(
      to_tensor_2d,
      num_attention_heads * size_per_head,
      activation=key_act,
      name="key",
      kernel_initializer=create_initializer(initializer_range))

  # `value_layer` = [B*T, N*H]
  value_layer = tf.compat.v1.layers.dense(
      to_tensor_2d,
      num_attention_heads * size_per_head,
      activation=value_act,
      name="value",
      kernel_initializer=create_initializer(initializer_range))

  # `query_layer` = [B, N, F, H]
  query_layer = transpose_for_scores(query_layer, batch_size,
                                     num_attention_heads, from_seq_length,
                                     size_per_head)

  # `key_layer` = [B, N, T, H]
  key_layer = transpose_for_scores(key_layer, batch_size, num_attention_heads,
                                   to_seq_length, size_per_head)

  # Take the dot product between "query" and "key" to get the raw
  # attention scores.
  # `attention_scores` = [B, N, F, T]
  attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)
  attention_scores = tf.multiply(attention_scores,
                                 1.0 / math.sqrt(float(size_per_head)))

  if attention_mask is not None:
    # `attention_mask` = [B, 1, F, T]
    attention_mask = tf.expand_dims(attention_mask, axis=[1])

    # Since attention_mask is 1.0 for positions we want to attend and 0.0 for
    # masked positions, this operation will create a tensor which is 0.0 for
    # positions we want to attend and -10000.0 for masked positions.
    adder = (1.0 - tf.cast(attention_mask, tf.float32)) * -10000.0
    
    # Since we are adding it to the raw scores before the softmax, this is
    # effectively the same as removing these entirely.
    attention_scores += adder

  # Normalize the attention scores to probabilities.
  # `attention_probs` = [B, N, F, T]
  attention_probs = tf.nn.softmax(attention_scores)

  # This is actually dropping out entire tokens to attend to, which might
  # seem a bit unusual, but is taken from the original Transformer paper.
  attention_probs = dropout(attention_probs, attention_probs_dropout_prob)

  # `value_layer` = [B, T, N, H]
  value_layer = tf.reshape(
      value_layer,
      [batch_size, to_seq_length, num_attention_heads, size_per_head])

  # `value_layer` = [B, N, T, H]
  value_layer = tf.transpose(value_layer, [0, 2, 1, 3])

  # `context_layer` = [B, N, F, H]
  context_layer = tf.matmul(attention_probs, value_layer)

  # `context_layer` = [B, F, N, H]
  context_layer = tf.transpose(context_layer, [0, 2, 1, 3])

  if do_return_2d_tensor:
    # `context_layer` = [B*F, N*H]
    context_layer = tf.reshape(
        context_layer,
        [batch_size * from_seq_length, num_attention_heads * size_per_head])
  else:
    # `context_layer` = [B, F, N*H]
    context_layer = tf.reshape(
        context_layer,
        [batch_size, from_seq_length, num_attention_heads * size_per_head])

  return context_layer


def transformer_model(input_tensor,
                      attention_mask=None,
                      hidden_size=768,
                      num_hidden_layers=12,
                      num_attention_heads=12,
                      intermediate_size=3072,
                      intermediate_act_fn=gelu,
                      hidden_dropout_prob=0.1,
                      attention_probs_dropout_prob=0.1,
                      initializer_range=0.02,
                      do_return_all_layers=False):
  """Multi-headed, multi-layer Transformer from "Attention is All You Need".

  This is almost an exact implementation of the original Transformer encoder.

  See the original paper:
  https://arxiv.org/abs/1706.03762

  Also see:
  https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py

  Args:
    input_tensor: float Tensor of shape [batch_size, seq_length, hidden_size].
    attention_mask: (optional) int32 Tensor of shape [batch_size, seq_length,
      seq_length], with 1 for positions that can be attended to and 0 in
      positions that should not be.
    hidden_size: int. Hidden size of the Transformer.
    num_hidden_layers: int. Number of layers (blocks) in the Transformer.
    num_attention_heads: int. Number of attention heads in the Transformer.
    intermediate_size: int. The size of the "intermediate" (a.k.a., feed
      forward) layer.
    intermediate_act_fn: function. The non-linear activation function to apply
      to the output of the intermediate/feed-forward layer.
    hidden_dropout_prob: float. Dropout probability for the hidden layers.
    attention_probs_dropout_prob: float. Dropout probability of the attention
      probabilities.
    initializer_range: float. Range of the initializer (stddev of truncated
      normal).
    do_return_all_layers: Whether to also return all layers or just the final
      layer.

  Returns:
    float Tensor of shape [batch_size, seq_length, hidden_size], the final
    hidden layer of the Transformer.

  Raises:
    ValueError: A Tensor shape or parameter is invalid.
  """
  if hidden_size % num_attention_heads != 0:
    raise ValueError(
        "The hidden size (%d) is not a multiple of the number of attention "
        "heads (%d)" % (hidden_size, num_attention_heads))

  attention_head_size = int(hidden_size / num_attention_heads)
  input_shape = get_shape_list(input_tensor, expected_rank=3)
  batch_size = input_shape[0]
  seq_length = input_shape[1]
  input_width = input_shape[2]

  # The Transformer performs sum residuals on all layers so the input needs
  # to be the same as the hidden size.
  if input_width != hidden_size:
    raise ValueError("The width of the input tensor (%d) != hidden size (%d)" %
                     (input_width, hidden_size))

  # We keep the representation as a 2D tensor to avoid re-shaping it back and
  # forth from a 3D tensor to a 2D tensor. Re-shapes are normally free on
  # the GPU/CPU but may not be free on the TPU, so we want to minimize them to
  # help the optimizer.
  prev_output = reshape_to_matrix(input_tensor)

  all_layer_outputs = []
  for layer_idx in range(num_hidden_layers):
    with tf.compat.v1.variable_scope("layer_%d" % layer_idx):
      layer_input = prev_output

      with tf.compat.v1.variable_scope("attention"):
        attention_heads = []
        with tf.compat.v1.variable_scope("self"):
          attention_head = attention_layer(
              from_tensor=layer_input,
              to_tensor=layer_input,
              attention_mask=attention_mask,
              num_attention_heads=num_attention_heads,
              size_per_head=attention_head_size,
              attention_probs_dropout_prob=attention_probs_dropout_prob,
              initializer_range=initializer_range,
              do_return_2d_tensor=True,
              batch_size=batch_size,
              from_seq_length=seq_length,
              to_seq_length=seq_length)
          attention_heads.append(attention_head)
    
        attention_output = None
        if len(attention_heads) == 1:
          attention_output = attention_heads[0]
        else:
          # In the case where we have other sequences, we just concatenate
          # them to the self-attention head before the projection.
          attention_output = tf.concat(attention_heads, axis=-1)
    
        # Run a linear projection of `hidden_size` then add a residual
        # with `layer_input`.
        with tf.compat.v1.variable_scope("output"):
          attention_output = tf.compat.v1.layers.dense(
              attention_output,
              hidden_size,
              kernel_initializer=create_initializer(initializer_range))
          attention_output = dropout(attention_output, hidden_dropout_prob)
          attention_output = layer_norm(attention_output + layer_input)
    
      # The activation is only applied to the "intermediate" hidden layer.
      with tf.compat.v1.variable_scope("intermediate"):
        intermediate_output = tf.compat.v1.layers.dense(
            attention_output,
            intermediate_size,
            activation=intermediate_act_fn,
            kernel_initializer=create_initializer(initializer_range))
    
      # Down-project back to `hidden_size` then add the residual.
      with tf.compat.v1.variable_scope("output"):
        layer_output = tf.compat.v1.layers.dense(
            intermediate_output,
            hidden_size,
            kernel_initializer=create_initializer(initializer_range))
        layer_output = dropout(layer_output, hidden_dropout_prob)
        layer_output = layer_norm(layer_output + attention_output)
        prev_output = layer_output
        all_layer_outputs.append(layer_output)

  if do_return_all_layers:
    final_outputs = []
    for layer_output in all_layer_outputs:
      final_output = reshape_from_matrix(layer_output, input_shape)
      final_outputs.append(final_output)
    return final_outputs
  else:
    final_output = reshape_from_matrix(prev_output, input_shape)
    return final_output


def get_shape_list(tensor, expected_rank=None, name=None):
  """Returns a list of the shape of tensor, preferring static dimensions.

  Args:
    tensor: A tf.Tensor object to find the shape of.
    expected_rank: (optional) int. The expected rank of `tensor`. If this is
      specified and the `tensor` has a different rank, and exception will be
      thrown.
    name: Optional name of the tensor for the error message.

  Returns:
    A list of dimensions of the shape of tensor. All static dimensions will
    be returned as python integers, and dynamic dimensions will be returned
    as tf.Tensor scalars.
  """
  if name is None:
    name = tensor.name

  if expected_rank is not None:
    assert_rank(tensor, expected_rank, name)

  shape = tensor.shape.as_list()

  non_static_indexes = []
  for (index, dim) in enumerate(shape):
    if dim is None:
      non_static_indexes.append(index)

  if not non_static_indexes:
    return shape

  dyn_shape = tf.shape(tensor)
  for index in non_static_indexes:
    shape[index] = dyn_shape[index]
  return shape


def reshape_to_matrix(input_tensor):
  """Reshapes a >= rank 2 tensor to a rank 2 tensor (i.e., a matrix)."""
  ndims = input_tensor.shape.ndims
  if ndims < 2:
    raise ValueError("Input tensor must have at least rank 2. Shape = %s" %
                     (input_tensor.shape))
  if ndims == 2:
    return input_tensor

  width = input_tensor.shape[-1]
  output_tensor = tf.reshape(input_tensor, [-1, width])
  return output_tensor


def reshape_from_matrix(output_tensor, orig_shape_list):
  """Reshapes a rank 2 tensor back to its original rank >= 2 tensor."""
  if len(orig_shape_list) == 2:
    return output_tensor

  output_shape = get_shape_list(output_tensor)

  orig_dims = orig_shape_list[0:-1]
  width = output_shape[-1]

  return tf.reshape(output_tensor, orig_dims + [width])


def assert_rank(tensor, expected_rank, name=None):
  """Raises an exception if the tensor rank is not of the expected rank.

  Args:
    tensor: A tf.Tensor to check the rank of.
    expected_rank: Python integer or list of integers, expected rank.
    name: Optional name of the tensor for the error message.

  Raises:
    ValueError: If the expected shape doesn't match the actual shape.
  """
  if name is None:
    name = tensor.name

  expected_rank_dict = {}
  if isinstance(expected_rank, six.integer_types):
    expected_rank_dict[expected_rank] = True
  else:
    for x in expected_rank:
      expected_rank_dict[x] = True

  actual_rank = tensor.shape.ndims
  if actual_rank not in expected_rank_dict:
    scope_name = tf.compat.v1.get_variable_scope().name
    raise ValueError(
        "For the tensor `%s` in scope `%s`, the actual rank "
        "`%d` (shape = %s) is not equal to the expected rank `%s`" %
        (name, scope_name, actual_rank, str(tensor.shape), str(expected_rank)))

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </=></=></=></=></=></=></=></=></=></=></=></=></=>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Natural Language Processing</category>
        <category>Bert</category>
        <category>Tensorflow 2.6</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Bert</tag>
        <tag>Natural Language Processing</tag>
        <tag>Tensorflow 2.6</tag>
      </tags>
  </entry>
  <entry>
    <title>crash分析类指标详解</title>
    <url>/2019/05/19/crash%E5%88%86%E6%9E%90%E7%B1%BB%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


**1) 错误次数** 
**定义**：在规定的时间段内，应用出现异常退出现象的次数总和。 
**涵义**：通常情况下，应用错误集中于两种：死机或强退，这样的现象都会严重影响用户体验，所以错误次数发生的越高，用户体验越差。降低错误次数是开发者应该时刻关注的重要指标。 
**2) 错误率** 
**定义**：在规定时间段内，一个应用发生错误的比率（错误次数/启动次数）。 
**涵义**：产品质量是一个应用发展壮大的基石，与网站不同，移动应用一旦被分发之后就无法再收回，应用错误率高会降低用户对产品的信任和口碑。通过对应用的质量监控，找到错误代码并及时发布修复版本，可以有效弥补这一问题。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据产品</category>
        <category>数据指标</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据指标</tag>
      </tags>
  </entry>
  <entry>
    <title>ToB产品的一些认知</title>
    <url>/2020/02/02/ToB%E4%BA%A7%E5%93%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# ToB产品

## ToB产品方法论

### PMF(Product-Market Fit)

#### 市场构成的四要素

- 客户群体
  - 互联网客户 --->>>互联网+（传统客户）
- 需求痛点
  - 客户需求到底是什么
  - 从单品极致--->>>产品矩阵

- 商业模式
  - 从license--->>> 订阅制；倒逼产品优化
- 竞争态势
  - 市场环境变化
  - 投资/并购/政策影响

### 打造ToB产品的四大原则

- 把事情做到极致
- 坚持产品化：能用产品解决，就不要用服务去解决；
  - 由于越靠后 越依赖于人，依赖于高阶的人
- 不卖期货，只卖已有产品功能，和三个月内即将上线的产品功能

- 面向价值交付的产品迭代
  - ToB产品发布即交付的开始
    - 需要重点考虑价值交付流程
  - ToC产品发布即交付

## ToB产品营销方法论

### 市场-获取线索

- 全栈式营销团队
- 潜客管理
- 全生命周期培育

市场营销的关键：让客户更主动

### 销售-转化线索

- 顾问式销售
- 效率提升工具
- ToB营销全漏斗
- Hunter

### 客户服务

- Farmer 

- 续约与复购
- 交叉销售
- 口碑营销

## ToB产品客户服务方法论

- 强化服务体系，就是强化销售

## ToB核心“产品”+“人”




---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>ToB产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>ToB产品</tag>
      </tags>
  </entry>
  <entry>
    <title>广告投放中的CTR预估模型</title>
    <url>/2021/03/28/ctr-predict/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 广告投放中的CTR预估模型

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import gc

import os

import lightgbm as lgb
```

## 数据清洗

```python
import numpy as np
import pandas as pd
import sklearn
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import gc

import os

import lightgbm as lgb
```


```python
data_path = './datasets/'
```


```python
train = pd.read_csv(os.path.join(data_path,'train.csv'))
```


```python
test = pd.read_csv(os.path.join(data_path,'test.csv'))
```

特征字段	字段描述
id	用户行为id，唯一表示，无重复
date	行为时间，精确到秒
user_id	用户id
product	产品
campaign_id	活动id
webpage_id	网页id
product_category_id	产品类型id
user_group_id	用户所属群组id
gender	性别
age_level	年龄等级
user_depth	用户价值深度
var_1	匿名特征
isClick	是否点击，1为点击，0为未点击


```python
train
```



```python
test
```



```python
data = pd.concat([train,test],ignore_index=True)
```


```python
data
```




```python
data['day_id'] = data['date'].apply(lambda x:int(x[3:5]))
```


```python
data['minute_id']=data['date'].apply(lambda x:int(x[-5:-3])*60 + int(x[-2:]))
```


```python
data
```


## 特征工程

#### 构建用户每天前后两次浏览行为之间的时间间隔及其衍生均值特征, 因为用户浏览时间往往和其是否点击具有相关性


```python
data['minute_id'].shift(-1)
```


    0            0.0
    1            0.0
    2            0.0
    3            1.0
    4            1.0
               ...  
    463286    1439.0
    463287    1439.0
    463288    1439.0
    463289    1439.0
    463290       NaN
    Name: minute_id, Length: 463291, dtype: float64


```python
data.groupby(['user_id','day_id'])['minute_id'].apply(lambda x :x.shift(-1) -x)
```


    0         NaN
    1         0.0
    2         2.0
    3         NaN
    4         NaN
             ... 
    463286    NaN
    463287    NaN
    463288    0.0
    463289    NaN
    463290    NaN
    Name: minute_id, Length: 463291, dtype: float64


```python
data.groupby(['user_id','day_id'])['minute_id'].agg(lambda x :x.shift(-1) -x)
```


    user_id  day_id
    0        2                                              NaN
             6                                              NaN
    1        2                                  [0.0, 2.0, nan]
    2        2                                              NaN
             3         [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 6.0, nan]
                                         ...                   
    150342   7                                       [0.0, nan]
    150343   7                                              NaN
    150344   7                                              NaN
    150345   7                                              NaN
    150346   7                                       [0.0, nan]
    Name: minute_id, Length: 249625, dtype: object


```python
data.groupby(['user_id','day_id'])['minute_id'].transform(lambda x :x.shift(-1) -x)
```


    0         NaN
    1         0.0
    2         2.0
    3         NaN
    4         NaN
             ... 
    463286    NaN
    463287    NaN
    463288    0.0
    463289    NaN
    463290    NaN
    Name: minute_id, Length: 463291, dtype: float64


```python
data['minute_id_diff'] = data.groupby(['user_id','day_id'])['minute_id'].transform(lambda x :x.shift(-1) -x)
```


```python
data.groupby(['user_id','day_id'])['minute_id_diff'].transform('mean')
```


    0           NaN
    1           1.0
    2           1.0
    3           NaN
    4           NaN
              ...  
    463286      NaN
    463287     34.0
    463288    154.8
    463289    154.8
    463290     26.0
    Name: minute_id_diff, Length: 463291, dtype: float64




```python
data.groupby(['user_id','day_id'])['minute_id_diff'].agg('mean')
```


    user_id  day_id
    0        2              NaN
             6              NaN
    1        2         1.000000
    2        2              NaN
             3         1.142857
                         ...   
    150342   7         0.000000
    150343   7              NaN
    150344   7              NaN
    150345   7              NaN
    150346   7         0.000000
    Name: minute_id_diff, Length: 249625, dtype: float64




```python
data.groupby(['user_id','day_id'])['minute_id_diff'].mean()
```


    user_id  day_id
    0        2              NaN
             6              NaN
    1        2         1.000000
    2        2              NaN
             3         1.142857
                         ...   
    150342   7         0.000000
    150343   7              NaN
    150344   7              NaN
    150345   7              NaN
    150346   7         0.000000
    Name: minute_id_diff, Length: 249625, dtype: float64




```python
data['minute_id_diff_mean'] = data.groupby(['user_id','day_id'])['minute_id_diff'].transform('mean')
```


```python
for col in ['user_id','product','campaign_id','webpage_id','product_category_id','user_group_id']:
    data['{}_count'.format(col)] = data.groupby(col)['minute_id'].transform('count')
    
```


```python
data.columns
```


    Index(['id', 'date', 'user_id', 'product', 'campaign_id', 'webpage_id',
           'product_category_id', 'user_group_id', 'gender', 'age_level',
           'user_depth', 'var_1', 'isClick', 'day_id', 'minute_id',
           'minute_id_diff', 'minute_id_diff_mean', 'user_id_count',
           'product_count', 'campaign_id_count', 'webpage_id_count',
           'product_category_id_count', 'user_group_id_count'],
          dtype='object')


```python
ycol = 'isClick'
drop_list = [
    ycol,
    'id',
    'date'
]

features = [x for x in data.columns if x not in drop_list]
```


```python
print("使用{} 个特征:{}".format(len(features),features))
```

    使用20 个特征:['user_id', 'product', 'campaign_id', 'webpage_id', 'product_category_id', 'user_group_id', 'gender', 'age_level', 'user_depth', 'var_1', 'day_id', 'minute_id', 'minute_id_diff', 'minute_id_diff_mean', 'user_id_count', 'product_count', 'campaign_id_count', 'webpage_id_count', 'product_category_id_count', 'user_group_id_count']

```python
# 下列特征转化为类别特征
categorical_feature = [
    'user_id',
    'product',
    'campaign_id',
    'webpage_id',
    'product_category_id',
    'user_group_id',
    'gender',
    'age_level',
    'user_depth',
]

for col in categorical_feature:
    data[col] = data[col].astype('category')
```


```python
train = data[~data[ycol].isnull()]
```


```python
test = data[data[ycol].isnull()]
```


```python
train.shape
```


    (391825, 23)


```python
test.shape
```


    (71466, 23)


```python
del(data)
```


```python
gc.collect()
```


    0




## 五折交叉验证训练模型



```python
NFLOD =5
random_state = 2021
KF = StratifiedKFold(n_splits = NFLOD,shuffle=True,random_state=random_state)

params_lgb = {
    'boosting':'gbdt',
    'objective':'binary',
    'metric':'auc',
    'force_row_size':True,
    'random_state':random_state,
    'learning_rate':0.03,
    'max_depth':8,
    'num_leaves':40,
    'subsamples':0.8,
    'subsample_freq':3,
    'colsample_bytree':0.8,
    'n_jobs':-1,
    'verbose':-1
}
```


```python
oof_lgb = np.zeros(len(train))
```


```python
predictions_lgb = np.zeros(len(test))
```


```python
df_importance_list = []
```


```python
# 五折交叉验证
for fold_,(trn_idx,val_idx) in enumerate(KF.split(train[features],train[ycol])):
    print('------------fold{}-----------'.format(fold_ + 1))
    trn_data = lgb.Dataset(train.iloc[trn_idx][features] , label=train.iloc[trn_idx][ycol])
    val_data = lgb.Dataset(train.iloc[val_idx][features], label=train.iloc[val_idx][ycol],reference=trn_data)
    
    clf_lgb = lgb.train(
        params = params_lgb,
        train_set = trn_data,
        valid_sets = [trn_data,val_data],
        valid_names = ('train','val'),
        num_boost_round = 50000,
        early_stopping_rounds = 200,
        verbose_eval = 100,
    )
    
    oof_lgb[val_idx] = clf_lgb.predict(train.iloc[val_idx][features],num_iteration=clf_lgb.best_iteration)
    predictions_lgb[:] += (clf_lgb.predict(test[features],num_iteration = clf_lgb.best_iteration)/ NFLOD)
    
    df_importance = pd.DataFrame({
        'column':features,
        'importance_split':clf_lgb.feature_importance(importance_type = 'split'),
        'importance_gain':clf_lgb.feature_importance(importance_type = 'gain')
    })
    
    df_importance_list.append(df_importance)
```

    ------------fold1-----------
    [LightGBM] [Warning] Unknown parameter: subsamples
    [LightGBM] [Warning] Unknown parameter: force_row_size


    /Users/gaozhiyong/Documents/pyenv/pyenv3.6/lib/python3.6/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.
      _log_warning('Overriding the parameters from Reference Dataset.')
    /Users/gaozhiyong/Documents/pyenv/pyenv3.6/lib/python3.6/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.
      _log_warning('{} in param dict is overridden.'.format(cat_alias))


    Training until validation scores don't improve for 200 rounds
    [100]	train's auc: 0.677174	val's auc: 0.628599
    [200]	train's auc: 0.690672	val's auc: 0.63003
    [300]	train's auc: 0.702212	val's auc: 0.631905
    [400]	train's auc: 0.711116	val's auc: 0.632443
    [500]	train's auc: 0.7182	val's auc: 0.632929
    [600]	train's auc: 0.725516	val's auc: 0.632789
    Early stopping, best iteration is:
    [499]	train's auc: 0.718131	val's auc: 0.632934
    ------------fold2-----------
    [LightGBM] [Warning] Unknown parameter: subsamples
    [LightGBM] [Warning] Unknown parameter: force_row_size
    Training until validation scores don't improve for 200 rounds
    [100]	train's auc: 0.679197	val's auc: 0.620851
    [200]	train's auc: 0.693258	val's auc: 0.622213
    [300]	train's auc: 0.703885	val's auc: 0.623473
    [400]	train's auc: 0.714255	val's auc: 0.62404
    [500]	train's auc: 0.720288	val's auc: 0.624115
    [600]	train's auc: 0.726659	val's auc: 0.624428
    [700]	train's auc: 0.732689	val's auc: 0.624295
    [800]	train's auc: 0.73929	val's auc: 0.624619
    [900]	train's auc: 0.744832	val's auc: 0.624663
    [1000]	train's auc: 0.754675	val's auc: 0.62499
    [1100]	train's auc: 0.759126	val's auc: 0.624757
    [1200]	train's auc: 0.763615	val's auc: 0.62502
    [1300]	train's auc: 0.769984	val's auc: 0.624564
    Early stopping, best iteration is:
    [1164]	train's auc: 0.761882	val's auc: 0.625101
    ------------fold3-----------
    [LightGBM] [Warning] Unknown parameter: subsamples
    [LightGBM] [Warning] Unknown parameter: force_row_size
    Training until validation scores don't improve for 200 rounds
    [100]	train's auc: 0.677937	val's auc: 0.623831
    [200]	train's auc: 0.691909	val's auc: 0.6257
    [300]	train's auc: 0.702329	val's auc: 0.626483
    [400]	train's auc: 0.712792	val's auc: 0.626889
    [500]	train's auc: 0.719476	val's auc: 0.627282
    [600]	train's auc: 0.726372	val's auc: 0.627444
    [700]	train's auc: 0.732891	val's auc: 0.627488
    [800]	train's auc: 0.739184	val's auc: 0.627696
    [900]	train's auc: 0.747272	val's auc: 0.62776
    Early stopping, best iteration is:
    [756]	train's auc: 0.736675	val's auc: 0.627805
    ------------fold4-----------
    [LightGBM] [Warning] Unknown parameter: subsamples
    [LightGBM] [Warning] Unknown parameter: force_row_size
    Training until validation scores don't improve for 200 rounds
    [100]	train's auc: 0.678244	val's auc: 0.632375
    [200]	train's auc: 0.693808	val's auc: 0.633363
    [300]	train's auc: 0.703073	val's auc: 0.633338
    [400]	train's auc: 0.712667	val's auc: 0.633605
    Early stopping, best iteration is:
    [212]	train's auc: 0.695547	val's auc: 0.633654
    ------------fold5-----------
    [LightGBM] [Warning] Unknown parameter: subsamples
    [LightGBM] [Warning] Unknown parameter: force_row_size
    Training until validation scores don't improve for 200 rounds
    [100]	train's auc: 0.677896	val's auc: 0.627158
    [200]	train's auc: 0.692087	val's auc: 0.628503
    [300]	train's auc: 0.701904	val's auc: 0.62927
    [400]	train's auc: 0.711159	val's auc: 0.629929
    [500]	train's auc: 0.718229	val's auc: 0.629463
    [600]	train's auc: 0.725839	val's auc: 0.629527
    Early stopping, best iteration is:
    [401]	train's auc: 0.711302	val's auc: 0.630001



```python
valid_auc_score = roc_auc_score(train[ycol],oof_lgb)
```


```python
valid_auc_score
```




    0.629614298701527



## 特征重要性



```python
df_features_importances= pd.concat(df_importance_list)
```


```python
df_features_importance= df_features_importances.groupby('column').mean().reset_index()
```


```python
df_features_importance
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column</th>
      <th>importance_split</th>
      <th>importance_gain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>age_level</td>
      <td>40.2</td>
      <td>407.363945</td>
    </tr>
    <tr>
      <th>1</th>
      <td>campaign_id</td>
      <td>565.6</td>
      <td>17419.711442</td>
    </tr>
    <tr>
      <th>2</th>
      <td>campaign_id_count</td>
      <td>1049.4</td>
      <td>5384.477741</td>
    </tr>
    <tr>
      <th>3</th>
      <td>day_id</td>
      <td>1194.6</td>
      <td>9639.523684</td>
    </tr>
    <tr>
      <th>4</th>
      <td>gender</td>
      <td>54.6</td>
      <td>253.445407</td>
    </tr>
    <tr>
      <th>5</th>
      <td>minute_id</td>
      <td>3935.8</td>
      <td>22181.027330</td>
    </tr>
    <tr>
      <th>6</th>
      <td>minute_id_diff</td>
      <td>3431.4</td>
      <td>23767.593485</td>
    </tr>
    <tr>
      <th>7</th>
      <td>minute_id_diff_mean</td>
      <td>3201.4</td>
      <td>21643.519522</td>
    </tr>
    <tr>
      <th>8</th>
      <td>product</td>
      <td>489.6</td>
      <td>6321.783218</td>
    </tr>
    <tr>
      <th>9</th>
      <td>product_category_id</td>
      <td>176.8</td>
      <td>2965.427346</td>
    </tr>
    <tr>
      <th>10</th>
      <td>product_category_id_count</td>
      <td>970.4</td>
      <td>6571.430858</td>
    </tr>
    <tr>
      <th>11</th>
      <td>product_count</td>
      <td>1215.4</td>
      <td>7685.000637</td>
    </tr>
    <tr>
      <th>12</th>
      <td>user_depth</td>
      <td>151.4</td>
      <td>900.218823</td>
    </tr>
    <tr>
      <th>13</th>
      <td>user_group_id</td>
      <td>395.0</td>
      <td>3675.279637</td>
    </tr>
    <tr>
      <th>14</th>
      <td>user_group_id_count</td>
      <td>610.2</td>
      <td>3107.873730</td>
    </tr>
    <tr>
      <th>15</th>
      <td>user_id</td>
      <td>3435.2</td>
      <td>67579.315769</td>
    </tr>
    <tr>
      <th>16</th>
      <td>user_id_count</td>
      <td>2032.4</td>
      <td>31719.678195</td>
    </tr>
    <tr>
      <th>17</th>
      <td>var_1</td>
      <td>248.8</td>
      <td>1597.959461</td>
    </tr>
    <tr>
      <th>18</th>
      <td>webpage_id</td>
      <td>91.6</td>
      <td>2045.332514</td>
    </tr>
    <tr>
      <th>19</th>
      <td>webpage_id_count</td>
      <td>359.8</td>
      <td>1744.924732</td>
    </tr>
  </tbody>
</table>



```python
df_features_importance.sort_values('importance_gain',ascending=False)
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>column</th>
      <th>importance_split</th>
      <th>importance_gain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>15</th>
      <td>user_id</td>
      <td>3435.2</td>
      <td>67579.315769</td>
    </tr>
    <tr>
      <th>16</th>
      <td>user_id_count</td>
      <td>2032.4</td>
      <td>31719.678195</td>
    </tr>
    <tr>
      <th>6</th>
      <td>minute_id_diff</td>
      <td>3431.4</td>
      <td>23767.593485</td>
    </tr>
    <tr>
      <th>5</th>
      <td>minute_id</td>
      <td>3935.8</td>
      <td>22181.027330</td>
    </tr>
    <tr>
      <th>7</th>
      <td>minute_id_diff_mean</td>
      <td>3201.4</td>
      <td>21643.519522</td>
    </tr>
    <tr>
      <th>1</th>
      <td>campaign_id</td>
      <td>565.6</td>
      <td>17419.711442</td>
    </tr>
    <tr>
      <th>3</th>
      <td>day_id</td>
      <td>1194.6</td>
      <td>9639.523684</td>
    </tr>
    <tr>
      <th>11</th>
      <td>product_count</td>
      <td>1215.4</td>
      <td>7685.000637</td>
    </tr>
    <tr>
      <th>10</th>
      <td>product_category_id_count</td>
      <td>970.4</td>
      <td>6571.430858</td>
    </tr>
    <tr>
      <th>8</th>
      <td>product</td>
      <td>489.6</td>
      <td>6321.783218</td>
    </tr>
    <tr>
      <th>2</th>
      <td>campaign_id_count</td>
      <td>1049.4</td>
      <td>5384.477741</td>
    </tr>
    <tr>
      <th>13</th>
      <td>user_group_id</td>
      <td>395.0</td>
      <td>3675.279637</td>
    </tr>
    <tr>
      <th>14</th>
      <td>user_group_id_count</td>
      <td>610.2</td>
      <td>3107.873730</td>
    </tr>
    <tr>
      <th>9</th>
      <td>product_category_id</td>
      <td>176.8</td>
      <td>2965.427346</td>
    </tr>
    <tr>
      <th>18</th>
      <td>webpage_id</td>
      <td>91.6</td>
      <td>2045.332514</td>
    </tr>
    <tr>
      <th>19</th>
      <td>webpage_id_count</td>
      <td>359.8</td>
      <td>1744.924732</td>
    </tr>
    <tr>
      <th>17</th>
      <td>var_1</td>
      <td>248.8</td>
      <td>1597.959461</td>
    </tr>
    <tr>
      <th>12</th>
      <td>user_depth</td>
      <td>151.4</td>
      <td>900.218823</td>
    </tr>
    <tr>
      <th>0</th>
      <td>age_level</td>
      <td>40.2</td>
      <td>407.363945</td>
    </tr>
    <tr>
      <th>4</th>
      <td>gender</td>
      <td>54.6</td>
      <td>253.445407</td>
    </tr>
  </tbody>
</table>


## 预测


```python
test.head()
```



```python
test.columns
```


    Index(['id', 'date', 'user_id', 'product', 'campaign_id', 'webpage_id',
           'product_category_id', 'user_group_id', 'gender', 'age_level',
           'user_depth', 'var_1', 'isClick', 'day_id', 'minute_id',
           'minute_id_diff', 'minute_id_diff_mean', 'user_id_count',
           'product_count', 'campaign_id_count', 'webpage_id_count',
           'product_category_id_count', 'user_group_id_count'],
          dtype='object')


```python
test.loc[:,ycol] = predictions_lgb
```

    /Users/gaozhiyong/Documents/pyenv/pyenv3.6/lib/python3.6/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      isetter(ilocs[0], value)



```python
test.loc[:,ycol]
```


    391825    0.082708
    391826    0.084275
    391827    0.046645
    391828    0.050657
    391829    0.126505
                ...   
    463286    0.079529
    463287    0.041204
    463288    0.046967
    463289    0.048984
    463290    0.078428
    Name: isClick, Length: 71466, dtype: float64


```python
test[['id',ycol]]
```

## 保存预测结果

```python
test[['user_id','product','campaign_id',ycol]].to_csv('res.csv',index=False)
```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>CTR</tag>
      </tags>
  </entry>
  <entry>
    <title>vscode中flutter找不到device</title>
    <url>/2019/10/01/flutter%E6%89%BE%E4%B8%8D%E5%88%B0%E8%AE%BE%E5%A4%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## vscode中flutter找不到device

昨天还在好好的运行flutter，今天跑vscode却找不到设备了，select也找不到

解决方案：

1、在vscode的terminal内输入flutter emulators

```shell
gaozhiyongdeMacBook-Pro:lemon gaozhiyong$ flutter emulators
2 available emulators:

Nexus_5X_API_29_x86 • Nexus 5X API 29 x86 • Google • android
apple_ios_simulator • iOS Simulator       • Apple  • ios

To run an emulator, run 'flutter emulators --launch <emulator id>'.
To create a new emulator, run 'flutter emulators --create [--name xyz]'.

You can find more information on managing emulators at the links below:
  https://developer.android.com/studio/run/managing-avds
  https://developer.android.com/studio/command-line/avdmanager
```

2、在vscode的terminal内输入flutter emulators --launch apple_ios_simulator

即可启用对应的设备



完整命令如下：

```shell
flutter emulators

flutter emulators --launch apple_ios_simulator
```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </emulator>]]></content>
      <categories>
        <category>移动开发</category>
        <category>flutter</category>
      </categories>
      <tags>
        <tag>移动开发</tag>
        <tag>flutter</tag>
      </tags>
  </entry>
  <entry>
    <title>echarts数据可视化</title>
    <url>/2020/02/10/echart%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## echarts数据可视化

**简介**

ECharts，一个使用 JavaScript 实现的开源可视化库，可以流畅的运行在 PC 和移动设备上，兼容当前绝大部分浏览器（IE8/9/10/11，Chrome，Firefox，Safari等），底层依赖矢量图形库 [ZRender](https://github.com/ecomfe/zrender)，提供直观，交互丰富，可高度个性化定制的数据可视化图表。

**丰富的可视化类型**

ECharts 提供了常规的[折线图](https://echarts.apache.org/zh/option.html#series-line)、[柱状图](https://echarts.apache.org/zh/option.html#series-bar)、[散点图](https://echarts.apache.org/zh/option.html#series-scatter)、[饼图](https://echarts.apache.org/zh/option.html#series-pie)、[K线图](https://echarts.apache.org/zh/option.html#series-candlestick)，用于统计的[盒形图](https://echarts.apache.org/zh/option.html#series-boxplot)，用于地理数据可视化的[地图](https://echarts.apache.org/zh/option.html#series-map)、[热力图](https://echarts.apache.org/zh/option.html#series-heatmap)、[线图](https://echarts.apache.org/zh/option.html#series-lines)，用于关系数据可视化的[关系图](https://echarts.apache.org/zh/option.html#series-graph)、[treemap](https://echarts.apache.org/zh/option.html#series-treemap)、[旭日图](https://echarts.apache.org/zh/option.html#series-sunburst)，多维数据可视化的[平行坐标](https://echarts.apache.org/zh/option.html#series-parallel)，还有用于 BI 的[漏斗图](https://echarts.apache.org/zh/option.html#series-funnel)，[仪表盘](https://echarts.apache.org/zh/option.html#series-gauge)，并且支持图与图之间的混搭。

![](echart数据可视化/index.jpg)

## 快速上手echarts

### 引入echarts

```html
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ECHARTS</title>
    <script src="https://cdn.jsdelivr.net/npm/echarts@4.6.0/dist/echarts.js"></script>
</head>
```

### 绘制一个简单图表

```html
<!-- 柱形图 -->
<body>
  <div id="bar-01" style="width: 400px;height: 300px;">
  </div>
  <script type="text/javascript">
    var barCahrt = echarts.init(document.getElementById('bar-01'));
    var option1 = {
            title: {
                text: "第一个柱形图"
            },
            tooltip: {},
            legend: {
                data: ["销量"],
            },
            xAxis: {
                data: ["衬衫", "羊毛衫", "雪纺衫", "裤子", "高跟鞋", "袜子"],
            },
            yAxis: {
            },

            series: {
                name: "销量",
                type: "bar",
                data: [
                    5, 20, 36, 10, 10, 20
                ],
            },
      };     
    
  </script>
  
</body>
```

<img src="/.top//bar.jpg" style="zoom:50%;">

```html
<div id="pie-01" style="width: 400px;height: 300px;"></div>
<script type="text/javascript">
  var pieChart = echarts.init(document.getElementById("pie-01"));
  //饼图数据
        var option2 = {
            title: {
                text: "第一个饼图"
            },
            tooltip: {},
            legend: {
                data: ["A", "B", "C"],
            },
            series: {
                type: "pie",
                data: [
                    { name: "A", value: 1231 },
                    { name: "B", value: 2323 },
                    { name: "C", value: 1919 },
                ],
            },
        };

</script>
```

<img src="/.top//pie.jpg" style="zoom:50%;">

```html
<div id="line-01" style="width: 400px;height: 300px;"></div>
<script>
  var lineChart = echarts.init(document.getElementById("line-01"));
  //折线图数据
        var option3 = {
            title: {
                text: "第一个折线图",
            },
            tooltip: {},
            legend: {
                data: ["数量"],
            },
            toolbox: {
                feature: {
                    dataView: {},
                    saveAsImage: {
                        pixelRadio: 2,
                    },
                    restore: {},
                },
            },
            xAxis: {
            },
            yAxis: {
            },
            series: [{
                type: "line",
                smooth: true,
                name: ["数量"],
                data: [
                    [12, 5],
                    [24, 20],
                    [36, 36],
                    [48, 10],
                    [60, 10],
                    [72, 20]
                ],
            }],
        };

</script>
```

<img src="/.top//line.jpg" style="zoom:50%;">


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>数据可视化</category>
        <category>echarts</category>
      </categories>
      <tags>
        <tag>数据可视化</tag>
        <tag>echarts</tag>
      </tags>
  </entry>
  <entry>
    <title>iOS开发基础</title>
    <url>/2017/11/06/iOS%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## iOS开发基础

- 基础UI组件

- - UILabel
  - UIButton
  - UIView
  - UIWindow
  - UIViewVontroller
  - 定时器和视图移动
  - UISwitch
  - UISlider
  - UIProgressView
  - 步进器和分栏控件
  - UITextField
  - UIScrollView
  - UITouch
  - UIGesture手势
  - XIB控件

- 高级UI组件

- - 手动布局子视图

  - 自动布局子视图

  - 事件响应链

  - 导航控制器

  - - 基础
    - 切换

  - 导航栏和工具栏

  - 分栏控制器

  - - 基础
    - 高级

  - UIPickerView

  - NSUserDefults

  - 多界面传值

  - UITableView

  - - 基础

    - - dataSource 数据代理对象
      - delegate 普通代理对象
      - numberOfSectionsInTableView         获得组数协议
      - numberOfRowsInSection         获得行数协议
      - cellForRowAtIndexPath         创建单元格协议

    - 协议

    - - heightFOrRowAtIndexPath         : 获取单元格高度协议
      - heightForHeaderInSection         :数据视图头部高度协议
      - heightForFooterInSection         :数据视图尾部高度协议
      - titleForFooterInSection         :获取数据视图尾部标题协议
      - titleForHeaderInSection:数据视图头部标题协议

    - 高级协议

    - - commitEditingStyle         :提交编辑函数
      - canEditRowAtIndexPath         :开启关闭编辑单元格
      - editingStyleForRowAtIndexPath         :编辑单元格风格设定
      - didSelectRowAtIndexPath         :选中单元格响应协议
      - didDeselectRowAtIndexPath         :反选单元格响应协议

    - 单元格

    - - UITableViewCell         :数据视图单元格类型

      - - UITableViewCellEditingStyleDelete          :删除状态
        - UITableViewCellEditingStyleInsert          :插入状态
        - UITableViewCellEditingStyleNone:          没有状态
        - UITableViewCellEditingStyleDelete          || UITableViewCellEditingStyleInsert :多选状态

      - dequeueReusableCellWithIdentifier         : 获取可以复用的单元格对象

      - initWithStyle         : 根据风格创建单元格

      - reuseIdentifier         : 设置可以复用单元格的ID

- 数据存储

- - iOS json文件处理

  - - json文件格式（javaScript Object Notation）轻量级的数据交换格式

    - json语法规则

    - - key:value 键值对
      - 花括号保存对象（dict）
      - 方括号保存数组（array）

    - json数据解析

    - - SBJsonPaser         : JSON数据解析类
      - objectWithString:jsonString         : 解析字符串数据
      - NSJSONSerialization         : iOS JSON 解析类
      - JSONObjectWithData         : 通过二进制解析数据

  - iOS XML文件处理

  - - XML文件格式

- 网络编程

- - NSURLConnection网络连接

  - - NSURLRequest 创建请求对象
    - NSURLConnect 网络连接对象
    - didFailWithError 错误处理协议
    - didReceiveData 获取数据协议
    - connectionDidFinishLoading 加载数据完成协议

  - NSThread多线程

  - - 基本概念

    - - 实现并发操作
      - 线程池加锁，解锁
      - initWithTarget         : 创建线程
      - detachNewThreadSelector         :类方法创建并启动线程
      - lock ：线程加锁
      - unlock :线程解锁
      - sleepForTimeInterval         :线程休眠

  - NSOperation

  - AFNetmork网络库

- 多媒体基础

- - 音频播放
  - 视频播放
  - SDWebImage

- 动画

- - UIView动画基础

  - - setAnimationDelegate : 设置动画代理对象
    - setAnimationDuration :设施动画时间长度
    - setAnimationDelay :设置动画开始时长
    - setAnimationWillStartSelector        : 设置动画开始处理函数
    - setAnimationDidStopSelector :        设置动画结束处理函数

  - 导航控制器动画

  - - CATransition :动画对象
    - duration : 设置动画长度
    - type : 设置动画类型
    - timingFunction : 设置动画运动类型
    - subtype : 设置动画子类型

  - 高级动画

  - - HMGLTransitionManager : 动画管理器对象
    - DoorsTransition : 动画类型对象
    - setTransition : 设置动画类型
    - beginTransition : 设置动画开始运动
    - commitTransition : 提交启动动画

- 第三方框架库

- - cocoapods

- 项目管理工具


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>移动开发</category>
        <category>Native</category>
        <category>iOS</category>
      </categories>
      <tags>
        <tag>iOS</tag>
        <tag>Navtive</tag>
      </tags>
  </entry>
  <entry>
    <title>训练item2vec实现电影推荐</title>
    <url>/2022/01/15/item2vec%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 训练item2vec实现电影推荐





<iframe src="https://ocaeneyes.github.io/recommendPrj/训练item2vec进行电影推荐.html" width="100%" height="1080"></iframe>



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>推荐</tag>
        <tag>item2vec</tag>
      </tags>
  </entry>
  <entry>
    <title>php即时通讯-socket</title>
    <url>/2019/02/22/php%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF-socket/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### Socket

- 一个工具，一个接口
- 封装了TCP/IP 协议
- 建立长链接的基础]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM</title>
    <url>/2021/03/01/lstm/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## LSTM原理

## 一、基础介绍

### 1.1 神经网络模型

简单来说，常见的神经网络模型结构有前馈神经网络(DNN)、RNN（常用于文本 / 时间系列任务）、CNN（常用于图像任务）等等。具体可以看之前文章：[一文概览神经网络模型。](https://links.jianshu.com/go?to=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fovx_lj2rCrrTx8DeU03yjQ)

前馈神经网络是神经网络模型中最为常见的，信息从输入层开始输入，每层的神经元接收前一级输入，并输出到下一级，直至输出层。整个网络信息输入传输中无反馈（循环）。即任何层的输出都不会影响同级层，可用一个有向无环图表示。
[![img](https://camo.githubusercontent.com/b463c73dc5cb2fcd7c356c0aa1501cd44065cc7bf018ddc1e2ddc5252bb4b70d/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d633165616464353863386136356639622e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/b463c73dc5cb2fcd7c356c0aa1501cd44065cc7bf018ddc1e2ddc5252bb4b70d/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d633165616464353863386136356639622e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 1.2 RNN 介绍

循环神经网络（RNN）是基于序列数据（如语言、语音、时间序列）的递归性质而设计的，是一种反馈类型的神经网络，它专门用于处理序列数据，如逐字生成文本或预测时间序列数据(例如股票价格、诗歌生成)。
[![img](https://camo.githubusercontent.com/6f33cfec65bf836ce91e9040c5bff43defca9965eb37edf6911f17ba099176f7/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d316266373331313061656562306634642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/6f33cfec65bf836ce91e9040c5bff43defca9965eb37edf6911f17ba099176f7/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d316266373331313061656562306634642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

RNN和全连接神经网络的本质差异在于“输入是带有反馈信息的”，RNN除了接受每一步的输入x(t) ，同时还有输入上一步的历史反馈信息——隐藏状态h (t-1) ，也就是当前时刻的隐藏状态h(t) 或决策输出O(t) 由当前时刻的输入 x(t) 和上一时刻的隐藏状态h (t-1) 共同决定。从某种程度，RNN和大脑的决策很像，大脑接受当前时刻感官到的信息（外部的x(t) ）和之前的想法（内部的h (t-1) ）的输入一起决策。

[![img](https://camo.githubusercontent.com/5e1105f1d2a1295456d6f50bd8bdf0618ed1671c62438e2c40a2591ff59a18db/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d373366626538303433643163313034342e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/5e1105f1d2a1295456d6f50bd8bdf0618ed1671c62438e2c40a2591ff59a18db/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d373366626538303433643163313034342e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

RNN的结构原理可以简要概述为两个公式，具体介绍可以看下[【一文详解RNN】](http://mp.weixin.qq.com/s?__biz=MzI4MDE1NjExMQ==&mid=2247486492&idx=1&sn=46c4391755acaf19607fe3ddd3d7b70a&scene=19#wechat_redirect)：

> RNN的隐藏状态为：h(t) = f( U * x(t) + W * h(t-1) + b1)， f为激活函数，常用tanh、relu;
> RNN的输出为：o(t) = g( V * h(t) + b2)，g为激活函数，当用于分类任务，一般用softmax;

### 1.3 从RNN到LSTM

但是在实际中，RNN在长序列数据处理中，容易导致梯度爆炸或者梯度消失，也就是长期依赖（long-term dependencies）问题，其根本原因就是模型“记忆”的序列信息太长了，都会一股脑地记忆和学习，时间一长，就容易忘掉更早的信息（梯度消失）或者崩溃（梯度爆炸）。

> 梯度消失：历史时间步的信息距离当前时间步越长，反馈的梯度信号就会越弱（甚至为0）的现象，梯度被近距离梯度主导，导致模型难以学到远距离的依赖关系。
> 改善措施：可以使用 ReLU 激活函数；门控RNN 如GRU、LSTM 以改善梯度消失。

> 梯度爆炸：网络层之间的梯度（值大于 1）重复相乘导致的指数级增长会产生梯度爆炸，导致模型无法有效学习。
> 改善措施：可以使用 梯度截断；引导信息流的正则化；ReLU 激活函数；门控RNN 如GRU、LSTM（和普通 RNN 相比多经过了很多次导数都小于 1激活函数，因此 LSTM 发生梯度爆炸的频率要低得多）以改善梯度爆炸。

所以，如果我们能让 RNN 在接受上一时刻的状态和当前时刻的输入时，有选择地记忆和遗忘一部分内容（或者说信息），问题就可以解决了。比如上上句话提及”我去考试了“，然后后面提及”我考试通过了“，那么在此之前说的”我去考试了“的内容就没那么重要，选择性地遗忘就好了。这也就是长短期记忆网络（Long Short-Term Memory， LSTM）的基本思想。

## 二、LSTM原理

LSTM是种特殊RNN网络，在RNN的基础上引入了“门控”的选择性机制，分别是遗忘门、输入门和输出门，从而有选择性地保留或删除信息，以能够**较好地**学习长期依赖关系。如下图RNN（上） 对比 LSTM（下）：

[![img](https://camo.githubusercontent.com/03e8e57928e72ed61c2d05964ffcbbb3cc56537dbf77cd399b012e47663880c0/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d386665373562353932653064373764662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/03e8e57928e72ed61c2d05964ffcbbb3cc56537dbf77cd399b012e47663880c0/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d386665373562353932653064373764662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 2.1 LSTM的核心

在RNN基础上引入门控后的LSTM，结构看起来好复杂！但其实LSTM作为一种反馈神经网络，**核心还是历史的隐藏状态信息的反馈**，也就是下图的Ct：
[![img](https://camo.githubusercontent.com/87785eeb21f6319c756acfbbd10fe9428e35477395c4f81ff97fbe3ad25af32b/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d326634346233633737636635306537632e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/87785eeb21f6319c756acfbbd10fe9428e35477395c4f81ff97fbe3ad25af32b/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d326634346233633737636635306537632e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)
对标RNN的ht隐藏状态的更新，**LSTM的Ct只是多个些“门控”删除或添加信息到状态信息**。由下面依次介绍LSTM的“门控”：遗忘门，输入门，输出门的​功能，LSTM的原理也就好理解了。

### 2.2 遗忘门

LSTM 的第一步是通过"遗忘门"从上个时间点的状态Ct-1中丢弃哪些信息。

具体来说，输入Ct-1，会先根据上一个时间点的输出ht-1和当前时间点的输入xt，并通过sigmoid激活函数的输出结果ft来确定要让Ct-1，来忘记多少，sigmoid后等于1表示要保存多一些Ct-1的比重，等于0表示完全忘记之前的Ct-1。
[![img](https://camo.githubusercontent.com/edc2645e0f370d37a8e711ecce87f1b7205a02d39fbe97f92fcf338d7ba93b42/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d626331383535363034383664613965662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/edc2645e0f370d37a8e711ecce87f1b7205a02d39fbe97f92fcf338d7ba93b42/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d626331383535363034383664613965662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 2.3 输入门

下一步是通过输入门，决定我们将在状态中存储哪些新信息。

我们根据上一个时间点的输出ht-1和当前时间点的输入xt 生成两部分信息i t 及C~~t，通过sigmoid输出i t，用tanh输出C~~t。之后通过把i t 及C~t两个部分相乘，共同决定在状态中存储哪些新信息。
[![img](https://camo.githubusercontent.com/8112de4e3ca5b8d779b7dda15f8fec8fae31d243571b64e51347cb0fa53073bf/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d303232316333653932333839336337302e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/8112de4e3ca5b8d779b7dda15f8fec8fae31d243571b64e51347cb0fa53073bf/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d303232316333653932333839336337302e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

在输入门 + 遗忘门控制下，当前时间点状态信息Ct为：

[![img](https://camo.githubusercontent.com/760a23e3bc9d0e7b39f038ab61156c47d701b46a52cd55fe573f1fe0b70605e1/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d356432616433653735373133346362382e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/760a23e3bc9d0e7b39f038ab61156c47d701b46a52cd55fe573f1fe0b70605e1/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d356432616433653735373133346362382e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 2.4 输出门

最后，我们根据上一个时间点的输出ht-1和当前时间点的输入xt 通过sigmid 输出Ot，再根据Ot 与 tanh控制的当前时间点状态信息Ct 相乘作为最终的输出。
[![img](https://camo.githubusercontent.com/915e8fc4731ac7dec46dac3a0561bcac86ea8805bca90031b1d85a1e528e6396/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d303639376232356637663732616363642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/915e8fc4731ac7dec46dac3a0561bcac86ea8805bca90031b1d85a1e528e6396/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d303639376232356637663732616363642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

**综上，一张图可以说清LSTM原理：**
[![img](https://camo.githubusercontent.com/561bc8e2c4c87fefecb71aecb1e70b6119afcdabc817546ac6fd26b54fa44795/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d633837383135646665643364663666362e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/561bc8e2c4c87fefecb71aecb1e70b6119afcdabc817546ac6fd26b54fa44795/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f31313638323237312d633837383135646665643364663666362e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>php即时通讯-WebSocket</title>
    <url>/2019/02/22/php%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF-WebSocket/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### WebSocket

- 一个应用层协议
- 长链接
- 主流即时通讯协议

]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>php即时通讯-http</title>
    <url>/2019/02/22/php%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF-http/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### HTTP

- 一个应用层协议
- Header + Body组成
- 比TCP更高级
- 短链接

]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>php学习--变量和数据类型</title>
    <url>/2018/12/20/php%E5%AD%A6%E4%B9%A0--%E5%8F%98%E9%87%8F%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### PHP变量

#### 变量

​	程序执行期间，可以变化的量即为变量。

#### 声明变量

 - 以美元$ 符号声明
 - 注意：（PHP严格区分大小写）
    - 变量名称以 字母、或下划线开始，后面跟上数字/字母/下划线，不能包含特殊字符
    - 变量名称最好含义明确
    - 变量名最好采用驼峰标记，或下划线法
       - 驼峰
          - 小驼峰 ：firstName
          - 大驼峰：FirstName
       - 下划线
          - first_name

#### 可变变量

- 等量代换

#### 使用变量

- 直接书写变量的名称
  - $变量名称



---

### PHP数据类型

#### 8种主要数据类型

- 标量类型 （特点：只能存储单一数据）
  - 整型  int | integer
    - 整数
      - 分类
        - 十进制
        - 八进制
        - 十六进制
      - 存储范围
        - 带符号 （-21亿   到 21亿）
        - 不带符号 （0  到42亿）
        - 超过整型存储范围，会出现溢出现象

  - 浮点型  float | double  | real

    - 带小数点
    - 科学计数法 ，e或者 E
    - 注意：
      - 浮点数是有误差的，不要比较两个浮点数的大小

  - 布尔型  bool  |  boolean

    - true 
    - false 

  - 字符串型  string    只能存储单一数据

    - 定界符

      - ' '  不解析变量

      - " "  解析变量

      - heredoc  “”

        - ```
          <<<名称 代码块 名称； ``` - <<<"名称" 名称; nowdoc 转义符 \n 换行 \r 回车 \t 水平制表符 \\ \ \' ' \" " \$ $ 花括号 {} 可以将php中的变量扩成一个整体来解析 {$变量名} ${变量名} 可以将字符串中指定字符进行增删改查的操作 字符串的下标 从0开始 根据下标找到对应的字符进行操作 复合类型 数组 array 对象 object 特殊类型 资源 resource 空 null | #### 5种伪类型 number mixed callback void ... ### php数据类型转换 自动转换（隐式转换） ​ 程序根据上下文自动转换 其他类型转换为数值型 true> 1
  - false -> 0
  - null -> 0
  - 字符串如果以 非法数值开始，直接转换成0
  - 如果字符串以合法数值开始，一直取到第一个非法数值结束

- 其他类型转换为字符串类型

  - 数值型直接转换成数值本身
  - true -> 1
  - false -> 空字符串
  - null -> 空字符串
  - 数组 -> array
  - 资源 -> resource
  - 对象 不能转换为字符串

- 其他类型转换成布尔型

   - 0 -> false
   - 0.0 -> false
   - 空字符串 ‘’ 或者"" , ‘0’或者 “0” ， -> false
   - null -> false
   - 空数组 -> false

   ```
    if (条件) {
        执行条件为真的代码段;
    }else {
        执行条件为假的代码段;
    }
   ```

    

#### 强制转换（显示转换）

- 临时转换   (不会改变变量本身的类型)

  - (变量类型)$变量名称
    - 整型  (int | integer)$变量名称      
    - 浮点型   (float | double | real)$变量名称      
    - 字符型   (string)$变量名称      
    - 布尔型    (bool | bollean)$变量名称      
    - 空     (unset)$变量名称      
    - 数组      (array)$变量名称      
    - 对象     (object)$变量名称
  - 通过系统函数实现      
    - intval
    - floatval
    - ...

- 永久转换

  - ```
    settype($var,$type)
    ```

  - ```
    gettype($var)
    ```

- 通过变量函数库检查变量的类型


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 

  </名称>]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php即时通讯-多进程</title>
    <url>/2019/02/22/php%E5%8D%B3%E6%97%B6%E9%80%9A%E8%AE%AF-%E5%A4%9A%E8%BF%9B%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 多进程

- 系统进程
- 用户进程
- 并发执行
- 性能更高]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>php学习--基础语法</title>
    <url>/2018/12/20/php%E5%AD%A6%E4%B9%A0--%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### PHP基础语法

#### PHP 文档结构

- 文件扩展名.php
- 文件名不要使用中文，不要包含特殊字符


#### PHP 标记

- 标准风格
  - <?php  代码片段  ?>
  - 注意：文档中如果不只有 php代码的时候， 开始标记<? , 结束标记 ?>，必须成对出现 
  - 注意：文档中如果只有 php代码的时候， 结束标记 ?> 需要省略掉

- 短风格
  - <? 代码片段 ?>
  - 需要配置PHP配置文件， pho.ini中的 short_open_tag=On,重启Apache服务器

- ASP风格
  - <% 代码片段 %>
  - 需要配置PHP配置文件， pho.ini中的 asp_tag=On,重启Apache服务器

#### PHP文档的组成

- PHP代码
- HTML
- CSS
- JS/Jquery

#### PHP语法规则

- php代码必须以英文分号 : 结尾

#### PHP注释

- 注释作用
- 注释的分类
  - 单行注释
    - “ //注释内容 ”    c++风格
    - “ #注释内容 ”     shell风格
  - 多行注释
    - “ /* 注释内容  */ ”

#### PHP常见错误

- Parse error（解析错误）
  - syntax error （语法错误），unexpected  '<' - notice（通知） undefined variable:{未定义的变量} unset（$var） ### php工作原理 php常用 echo 输出一个或多个字符串 var_dump 打印变量的详细信息，可以一次打印一个或者多个变量的详细信息 var_dump($str...) --- php环境搭建 #### lamp ​ linux + apache mysql php lnmp nginx+ lnmpa wamp windows ##### 集成环境 wampserver xampp phpstudy about me 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</'></%>]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php学习--序言</title>
    <url>/2018/12/20/php%E5%AD%A6%E4%B9%A0--%E5%BA%8F%E8%A8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### PHP（超文本预处理器）

 

> 百度百科定义：
>
> ​	PHP（外文名:PHP: Hypertext Preprocessor，中文名：“[超文本](https://baike.baidu.com/item/%E8%B6%85%E6%96%87%E6%9C%AC)[预处理器](https://baike.baidu.com/item/%E9%A2%84%E5%A4%84%E7%90%86%E5%99%A8)”）是一种通用[开源](https://baike.baidu.com/item/%E5%BC%80%E6%BA%90/246339)[脚本语言](https://baike.baidu.com/item/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/1379708)。[语法](https://baike.baidu.com/item/%E8%AF%AD%E6%B3%95/2447258)吸收了[C语言](https://baike.baidu.com/item/C%E8%AF%AD%E8%A8%80)、[Java](https://baike.baidu.com/item/Java)和[Perl](https://baike.baidu.com/item/Perl)的特点，利于学习，使用[广泛](https://baike.baidu.com/item/%E5%B9%BF%E6%B3%9B/6246786)，主要适用于[Web](https://baike.baidu.com/item/Web)开发领域。PHP 独特的[语法](https://baike.baidu.com/item/%E8%AF%AD%E6%B3%95/2447258)混合了[C](https://baike.baidu.com/item/C)、[Java](https://baike.baidu.com/item/Java)、[Perl](https://baike.baidu.com/item/Perl)以及[PHP](https://baike.baidu.com/item/PHP)自创的语法。它可以比[CGI](https://baike.baidu.com/item/CGI)或者[Perl](https://baike.baidu.com/item/Perl)更快速地执行[动态网页](https://baike.baidu.com/item/%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5/6327050)。 

> #### 特性
>
> PHP的特性包括：
>
> 1. PHP 独特的语法混合了 C、Java、Perl 以及 PHP 自创新的语法。
>
> 2. PHP可以比CGI或者Perl更快速的执行[动态](https://baike.baidu.com/item/%E5%8A%A8%E6%80%81)网页——动态页面方面，与其他的编程语言相比，
>
>    PHP是将程序嵌入到[HTML](https://baike.baidu.com/item/HTML)文档中去执行，执行效率比完全生成htmL标记的CGI要高许多；
>
>    PHP具有非常强大的功能，所有的CGI的功能PHP都能实现。
>
> 3. PHP支持几乎所有流行的数据库以及[操作系统](https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)。
>
> 4. 最重要的是PHP可以用C、C++进行程序的扩展！
>
> #### 优势
>
> ##### 开放源代码
>
> ​	所有的PHP[源代码](https://baike.baidu.com/item/%E6%BA%90%E4%BB%A3%E7%A0%81)事实上都可以得到。
>
> ##### 免费性
>
> ​	和其它技术相比，PHP本身免费且是开源代码。
>
> ##### 快捷性
>
> ​	程序开发快，运行快，技术本身学习快。嵌入于[HTML](https://baike.baidu.com/item/HTML)：因为PHP可以被嵌入于[HTML](https://baike.baidu.com/item/HTML)语言，它相对于其他语言。[编辑](https://baike.baidu.com/item/%E7%BC%96%E8%BE%91)简单，实用性强，更适合初学者。
>
> ##### 跨平台性强
>
> ​	由于PHP是运行在服务器端的[脚本](https://baike.baidu.com/item/%E8%84%9A%E6%9C%AC)，可以运行在[UNIX](https://baike.baidu.com/item/UNIX)、[LINUX](https://baike.baidu.com/item/LINUX)、[WINDOWS](https://baike.baidu.com/item/WINDOWS)、[Mac OS](https://baike.baidu.com/item/Mac%20OS)、[Android](https://baike.baidu.com/item/Android/60243)等平台
>
> ##### 效率高
>
> ​	[PHP](https://baike.baidu.com/item/PHP/9337)消耗相当少的[系统资源](https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E8%B5%84%E6%BA%90)。
>
> ##### 图像处理
>
> ​	用PHP动态创建[图像](https://baike.baidu.com/item/%E5%9B%BE%E5%83%8F),PHP图像处理默认使用GD2。且也可以配置为使用image magick进行图像处理。
>
> ##### 面向对象
>
> ​	在php4,php5 中，面向对象方面都有了很大的改进，php完全可以用来开发大型商业程序。
>
> ##### 专业专注
>
> ​	PHP支持脚本语言为主，同为类C语言。
>
> ##### 技术应用
>
> 1. [伪静态](https://baike.baidu.com/item/%E4%BC%AA%E9%9D%99%E6%80%81)
> 2. [静态页面](https://baike.baidu.com/item/%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2)生成
> 3. [数据库](https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%BA%93)[缓存](https://baike.baidu.com/item/%E7%BC%93%E5%AD%98)
> 4. 过程缓存
> 5. [div+css](https://baike.baidu.com/item/div%2Bcss)w3c标准
> 6. 大负荷
> 7. [分布式](https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F)
> 8. [flex](https://baike.baidu.com/item/flex)
> 9. 桌面程序应用（不擅长）
> 10. 支持[MVC](https://baike.baidu.com/item/MVC)模型
> 11. [Smarty](https://baike.baidu.com/item/Smarty)模版引擎



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php学习--常量</title>
    <url>/2018/12/20/php%E5%AD%A6%E4%B9%A0--%E5%B8%B8%E9%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### PHP常量

​	常量是一个简单的标识符，一经定义在脚本执行期间不能改变。

#### 常量分类

- 系统常量
  - PHP_VERSION
  - PHP_OS
  - PHP_INT_MAX
- 自定义常量
- 魔术常量


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php常用操作--文件操作</title>
    <url>/2018/12/22/php%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C--%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### PHP文件操作

#### 基本操作

##### 文件目录函数库

- 文件相关API

  - 文件信息相关

    ```php
    <?php
        //识别中文
        header('content-type:text/html;charset=utf-8')
        //文件路径
        $filename = "./test1.txt"
        //filetype 文件类型，通常返回file,dir
        echo '文件类型',filetype($filename);
    	//filesize 文件大小，返回字节
    	echo '文件大小',filesize($filename);
    	//filectime 文件创建时间
    	echo '文件创建时间',filectime($filename);
    	echo date('Y年m月d日 H:i:s',filectime($filename));
    
    	//filemtime 文件修改时间
    	echo '文件修改时间',filemtime($filename);
    	echo date('Y年m月d日 H:i:s',filemtime($filename));
    
    	//fileatime 文件最后访问时间
    	echo '文件最后访问时间',fileatime($filename);
    	echo date('Y年m月d日 H:i:s',fileatime($filename));
    
    	//检测文件的权限
    	// 可读
    	var_dump(is_readable($filename));	
    	// 可写
    	var_dump(is_writeable($filename));	
    	// 可执行
    	var_dump(is_executable($filename));
    
    	//检测是否为文件,并且文件存在
    	var_dump(is_file($filename));
    
    	//file_exists($filename):检测文件是否存在
    	var_dump(file_exists($filename));
    	
    ```

  - 文件操作相关

    ```php
    <?php
        //识别中文
        header('content-type:text/html;charset=utf-8')
        //文件路径
        $filename = "test1.txt"
        //touch($filename):创建文件
        touch($filename);
    
    	//unlink($filename):删除指定文件
    	unlink($filename);
    
    	//检测文件存在则删除
    	if (file_exists($filename)) {
            if (unlink($filename)) {
                echo '文件删除成功';
            }else{
                echo '文件删除失败';
            }
        }else {
            echo '要删除的文件不存在';
        }
    
    	//重命名文件
    	rename($filename,$newname);
    	//复制文件
    	copy($filename);
    ```

    

  - 文件内容相关

  

##### 文件函数库常用函数

##### 目录函数库常用函数

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt="" width="240" > 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php开发APP后端---学习异常监控</title>
    <url>/2019/01/22/php%E5%BC%80%E5%8F%91APP%E5%90%8E%E7%AB%AF---%E5%AD%A6%E4%B9%A0%E5%BC%82%E5%B8%B8%E7%9B%91%E6%8E%A7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### APP端异常基本情况

---

- Crash   ，app突然发生闪退现象

- 卡顿   ， 出现画面卡顿

- Exception  ， 程序被catch的 exception

- ANR  ，  出现提示无响应弹框（android）

  

### 数据收集方案
---
#### 数据内容
- Crash ，卡顿 ，exception， ANR 的次数
- 影响用户数

#### 收集实现
- 表的设计

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php常用操作--会话控制</title>
    <url>/2018/12/21/php%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C--%E4%BC%9A%E8%AF%9D%E6%8E%A7%E5%88%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### PHP会话控制

#### session

- **session作用**

  1、SESSION允许通过将数据存储在HTTP服务器中，以在整个用户会话过程中保持该数据；所以，SESSION不仅是一个时间概念，还包括了特定的用户和服务器；

  2、SESSION提供在PHP脚本中定义全局变量的方法，使得这个全局变量在同一个SESSION中对于所有的PHP脚本文件内都有效。所以，SESSION是基于HTTP服务器的用于保持状态的方法；

- **session工作原理**

  ![1550312056583](C:\Users\YSILHO~1\AppData\Local\Temp\1550312056583.png)

- **不同浏览器的cookie位置**

  1、在Windows系统上（Win7为例）浏览器的Cookie数据存在%APPDATA%\Microsoft\Windows\Cookies\目录中的xxx.txt文件

  2、Firefox的Cookie数据存储在：%APPDATA%\Mozilla\Firefox\Profiles\目录中的xxx.default目录，名为cookies.sqlite的文件；

  3、Chrome的Cookie数据存储在：%LOCALAPPDATA%\Google\Chrome\UserData\Default目录中，名为Cookies的文件；

- **session相关的函数**

  - **session_start**

    ```
    bool session_start([array $options = []])
    
    描述：启动新会话，或者重用现有会话
    说明：
    1、$options参数是一个关联数组，如果提供的话，则会用其中的项目覆盖“会话配置”中的配置选项；
    2、如果通过GET或者POST方式，或者使用cookie提交了会话ID，则会重用现有会话； 
    ```

  - **session_id**

    ```
    string session_id([string $id])
    
    描述：获取、设置当前会话ID
    说明：
    1、如果指定$id参数的值，则使用指定值作为会话ID；
    2、必须在调用session_start()函数之前调用session_id()函数；
    ```

  - **session_name**
    ```
    string session_name([string$name])
    
    描述：读取/设置会话名称语法
    说明：
    1、如果指定$name参数，session_name()函数会更新会话名称，并返回原来的会话名称；
    2、必须在调用session_start()函数之前调用session_name()函数；与SESSION相关的函数；
    ```

  - **session_destroy**
    ```
    string session_destroy(void)
    
    描述：销毁一个会话中的全部数据
    ```
#### cookie

- **cookie 相关函数**

  - setcookie

    ```
    boolsetcookie(string$name[,string$value=""[,int$expire=0[,string$path=""[,string$domain=""]]]])
    
    描述：设置cookie
    说明：
    1、$name参数用于指定cookie名称；
    2、$value参数用于设置cookie值；
    
    ```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>Python设计模式-六大设计原则</title>
    <url>/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%85%AD%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>

## Python设计模式-六大设计原则

### 单一职责原则 (Single Responsibility Principle)
顾名思义，单一职责的原则是说一个类只负责一项职责（操作）。如果一个类负责多个职责，其中一项职责发生变化就需要修改整个类，这可能会导致其他的职责运行错误。一个类，只应该有一个引起它变化的原因。

其优点有：

- 可以降低类的复杂度，一个类只负责一项职责，其逻辑肯定要比负责多项职责简单的多；
- 提高类的可读性，提高系统的可维护性；
- 变更引起的风险降低，变更是必然的，如果单一职责原则遵守的好，当修改一个功能时，可以显著降低对其他功能的影响。

### 里氏替换原则 (Liskov Substitution Principle)
里氏替换的意思是说所有引用基类的地方必须能透明地使用其子类的对象。这种情况在代码中随处可以，我们在类中使用基类进行定义，而在运行时使用子类对象，为了确保代码运行正常，在实现子类时要注意以下一些地方：

- 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法；
- 子类中可以增加自己特有的方法；
- 当子类的方法重载父类的方法时，子类方法的输入参数要比父类方法的输入参数更宽松；

### 依赖倒置原则 (Dependence Inversion Principle)
**定义**：抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。依赖倒置原则要求我们在程序代码中传递参数时或在关联关系中，尽量引用层次高的抽象层类，即使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。依赖倒置原则的本质就是通过抽象（接口或抽象类）使各个类或模块的实现彼此独立，不互相影响，实现模块间的松耦合。在编写代码中落到实处，需要注意以下一些地方：

每个类尽量都有接口或抽象类，或者抽象类和接口两者都具备；
- 变量的表名类型尽量是接口或者抽象类；
- 尽量不要覆写基类的方法；
- 结合里氏替换原则使用。

由于 Python 是一门动态语言，在传递参数时不需要定义具体类型，所以依赖倒置原则其实一定程度上已经内嵌在了 Python 语言中。

### 接口隔离原则 (Interface Segregation Principle)
接口隔离原则提示我们客户端不应该依赖它不需要的接口，一个类对另一个类的依赖应该建立在最小的接口上。根据接口隔离原则，当一个接口太大时，我们需要将它分割成一些更细小的接口，使用该接口的客户端仅需知道与之相关的方法即可。每一个接口应该承担一种相对独立的角色，不干不该干的事，该干的事都要干。

看到这里你们或许认为接口隔离原则与单一职责原则是相同的。其实接口隔离原则与单一职责原则的审视角度是不相同的，单一职责原则要求的是类和接口职责单一，注重的是职责，这是业务逻辑上的划分，而接口隔离原则要求接口的方法尽量少。在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。

### 迪米特原则 (Law of Demeter)
**定义**：一个对象应该对其他对象有最少的了解。通俗地讲，一个类应该对自己需要耦合或调用的类知道得最少，你（被耦合或调用的类）的内部是如何复杂都和我没关系，那是你的事情，我就知道你提供的公开方法，我就调用这么多，其他的我一概不关心。迪米特法则指导我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。可以看到迪米特原则在代理模式和外观模式中都有被使用。

### 开闭原则 (Open Closed Principle)
软件实体应该对扩展开放，对修改关闭，其含义是说一个软件实体应该通过扩展来实现变化，而不是通过修改已有的代码来实现变化。根据开闭原则，在设计一个软件系统模块（类，方法）的时候，应该可以在不修改原有的模块（修改关闭）的基础上，能扩展其功能（扩展开放）。遵循开闭原则的系统设计，可以让软件系统可复用，并且易于维护。这也是系统设计需要遵循开闭原则的原因：

- 稳定性：开闭原则要求扩展功能不修改原来的代码，这可以让软件系统在变化中保持稳定。
- 扩展性：开闭原则要求对扩展开放，通过扩展提供新的或改变原有的功能，让软件系统具有灵活的可扩展性。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>php开发APP后端---环境准备</title>
    <url>/2019/01/02/php%E5%BC%80%E5%8F%91APP%E5%90%8E%E7%AB%AF---%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 环境和工具

#### 集成环境
- phpstudy
- xampp
- mamp

#### 工具

- PHP开发工具  ：phpstorm, sublime, vim
- mysql管理工具： phpmyadmin , navicate , mysql 
- postman
- 手机设备，外网服务环境

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>php开发APP后端---学习序言</title>
    <url>/2019/01/02/php%E5%BC%80%E5%8F%91APP%E5%90%8E%E7%AB%AF--%E5%AD%A6%E4%B9%A0%E5%BA%8F%E8%A8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 序言
---
梳理学习计划

##### 1、后台登录功能详解

##### 2、娱乐新闻内容管理

##### 3、restful api

##### 4、api数据安全解决方案

##### 5、app-api 基础信息接口开发以及接口文档详解

##### 6、app版本升级业务开发

##### 7、登录、个人中心、点赞以及评论功能开发

##### 8、app端异常、性能监控以及定位分析

##### **9、打造app消息推送服务**

---
### 功能分析

#### 后台

- 后台登录
- 退出登录
- 娱乐新闻管理
  - 添加功能
  - 列表
  - 修改状态、删除文章
  - 编辑功能
- 管理员管理
  - 增删改查
  - 权限控制
    
---
#### app
- 版本升级
- 首页接口API
- 栏目接口
- 栏目列表页数据接口
- 详情页接口
- 相关推荐
- 内容搜索
- 评论、点赞
- 登录功能
  - 手机号+验证码
  - 手机号+密码
- 个人中心
- 消息推送服务
- APP端异常分析定位 
---
### 数据表ER关系总图

![1550155519929](C:\Users\YSILHO~1\AppData\Local\Temp\1550155519929.png)



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>后端服务</tag>
      </tags>
  </entry>
  <entry>
    <title>Python设计模式-创建型</title>
    <url>/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## Python设计模式-创建型：单例模式和工厂模式家族

**知识点**：
- 单例模式概念及一般实现
- 单例模式的装饰器实现
- 简单工厂模式
- 抽象工厂模式

### 单例模式(singleton)

>- 所谓单例模式，也就是说不管什么时候我们要确保只有一个对象实例存在。
>- 很多情况下，整个系统中只需要存在一个对象，所有的信息都从这个对象获取，比如系统的配置对象，或者是线程池。
>- 这些场景下，就非常适合使用单例模式。总结起来，就是说不管我们初始化一个对象多少次，真正干活的对象只会生成一次并且在首次生成。


#### Singleton._instance
```python3
# -*- coding: utf-8 -*-

class Singleton(object):
    """
    单例模式
    """
    class _A(object):
        """
       真正干活的类, 对外隐藏
        """
        def __init__(self):
            pass

        def display(self):
            """ 返回当前实例的 ID，是全局唯一的"""
            return id(self)

    # 类变量，用于存储 _A 的实例
    _instance = None

    def __init__(self):
        """ 先判断类变量中是否已经保存了 _A 的实例，如果没有则创建一个后返回"""
        if Singleton._instance is None:
            Singleton._instance = Singleton._A()

    def __getattr__(self, attr):
        """ 所有的属性都应该直接从 Singleton._instance 获取"""
        return getattr(self._instance, attr)


if __name__ == '__main__':
    # 创建两个实例
    s1 = Singleton()
    s2 = Singleton()
    print(id(s1), s1.display())
    print(id(s2), s2.display())


```


- 使用类变量 Singleton._instance 来存储创建的实例，并且保证只会创建一次实例。

- 由于 Python 是一门动态语言，我们可以在运行时改变类定义。

- 在首次初始化Singleton时，我们将首次生成类_A的实例,并将其存储到 Singleton._instance 中，以后每次初始化 Singleton 时都从 Singleton._instance 获取真正干活的实例，这样我们就实现了单例模式。



#### 装饰器
```python3
# -*- coding: utf-8 -*-

class Singleton:

    """
    单例类装饰器，可以用于想实现单例的任何类。注意，不能用于多线程环境。
    """

    def __init__(self, cls):
        """ 需要的参数是一个类 """
        self._cls = cls

    def Instance(self):
        """
        返回真正的实例
        """
        try:
            return self._instance
        except AttributeError:
            self._instance = self._cls()
            return self._instance

    def __call__(self):
        raise TypeError('Singletons must be accessed through `Instance()`.')

    def __instancecheck__(self, inst):
        return isinstance(inst, self._decorated)


# 装饰器
@Singleton
class A:
    """一个需要单例模式的类"""
    def __init__(self):
        pass

    def display(self):
        return id(self)

if __name__ == '__main__':
    s1 = A.Instance()
    s2 = A.Instance()
    print(s1, s1.display())
    print(s2, s2.display())
    print(s1 is s2)

```

- 用装饰器实现了单例模式，任何想使用单例模式的类，只需要使用 Singleton 装饰器装饰一下就可以使用了。
- 可以看到其核心工作原理其实和第一种实现方式是一致的，也是使用内置的属性 Singleton._instance 来存储实例的。通过使用装饰器的模式我们将代码解耦了，使用更加灵活



#### 案例-单例模式-连接sqlite3数据库

```python3
# -*- coding: utf-8 -*-


import sqlite3
from flask import current_app
from flask import _app_ctx_stack as stack


class SQLite3(object):

    def __init__(self, app=None):
        self.app = app
        if app is not None:
            self.init_app(app)

    def init_app(self, app):
        """
        典型的 Flask 扩展的初始化方式
        """
        app.config.setdefault('SQLITE3_DATABASE', ':memory:')
        app.teardown_appcontext(self.teardown)

    def connect(self):
        """
        连接到 sqlite 数据库
        """
        return sqlite3.connect(current_app.config['SQLITE3_DATABASE'])

    def teardown(self, exception):
          """
          关闭 sqlite 链接
          """
        ctx = stack.top
        if hasattr(ctx, 'sqlite3_db'):
            ctx.sqlite3_db.close()

    @property
    def connection(self):
        """
        单例模式在这里：使用 flask._app_ctx_stack 存放 sqlite 链接,
        每次获取数据库链接时都通过 connection 获取
        """
        ctx = stack.top
        if ctx is not None:
            if not hasattr(ctx, 'sqlite3_db'):
                ctx.sqlite3_db = self.connect()
            return ctx.sqlite3_db
```

### 简单工厂模式 Simple factory

一个函数，传入需要创建的产品类型，然后返回相应的产品

```python3
# -*- coding: utf-8 -*-


import random


class BasicCourse(object):
    """
    基础课程
    """
    def get_labs(self):
        return "basic_course: labs"

    def __str__(self):
        return "BasciCourse"


class ProjectCourse(object):
    """
    项目课
    """

    def get_labs(self):
        return "project_course: labs"

    def __str__(self):
        return "ProjectCourse"


class SimpleCourseFactory(object):

    @staticmethod
    def create_course(type):
        """ 简单工厂，用于创建课程"""
        if type == 'bc':
            return BasicCourse()
        elif type == 'pc':
            return ProjectCourse()


if __name__ == '__main__':
    t = random.choice(['bc', 'pc'])
    course = SimpleCourseFactory.create_course(t)
    print(course.get_labs())

```


### 工厂方法模式 factory method

上面的简单工厂模式中，我们遇到了问题：如果需要增加一种课程，那我们需要修改工厂代码。仔细想想，如果对工厂进行抽象化，让每个工厂只负责一种产品的生产，那这样当增加一种产品时，就不需要修改已有的工厂了，只需要新增加一个工厂就行了，这样就避免修改整个工厂了

```python3
# -*- coding: utf-8 -*-

import random
import abc


class BasicCourse(object):
    """
        基础课程
        """
    def get_labs(self):
        return "basic_course: labs"

    def __str__(self):
        return "BasicCourse"


class ProjectCourse(object):
    """
        项目课
        """

    def get_labs(self):
        return "project_course: labs"

    def __str__(self):
        return "ProjectCourse"


class Factory(metaclass=abc.ABCMeta):
    """
        抽象工厂类
        """

    @abc.abstractmethod
    def create_course(self):
        pass


class BasicCourseFactory(Factory):
    """
        基础课程工厂类
        """

    def create_course(self):
        return BasicCourse()


class ProjectCourseFactory(Factory):
    """
        项目课程工厂类
        """
    def create_course(self):
        return ProjectCourse()


def get_factory():
    """
        随机获取一个工厂类
        """
    return random.choice([BasicCourseFactory, ProjectCourseFactory])()


if __name__ == '__main__':
    factory = get_factory()
    course = factory.create_course()
    print(course.get_labs())

```

我们有两种课程：BasicCourse 和 ProjectCourse，分别对应基础课和项目课。接着，我们创建了一个抽象的工厂 Factory，该工厂有一抽象方法Factory.create_course用于创建课程，最后我们基于抽象工厂实现了生产基础课程的工厂BasicCourseFactory和生产项目课的工厂ProjectCourseFactory。这样当我们新增加一种课程时，就不需要修改已经存在的基础课工厂和项目课工厂了。这里需要说明下，我们通过 Python 的abc模块实现抽象类和抽象方法。


### 抽象工厂模式

在工厂方法模式中，我们会遇到一个问题，当产品非常多时，继续使用工厂方法模式会产生非常多的工厂类。

如果按照工厂方法模式的作法，我们需要创建 Linux 虚拟机工厂类和 Mac 虚拟机工厂类， 这样我们就会有一堆工厂类了。我们就不能创建出一个能同时创建课程和虚拟机的工厂吗？


```python3
-*- coding: utf-8 -*-

import random
import abc

# 两种类型的课程
class BasicCourse(object):
    """
    基础课程
    """
    def get_labs(self):
        return "basic_course: labs"

    def __str__(self):
        return "BasicCourse"


class ProjectCourse(object):
    """
    项目课
    """

    def get_labs(self):
        return "project_course: labs"

    def __str__(self):
        return "ProjectCourse"


# 两种类型的虚拟机
class LinuxVm(object):
    """
    Linux 虚拟机
    """

    def start(self):
        return "Linux vm running"


class MacVm(object):
    """
    Mac OSX 虚拟机
    """

    def start(self):
        return "Mac OSX vm running"


class Factory(metaclass=abc.ABCMeta):
    """
    抽象工厂类, 现在工厂类不仅能创建课程，还能创建虚拟机了
    """

    @abc.abstractmethod
    def create_course(self):
        pass

    @abc.abstractmethod
    def create_vm(self):
        pass


class BasicCourseLinuxFactory(Factory):
    """
    基础课程工厂类
    """

    def create_course(self):
        return BasicCourse()

    def create_vm(self):
        return LinuxVm()


class ProjectCourseMacFactory(Factory):
    """
    项目课程工厂类
    """

    def create_course(self):
        return ProjectCourse()

    def create_vm(self):
        return MacVm()


def get_factory():
    """
    随机获取一个工厂类
    """
    return random.choice([BasicCourseLinuxFactory, ProjectCourseMacFactory])()


if __name__ == '__main__':
    factory = get_factory()
    course = factory.create_course()
    vm = factory.create_vm()
    print(course.get_labs())
    print(vm.start())

```









---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Python设计模式-结构型</title>
    <url>/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>

## Python设计模式-结构型：适配器模式,装饰者模式,代理模式,组合模式,外观模式

- 适配器模式定义及简单实现案例
- 装饰者模式定义及简单实现案例
- 代理模式定义及简单实现案例
- 组合模式定义及简单实现案例
- 外观模式定义及简单实现案例

### 适配器模式 adapter
电子产品的电源插头插在转换插头上，然后转换插头插上电源，电子产品就能正常工作了。这就是适配器模式

```python3
# -*- coding: utf-8 -*-
class OldCourse(object):
    """
    老的课程类
    """

    def show(self):
        """
        显示关于本课程的所有信息
        """
        print("show description")
        print("show teacher of course")
        print("show labs")


class Page(object):
    """
    使用课程对象的客户端
    """

    def __init__(self, course):
        self.course = course

    def render(self):
        self.course.show()


class NewCourse(object):
    """
    新的课程类, 为了模块化显示课程信息，实现了新的课程类
    """
    def show_desc(self):
        """
        显示描述信息
        """
        print("show description")

    def show_teacher(self):
        """
        显示老师信息
        """
        print("show teacher of course")

    def show_labs(self):
        """
        显示实验
        """
        print("show labs")


class Adapter(object):
    """
    适配器, 尽管实现了新的课程类，但是在很多代码中还是需要使用 OldCourse.show() 方法
    """

    def __init__(self, course):
        self.course = course

    def show(self):
        """
        适配方法，调用真正的操作
        """
        self.course.show_desc()
        self.course.show_teacher()
        self.course.show_labs()


if __name__ == '__main__':
    old_course = OldCourse()
    page = Page(old_course)
    page.render()
    print("")
    new_course = NewCourse()
    # 新课程类没有 show 方法，我们需要使用适配器进行适配
    adapter = Adapter(new_course)
    page = Page(adapter)
    page.render()
```

**适配器模式就是把一个类的接口变换成客户端所期待的另一种接口，使原本因接口不兼容而无法在一起工作的两个类能够在一起工作。**


### 装饰者模式 Decorator

装饰者模式能动态的给对象添加行为。如果你对 Flask 比较熟悉的话，应该知道在使用 Flask-Login 的时候可以使用 login_required 装饰器包装一个需要用户登录访问的view

```python3
# -*- coding: utf-8 -*-
from functools import wraps

HOST_DOCKER = 0


def docker_host_required(f):
    """
    装饰器，必须要求 host 类型是 HOST_DOCKER
    """
    @wraps(f)
    def wrapper(*args, **kwargs):
        if args[0].type != HOST_DOCKER:
            raise Exception("Not docker host")
        else:
            return f(*args, **kwargs)
    return wrapper


class Host(object):
    """
    host 类
    """

    def __init__(self, type):
        self.type = type

    # 装饰这一方法
    @docker_host_required
    def create_container(self):
        print("create container")


if __name__ == '__main__':
    # 初始化 Host
    host = Host(HOST_DOCKER)
    host.create_container()
    print("")
    # 再次初始化 Host
    host = Host(1)
    host.create_container()
```

在上面的代码中，Host有一个方法Host.create_container，只有当Host实例的类型是DOCKER_HOST的时候才能执行该方法。为了加上这一行为，我们使用了装饰者模式。可以看出使用装饰者模式，我们可以动态改变类的行为，同时能提高代码复用性，因为任何类型为HOST_DOCKER的Host都可以使用该装饰器。另外要说明下：为了更好的实现装饰器，我们使用functools.wrap函数。

### 代理模式 proxy

所谓代理模式就是给一个对象提供一个代理，并由代理对象控制对原对象的访问。通过代理，我们可以对访问做一些控制。在开发网站的过程中，针对一些频繁访问的资源，我们会使用缓存。

```python3
# -*- coding: utf-8 -*-
from time import sleep


class Redis(object):
    """
    用于模拟 redis 服务
    """

    def __init__(self):
        """
        使用字典存储数据
        """
        self.cache = dict()

    def get(self, key):
        """
        获取数据
        """
        return self.cache.get(key)

    def set(self, key, value):
        """
        设置数据
        """
        self.cache[key] = value


class Image(object):
    """
    图片对象，图片存在七牛云存储中，我们只保存了一个地址
    """

    def __init__(self, name):
        self.name = name

    @property
    def url(self):
        sleep(2)
        return "https://dn-syl-static.qbox.me/img/logo-transparent.png"


class Page(object):
    """
    用于显示图片
    """

    def __init__(self, image):
        """
        需要图片进行初始化
        """
        self.image = image

    def render(self):
        """
        显示图片
        """
        print(self.image.url)


redis = Redis()


class ImageProxy(object):
    """
    图片代理，首次访问会从真正的图片对象中获取地址，以后都从 Redis 缓存中获取
    """

    def __init__(self, image):
        self.image = image

    @property
    def url(self):
        addr = redis.get(self.image.name)
        if not addr:
            addr = self.image.url
            print("Set url in redis cache!")
            redis.set(self.image.name, addr)
        else:
            print("Get url from redis cache!")
        return addr


if __name__ == '__main__':
    img = Image(name="logo")
    proxy = ImageProxy(img)
    page = Page(proxy)
    # 首次访问
    page.render()
    print("")
    # 第二次访问
    page.render()
```
代理对象和真实的对象之间都实现了共同的接口，这使我们可以在不改变原接口情况下，使用真实对象的地方都可以使用代理对象。其次，代理对象在客户端和真实对象之间直接起到了中介作用，同时通过代理对象，我们可以在将客户请求传递给真实对象之前做一些必要的预处理。

### 组合模式 composite

什么是组合模式？按照定义来说，组合模式是将对象组合成树形结构表示，使得客户端对单个对象和组合对象的使用具有一致性。组合模式的使用通常会生成一棵对象树，对象树中的叶子结点代表单个对象，其他节点代表组合对象。调用某一组合对象的方法，其实会迭代调用所有其叶子对象的方法。

使用组合模式的经典例子是 Linux 系统内的树形菜单和文件系统。在树形菜单中，每一项菜单可能是一个组合对象，其包含了菜单项和子菜单，这样就形成了一棵对象树。在文件系统中，叶子对象就是文件，而文件夹就是组合对象，文件夹可以包含文件夹和文件，同样又形成了一棵对象树。同样的例子还有员工和领导之间的关系

```python3
# -*- coding: utf-8 -*-
import abc


class Worker(object):
    """
    员工抽象类
    """
    __metaclass__ = abc.ABCMeta

    def __init__(self, name):
        self.name = name

    @abc.abstractmethod
    def work(self):
        pass


class Employe(Worker):
    """
    员工类
    """
    __metaclass__ = abc.ABCMeta

    def work(self):
        print("Employ: %s start to work " % self.name)


class Leader(Worker):
    """
    领导类
    """

    def __init__(self, name):
        self.members = []
        super(Leader, self).__init__(name)

    def add_member(self, employe):
        if employe not in self.members:
            self.members.append(employe)

    def remove_member(self, employe):
        if employe in self.members:
            self.members.remove(employe)

    def work(self):
        print("Leader: %s start to work" % self.name)
        for employe in self.members:
            employe.work()


if __name__ == '__main__':
    employe_1 = Employe("employe_1")
    employe_2 = Employe("employe_2")
    leader_1 = Leader("leader_1")
    leader_1.add_member(employe_1)
    leader_1.add_member(employe_2)

    employe_3 = Employe("employe_3")
    leader_2 = Leader("leader_2")
    leader_2.add_member(employe_3)
    leader_2.add_member(leader_1)

    leader_2.work()
```

### 外观模式 facade

所谓外观模式，就是将各种子系统的复杂操作通过外观模式简化，让客户端使用起来更方便简洁。
- 比如你夏天晚上出门时，要关闭电灯，关闭电视机，关闭空调，如果有了一个总开关，通过它可以关闭电灯，电视机和空调，你出门的时候关闭总开关就行了。
    - 在这个例子中，你就是客户端，总开关就是外观模式的化身

```python3
# -*- coding: utf-8 -*-


class User(object):
    """
    用户类
    """
    def is_login(self):
        return True

    def has_privilege(self, privilege):
        return True


class Course(object):
    """
    课程类
    """
    def can_be_learned(self):
        return True


class Lab(object):
    """
    实验类
    """
    def can_be_started(self):
        return True


class Client(object):
    """
    客户类，用于开始一个实验
    """
    def __init__(self, user, course, lab):
        self.user = user
        self.course = course
        self.lab = lab

    def start_lab(self):
        """
        开始实验，需要一系列的判断：用户是否登录，课程是否可以学习，实验是否可以开始。判断非常繁琐！
        """
        if self.user.is_login() and self.course.can_be_learned() and self.lab.can_be_started():
            print("start lab")
        else:
            print("can not start lab")


class FacadeLab(object):
    """
    新的Lab类，应用了面向对象模式
    """

    def __init__(self, user, course, lab):
        self.user = user
        self.course = course
        self.lab = lab

    def can_be_started(self):
        if self.user.is_login() and self.course.can_be_learned() and self.lab.can_be_started():
            return True
        else:
            return False


class NewClient(object):
    """
    新的客户类，使用外观模式
    """
    def __init__(self, facade_lab):
        self.lab = facade_lab

    def start_lab(self):
        """
        开始实验，只需要判断 FacadeLab 是否可以开始
        """
        if self.lab.can_be_started:
            print("start lab")
        else:
            print("can not start lab")


if __name__ == '__main__':
    user = User()
    course = Course()
    lab = Lab()
    client = Client(user, course, lab)
    client.start_lab()

    print("Use Facade Pattern:")
    facade_lab = FacadeLab(user, course, lab)
    facade_client = NewClient(facade_lab)
    facade_client.start_lab()

```

外观模式的主要目的在于降低系统的复杂程度，在面向对象软件系统中，类与类之间的关系越多，不能表示系统设计得越好，反而表示系统中类之间的耦合度太大，这样的系统在维护和修改时都缺乏灵活性，因为一个类的改动会导致多个类发生变化，而外观模式的引入在很大程度上降低了类与类之间的耦合关系。引入外观模式之后，增加新的子系统或者移除子系统都非常方便，客户类无须进行修改（或者极少的修改），只需要在外观类中增加或移除对子系统的引用即可。



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Python设计模式-行为型</title>
    <url>/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>

## Python设计模式-行为型：策略模式,观察者模式,命令模式,模板方法

> 行为型模式会涉及到算法和对象间的职责分配，不仅描述对象或类的模式，还描述它们之间的通信方式，刻划了运行时难以跟踪的复杂的控制流，它们将你的注意力从控制流转移到对象间的关系上来。

- 策略模式定义及简单实现案例
- 观察者模式定义及简单实现案例
- 命令模式定义及简单实现案例
- 模板方法模式定义及简单实现案例

### 策略模式 strategy
    case:一个问题可能有多种显示方式。如果用户有管理权限，那么问题的详情页面可能会显示编辑按钮，如果是普通用户则只显示问题内容。这样一个对象我们该怎么实现呢

```python3
# -*- coding: utf-8 -*-

class Question(object):
    """
    问题对象，没有使用策略模式之前的作法
    """

    def __init__(self, admin=True):
        self._admin = admin

    def show(self):
        """
        根据是否是管理员显示不同的信息
        """
        if self._admin is True:
            return "show page with admin"
        else:
            return "show page with user"


if __name__ == '__main__':
    q = Question(admin=False)
    print(q.show())
```
以上代码中，最重要的操作就是Question.show操作，它会根据Quesiton._admin标志的不同完成两种显示。

现在我们有一些新的需求，增加Question的显示方式，怎么办？
- 如果增加更多的显示方式，按照以上作法，我们必然要修改Quesiton.show方法，并增加更多的标志位。
- 这样一来Question在面对不断增加的显示需求时都需要修改其代码，显然这是一种不好的设计。

下面该轮到策略模式发挥作用的时候了，策略模式将各种操作（算法）进行封装，并使它们之间可以互换。互换的意思是说可以动态改变对象的操作方式（算法）。

```python3
# -*- coding: utf-8 -*-

import abc


class AbsShow(object):
    """
    抽象显示对象
    """

    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def show(self):
        pass


class AdminShow(AbsShow):
    """
    管理员的显示操作
    """

    def show(self):
        return "show with admin"


class UserShow(AbsShow):
    """
    普通用户的显示操作
    """

    def show(self):
        return "show with user"


class Question(object):
    """
    问题对象，使用策略模式之后的作法
    """

    def __init__(self, show_obj):
        self.show_obj = show_obj

    def show(self):
        return self.show_obj.show()



if __name__ == '__main__':
    q = Question(show_obj=AdminShow())
    print(q.show())
    # 替换原来的显示对象，体现了策略模式的互换行为
    q.show_obj = UserShow()
    print(q.show())
```
将 Question 对象和显示方法进行了解耦，增加新的显示方法时，只需要增加新的显示对象就可以了。同时，在代码中还可以看到我们可以动态改变 Question 的显示方式，这也体现了策略模式的互换行为。



### 观察者模式 Observer

所谓观察者模式，就是说当一个对象发生变化时，观察者能及时得到通知并更新


```python3
# -*- coding: utf-8 -*-

import abc


class Subject(object):
    """
    被观察对象的基类
    """

    def __init__(self):
        self._observers = []

    def attach(self, observer):
        """
        注册一个观察者
        """
        if observer not in self._observers:
            self._observers.append(observer)

    def detach(self, observer):
        """
        注销一个观察者
        """
        try:
            self._observers.remove(observer)
        except ValueError:
            pass

    def notify(self):
        """
        通知所有观察者，执行观察者的更新方法
        """
        for observer in self._observers:
            observer.update(self)


class Course(Subject):
    """
    课程对象，被观察的对象
    """

    def __init__(self):
        super(Course, self).__init__()
        self._message = None

    @property
    def message(self):
        """
        message 是一个属性
        """
        return self._message

    @message.setter
    def message(self, msg):
        """
        message 属性设置器
        """
        self._message = msg
        self.notify()


class Observer(object):
    """
    观察者抽象类
    """

    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def update(self, subject):
        pass


class UserObserver(Observer):
    """
    用户观察者
    """

    def update(self, subject):
        print("User observer: %s" % subject.message)


class OrgObserver(Observer):
    """
    机构观察者
    """

    def update(self, subject):
        print("Organization observer: %s" % subject.message)


if __name__ == '__main__':
    # 初始化一个用户观察者
    user = UserObserver()
    # 初始化一个机构观察者
    org = OrgObserver()

    # 初始化一个课程
    course = Course()
    # 注册观察者
    course.attach(user)
    course.attach(org)

    # 设置course.message，这时观察者会收到通知
    course.message = "two observers"

    # 注销一个观察者
    course.detach(user)
    course.message = "single observer"
```

- Subject类，它实现了观察者模式中大部分功能。
    - 作为一个被观察的对象，Subject实现了注册观察者，注销观察者和通知观察者的功能。
    - 接着我们基于Subject创建了我们的课程Course类，并且当我们设置Course.message属性时，Course对象会通知到所有观察者。
- 可以看出，观察者模式使被观察的对象（主题）和观察者之间解耦了


### 命令模式 Command

命令模式就是对命令的封装。
- 所谓封装命令，就是将一系列操作封装到命令类中，并且命令类只需要对外公开一个执行方法execute，调用此命令的对象只需要执行命令的execute方法就可以完成所有的操作。
- 这样调用此命令的对象就和命令具体操作之间解耦了。
- 更进一步，通过命令模式我们可以抽象出调用者，接收者和命令三个对象。
    - 调用者就是简单的调用命令，然后将命令发送给接收者，而接收者则接收并执行命令，执行命令的方式也是简单的调用命令的execute方法就可以了。
    - 发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求


```python3
# -*- coding: utf-8 -*-

import abc


class VmReceiver(object):
    """
    命令接收者，真正执行命令的地方
    """

    def start(self):
        print("Virtual machine start")

    def stop(self):
        print("Virtual machine stop")


class Command(object):
    """
    命令抽象类
    """
    __metaclass__ = abc.ABCMeta

    @abc.abstractmethod
    def execute(self):
        """
        命令对象对外只提供 execute 方法
        """
        pass


class StartVmCommand(Command):
    """
    开启虚拟机的命令
    """

    def __init__(self, recevier):
        """
        使用一个命令接收者初始化
        """
        self.recevier = recevier

    def execute(self):
        """
        真正执行命令的时候命令接收者开启虚拟机
        """
        self.recevier.start()


class StopVmCommand(Command):
    """
    停止虚拟机的命令
    """

    def __init__(self, recevier):
        """
        使用一个命令接收者初始化
        """
        self.recevier = recevier

    def execute(self):
        """
        真正执行命令的时候命令接收者关闭虚拟机
        """
        self.recevier.stop()


class ClientInvoker(object):
    """
    命令调用者
    """

    def __init__(self, command):
        self.command = command

    def do(self):
        self.command.execute()


if __name__ == '__main__':
    recevier = VmReceiver()
    start_command = StartVmCommand(recevier)
    # 命令调用者同时也是客户端，通过命令实例也执行真正的操作
    client = ClientInvoker(start_command)
    client.do()

    # 能告诉命令接收者执行不同的操作
    stop_command = StopVmCommand(recevier)
    client.command = stop_command
    client.do()
```
命令模式的封装性很好：每个命令都被封装起来，对于客户端来说，需要什么功能就去调用相应的命令，而无需知道命令具体是怎么执行的。同时命令模式的扩展性很好，在命令模式中，在接收者类中一般会对操作进行最基本的封装，命令类则通过对这些基本的操作进行二次封装，当增加新命令的时候，对命令类的编写一般不是从零开始的，有大量的接收者类可供调用，也有大量的命令类可供调用，代码的复用性很好


### 模板方法模式 template method

在模板方法模式中，我们先定义一个类模板，在这个类中，我们定义了各种操作的顺序（轮毂或者说是骨架），但是并不实现这些操作，这些操作由子类来操作。

```python3
# -*- coding: utf-8 -*-

import abc


class Fishing(object):
    """
    钓鱼模板基类
    """
    __metaclass__ = abc.ABCMeta

    def finishing(self):
        """
        钓鱼方法中，确定了要执行哪些操作才能钓鱼
        """
        self.prepare_bait()
        self.go_to_riverbank()
        self.find_location()
        print("start fishing")

    @abc.abstractmethod
    def prepare_bait(self):
        pass

    @abc.abstractmethod
    def go_to_riverbank(self):
        pass

    @abc.abstractmethod
    def find_location(self):
        pass


class JohnFishing(Fishing):
    """
    John 也想去钓鱼，它必须实现钓鱼三步骤
    """

    def prepare_bait(self):
        """
        从淘宝购买鱼饵
        """
        print("John: buy bait from Taobao")

    def go_to_riverbank(self):
        """
        开车去钓鱼
        """
        print("John: to river by driving")

    def find_location(self):
        """
        在岛上选择钓点
        """
        print("John: select location on the island")


class SimonFishing(Fishing):
    """
    Simon 也想去钓鱼，它也必须实现钓鱼三步骤
    """

    def prepare_bait(self):
        """
        从京东购买鱼饵
        """
        print("Simon: buy bait from JD")

    def go_to_riverbank(self):
        """
        骑自行车去钓鱼
        """
        print("Simon: to river by biking")

    def find_location(self):
        """
        在河边选择钓点
        """
        print("Simon: select location on the riverbank")


if __name__ == '__main__':
    # John 去钓鱼
    f = JohnFishing()
    f.finishing()

    # Simon 去钓鱼
    f = SimonFishing()
    f.finishing()
```

**模板方法模式是结构最简单的行为型设计模式，在其结构中只存在父类与子类之间的继承关系。**
- 通过使用模板方法模式，可以将一些复杂流程的实现步骤封装在一系列基本方法中，在抽象父类中提供一个称之为模板方法的方法来定义这些基本方法的执行次序，而通过其子类来覆盖某些步骤，从而使得相同的算法框架可以有不同的执行结果。
- 模板方法模式提供了一个模板方法来定义算法框架，而某些具体步骤的实现可以在其子类中完成


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>Python3</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>基于PyTorch实现图像去模糊-学习</title>
    <url>/2021/11/19/pytorch%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%A8%A1%E7%B3%8A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 基于PyTorch实现图像去模糊-学习

## 任务描述

- 相机的抖动、快速运动的物体都会导致拍摄出模糊的图像，景深变化也会使图像进一步模糊。
- 对于传统方法来说，要想估计出每个像素点对应的 “blur kernel” 几乎是不可行的。因此，传统方法常常需要对模糊源作出假设，将 “blur kernel” 参数化。显然，这类方法不足以解决实际中各种复杂因素引起的图像模糊。
- 卷积神经网络能够从图像中提取出复杂的特征，从而使得模型能够适应各种场景。  
- 本教程以 CVPR2017 的 《Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring》 为例，来完成图像去模糊的任务。

### 方法概述

- 利用pytorch深度学习工具实现一个端到端的图像去模糊模型，通过参数设置、加载数据、构建模型、训练模型和测试用例依次实现一个图像去模糊工具，在训练和预处理过程中通过可视化监督训练过程。 
- 模型采用了残差形式的CNN，输入和输出都采用高斯金字塔（Gaussian pyramid）的形式。
- 整个网络结构由三个相似的CNN构成，分别对应输入金字塔中的每一层。网络最前面是分辨率最低的子网络（coarest level network），在这个子网络最后，是“upconvolution layer”，将重建的低分辨率图像放大为高分辨率图像，然后和高一层的子网络的输入连接在一起，作为上层网络的输入。

![image-20211120221821489](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120221821489.png)


```python
%config Completer.use_jedi = False
```


```python
#!pip install pytorch_msssim -i https://pypi.tuna.tsinghua.edu.cn/simple
# !jupyter nbextension enable --py widgetsnbextension
```


```python
import torch

import numpy as np

import os
import random
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from tensorboardX import SummaryWriter
from torchsummary import summary
from torch.optim import lr_scheduler
from torch.utils import data
from torchvision import transforms
from tqdm.notebook import tqdm


import pytorch_msssim # 用于计算指标 ssim 和 mssim

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```

## 参数设置


```python
class Config():
    def __init__(self,name="Configs"):
        # train set
        self.data_dir = 'datasets/train' # 训练集目录
        self.patch_size = 256  # 输入模型的patch的尺寸
        self.batch_size= 2 #16 # 训练时每个batch中的样本个数
        self.n_threads = 1 # 用于加载数据的线程数
        
        # test set
        self.test_data_dir = 'datasets/test' # 测试集目录
        self.test_batch_size=1 # 测试时的 batch_size
        
        # model
        self.multi = True # 模型采用多尺度方法True
        self.skip = True # 模型采用滑动连接方法
        self.n_resblocks = 3 #9  # resblock的个数
        self.n_feats = 8 #64  #feature map的个数
        
        # optimization 
        self.lr = 1e-4  # 初始学习率
        self.epochs =5 #800 # 训练epoch的数目
        self.lr_step_size = 600 #采用步进学习率策略所用的 step_size
        self.lr_gamma = 0.1 #每 lr_step_size后，学习率变成 lr * lr_gamma
        
        # global
        self.name = name #配置的名称
        self.save_dir = 'temp/result'  # 保存训练过程中所产生数据的目录
        self.save_cp_dir = 'temp/models'  # 保存 checkpoint的目录
        self.imgs_dir = 'datasets/pictures'  # 此 notebook所需的图片目录
        
        
        if not os.path.exists(self.save_dir):
            os.makedirs(self.save_dir)
        if not os.path.exists(self.save_cp_dir):
            os.makedirs(self.save_cp_dir)
#         if not os.path.exists(self.data_dir):
#             os.makedirs(self.data_dir)
#         if not os.path.exists(self.test_data_dir):
#             os.makedirs(self.test_data_dir)

args =  Config(name="image-deblurring")
```

## 数据准备

- 数据集展示
- 数据增强
- 构造 dataset类
- 数据加载 dataloader

### 数据集展示


```python
sample_idx = 1 # 样本编号
blur_path = os.path.join(args.imgs_dir,f"blur/test{sample_idx}.png")  # 模糊图片
sharp_path = os.path.join(args.imgs_dir,f"sharp/test{sample_idx}.png") # 去模糊图片
blur_img = plt.imread(blur_path)
sharp_img = plt.imread(sharp_path)
```


```python
plt.figure(figsize=(10,4))
plt.subplot(121)
plt.imshow(blur_img)
plt.subplot(122)
plt.imshow(sharp_img)
plt.show()
```


![image-20211120221933618](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120221933618.png)  


### 数据增强

为了防止过拟合，需要对数据集进行数据增强，增强方式如下所示，对每一个输入图像，都将其进行随机角度旋转，旋转的角度在 [0, 90, 180, 270] 中随机选取。除此之外，考虑到图像质量下降，对 HSV 颜色空间的饱和度乘以 0.8 到 1.2 内的随机数


```python
def augment(img_input, img_target):
    degree = random.choice([0,90,180,270])
    img_input = transforms.functional.rotate(img_input,degree)
    img_target = transforms.functional.rotate(img_target,degree)
    
    # color augmentation
    img_input = transforms.functional.adjust_gamma(img_input,1)
    img_target = transforms.functional.adjust_gamma(img_target,1)
    sat_factor = 1 + (0.2 - 0.4* np.random.rand())
    img_input = transforms.functional.adjust_saturation(img_input,sat_factor)
    img_target = transforms.functional.adjust_saturation(img_target,sat_factor)
    
    return img_input,img_target
```


```python
img_input = Image.open(blur_path)
img_target = Image.open(sharp_path)

img_aug_input,img_aug_target = augment(img_input,img_target)
```


```python
plt.figure(figsize=(10,5))
plt.subplot(121)
plt.imshow(img_aug_input)
plt.subplot(122)
plt.imshow(img_aug_target)
plt.show()
```


![image-20211120221955392](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120221955392.png)


### 构造 dataset类

对每一个输入图像，对齐进行随机裁剪，得到patch_size大小的输入


```python
def getPatch(img_input,img_target,patch_size):
    w,h = img_input.size
    p = patch_size
    x = random.randrange(0,w-p +1)
    y = random.randrange(0,h -p +1)
    
    img_input = img_input.crop((x,y,x+p,y+p))
    img_target = img_target.crop((x,y,x+p,y+p))
    
    return img_input,img_target
```


```python
class ImgMission(data.Dataset):
    def __init__(self,data_dir, patch_size=256, is_train= False, multi=True):
        super(ImgMission,self).__init__()
        
        self.is_train = is_train  #是否是训练集
        self.patch_size = patch_size # 训练时 patch的尺寸
        self.multi = multi  # 是否采用多尺度因子，默认采用
        
        self.sharp_file_paths = []
        sub_folders = os.listdir(data_dir)
        print(sub_folders)
        
        for folder_name in sub_folders:
            sharp_sub_folder = os.path.join(data_dir,folder_name,'sharp')
            sharp_file_names = os.listdir(sharp_sub_folder)
            # print(sharp_file_names)
            for file_name in sharp_file_names:
                sharp_file_path = os.path.join(sharp_sub_folder,file_name)
                # print(sharp_file_path)
                self.sharp_file_paths.append(sharp_file_path)
                
        self.n_samples = len(self.sharp_file_paths)
        
    def get_img_pair(self,idx):
        sharp_file_path = self.sharp_file_paths[idx]
        blur_file_path = sharp_file_path.replace("sharp","blur")
        # print(blur_file_path)
        img_input = Image.open(blur_file_path).convert('RGB')
        img_target = Image.open(sharp_file_path).convert('RGB')
        
        return img_input,img_target
    
    def __getitem__(self,idx):
        img_input,img_target = self.get_img_pair(idx)
        
        if self.is_train:
            img_input,img_target = getPatch(img_input,img_target, self.patch_size)
            img_input,img_target=  augment(img_input,img_target)
            
            
        # 转换为 tensor类型
        input_b1 = transforms.ToTensor()(img_input)
        target_s1 = transforms.ToTensor()(img_target)
        
        H = input_b1.size()[1]
        W= input_b1.size()[2]
        
        if self.multi:
            input_b1 = transforms.ToPILImage()(input_b1)
            target_s1 = transforms.ToPILImage()(target_s1)
            
            input_b2 = transforms.ToTensor()(transforms.Resize([int(H/2), int(W/2)])(input_b1))
            input_b3 = transforms.ToTensor()(transforms.Resize([int(H/4), int(W/4)])(input_b1))
            
            # 只对训练集进行数据增强
            if self.is_train:
                target_s2 = transforms.ToTensor()(transforms.Resize([int(H/2), int(W/2)])(target_s1))
                target_s3 = transforms.ToTensor()(transforms.Resize([int(H/4), int(W/4)])(target_s1))
            else:
                target_s2 = []
                target_s3 = []
                
            input_b1 = transforms.ToTensor()(input_b1)
            target_s1 = transforms.ToTensor()(target_s1)
            
            return {
                'input_b1': input_b1, # 参照下文的网络结构，输入图像的尺度 1
                'input_b2': input_b2, # 输入图像的尺度 2
                'input_b3': input_b3, # 输入图像的尺度 3
                'target_s1': target_s1, # 目标图像的尺度 1
                'target_s2': target_s2, # 目标图像的尺度 2
                'target_s3': target_s3 # 目标图像的尺度 3
            }
        else:
            return {'input_b1': input_b1, 'target_s1': target_s1}
            
        
        
    def __len__(self):
        return self.n_samples
```

### 数据加载 dataloader


```python
def get_dataset(data_dir,patch_size=None, 
                batch_size=1, n_threads=1, 
                is_train=False,multi=False):
    # Dataset实例化
    
#     print(data_dir)
#     print(patch_size)
#     print(is_train)
#     print(multi)

    dataset = ImgMission(data_dir,patch_size=patch_size,
                    is_train=is_train,multi=multi)
    
    # print(dataset)
    # 利用封装好的 dataloader 接口定义训练过程的迭代器
    # 参数num_workers表示进程个数，在jupyter下改为0
    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,
                                            drop_last=True, shuffle=is_train,
                                             num_workers = 0)
    return dataloader
```

- 将训练时的dataloader实例化


```python
data_loader = get_dataset(args.data_dir,
                          patch_size=args.patch_size,
                          batch_size= args.batch_size,
                          n_threads= args.n_threads,
                          is_train=True,
                          multi = args.multi
                         )
```

    ['GOPR0372_07_00', 'GOPR0372_07_01', 'GOPR0374_11_00', 'GOPR0374_11_01', 'GOPR0374_11_02', 'GOPR0374_11_03', 'GOPR0378_13_00', 'GOPR0379_11_00', 'GOPR0380_11_00', 'GOPR0384_11_01', 'GOPR0384_11_02', 'GOPR0384_11_03', 'GOPR0384_11_04', 'GOPR0385_11_00', 'GOPR0386_11_00', 'GOPR0477_11_00', 'GOPR0857_11_00', 'GOPR0868_11_01', 'GOPR0868_11_02', 'GOPR0871_11_01', 'GOPR0881_11_00', 'GOPR0884_11_00']


## 模型构建

- 模型介绍
- 模型定义
- 实例化模型
- 损失函数和优化器

![image-20211120222025823](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222025823.png)

CONV 表示卷积层，
ResBlock 表示残差模块，
Upconv 表示上采样（也可以用反卷积代替）。
从图中可以看出，该模型使用了 “multi-scale” 的结构，
在输入和输出部分都都采用了高斯金字塔（Gaussian pyramid）的形式（即对原图像进行不同尺度的下采样，从而获得处于不同分辨率的图像）

![image-20211120222042862](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222042862.png)

### 模型定义

- default_conv 是模型采用的默认卷积层，
- UpConv 用于上采样卷积，
- ResidualBlock 是模型使用的残差模块，
- SingleScaleNet 是单个尺度网络，
- MultiScaleNet 将几个 SingleScaleNet 整合成了最终的多尺度网络模型

*具体作用*

- default_conv : 网络中默认采用的卷积层，定义之后，避免重复代码
- UpConv : 上卷积，对应上图中的 Up Conv，将图像的尺度扩大，输入到另一个单尺度网络
- ResidualBlock : 残差模块，网络模型中采用的残差模块，之所以采用残差模块，是因为网络“只需要需要模糊图像与去模糊图像之间的差异即可”
- SingleScaleNet : 单尺度模型，一个尺度对应一个单尺度模型实例
- MultiScaleNet : 多尺度模型，将多个单尺度模型实例组合即可得到上图所示的多尺度去模糊网络


```python
def default_conv(in_channels,out_channels, kernel_size, bias):
    return nn.Conv2d(in_channels,
                    out_channels,
                    kernel_size,
                    padding=(kernel_size // 2),
                    bias=bias)

class UpConv(nn.Module):
    def __init__(self):
        super(UpConv, self).__init__()
        self.body = nn.Sequential(default_conv(3,12,3,True),
                                 nn.PixelShuffle(2),
                                 nn.ReLU(inplace=True))
    def forward(self,x):
            return self.body(x)

class ResidualBlock(nn.Module):
    def __init__(self,n_feats):
        super(ResidualBlock,self).__init__()
        
        modules_body = [
            default_conv(n_feats, n_feats, 3, bias=True),
            nn.ReLU(inplace=True),
            default_conv(n_feats,n_feats,3,bias=True)
        ]
        
        self.body = nn.Sequential(*modules_body)
        
    def forward(self,x):
        res= self.body(x)
        res += x
        return res

class SingleScaleNet(nn.Module):
    def __init__(self,n_feats,n_resblocks, is_skip, n_channels=3):
        super(SingleScaleNet, self).__init__()
        self.is_skip = is_skip
        
        modules_head = [
            default_conv(n_channels,n_feats,5,bias=True),
            nn.ReLU(inplace=True)
        ]
        
        modules_body = [ResidualBlock(n_feats) for _ in range(n_resblocks)]
        modules_tail = [default_conv(n_feats, 3,5,bias=True)]
        
        self.head = nn.Sequential(*modules_head)
        self.body = nn.Sequential(*modules_body)
        self.tail = nn.Sequential(*modules_tail)
        
    def forward(self,x):
        x= self.head(x)
        res= self.body(x)
        if self.is_skip:
            res += x
        
        res = self.tail(res)
        return res

class MultiScaleNet(nn.Module):
    def __init__(self,n_feats, n_resblocks ,is_skip):
        super(MultiScaleNet,self).__init__()
        
        self.scale3_net = SingleScaleNet(n_feats,
                                         n_resblocks,
                                         is_skip,
                                         n_channels=3)
        self.upconv3 = UpConv()
        self.scale2_net = SingleScaleNet(n_feats,
                                         n_resblocks,
                                         is_skip,
                                         n_channels=6)
        self.upconv2 = UpConv()
        
        self.scale1_net = SingleScaleNet(n_feats,
                                        n_resblocks,
                                        is_skip,
                                        n_channels=6)
        
    def forward(self,mulscale_input):
        input_b1, input_b2,input_b3 = mulscale_input
        
        output_l3 = self.scale3_net(input_b3)
        output_l3_up = self.upconv3(output_l3)
        
        output_l2 = self.scale2_net(torch.cat((input_b2,output_l3_up),1))
        output_l2_up = self.upconv2(output_l2)
        
        output_l1 = self.scale2_net(torch.cat((input_b1,output_l2_up),1))
        
        return output_l1,output_l2,output_l3
```

### 模型实例化


```python
if args.multi:
    my_model = MultiScaleNet(n_feats=args.n_feats,
                            n_resblocks = args.n_resblocks,
                            is_skip= args.skip)
else:
    my_model = SingleScaleNet(n_feats=args.n_feats,
                             n_resblocks=args.n_resblocks,
                             is_skip = args.skip)
```


```python
if torch.cuda.is_available():
    my_model.cuda()
    loss_function = nn.MSELoss().cuda()
else:
    loss_function = nn.MSELoss()
    
optimizer = optim.Adam(my_model.parameters(),lr=args.lr)
print(my_model)
print(loss_function)
```

    MultiScaleNet(
      (scale3_net): SingleScaleNet(
        (head): Sequential(
          (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          (1): ReLU(inplace=True)
        )
        (body): Sequential(
          (0): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (1): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (2): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
        )
        (tail): Sequential(
          (0): Conv2d(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        )
      )
      (upconv3): UpConv(
        (body): Sequential(
          (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
          (2): ReLU(inplace=True)
        )
      )
      (scale2_net): SingleScaleNet(
        (head): Sequential(
          (0): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          (1): ReLU(inplace=True)
        )
        (body): Sequential(
          (0): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (1): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (2): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
        )
        (tail): Sequential(
          (0): Conv2d(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        )
      )
      (upconv2): UpConv(
        (body): Sequential(
          (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): PixelShuffle(upscale_factor=2)
          (2): ReLU(inplace=True)
        )
      )
      (scale1_net): SingleScaleNet(
        (head): Sequential(
          (0): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
          (1): ReLU(inplace=True)
        )
        (body): Sequential(
          (0): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (1): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (2): ResidualBlock(
            (body): Sequential(
              (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
              (1): ReLU(inplace=True)
              (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
        )
        (tail): Sequential(
          (0): Conv2d(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        )
      )
    )
    MSELoss()


### 损失函数和优化器

- Adam 优化器，初始学习率为 lr，其相对于 SGD，更自动化，实际中需要调整的参数较少，但需要注意的是，其使用内存也比 SGD 要高。
- 损失函数使用最常见的均方损失函数（MSELoss）:
  ![image-20211120222105417](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222105417.png)
  其中 $f^{\prime}(i,j)$  和  $f(i,j)$  分别为模型输出结果图和非模糊图上坐标为  $(i,j)$  的像素，M,N分别表示图片的长与宽。
- 具体的，本文所用的多尺度损失函数为：
  ![image-20211120222124809](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222124809.png)
  $f^{\prime}_k$ 和  $f_k$ 分别表示第  $k$  个尺度上的输出结果图和非模糊图。

## 模型训练

1) 训练策略
2) 训练模型
3) 训练过程可视化

### 训练策略

- 在模型训练过程中，随着训练的进行，更新网络参数的步进（学习率）应该越来越小，整体训练过程应该满足 “先粗调后细调”，这就是常说的学习率策略。
- 本次训练采用的学习率优化策略为 lr_scheduler.StepLR，步进为 lr_step_size，学习率每隔 lr_step_size 个 epoch 乘以 lr_gamma


```python
scheduler = lr_scheduler.StepLR(optimizer,args.lr_step_size,args.lr_gamma)

scheduler
```




    <torch.optim.lr_scheduler.StepLR at 0x290378a0198>



### 训练模型

在训练开始之前，要先创建一个 SummaryWriter，用来记录和可视化训练过程


```python
writer = SummaryWriter(os.path.join(args.save_dir,"temp/logs/"))

writer
```




    <tensorboardX.writer.SummaryWriter at 0x290378d6e10>



- 在命令行运行 tensorboard --logdir=experiment/logs 来启动tensorboard。
- 在训练模型时，每训练完一个 epoch 将模型的参数保存下来，防止训练被意外中断以及方便测试，如果需要不断更新最新的一次训练的参数，可以取消最后一行的注释。
- 训练过程中，使用 tqdm 的进度条来观察训练过程


```python
bar_format = '{desc}{percentage:3.0f}% | [{elapsed}<{remaining},{rate_fmt}]' 3 8 10 # 进度条格式 for epoch in range(args.epochs): total_loss="0" batch_bar="tqdm(data_loader," bar_format="bar_format)" 利用tqdm动态显示训练过程 batch,images enumerate(batch_bar): my_model.train() curr_batch="epoch" * data_loader.__len__() + batch 当前batch在整个训练过程中的索引 input_b1="images['input_b1'].to(device)" 原始输入图像 target_s1="images['target_s1'].to(device)" 目标非模糊图片 if args.multi: input_b2="images['input_b2'].to(device)" level-2 尺度 target_s2="images['target_s2'].to(device)" input_b3="images['input_b3'].to(device)" level-3 target_s3="images['target_s3'].to(device)" output_l1, output_l2, output_l3="my_model((input_b1,input_b2,input_b3))" 损失函数 loss="(loss_function(output_l1,target_s1)" loss_function(output_l2,target_s2) loss_function(output_l3, target_s3)) else: output_l1="my_model(input_b1)" my_model.zero_grad() loss.backward() #反向传播 optimizer.step() 更新权值 print_str="|" .join([ "epoch:%3d %3d" % (epoch 1, args.epochs), "batch:%3d (batch data_loader.__len__()), "loss:%.5f" (loss.item()), ]) batch_bar.set_description(print_str,refresh="True)" 更新进度条 writer.add_scalar('train batch_loss', loss.item(), curr_batch) batch_bar.close() scheduler.step() #调整学习率 +1) batch_loss',loss,epoch) torch.save(my_model.state_dict(),os.path.join(args.save_cp_dir, f'epoch_{epoch}.pt')) 保存每个 的参数 f'epoch_lastest.pt')) 保存最新的参数 ``` ![image-20211120222241087](c:\users\administrator\appdata\roaming\typora\typora-user-images\image-20211120222241087.png) ## 模型评估 1) 指标介绍 2) 指标实现 ### 为了评估模型的效果如何，我们通过计算 峰值信噪比（peak signal-to-noise ratio, psnr）， 结构相似性（structural similarity, ssim）和 多尺度的 ssim（multi-scale ssim，mssim）三个指标来对结果进行分析 ##### psnr 的定义如下： ![image-20211120222352850](c:\users\administrator\appdata\roaming\typora\typora-user-images\image-20211120222352850.png) 其中，$m a x_{i}$表示图像点颜色的最大数值，如果每个采样点用 位表示，则最大数值为 255，$mse$是两个图像之间的均方误差。 psnr值越大代表模糊图像与参考图像越接近，即去模糊效果越好。 ssim ssim也是衡量两幅图片相似性的指标，其定义如下： ![image-20211120222344621](c:\users\administrator\appdata\roaming\typora\typora-user-images\image-20211120222344621.png) ssim由模型输出图像 $x$ 和参考图像 $y$ 之间的亮度对比（$ l(\mathbf{x}, \mathbf{y})$）、对比度对比（$c(\mathbf{x}, \mathbf{y})$）和结构对比（$s(\mathbf{x}, \mathbf{y}) $）三部分组成，$\alpha$，$\beta$ 和 $\gamma$是各自的权重因子，一般都取为 1： ![image-20211120222325752](c:\users\administrator\appdata\roaming\typora\typora-user-images\image-20211120222325752.png) 其中，$c_{1}$，$c_{2}$和$c_{3}$为常数，是为了避免分母接近于0时造成的不稳定性。$\mu_{x}$ $\mu_{y}$ 分别为模型输出图像和参考图像的均值。$\sigma_{x}$ $\sigma_{y}$ 分别为模型输出图像和参考图像的标准差。通常取 $c1="(K1*L)^2$，$C2=(K2*L)^2$，$C3=C2/2$，一般地$K1=0.01$，" $k2="0.03$," $l="255$（" $l$是像素值的动态范围，一般都取为255）。 输出图片和目标图片的结构相似值越大，则表示相似性越高，图像去模糊效果越好。 ssim是一种符合人类直觉的图像质量评价标准。从名字上我们不难发现，这种指标是在致力于向人类的真实感知看齐，详细细节可以参考[原论文](https: www.cns.nyu.edu pub lcv wang03-preprint.pdf) mssim mssim相当于是在多个尺度上来进行ssim指标的测试，相对于ssim，其能更好的衡量图像到观看者的距离、像素信息密集程度等因素对观看者给出的主观评价所产生的影响。 论文中给出的一个例子是，观看者给一个分辨率为1080p的较为模糊的画面的评分可能会比分辨率为720p的较为锐利的画面的评分高。因此在评价图像质量的时候不考虑尺度因素可能会导致得出片面的结果。 mssim提出在不同分辨率（尺度）下多次计算结构相似度后综合结果得到最终的评价数值。其计算过程框图如下所示 ![image-20211120222301708](c:\users\administrator\appdata\roaming\typora\typora-user-images\image-20211120222301708.png) 的详细细节可以参考[原论文](https: ece.uwaterloo.ca ~z70wang publications msssim.pdf) ```python class psnr(nn.module): def forward(self,img1,img2): mse="((img1" - img2) ** 2).mean() 输出图像和参考图像的 torch.log10(1.0 1.0 (mse (-10))) return 的计算较为复杂，在这里，我们直接调用 pytorch-msssim 的接口来进行计算 size_average="True," channel="3)" 实例化 模型预测 绘图函数定义 模型加载 3) 数据加载 4) 模型预测与指标分析 5) 结果展示与保存 plot_tensor(tensor): tensor.dim()="=" 4: tensor="tensor.squeeze(0)" ret="transforms.ToPILImage()(tensor.squeeze(0))" plt.imshow(ret) 训练过程中我们保存了多个 checkpoint ，现在对其进行加载和测试。这里我们提供了两种选择 的方式，一种是选择指定 checkpoint，一种是选择最新的 checkpoint。在这里我们以最新的 为例进行测试 option-a ：测试指定epoch best_epoch="100" best_cp="f"{args.save_cp_dir}/Epoch_{best_epoch}.pt"" option-b ：测试最终epoch my_model.to("cuda").load_state_dict(torch.load(best_cp)) my_model="my_model.eval()" 由于此模型采用的是多尺度训练，因此对于单张输入图像，需要对其进行处理，定义加载图像的函数 load_images 为 load_images(blur_img_path,multi): sharp_img_path="blur_img_path.replace("blur","sharp")" os.path.exists(sharp_img_path): img_target="Image.open(sharp_img_path).convert('RGB')" img_input="Image.open(blur_img_path).convert('RGB')" 转换为image类型 方便进行resize multi: h="input_b1.size()[1]" w="input_b1.size()[2]" int(w 2)])(input_b1)).unsqueeze(0) 4)])(input_b1)).unsqueeze(0) {'input_b1':input_b1, 'input_b2':input_b2, 'input_b3':input_b3, 'target_s1':target_s1} {'input_b1':unsqueeze(0), #目录一 idx="1" blur_img_path="f"datasets/pictures/blur/test{idx}.png"" 目录二 item="load_images(blur_img_path,args.multi)" output_l1,_,_="my_model((input_b1,input_b2,input_b3))" 指标分析 原始模糊图片与不模糊图片之间的指标计算 blur_psnr="psnr(input_b1,target_s1)" blur_ssim="ssim(input_b1,target_s1)" blur_mssim="mssim(input_b1,target_s1)" print(f"原始模糊图片:psnr="{blur_psnr.float()}," 原始模糊图片:psnr="24.050003051757812," 去模糊图片与不模糊的图片之间的指标计算 output_psnr="psnr(output_l1,target_s1)" output_ssim="ssim(output_l1,target_s1)" output_mssim="mssim(output_l1,target_s1)" print(f"网络输出图片:psnr="{output_psnr.float()}," 网络输出图片:psnr="24.012224197387695," 结果展示 plt.figure(figsize="(6,10))" plt.subplot(311) plot_tensor(input_b1) plt.subplot(312) plot_tensor(output_l1) plt.subplot(313) plot_tensor(target_s1) ![image-20211120222412395](c:\users\administrator\appdata\roaming\typora\typora-user-images\image-20211120222412395.png) 将结果保存 save_name="blur_img_path.split("/")[-1]" save_path="os.path.join(args.save_dir,save_name)" save_img="transforms.ToPILImage()(output_l1.squeeze(0))" save_img.save(save_path) --- about me 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</{remaining},{rate_fmt}]'></tensorboardX.writer.SummaryWriter></torch.optim.lr_scheduler.StepLR>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
        <category>CV</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>PyTorch</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title>redis学习---安装入门</title>
    <url>/2019/01/22/redis%E5%AD%A6%E4%B9%A0--%E5%AE%89%E8%A3%85%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### CentOS下安装启动

```
# 下载安装fedora的仓库
yum install epel-release
```



```
# 安装redis
yum install redis
```



```
# 开启redis服务
service redis start
```



```
# 可选项，修改可访问的域名IP，修改保护模式为no
vi /etc/redis.conf
	注释掉 bind 127.0.0.1
	改 protected  为 no 
```



```
# 重启redis服务
service redis restart
```



```
# 根据需要可，修改防火墙，增加6379端口
firewall-cmd --zone=public --add-port=6379/tcp -permanent   (-permanent,长期生效)
# 查询端口
firewall-cmd --zone-public --query-port=6379/tcp
```



```
# 连接redis
redis-cli -h host -p port -a password
```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>redis学习---数据类型</title>
    <url>/2019/01/22/redis%E5%AD%A6%E4%B9%A0-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### redis数据类型

#### string字符串

]]></content>
      <categories>
        <category>Linux</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>上瘾,一步步让你PICK ME</title>
    <url>/2020/02/06/%E4%B8%8A%E7%98%BE%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 上瘾,一步步让你PICK ME



##### **让用户习惯你的产品*==**

习惯：下意识做出的举动。

简单的习惯是在很少或完全没有意识思考的情况下完成的行为，指导了每个人日常近一半的行为。

习惯是人们能够通过在 ==基底神经节中存储自动反应，来将注意力集中在其他事物==

当大脑才去捷径并停止积极思考下一步该怎么做的时候， 就会形成习惯；大脑很快便学会编纂行为，为其遇到的任何情况提供解决方案。

深谙此道的企业，一直将培养用户习惯作为产品开发的一个基本原则。

##### 习惯养成类产品能够改变用户的行为，使用户无须外部诱因就会开始从事某种活动：

- 使用一而再，再而三的接触和亲近产品
- 不需要广告和促销的外显的行动召唤
- 一旦形成对产品的依赖性，用户便会在一些习惯事物中使用这个产品打发时间，比如排队的时候看头条，路上刷淘宝、路上听网易云发现音乐……

##### 用户对产品产生习惯依赖的好处：

- 提高用户终身价值
- 提供定价灵活性
- 加快增长速度
- 提高竞争优势

##### 打造习惯类产品，需要认真考虑的因素

- 频率：某种行为多久发生一次
- 可感知用途：在用户心中，该产品与其他相比多出了哪些用途和好处

具有足够频率和感知效用的行为进入“习惯区域”，有助于使其成为默认行为。

**所有成功创新的共同点=解决明显问题**

一个习惯就是在不采取行动时会引起一些痛苦

![](上瘾基础模型.jpg)

## 触发

新的习惯需要建立基础，而触发则为持续的行为改变提供了基础条件。触发即为行为的执行器。

==**分为：外部触发、内部触发。**==

### 外部触发

习惯形成首先要通过号召，用户提示，暗示用户来开始改变行为。

外部触发时嵌入了信息，告诉用户下一步应该做什么，传达给用户具体应该怎么操作。比如：常见的“登录”、“注册”、“付费”等操作

#### 付费型触发

多为保持用户回访的有效而昂贵的方法；比如广告投放、搜索引擎营销、其他付费频道

对于大多数商业模式而言，付费是不可持续的，公司通常使用付费触发来获取新用户，然后利用其他各类触发将用户流量转入。习惯形成后公司通常不会长时间以来付费触发。

#### 回馈型触发

多为需要以公共和媒体关系所花费的时间进行投资。比如有利的媒体提及，病毒视频、有利的特色应用展示位

回馈型触发引发的用户往往容易昙花一现，如果需要充分利用回馈型触发维护用户，就需要本身长期处于“明星”状态，这一项却是异常艰巨的，很难长时间保持一个超高的关注名气。

#### 人际关系型触发

多为口口相传形式，一个人告诉别人有关产品或服务的信息

正常使用关系触发器需要建立一个积极的用户群，热衷分享产品、获得收益；类似小红书、直播带货、拼多多、拼购类

以拼多多举例解析：

拼多多选中“占便宜”用户群体进行资源投入，凭借价格优势和福利优势，捕捉到一大批的“自带营销光环的初期用户”，补贴并奖励这些用户，由这些用户来推广宣传，扩大用户规模。

![](拼多多的推广理念.jpeg)

之前的时候拼多多更多的把进入的用户流量在做业务转化的同时，也在将这部分流量变为了推广者流量。



![](拼多多的增长模式.jpeg)

#### 自主型触发

始终出现在日常生活中，最终由用户选择允许这些触发出现。比如app通知、电子邮件订阅

只要用户同意接收触发，那么被设置允许触发的公司就拥有了用户注意力的份额

### 内部触发

当产品应用与使用者的思想、情感或预先存在的活动紧密结合时，就是内部触发在起作用。

#### 情绪调动

情绪，特别是消极情绪是极为强大的内部触发因素，并且在极大程度上影响我们的日常生活。

**消极情绪**

厌倦、孤独、沮丧、困惑、犹豫不决等感觉经常会隐私轻微的痛苦或刺激，并会促使瞬间的，通常无意识的行动来平息消极感觉。

比如：刷抖音快手某种程度上是消除孤独寂寞；打开网易云音乐听歌看评论是寄托平息感情

**积极情绪**

解决并满足困扰我们的事物来内部触发人们。

比如：分享好消息的需要，被认为是寻找和维持社交关系的尝试

发现减轻疼痛产品的用户，将随着时间的推移与产品形成强烈的积极关联。

在继续使用之后，产品和需要它的用户之间形成债券。逐渐的，当用户在遇到某种内部触发因素时，便会选择产品，会变成一种习惯。

==一旦用户被产品迷住，使用产品时并不总是需要明确号召性用语==。更多的时候，依靠对感情的自动反应来促成期望的行为。

==一旦用户被产品勾住，那么用户就不一定只在清洗明确的行动召唤下才想到产品。==更多的时候，情绪引发的自动反应会引导人们做出特定的举动。比如：感到无聊的时候会刷新闻，逛淘宝，刷微博；压力大的时候会听网易云、刷抖音视频……

内部触发和产品之间的关联不是一夜之间形成。

内部触发器很多时候需要数周或数月的频繁使用才能形成。

### 如何触发

如何更快的更好的为产品注入内部触发的源动力，要做到产品对用户的特定情绪起到安抚作用，产品设计的时候必须了解用户的内部触发因素---他们寻求解决痛苦点。

**习惯形成产品的最终目标是通过获取用户的关注、消除用户的烦恼、解决用户的痛苦、创造好的情感/情绪感受，以便用户将公司的产品/服务默认为精神抚慰的来源。**

公司的必须首先在情感方面确定用户特定的挫折或痛点，在产品设计和打造上注入解决该痛点的基因。

比如成功的习惯养成类的产品背后的驱动因素：

- 用户希望借助产品实现什么样的目的？
- 用户会在何时何地使用这个产品？
- 什么样的情绪会促使他们使用产品、触发行动？
- 产品能否对用户的这个情绪解决，需求满足提供支撑？

## 行动

外部触发和内部触发可以指引提示用户下一步的行动方向，但，如果用户没有付诸行动，触发就未能生效。

斯坦福的福格行为模型，要使人们行动起来，有三个必备因素：

- 充分的动机
- 完成这一行为的能力
- 促使人们付诸行动的触发

**B= MAT**

- B，行为
- M，动机
- A，能力
- T，触发

如果该环节内容任何组件部位却是，用户将不会越过“行动线”，并且不回实施某些行为。

示例：有一个手机电话没有应答。

原因：

1、手机被放在一起不能拿到的位置==能力不够

2、发现电话是推销电话，一个不想接的电话 ====缺乏接听动力，动机不够

3、没有电话铃声，也没有震动，导致没有发现手机来电 ==== 没有触发因素

### 动机

触发提醒用户才去行动，而动机则决定用户是否愿意采取行动。

能驱使人们采取行动的核心动机不外乎三种：

- 寻求快乐，避免痛苦
- 寻求希望，避免恐惧
- 寻求社会认可并避免拒绝

### 能力

产品创新基本分为三个步骤：

- 了解人们使用某个产品/服务的原因
- 列举用户使用该产品的必经环节
- 在明确所有环节以后开始做减法，直至做到极致

凡是能够让用户以最简便的方式享用到的产品/服务，一定是用户使用率最高的。

任务的难易程度会直接影响人们完成这一任务的可能性。

福格，影响任务难度的6个因素：

- 时间：完成一项行动需要多长时间
- 金钱：采取行动的资金成本
- 体力劳动：采取行动所涉及消耗的劳动量
- 脑力：采取行动所需的精神努力和注意力水平
- 社会偏差：他人如何接受这种行为
- 非常规：动作与现有例程匹配度 或中断的程度



在能力和动机两个选项面前，如何选择该优先解决哪一个？

**增加用户动机是昂贵且耗时的，而先解决能力问题更加容易。**优质高效的产品应用，提供便捷高效的痛点需求解决体验，以及产品的惊喜度，来反向影响和提升用户动机。

#### 稀缺效应

#### 环境效应

产品所处环境

#### 锚定效应

人们在做决定时经常会锚定一条信息

#### 赠券效应

增加动力的现象



## 多变的酬赏

很多时候驱使人们行动的，并不是酬赏本身，而是人们渴望酬赏时产生的那种迫切需要。

大脑因为渴望而形成的紧张感会促使人们重复某个动作。

主要分为三种形式：

- 社交酬赏
- 猎物酬赏
- 自我酬赏

### 社交酬赏--人际奖励

人类时社会化的物种，彼此依存。社交酬赏，抑或说部落酬赏，院子和他人之间的互动关系。

为了让自己觉得被接纳、被认同、受重视、受喜爱，大脑会自动调试已获得酬赏。

### 猎物酬赏--具体的资源或信息

在追捕的过程中，猎手是为了追逐而追逐。在某种意义上，这个解释了现代人需索无度的状态。

猎手在追捕猎物时，内心的执念催促它不断向前；

### 自我酬赏--体验到的操纵感、成就感、终结感

人们对于个体愉悦感的渴望。在目标驱动下，人们会去克服障碍，即便仅仅是因为这个过程能带来满足感。

很多时候，完成任务的强烈渴望会成为促使人们继续某种行为的主要因素。

**上瘾模型驱动场景化设计**

![](上瘾模型驱动场景化设计.jpeg)

**需要注意的是：**

- 多变的酬赏不是免费的
- 保护用户的自主权：用户有权接受，也有权拒绝
- 有限的多边性

示例：电子邮件业务

原因：

1、社交酬赏：不确定哪些人会发送邮件过来，同时我们渴望与他人进行良性互动，会进行回信

2、猎物酬赏：邮件的内容多种多样，有商品营销，有与职业发展相关等等，查邮件有助于把握机会或规避风险

3、自我酬赏：筛选分类邮件，标记，删除，过滤，分组等一系列的操作会使用户感知到 邮箱在自己的操控之中

## 投入

用户在某件产品或某服务商投入的时间或精力越多，对该产品/服务就越重视。

![](用户转化至上瘾的流程链路.jpg)

最后形成良性的pick模型。

![](pick模型.jpeg)

最后，感谢各位的阅读～

<img src="/.top//微信公众号二维码.png" alt="微信公众号" style="zoom:50%;">

<img src="/.top//网站二维码.png" style="zoom:50%;" alt="个人网站">


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>营销</category>
        <category>心理学</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>心理学</tag>
        <tag>营销</tag>
      </tags>
  </entry>
  <entry>
    <title>一个策略产品的自我修养</title>
    <url>/2020/02/05/%E4%B8%80%E4%B8%AA%E7%AD%96%E7%95%A5%E4%BA%A7%E5%93%81%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 策略产品

- 新闻推荐策略
- 增长策略
- 反欺诈策略
- 价格策略
- 后台策略
- 搜索策略
- 渲染策略
- ……

不是一个明确的行业

不是一种具体的产品形态

是一种解决问题的手段

是一种实现目标的手段

### 策略四要素

1. 待解决问题
2. 输入---影响解决方案的因素
3. 计算逻辑---将输入转换成为输出的规则
4. 输出---具体的解决方案

### 策略产品与功能产品的区别

#### 发现问题阶段

##### 功能产品

对用户人群诉求，抽象成为一套相对聚焦的需求

##### 策略产品

宏观想象各类用户的诉求，一群人更多样和更有统计意义的需求，需评估实现到什么程度

#### 撰写需求、发起项目

##### 功能产品

收敛的解决方案

通过流程和原型表达产品实现效果

##### 策略产品

发散的解决方案

通过逻辑描述和效果示例表达产品实现效果

#### 跟进开发评估

##### 功能产品

面对开发结果是验收的性质

更关注呈现效果、而非实现过程

##### 策略产品

更多参与过程

通过多轮评估深入参与开发过程

与策略RD一起发现各要素中的问题

#### 产品上线后的回归&新的产品循环

##### 功能产品

更快达到理想态

面对明确单一的问题，通常可以更快达到较好效果

close该feature产品循环

##### 策略产品

可能是永无止境的产品循环

复杂且受很多因素影响的问题，需要多个产品循环才能达到理想效果

### 策略产品的工作流程

- 发现问题
  - 上帝视角
  - 面对的是一群人的问题
- 需求撰写
- 跟进评估
  - 较强数据敏感度
  - 从数据中发现问题，引导下一个产品循环
- 上线&效果回归
  - 拥抱不确定性
  - 持续迭代在黑暗中寻找道路



### 策略产品发现问题的方法

#### 用户反馈

处理用户反馈的基本流程

1. 收集用户问题
   1. 自有渠道收集
   2. 外部渠道收集
2. 用户反馈分析
   1. 数据处理：清洗、标注
   2. 问题管理：分析、汇总
3. 整理撰写需求
4. 落实产品改进

#### 系统监控

##### 定义待监控指标

告诉机器观察哪些指标

- 白盒部分--效果监控
  - 用户操作行为
  - 监控用户的体验，即产品的核心指标
  - 该指标异常变化时需要重点即刻关注
- 黑盒部分--策略监控
  - 策略产品---策略监控
  - 监控某个策略的运转情况，对象为各类指标，监测大于监控
  - 功能产品---技术监控

##### 定义报警规则

告诉机器什么通知&以什么方式通知

- 触发报警条件
  - 历史的波动数据
    - 数据敏感度：波动是否超越历史波动范围
    - 三西格玛理论：波动范围在+/- 三西格玛之内
  - 指标重要程度
    - 四象限方式
- 报警方式
  - 监控指标的重要程度和波动幅度

##### 监控的适用范围

###### 效果监控

- 产品满足效果
- 产品覆盖情况

###### 策略监控

- 需求识别策略监控---需求识别
- 检索策略监控---检索
- 展现策略监控---结果展示

##### 监控的局限性

- 考虑到准确率，监控覆盖的精度有限（策略意义上召回率）
- 监控可以发现异常，但通常不能直接定位问题，最终依然需要配合人工手段进行问题解决修复

==人工排查繁琐且不经济，线上监控作为一种自动、实时、针对效果的问题发现方法，就显得愈发的重要。==

#### 效果回归

==效果回归是策略产品非常重要的一部分工作==

- 产品循环
  - 判断产品循环是否中止
  - 确定产品接下来的计划
- 自我成长
  - 验证解决方案可行性
  - 修正和巩固方法论

##### 定义理想态

任何一个产品都是用来解决用户的问题。

产品的理想态即给出的方案解决了用户的问题

==所有的理想态都是为阶段性的产品目标服务，随着产品的进化，理想态的定义也在随着进化==

- 简单情况

  对于大多数刚需和工具型产品，通常可以以【帮助用户解决了问题】作为理想态，并找到单一的数据指标来衡量

  - 示例：滴滴

    - 订单成交率

      随着平台对服务的掌控能力增加，理想态在进化

      应答率---成交率---到达目的地时间

  - 示例：墨迹天气

    - 天气准确率

- 复杂情况

  - 示例：百度

    搜索产品，通常以平台当前能够给出的最佳产品方案作为理想态。

  - 示例：头条

    推荐产品，通常以平台当前能够给出的最佳产品方案作为理想态

    评估策略推荐出的结果在 候选集内是否最佳，用户行为指标作为发现问题的辅助手段

##### 拆解未达理想态的情况

##### 提出解决方案

##### 验证是否解决

==通用手段==

- 定义理想态：并以数字化的指标或其他明确标砖来衡量
- 抽样分析：将所有不达理想态的case抽样分析，并做统计分类，明确不好的原因
- 优先级判断：汇总所有问题，综合影响面、问题严重程度和解决成本确定优先级，作为接下来的项目计划

#### 阶段性调研

==阶段性调用针对产品现状进行系统性分析==

==此时产出的分析结论最能代表产品问题全貌，可有效指导阶段的产品计划==

##### 阶段性调研的时间节点

###### 接触新产品

接受某个产品方向的时候

###### 周期性回顾

每个月/季度/半年等固定周期的回顾

###### 不定期回顾

其他需要临时回顾整个产品现状时





---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>策略产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>策略产品</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能的三大要素</title>
    <url>/2018/11/25/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E4%B8%89%E5%A4%A7%E8%A6%81%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 人工智能的三大要素

#### Algorithm 算法



#### Big Data 数据



#### 计算力


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能的历史</title>
    <url>/2018/11/25/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 人工智能的诞生：1943 - 1956



在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。

1956年的夏天，香农和一群年轻的学者在达特茅斯学院召开了一次头脑风暴式研讨会。会议的组织者是马文·闵斯基，约翰·麦卡锡和另两位资深科学家Claude Shannon以及Nathan Rochester，后者来自IBM。与会者包括Ray Solomonoff，Oliver Selfridge，Trenchard More，Arthur Samuel，Newell和Simon，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。

会议虽然叫做“达特茅斯夏季人工智能研究会议”，其实它不同于今天我们召开几天的学术会议，因为一来没有什么可以报告的科研成果，二来这个会议持续了一个暑假。事实上，这是一次头脑风暴式的讨论会，这10位年轻的学者讨论的是当时计算机尚未解决，甚至尚未开展研究的问题，包括人工智能、自然语言处理和神经网络等。

会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上人工智能的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为人工智能诞生的标志。

黄金年代：1956 - 1974

达特茅斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。ARPA（国防高等研究计划署）等政府机构向这一新兴领域投入了大笔资金。

第一代AI研究者们非常乐观，曾作出了如下预言:

- 1958年，H. A. Simon，Allen Newell：“十年之内，数字计算机将成为国际象棋世界冠军。” “十年之内，数字计算机将发现并证明一个重要的数学定理。”
- 1965年，H. A. Simon：“二十年内，机器将能完成人能做到的一切工作。”
- 1967年，Marvin Minsky：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”
- 1970年，Marvin Minsky：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”

早期，人工智能使用传统的人工智能方法进行研究，什么是传统的人工智能研究呢？简单的讲，就是首先了解人类是如何产生智能的，然后让计算机按照人的思路去做。因此在语音识别、机器翻译等领域迟迟不能突破，人工智能研究陷入低谷。

## 第一次AI低谷：1974 - 1980

由于人工智能研究者们对项目难度评估不足，这除了导致承诺无法兑现外，还让人们当初的乐观期望遭到严重打击。到了70年代，人工智能开始遭遇批评，研究经费也被转移到那些目标明确的特定项目上。

1972年康奈尔大学的教授弗雷德.贾里尼克（Fred Jelinek)被要求到IBM做语音识别。在之前各个大学和研究这个问题已经花了20多年的时间，主流的研究方法有两个特点，一个是让计算机尽可能地模拟人的发音特点和听觉特征，一个是让计算机尽可能的方法理解人所讲的完整的语句。对于前一项研究，有被称为特征提取，后一项的研究大都使用传统人工智能的方法，它基于规则和语义。

贾里尼克任务，人的大脑是一个信息源，从思考到找到合适的语句，再通过发音说出来，是一个编码的过程，经过媒介传播到耳朵，是一个解码的过程。既然是一个典型的通讯问题，那就可以用解决通讯方法来解决问题，为此贾里尼克用两个数据模型（马尔科夫模型）分别描述信源和信道。然后使用大量的语音数据来训练。最后，贾里尼克团队花了4年团队，将语音识别从过去的70%提高到90%。后来人们尝试使用此方法来解决其他智能问题，但因为缺少数据，结果不太理想。

在当时，由于计算机性能的瓶颈、计算复杂性的指数级增长、数据量缺失等问题，一些难题看上去好像完全找不到答案。比如像今天已经比较常见的机器视觉功能在当时就不可能找到一个足够大的数据库来支撑程序去学习，机器无法吸收足够的数据量自然也就谈不上视觉方面的智能化。

项目的停滞不但让批评者有机可乘——1973年Lighthill针对英国人工智能研究状况的报告批评了人工智能在实现其“宏伟目标”上的完全失败，也影响到了项目资金的流向。人工智能遭遇了6年左右的低谷。

## 繁荣：1980 - 1987

在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。

受到日本刺激，其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。人工智能又迎来了大发展。

专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。

专家系统的能力来自于它们存储的专业知识。这是70年代以来AI研究的一个新方向。Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对[分门别类](https://www.baidu.com/s?wd=%E5%88%86%E9%97%A8%E5%88%AB%E7%B1%BB&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的大量知识的多种处理方法之上。” “70年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。”知识库系统和知识工程成为了80年代AI研究的主要方向。

1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。

## 第二次AI低谷：1987 - 1993

“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。

变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。

XCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现[莫名其妙](https://www.baidu.com/s?wd=%E8%8E%AB%E5%90%8D%E5%85%B6%E5%A6%99&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)的错误），成了以前已经暴露的各种各样的问题的牺牲品。专家系统的实用性仅仅局限于某些特定情景。到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。

1991年人们发现十年前日本人宏伟的“第五代工程”并没有实现。事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。与其他AI项目一样，期望比真正可能实现的要高得多。

## 走在正确的路上：1993 - 2005

现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。

“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。

第一次让全世界感到计算机智能水平有了质的飞跃实在1966年，IBM的超级计算机深蓝大战人类国际象棋冠军卡斯伯罗夫，卡斯伯罗夫是世界上最富传奇色彩的国际象棋世界冠军，这次比赛最后以4：2比分战胜了深蓝。对于这次比赛媒体认为深蓝虽然输了比赛，但这毕竟是国际象棋上计算机第一次战胜世界冠军两局。时隔一年后，改进后的深蓝[卷土重来](https://www.baidu.com/s?wd=%E5%8D%B7%E5%9C%9F%E9%87%8D%E6%9D%A5&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)，以3.5：2.5的比分战胜了斯伯罗夫。自从1997年以后，计算机下棋的本领越来越高，进步超过人的想象。到了现在，棋类游戏中计算机已经可以完败任何人类。

深蓝实际上收集了世界上百位国际大师的对弈棋谱，供计算机学习。这样一来，深蓝其实看到了名家们在各种局面下的走法。当然深蓝也会考虑卡斯伯罗夫可能采用的走法，对不同的状态给出可能性评估，然后根据对方下一步走法对盘面的影响，核实这些可能性的估计，找到一个最有利自己的状态，并走出这步棋。因此深蓝团队其实把一个机器智能问题变成了一个大数据和大量计算的问题。


越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。

Judea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。

## 大数据：2005 - 现在

从某种意义上讲，2005年是大数据元年，虽然大部分人感受不到数据带来的变化，但是一项科研成果却让全世界从事机器翻译的人感到震惊，那就是之前在机器翻译领域从来没有技术积累、不为人所知的Google，以巨大的优势打败了全世界所有机器翻译研究团队，一跃成为这个领域的领头羊。

就是Google花重金请到了当时世界上水平最高的机器翻译专家弗朗兹·奥科 (Franz Och)博士。奥科用了上万倍的数据来训练系统。量变的积累就导致了质变的发生。奥科能训练出一个六元模型，而当时大部分研究团队的数据量只够训练三元模型。简单地讲，一个 好的三元模型可以准确地构造英语句子中的短语和简单的句子成分之间的搭配，而六元模型则可以构造整个从句和复杂的句子成分之间的搭配，相当于将这些片段从一种语言到另一种语言直接对译过去了。不难想象，如果一个系统对大部分句子在很长的片段上直译，那么其准确性相比那些在词组单元做翻译的系统要准确得多。

如今在很多与“智能”有关的研究领域，比如图像识别和自然语言理解，如果所采用的方法无法利用数据量的优势，会被认为是落伍的。

数据驱动方法从20世纪70年代开始起步，在八九十年代得到缓慢但稳步的发展。进入21世纪后，由于互联网的出现，使得可用的数据量剧增，数据驱动方法的优势越来越明显，最终完成了从量变到质变的飞跃。如今很多需要类似人类智能才能做的事情，计算机已经可以胜任了，这得益于数据量的增加。

全世界各个领域数据不断向外扩展，渐渐形成了另外一个特点，那就是很多数据开始出现交叉，各个维度的数据从点和线渐渐连成了网，或者说，数据之间的关联性极大地增强，在这样的背景下，就出现了大数据。

大数据是一种思维方式的改变。现在的相比过去大了很多，量变带来了质变，思维方式、做事情的方法就应该和以往有所不同。这其实是帮助我们理解大数据概念的一把钥匙。在有大数据之前，计算机并不擅长解决需要人类智能来解决的问题，但是今天这些问题换个思路就可以解决了，其核心就是变智能问题为数据问题。由此，全世界开始了新的一轮技术革命——智能革命。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是图像识别和图像识别的特征提取</title>
    <url>/2018/12/20/%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E5%92%8C%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E7%9A%84%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E9%A2%9D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>




RGB三个通道，三个矩阵
---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>保障交易/营销安全的措施</title>
    <url>/2020/02/06/%E4%BF%9D%E9%9A%9C%E4%BA%A4%E6%98%93%E8%90%A5%E9%94%80%E5%AE%89%E5%85%A8%E7%9A%84%E6%8E%AA%E6%96%BD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 保障交易/营销安全的措施

### 黄牛风险防控服务

评估账号的限购评估，比如六个唯一，身份证号、账号、银行卡号、绑定手机号、设备号、户头号，怎样判别并鉴定是否为黄牛

#### 黄牛防控策略

1、创建黄牛防控策略

2、添加需要监控的商品信息/券信息

3、设置不同的监控级别

​     日常类、非秒杀类的商品/券，配置初级防控；

​	  秒杀类的商品/券，配置高级防控；

4、不同的防控级别设定，对账户设置不同的领取/购买量

5、设置策略生效时间

6、页面增加规则描述，黄牛拒发等通告

7、上线策略，指定生效时间段

8、策略列表，包含草稿、生效中、待生效、已失效

#### 黄牛防控效果

##### 黄牛风险总览

- 提交订单买家量
- 黄牛买家拦截量
- 黄牛买家占比
- 黄牛订单拦截量
- 订单创建成功量

##### 防控商品/券风险详情

- 商品/券关键词检索
- 时间段检索

##### 防控商品/券的黄牛拦截趋势

##### 会员分析

- 黄牛订单用户中的新会员、老会员分布
- 成功订单用户中新会员、老会员分布

#### 手动反馈录入漏防交易

### 恶意订单风险防控服务

退货类：买家频繁通过滥用退款售后权益

敲诈类：不以真实消费为目的，利用平台规则牟取利益的非正常消费者行为

攻击类

### 异常评价防控服务


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <tags>
        <tag>产品</tag>
        <tag>安全</tag>
        <tag>运营</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-使用决策树预测隐性眼镜类型</title>
    <url>/2021/01/01/%E4%BD%BF%E7%94%A8%E5%86%B3%E7%AD%96%E6%A0%91%E9%A2%84%E6%B5%8B%E9%9A%90%E6%80%A7%E7%9C%BC%E9%95%9C%E7%B1%BB%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 案例-使用决策树预测隐性眼镜类型

- 收集数据：提供的文本文件
- 准备数据：解析tab键分割的数据
- 分析数据：快速检查数据
- 训练算法：
- 测试算法：编写测试函数 验证决策树可以正确分类给定的数据实例
- 使用算法：存储树的数据结构，以便下次使用


```python
from math import log
import operator
```


```python
def calcShannonEnt(dataSet):
    numEntries = len(dataSet)
    # 为所有可能分类创建字典
    labelCounts= {}
    for featVec in dataSet:
        currentLabel = featVec[-1]
        if currentLabel not in labelCounts.keys():
            labelCounts[currentLabel] = 0
        labelCounts[currentLabel] += 1
    shannonEnt = 0.0
    for key in labelCounts:
        prob = float(labelCounts[key])/numEntries
        shannonEnt -= prob * log(prob,2)   # 以 2为底求对数
    return shannonEnt     
```


```python
# 按照给定特征划分数据集
# 输入参数： 待划分待数据集、划分数据集的特征、需要返回的特征的值
def splitDataSet(dataSet,axis,value):
    retDataSet = []
    for featVec in dataSet:
        print("featVec",featVec)
        if featVec[axis] == value:
            print("axis",axis,"featVec[axis]",featVec[axis])
            reducedFeatVec = featVec[:axis]
            print("axis",axis,"reducedFeatVec:",reducedFeatVec)
            reducedFeatVec.extend(featVec[axis+1:])
            print("featVec[axis+1:]",featVec[axis+1:])
            print("axis",axis,"reducedFeatVec:",reducedFeatVec)
            retDataSet.append(reducedFeatVec)
    return retDataSet
```


```python
# 选择最好的数据集划分方式
def chooseBestFeatureToSplit(dataSet):
    numFeatures = len(dataSet[0])-1  #特征的个数
    baseEntropy = calcShannonEnt(dataSet) # 基线熵
    print("baseEntropy:",baseEntropy)
    bestInfoGain = 0.0
    bestFeature = -1
    # 创建唯一的分类标签
    for i in range(numFeatures):
        featList = [example[i] for example in dataSet]
        print("featList:",featList)
        uniqueVals =  set(featList)
        print("uniqueVals:",uniqueVals)
        
        # 计算每种划分方式的信息熵
        newEntropy = 0.0
        for value in uniqueVals:
            subDataSet = splitDataSet(dataSet, i ,value)
            prob = len(subDataSet) / float(len(dataSet))
            newEntropy += prob * calcShannonEnt(subDataSet)
        infoGain = baseEntropy - newEntropy  # 计算信息增益
        print("baseEntropy",baseEntropy,"i:",i,"newEntropy",newEntropy,"infoGain",infoGain)
        if(infoGain > bestInfoGain):
            bestInfoGain = infoGain   # 计算最好的信息增益
            bestFeature = i
    return bestFeature
```


```python
def majorityCnt(classList):
    classCount = {}
    for vote in classCount:
        if vote not in classCount.keys():
            classCount[vote] =0
        classCount[vote] += 1
    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse =True)
    return sortedClassCount[0][0]
```


```python
# 创建决策树
def createTree(dataSet,labels):
    classList = [example[-1] for example in dataSet]
    print("labels:",labels)
    print("classList:",classList)
    print("classList[0]:",classList[0])
    print("classList.count(classList[0]):",classList.count(classList[0]))
    
    ## 类别相同则停止划分
    if classList.count(classList[0]) == len(classList):
        return classList[0]
    
    ## 遍历完所有特征时 返回出现次数最多的
    if len(dataSet[0]) == 1:
        return majorityCnt(classList)
    
    bestFeat = chooseBestFeatureToSplit(dataSet)
    bestFeatLabel = labels[bestFeat] 
    print("bestFeatLabel",bestFeatLabel)
    myTree = {bestFeatLabel:{}}
    print("myTree:::",myTree)
    del(labels[bestFeat])
    print("labels:",labels)
    featValues = [example[bestFeat] for example in dataSet]
    uniqueVals = set(featValues)
    for value in uniqueVals:
        subLabels = labels[:]
        print("subLabels:",subLabels)
        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)
    return myTree
```


```python
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
simheifont = FontProperties(fname='../simhei.ttf')
```


```python
decisionNode = dict(boxstyle="sawtooth", fc="0.8")
leafNode = dict(boxstyle="round4", fc="0.8")
arrow_args = dict(arrowstyle="<-") def plotnode(nodetxt,centerpt,parentpt,nodetype): createplot.ax1.annotate(nodetxt,xy="parentPt," xycoords="axes fraction" , xytext="centerPt," textcoords="axes fraction" va="center" ,ha="center" ,bbox="nodeType," arrowprops="arrow_args," fontproperties="simheifont)" ``` ```python # 获取叶节点和树的层数 getnumleafs(mytree): numleafs="0" firststr="list(myTree.keys())[0]" seconddict="myTree[firstStr]" for key in seconddict.keys(): if type(seconddict[key]).__name__="=" 'dict': ## 测试节点的数据类型是否字典 +="getNumLeafs(secondDict[key])" else: return gettreedepth(mytree): maxdepth="0" thisdepth="1" gettreedepth(seconddict[key])> maxDepth:
            maxDepth = thisDepth
    return maxDepth
```


```python
def plotMidText(cntrPt, parentPt, txtString):
    xMid = (parentPt[0] - cntrPt[0]) /2.0 + cntrPt[0]
    yMid = (parentPt[1] - cntrPt[1]) /2.0 + cntrPt[1]
    createPlot.ax1.text(xMid,yMid, txtString)

def plotTree(myTree, parentPt, nodeText):
    numLeafs = getNumLeafs(myTree)
    depth = getTreeDepth(myTree)
    
    firstStr = list(myTree.keys())[0]
    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs)) /2.0 / plotTree.totalW, plotTree.yOff)
    plotMidText(cntrPt, parentPt, nodeText)
    plotNode(firstStr, cntrPt, parentPt, decisionNode)
    
    secondDict = myTree[firstStr]
    plotTree.yOff = plotTree.yOff - 1.0 / plotTree.totalD
    for key in secondDict.keys():
        if type(secondDict[key]).__name__ == 'dict':
            plotTree(secondDict[key], cntrPt, str(key))
        else:
            plotTree.xOff = plotTree.xOff + 1.0 / plotTree.totalW
            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)
            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt,str(key))
    plotTree.yOff = plotTree.yOff + 1.0 / plotTree.totalD

def createPlot(inTree):
    fig = plt.figure(1, facecolor='white')
    fig.clf()
    axprops = dict(xticks=[], yticks=[])
    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)
    plotTree.totalW = float(getNumLeafs(inTree))
    plotTree.totalD = float(getTreeDepth(inTree))
    plotTree.xOff = - 0.5/ plotTree.totalW
    plotTree.yOff = 1.0
    plotTree(inTree,(0.5,1.0),'')
    plt.show()
```


```python
# 使用决策树的分类函数
def classify(inputTree,featLabels, testVec):
    firstStr = list(inputTree.keys())[0]
    secondDict = inputTree[firstStr]
    featIndex = featLabels.index(firstStr)
    print(featIndex)
    
    for key in secondDict.keys():
        if testVec[featIndex] == key:
            if type(secondDict[key]).__name__ == 'dict':
                classLabel = classify(secondDict[key], featLabels, testVec)
            else:
                classLabel = secondDict[key]
    return classLabel
```


```python
def storeTree(inputTree,fileName):
    import _pickle as cPickle
    fw = open(fileName, 'w')
    cPickle.dump(inputTree,fw)
    fw.close()
    
def grabTree(fileName):
    import _pickle as cPickle
    fr = open(fileName)
    return cPickle.load(fr)
```


```python
with open("./dataset/lenses.txt",'r') as fr:
    lenses = [inst.strip().split('\t')  for inst in fr.readlines()]
    print(lenses)
    lensesLabels = ['age','prescript','astigmatic','tearRate']
    lensesTree = createTree(lenses,lensesLabels)
    lensesTree
```

    [['young', 'myope', 'no', 'reduced', 'no lenses'], ['young', 'myope', 'no', 'normal', 'soft'], ['young', 'myope', 'yes', 'reduced', 'no lenses'], ['young', 'myope', 'yes', 'normal', 'hard'], ['young', 'hyper', 'no', 'reduced', 'no lenses'], ['young', 'hyper', 'no', 'normal', 'soft'], ['young', 'hyper', 'yes', 'reduced', 'no lenses'], ['young', 'hyper', 'yes', 'normal', 'hard'], ['pre', 'myope', 'no', 'reduced', 'no lenses'], ['pre', 'myope', 'no', 'normal', 'soft'], ['pre', 'myope', 'yes', 'reduced', 'no lenses'], ['pre', 'myope', 'yes', 'normal', 'hard'], ['pre', 'hyper', 'no', 'reduced', 'no lenses'], ['pre', 'hyper', 'no', 'normal', 'soft'], ['pre', 'hyper', 'yes', 'reduced', 'no lenses'], ['pre', 'hyper', 'yes', 'normal', 'no lenses'], ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'], ['presbyopic', 'myope', 'no', 'normal', 'no lenses'], ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'], ['presbyopic', 'myope', 'yes', 'normal', 'hard'], ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'], ['presbyopic', 'hyper', 'no', 'normal', 'soft'], ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'], ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]
    labels: ['age', 'prescript', 'astigmatic', 'tearRate']
    classList: ['no lenses', 'soft', 'no lenses', 'hard', 'no lenses', 'soft', 'no lenses', 'hard', 'no lenses', 'soft', 'no lenses', 'hard', 'no lenses', 'soft', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'hard', 'no lenses', 'soft', 'no lenses', 'no lenses']
    classList[0]: no lenses
    classList.count(classList[0]): 15
    baseEntropy: 1.3260875253642983
    featList: ['young', 'young', 'young', 'young', 'young', 'young', 'young', 'young', 'pre', 'pre', 'pre', 'pre', 'pre', 'pre', 'pre', 'pre', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic']
    uniqueVals: {'young', 'pre', 'presbyopic'}
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'normal', 'soft']
    axis 0 reducedFeatVec: ['myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'normal', 'hard']
    axis 0 reducedFeatVec: ['myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'normal', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'normal', 'hard']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'normal', 'soft']
    axis 0 reducedFeatVec: ['myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'normal', 'hard']
    axis 0 reducedFeatVec: ['myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'normal', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'normal', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'normal', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'normal', 'hard']
    axis 0 reducedFeatVec: ['myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'normal', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'reduced', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'normal', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'normal', 'no lenses']
    baseEntropy 1.3260875253642983 i: 0 newEntropy 1.286691021718177 infoGain 0.03939650364612124
    featList: ['myope', 'myope', 'myope', 'myope', 'hyper', 'hyper', 'hyper', 'hyper', 'myope', 'myope', 'myope', 'myope', 'hyper', 'hyper', 'hyper', 'hyper', 'myope', 'myope', 'myope', 'myope', 'hyper', 'hyper', 'hyper', 'hyper']
    uniqueVals: {'myope', 'hyper'}
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['no', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['young', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['no', 'normal', 'soft']
    axis 1 reducedFeatVec: ['young', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['yes', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['young', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['yes', 'normal', 'hard']
    axis 1 reducedFeatVec: ['young', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['pre', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no', 'normal', 'soft']
    axis 1 reducedFeatVec: ['pre', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['yes', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['pre', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['yes', 'normal', 'hard']
    axis 1 reducedFeatVec: ['pre', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no', 'normal', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['yes', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['yes', 'normal', 'hard']
    axis 1 reducedFeatVec: ['presbyopic', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['no', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['young', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['no', 'normal', 'soft']
    axis 1 reducedFeatVec: ['young', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['yes', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['young', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['yes', 'normal', 'hard']
    axis 1 reducedFeatVec: ['young', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['pre', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no', 'normal', 'soft']
    axis 1 reducedFeatVec: ['pre', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['yes', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['pre', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['yes', 'normal', 'no lenses']
    axis 1 reducedFeatVec: ['pre', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no', 'normal', 'soft']
    axis 1 reducedFeatVec: ['presbyopic', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['yes', 'reduced', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['yes', 'normal', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'yes', 'normal', 'no lenses']
    baseEntropy 1.3260875253642983 i: 1 newEntropy 1.2865766899407325 infoGain 0.039510835423565815
    featList: ['no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes']
    uniqueVals: {'yes', 'no'}
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['young', 'myope', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['normal', 'hard']
    axis 2 reducedFeatVec: ['young', 'myope', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['young', 'hyper', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['normal', 'hard']
    axis 2 reducedFeatVec: ['young', 'hyper', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['pre', 'myope', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['normal', 'hard']
    axis 2 reducedFeatVec: ['pre', 'myope', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['normal', 'no lenses']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['normal', 'hard']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['normal', 'no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'normal', 'no lenses']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['young', 'myope', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['normal', 'soft']
    axis 2 reducedFeatVec: ['young', 'myope', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['young', 'hyper', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['normal', 'soft']
    axis 2 reducedFeatVec: ['young', 'hyper', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['pre', 'myope', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['normal', 'soft']
    axis 2 reducedFeatVec: ['pre', 'myope', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['normal', 'soft']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['normal', 'no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['reduced', 'no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['normal', 'soft']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    baseEntropy 1.3260875253642983 i: 2 newEntropy 0.9490822953528211 infoGain 0.37700523001147723
    featList: ['reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal', 'reduced', 'normal']
    uniqueVals: {'reduced', 'normal'}
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'myope', 'no', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'myope', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'myope', 'yes', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'hyper', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'hyper', 'no', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'myope', 'no', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'myope', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'myope', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'hyper', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'myope', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes', 'no lenses']
    baseEntropy 1.3260875253642983 i: 3 newEntropy 0.7772925846688997 infoGain 0.5487949406953986
    bestFeatLabel tearRate
    myTree::: {'tearRate': {}}
    labels: ['age', 'prescript', 'astigmatic']
    subLabels: ['age', 'prescript', 'astigmatic']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'myope', 'no', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'myope', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'myope', 'yes', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'hyper', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'hyper', 'no', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'myope', 'no', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    axis 3 featVec[axis] reduced
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    labels: ['age', 'prescript', 'astigmatic']
    classList: ['no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses', 'no lenses']
    classList[0]: no lenses
    classList.count(classList[0]): 12
    subLabels: ['age', 'prescript', 'astigmatic']
    featVec ['young', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'myope', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'myope', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'myope', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'hyper', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['young', 'hyper', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'myope', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'myope', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['pre', 'hyper', 'yes', 'normal', 'no lenses']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'normal', 'no lenses']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'normal', 'hard']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes']
    featVec[axis+1:] ['hard']
    axis 3 reducedFeatVec: ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'no', 'normal', 'soft']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no']
    featVec[axis+1:] ['soft']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses']
    featVec ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']
    axis 3 featVec[axis] normal
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes']
    featVec[axis+1:] ['no lenses']
    axis 3 reducedFeatVec: ['presbyopic', 'hyper', 'yes', 'no lenses']
    labels: ['age', 'prescript', 'astigmatic']
    classList: ['soft', 'hard', 'soft', 'hard', 'soft', 'hard', 'soft', 'no lenses', 'no lenses', 'hard', 'soft', 'no lenses']
    classList[0]: soft
    classList.count(classList[0]): 5
    baseEntropy: 1.5545851693377994
    featList: ['young', 'young', 'young', 'young', 'pre', 'pre', 'pre', 'pre', 'presbyopic', 'presbyopic', 'presbyopic', 'presbyopic']
    uniqueVals: {'young', 'pre', 'presbyopic'}
    featVec ['young', 'myope', 'no', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'soft']
    axis 0 reducedFeatVec: ['myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'hard']
    axis 0 reducedFeatVec: ['myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'hard']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    featVec ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'soft']
    axis 0 reducedFeatVec: ['myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'hard']
    axis 0 reducedFeatVec: ['myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    featVec ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'yes', 'hard']
    axis 0 reducedFeatVec: ['myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'yes', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'yes', 'no lenses']
    baseEntropy 1.5545851693377994 i: 0 newEntropy 1.3333333333333333 infoGain 0.22125183600446618
    featList: ['myope', 'myope', 'hyper', 'hyper', 'myope', 'myope', 'hyper', 'hyper', 'myope', 'myope', 'hyper', 'hyper']
    uniqueVals: {'myope', 'hyper'}
    featVec ['young', 'myope', 'no', 'soft']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['no', 'soft']
    axis 1 reducedFeatVec: ['young', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['yes', 'hard']
    axis 1 reducedFeatVec: ['young', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no', 'soft']
    axis 1 reducedFeatVec: ['pre', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['yes', 'hard']
    axis 1 reducedFeatVec: ['pre', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['yes', 'hard']
    axis 1 reducedFeatVec: ['presbyopic', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    featVec ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['no', 'soft']
    axis 1 reducedFeatVec: ['young', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['yes', 'hard']
    axis 1 reducedFeatVec: ['young', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no', 'soft']
    axis 1 reducedFeatVec: ['pre', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['yes', 'no lenses']
    axis 1 reducedFeatVec: ['pre', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no', 'soft']
    axis 1 reducedFeatVec: ['presbyopic', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['yes', 'no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'yes', 'no lenses']
    baseEntropy 1.5545851693377994 i: 1 newEntropy 1.4591479170272446 infoGain 0.09543725231055489
    featList: ['no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes']
    uniqueVals: {'yes', 'no'}
    featVec ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['young', 'myope', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['young', 'hyper', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['pre', 'myope', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['no lenses']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'no lenses']
    featVec ['young', 'myope', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['young', 'myope', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['young', 'hyper', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['pre', 'myope', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    baseEntropy 1.5545851693377994 i: 2 newEntropy 0.7841591278514218 infoGain 0.7704260414863776
    bestFeatLabel astigmatic
    myTree::: {'astigmatic': {}}
    labels: ['age', 'prescript']
    subLabels: ['age', 'prescript']
    featVec ['young', 'myope', 'no', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['young', 'myope', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['young', 'hyper', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['pre', 'myope', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['no lenses']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['hard']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    axis 2 featVec[axis] yes
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'no lenses']
    labels: ['age', 'prescript']
    classList: ['hard', 'hard', 'hard', 'no lenses', 'hard', 'no lenses']
    classList[0]: hard
    classList.count(classList[0]): 4
    baseEntropy: 0.9182958340544896
    featList: ['young', 'young', 'pre', 'pre', 'presbyopic', 'presbyopic']
    uniqueVals: {'young', 'pre', 'presbyopic'}
    featVec ['young', 'myope', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'hard']
    axis 0 reducedFeatVec: ['myope', 'hard']
    featVec ['young', 'hyper', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'hard']
    axis 0 reducedFeatVec: ['hyper', 'hard']
    featVec ['pre', 'myope', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    featVec ['young', 'myope', 'hard']
    featVec ['young', 'hyper', 'hard']
    featVec ['pre', 'myope', 'hard']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'hard']
    axis 0 reducedFeatVec: ['myope', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    featVec ['young', 'myope', 'hard']
    featVec ['young', 'hyper', 'hard']
    featVec ['pre', 'myope', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'hard']
    axis 0 reducedFeatVec: ['myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'no lenses']
    axis 0 reducedFeatVec: ['hyper', 'no lenses']
    baseEntropy 0.9182958340544896 i: 0 newEntropy 0.6666666666666666 infoGain 0.2516291673878229
    featList: ['myope', 'hyper', 'myope', 'hyper', 'myope', 'hyper']
    uniqueVals: {'myope', 'hyper'}
    featVec ['young', 'myope', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['young', 'hard']
    featVec ['young', 'hyper', 'hard']
    featVec ['pre', 'myope', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['pre', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['presbyopic', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    featVec ['young', 'myope', 'hard']
    featVec ['young', 'hyper', 'hard']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['young', 'hard']
    featVec ['pre', 'myope', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no lenses']
    axis 1 reducedFeatVec: ['pre', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no lenses']
    baseEntropy 0.9182958340544896 i: 1 newEntropy 0.4591479170272448 infoGain 0.4591479170272448
    bestFeatLabel prescript
    myTree::: {'prescript': {}}
    labels: ['age']
    subLabels: ['age']
    featVec ['young', 'myope', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['young', 'hard']
    featVec ['young', 'hyper', 'hard']
    featVec ['pre', 'myope', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['pre', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['presbyopic', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    labels: ['age']
    classList: ['hard', 'hard', 'hard']
    classList[0]: hard
    classList.count(classList[0]): 3
    subLabels: ['age']
    featVec ['young', 'myope', 'hard']
    featVec ['young', 'hyper', 'hard']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['hard']
    axis 1 reducedFeatVec: ['young', 'hard']
    featVec ['pre', 'myope', 'hard']
    featVec ['pre', 'hyper', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['no lenses']
    axis 1 reducedFeatVec: ['pre', 'no lenses']
    featVec ['presbyopic', 'myope', 'hard']
    featVec ['presbyopic', 'hyper', 'no lenses']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no lenses']
    labels: ['age']
    classList: ['hard', 'no lenses', 'no lenses']
    classList[0]: hard
    classList.count(classList[0]): 1
    baseEntropy: 0.9182958340544896
    featList: ['young', 'pre', 'presbyopic']
    uniqueVals: {'young', 'pre', 'presbyopic'}
    featVec ['young', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hard']
    axis 0 reducedFeatVec: ['hard']
    featVec ['pre', 'no lenses']
    featVec ['presbyopic', 'no lenses']
    featVec ['young', 'hard']
    featVec ['pre', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no lenses']
    axis 0 reducedFeatVec: ['no lenses']
    featVec ['presbyopic', 'no lenses']
    featVec ['young', 'hard']
    featVec ['pre', 'no lenses']
    featVec ['presbyopic', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no lenses']
    axis 0 reducedFeatVec: ['no lenses']
    baseEntropy 0.9182958340544896 i: 0 newEntropy 0.0 infoGain 0.9182958340544896
    bestFeatLabel age
    myTree::: {'age': {}}
    labels: []
    subLabels: []
    featVec ['young', 'hard']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hard']
    axis 0 reducedFeatVec: ['hard']
    featVec ['pre', 'no lenses']
    featVec ['presbyopic', 'no lenses']
    labels: []
    classList: ['hard']
    classList[0]: hard
    classList.count(classList[0]): 1
    subLabels: []
    featVec ['young', 'hard']
    featVec ['pre', 'no lenses']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no lenses']
    axis 0 reducedFeatVec: ['no lenses']
    featVec ['presbyopic', 'no lenses']
    labels: []
    classList: ['no lenses']
    classList[0]: no lenses
    classList.count(classList[0]): 1
    subLabels: []
    featVec ['young', 'hard']
    featVec ['pre', 'no lenses']
    featVec ['presbyopic', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no lenses']
    axis 0 reducedFeatVec: ['no lenses']
    labels: []
    classList: ['no lenses']
    classList[0]: no lenses
    classList.count(classList[0]): 1
    subLabels: ['age', 'prescript']
    featVec ['young', 'myope', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'myope']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['young', 'myope', 'soft']
    featVec ['young', 'myope', 'yes', 'hard']
    featVec ['young', 'hyper', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['young', 'hyper']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['young', 'hyper', 'soft']
    featVec ['young', 'hyper', 'yes', 'hard']
    featVec ['pre', 'myope', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'myope']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['pre', 'myope', 'soft']
    featVec ['pre', 'myope', 'yes', 'hard']
    featVec ['pre', 'hyper', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['pre', 'hyper']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['pre', 'hyper', 'soft']
    featVec ['pre', 'hyper', 'yes', 'no lenses']
    featVec ['presbyopic', 'myope', 'no', 'no lenses']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'myope']
    featVec[axis+1:] ['no lenses']
    axis 2 reducedFeatVec: ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'myope', 'yes', 'hard']
    featVec ['presbyopic', 'hyper', 'no', 'soft']
    axis 2 featVec[axis] no
    axis 2 reducedFeatVec: ['presbyopic', 'hyper']
    featVec[axis+1:] ['soft']
    axis 2 reducedFeatVec: ['presbyopic', 'hyper', 'soft']
    featVec ['presbyopic', 'hyper', 'yes', 'no lenses']
    labels: ['age', 'prescript']
    classList: ['soft', 'soft', 'soft', 'soft', 'no lenses', 'soft']
    classList[0]: soft
    classList.count(classList[0]): 5
    baseEntropy: 0.6500224216483541
    featList: ['young', 'young', 'pre', 'pre', 'presbyopic', 'presbyopic']
    uniqueVals: {'young', 'pre', 'presbyopic'}
    featVec ['young', 'myope', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'soft']
    axis 0 reducedFeatVec: ['myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    featVec ['young', 'myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'soft']
    axis 0 reducedFeatVec: ['myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    featVec ['young', 'myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'soft']
    baseEntropy 0.6500224216483541 i: 0 newEntropy 0.3333333333333333 infoGain 0.3166890883150208
    featList: ['myope', 'hyper', 'myope', 'hyper', 'myope', 'hyper']
    uniqueVals: {'myope', 'hyper'}
    featVec ['young', 'myope', 'soft']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['soft']
    axis 1 reducedFeatVec: ['young', 'soft']
    featVec ['young', 'hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['soft']
    axis 1 reducedFeatVec: ['pre', 'soft']
    featVec ['pre', 'hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    axis 1 featVec[axis] myope
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['no lenses']
    axis 1 reducedFeatVec: ['presbyopic', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    featVec ['young', 'myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['young']
    featVec[axis+1:] ['soft']
    axis 1 reducedFeatVec: ['young', 'soft']
    featVec ['pre', 'myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['pre']
    featVec[axis+1:] ['soft']
    axis 1 reducedFeatVec: ['pre', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    axis 1 featVec[axis] hyper
    axis 1 reducedFeatVec: ['presbyopic']
    featVec[axis+1:] ['soft']
    axis 1 reducedFeatVec: ['presbyopic', 'soft']
    baseEntropy 0.6500224216483541 i: 1 newEntropy 0.4591479170272448 infoGain 0.19087450462110933
    bestFeatLabel age
    myTree::: {'age': {}}
    labels: ['prescript']
    subLabels: ['prescript']
    featVec ['young', 'myope', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'soft']
    axis 0 reducedFeatVec: ['myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    axis 0 featVec[axis] young
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    labels: ['prescript']
    classList: ['soft', 'soft']
    classList[0]: soft
    classList.count(classList[0]): 2
    subLabels: ['prescript']
    featVec ['young', 'myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'soft']
    axis 0 reducedFeatVec: ['myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    axis 0 featVec[axis] pre
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    labels: ['prescript']
    classList: ['soft', 'soft']
    classList[0]: soft
    classList.count(classList[0]): 2
    subLabels: ['prescript']
    featVec ['young', 'myope', 'soft']
    featVec ['young', 'hyper', 'soft']
    featVec ['pre', 'myope', 'soft']
    featVec ['pre', 'hyper', 'soft']
    featVec ['presbyopic', 'myope', 'no lenses']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['myope', 'no lenses']
    axis 0 reducedFeatVec: ['myope', 'no lenses']
    featVec ['presbyopic', 'hyper', 'soft']
    axis 0 featVec[axis] presbyopic
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['hyper', 'soft']
    axis 0 reducedFeatVec: ['hyper', 'soft']
    labels: ['prescript']
    classList: ['no lenses', 'soft']
    classList[0]: no lenses
    classList.count(classList[0]): 1
    baseEntropy: 1.0
    featList: ['myope', 'hyper']
    uniqueVals: {'myope', 'hyper'}
    featVec ['myope', 'no lenses']
    axis 0 featVec[axis] myope
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no lenses']
    axis 0 reducedFeatVec: ['no lenses']
    featVec ['hyper', 'soft']
    featVec ['myope', 'no lenses']
    featVec ['hyper', 'soft']
    axis 0 featVec[axis] hyper
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['soft']
    axis 0 reducedFeatVec: ['soft']
    baseEntropy 1.0 i: 0 newEntropy 0.0 infoGain 1.0
    bestFeatLabel prescript
    myTree::: {'prescript': {}}
    labels: []
    subLabels: []
    featVec ['myope', 'no lenses']
    axis 0 featVec[axis] myope
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no lenses']
    axis 0 reducedFeatVec: ['no lenses']
    featVec ['hyper', 'soft']
    labels: []
    classList: ['no lenses']
    classList[0]: no lenses
    classList.count(classList[0]): 1
    subLabels: []
    featVec ['myope', 'no lenses']
    featVec ['hyper', 'soft']
    axis 0 featVec[axis] hyper
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['soft']
    axis 0 reducedFeatVec: ['soft']
    labels: []
    classList: ['soft']
    classList[0]: soft
    classList.count(classList[0]): 1



```python
createPlot(lensesTree)
```


![png](./使用决策树预测隐形眼镜类型/output_14_0.png)

 

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </-")>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>内容平台的内容规范</title>
    <url>/2019/11/03/%E5%85%B3%E4%BA%8E%E5%86%85%E5%AE%B9%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 内容平台的内容规范

- 禁止发布违背现行法律法规，危害国家及社会安全的信息
- 禁止发布淫秽色情信息
- 禁止发布不实信息
- 禁止发布垃圾广告
- 禁止发布不适合平台推广的信息
- 禁止发布泄漏他人隐私信息的内容
- 禁止发布侵犯他人版权、肖像权、知识产权的内容
- 禁止在内容中对他人进行诽谤、侮辱、人身攻击

### 规范要求

#### 文案

内容的文案需通顺，观点清晰

- 标题，禁止使用网络用语
- 文案，禁止虚假自卖自夸

#### 图片

需美观、清晰，突出主题

#### 商品

|          | 评估项   | 描述                                                     |
| -------- | -------- | -------------------------------------------------------- |
| 安全相关 | 敏感信息 | - 封建迷信型  -色情擦边型   - 危害生命型   - 保健功效型  |
|          | 站外推广 | 图片中出现站外平台的水印、logo；内容中出现站外平台的名称 |



|          |          |                                                              |
| -------- | -------- | ------------------------------------------------------------ |
| 内容素材 | 明星八卦 | - 未经授权的明星图片、明星八卦   - 过度拼图   - 图片拉伸变形、裁剪不当 |
|          | 段子资讯 | 搞笑段子、新闻资讯、表情包                                   |
|          | 图文不符 | 图片与正文内容相关度低                                       |
|          | 文品不符 | 文章与所推商品符合度较低                                     |
|          | 题文不符 | 标题与正文符合度较低                                         |

|      |            |                                                    |
| ---- | ---------- | -------------------------------------------------- |
| 标题 | 有错字     | 标题内有错别字，或者句号                           |
|      | 不通顺     | 阅读不通顺、全英文、全数字、繁体字                 |
|      | 纯商品标题 | 标题与商品名称完全一致，成为纯商品描述             |
|      | 时效标题   | 标题哪出现几月几日，节假日等强调时效信息、过时信息 |
|      | 不合规     | 标题出现广告禁用词，如：最高，第一，全国最优       |
|      |            | 标题命中标题党模型，如：                           |
|      |            | - 故弄玄虚型：不为人知，万万没想到，真相竟是这样   |
|      |            | - 震惊松动型：看哭了，惊呆了，吓死了               |
|      |            | - 挑衅威胁型：肠子都悔青了                         |
|      |            | - 夸大数据型：99%的人                              |
|      |            | - 夸大效果型：千万不要，堪比整容                   |
|      |            | - 危害生命型：让人窒息，犹如服毒                   |
|      |            | - 绝对因果型：就是因为XXX，导致了XXX               |
|      |            | - 编造冲突型：败家、渣男                           |
|      |            | 不宜推广的标题，如，出现人隐私部位的               |
|      |            | 不良价值观的标题，如：                             |
|      |            | - 不实炫富型：干爹送、XX送贵重首饰、车等编造的内容 |
|      |            | - 嫌贫爱富型：穷人不配，买不起                     |
|      |            | 色情擦边的标题                                     |

|      |            |                                                             |
| ---- | ---------- | ----------------------------------------------------------- |
| 正文 | 有错字     | 正文包含错别字，或故意写错的字                              |
|      | 不通顺     | 正文不符合基本文法、阅读不通畅                              |
|      |            | 正文全英文、全数字、全繁体字，全少数民族文字，颜文字超过50% |
|      | 时效强     | 正文出现几月几日，周几次泪强时效信息，过时信息              |
|      | 段落错误   | 正文全文无分段，或段落与段落之间的空行过多                  |
|      |            | 正文段落重复，或连续20个字重复出现                          |
|      | 低质过短   | 正文篇幅过短，内容无实质信息                                |
|      | 无真实心得 | 正文无本人视角，不是真实的心得分享                          |
|      | 情感负面   | 正文情感负面，如：                                          |
|      |            | - 态度消极：觉得生活没有希望                                |
|      |            | - 用词低俗：渣男，穷B，败家                                 |
|      |            | - 恶意对比：闺蜜没有我好看                                  |
|      |            | - 贬义词频发：黑心商家、无良商人                            |
|      |            | - 不良价值观：不实炫富、嫌贫爱富                            |

|      |          |                                      |
| ---- | -------- | ------------------------------------ |
| 图片 | 不清晰   | - 图片分辨率低，模糊不清             |
|      |          | - 图片拉伸变形，剪裁不当             |
|      |          | - 过度拼图                           |
|      | 不美观   | - 图片拍摄过暗、背景杂乱，主题不明显 |
|      |          | - 图片含马赛克、文字过载             |
|      |          | - 图片旋转倒置，尺寸不一             |
|      |          | - 图片留白过多                       |
|      | 有重复   | - 图片有重复或者拍摄陈列一致         |
|      | 过度P图  | - 人脸，身材PS过度                   |
|      | 无场景感 | - 白底或者其他纯色商品图             |
|      |          | - 平铺挂拍图，假模道具图，棚拍图     |
|      |          | - 商业营销图                         |
|      |          | - 素材插画图                         |
|      | 敏感不雅 | 图片涉黄、色情、姿势不雅，如：       |
|      |          | - 裸露类                             |
|      |          | - 制服类                             |
|      |          | - 引诱类                             |
|      | 恶心低俗 | 图片恶心、低俗、惊惧、密恐           |

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>内容产品</category>
        <category>内容审核</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>内容产品</tag>
        <tag>内容审核</tag>
      </tags>
  </entry>
  <entry>
    <title>关于产品增长的一些思考</title>
    <url>/2020/02/08/%E5%85%B3%E4%BA%8E%E4%BA%A7%E5%93%81%E5%A2%9E%E9%95%BF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 关于产品增长的一些思考

**增长的定义：增长是把产品的价值传播最大化的过程，即为，让更多用户更快更顺利更频繁的体验到产品的核心价值。**

## 思维框架

### 前提条件

- 产品本身有核心价值
- 公司的商业变现模式有效
- 公司战略本身符合行业和市场本身趋势

### 依赖条件

- 比较完整而精确的数据
- 能够操作实验，且能及时获得反馈
- 可以依靠技术和精细化的产品、运营手段驱动增长

**基于产品形态和数据分析，利用技术手段达到数据倍数的增长。**

### 关键特点

- 要关注用户生命周期，不要仅仅限制于拉新
- 通过科学方法带来高效、持续的增长
- 强调实验和数据驱动
- 跨功能增长团队，直接对指标负责

![img](https://cdn.nlark.com/yuque/0/2019/png/512357/1571140439058-85992a38-38ef-46ec-aedd-396033d4d653.png)

### 内核逻辑

1、精准定义问题---细分问题并设计权重

2、定义清晰目标---收集问题相关的信息

3、解决思路及方案---针对高权重的问题

操作方案：

- 根据业务现状、灵活调整，找合适的增长点
- 集中火力，重点突破
- 借鉴其他产品的策略，可持续增长

在公司业务的不同阶段，增长的重点工作方向不同

![6.jpg](https://cdn.nlark.com/yuque/0/2019/jpeg/512357/1571140749697-e03f2160-9ed9-4c74-a46d-eed71f97e3d8.jpeg?x-oss-process=image/resize,w_1200)

## 从全局看增长

### 明确是否已准备好进行大规模增长

**PMF（Product Market Fit）产品市场契合，即，不仅有用户需要你的产品，并且在较长时间内重复使用它。**

大规模增长的判断条件：==达到PMF后==

新产品/初创产品的增长顺序尽量改变增长推荐顺序---RARRA，通过打磨产品实现PMF，然后有策略又不知道推进增长

![5.jpg](https://cdn.nlark.com/yuque/0/2019/jpeg/512357/1571140635352-f241e7fc-e60b-4bec-bdc8-45737d1b70e0.jpeg?x-oss-process=image/resize,w_1288)

#### 判断是否达到PMF

- 直观表现：高自然增长率，有口碑，核心用户留存和使用率高
- 数据表现：用户留存率高，留存曲线更扁平

#### 寻找PMF的步骤

即为产品验证的过程

- 找到需求市场：市场足够大，足够紧急，解决问题能给用户创造价值
- 构建MVP：验证产品是否真的需要
- 通过数据反馈优化产品，直至达到PMF

### 评估增长的重点

AARRR模型 适用于各行业，==**但是产品阶段不同，产品品类不同，产品所处的市场周期不同决定了产品增长的重点会有所不同。**==

#### 寻找增长重点的四个有效步骤

##### 目标市场处于什么阶段？

- 增量市场：重点在获客，抢占流量红利
- 存量市场：重点在留存和变现；寻找增量市场

##### 自身产品处于生命周期的哪个阶段？

- 探索期：PMF留存
- 成长期：获客
- 成熟期：留存+获客+变现
- 衰退期：留存+变现+迁移（寻找第二增长曲线）

###### 判断生命周期的方法：

- 参考市场渗透度曲线
- 参考净增长+留存矩阵

![3.jpg](https://cdn.nlark.com/yuque/0/2019/jpeg/512357/1571140528599-facbe6c7-59d9-4b28-bd99-e11e7e7762e6.jpeg?x-oss-process=image/resize,w_1320)

##### 自身产品属于哪个品类？

类别：

- 工具
- 内容
- 游戏
- 社交
- 电商
- 平台
- SaaS
- 复合产品

![2.jpg](https://cdn.nlark.com/yuque/0/2019/jpeg/512357/1571140491243-e079bab7-1b16-4186-bb0c-33e95e6fc133.jpeg?x-oss-process=image/resize,w_1318)

**洞察**

- 社交或互动属性的产品，可依赖社交获客和留存
- 用户付费意愿高的产品直接去变现，从而支持买辆获客
- 免费高频机用户投入时间大的产品先做留存，再变现
- 越来越复合型的产品模式，将社交/付费和留存结合起来

##### 自身产品的商业模式有哪些独特的重要因素？（对产品增长有影响的）

![7.jpg](https://cdn.nlark.com/yuque/0/2019/jpeg/512357/1571140705332-8fbfb8e7-ebaf-460d-a4e9-f85bf7d11a0d.jpeg?x-oss-process=image/resize,w_1284)



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>增长产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>增长</tag>
        <tag>GrowthHacking</tag>
      </tags>
  </entry>
  <entry>
    <title>内容类产品——个性化推荐和热度算法</title>
    <url>/2019/01/14/%E5%86%85%E5%AE%B9%E4%BA%A7%E5%93%81%E2%80%94%E2%80%94%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E5%92%8C%E7%83%AD%E5%BA%A6%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 1 初期阶段

​	个性化推荐不是产品首次发布就能自带的。无论是基于用户行为的个性化，还是基于内容相似度的个性化，都建立在大量的用户数和内容的基础上。

​	产品发布之初，一般两遍的数据都有残缺，因此个性化推荐并不能完整开展。

​	故，产品发展初期 推荐内容一般采用更加聚合的“热度算法”，把热点的内容有限推荐给用户；虽无法做到基于兴趣和习惯为每一个用户做到准确化推荐，但能覆盖到大部分用户需求，而且启动成本比个性化推荐算法低很多。



## 2 热度算法

### 2.1 热度算法基本原理

新闻热度分 = 初始热度分 + 用户交互产生的热度分 – 随时间衰减的热度分

**Score = S0 + S(Users) – S(Time)**

1、新闻入库后，被系统赋予一个初始热度值，该新闻进入推荐列表进行排序

2、随着新闻不断被用户点击阅读，收藏，分享...... 用户行为被视作帮助提升新闻热度，系统需要为每种新闻重新赋予热度值

3、同时，新闻自身具有较强的实效性，随着时间的变化而变的陈旧，进而热度衰减



### 2.2 初始热度需要不一致



由于不同的新闻本身属性所在，受欢迎程度是不一样的。

如：娱乐类比文化类受欢迎程度高；

​	某些突发事件的受关注度也会急剧变高；

​	体育活动期间，体育类的关注度也会继续变高；

解决方案：把初始热度设置为变量。

（1）按照新闻类别给予新闻不同的初始热度，让用户关注高的类别获得更高的初始热度分，从而获得更多的曝光

​	![img](https://cdn.nlark.com/yuque/0/2018/png/153571/1542210593928-b2cc24d5-5f9a-4e13-8f27-a1b84de07e10.png)

（2）对于重大事件的报道，可通过热词匹配来使其入库即具备更高的热度

​		对大型新闻站点的头条，Twitter热点，竞品头条监控和爬取，并将关键词维护到热词库并保持更新；

​		每条新闻入库时，用新闻的关键词去匹配热词库，匹配度越高，则有越高的初始化热度；



### 2.3 用户行为分规则不是固定不变的

​		

有了初始热度分之后，需要考虑热度分的变化。

1、先明确用户哪些行为会影响到热度分值，并对这些行为赋予一定的得分规则

2、例如：点击（click）、收藏（favor）、分享（share）、评论（comment），对行为赋予分数，即可得到实时用户行为分：

​		**S(Users) = 1*****click + 5*****favor + 10*****comment + 20*****share**

​	示例分数：但分数值不是一成不变的，做内容运营时需要对行为分不断调整

​		click ， 1分，

​		favor，5分，

​		share，10分，

​		comment ，20分，

​	当用户规模小的时候，各项事件量小，需要提高每个事件的行为分来提升用户行为的影响力；

​	当用户规模变大时，行为分也应该相应的慢慢降低；



### 2.4 热度随时间的衰减不是线性的

1、由于内容的时效性，已发布的新闻热度值必须随时间流逝二衰减，并且衰减趋势越来越快，直至趋于0热度。

​	如果一条新闻（内容）需要长期处于靠前的位置，随时间推移必须有越来越多的用户来维持。

![img](https://cdn.nlark.com/yuque/0/2018/png/153571/1542210701999-d31971f0-a790-49a2-94ec-8340e6e8b377.png)

2、要求推荐给用户的新闻（内容）必须是24h以内，故 衰减算法必须保证在24h后 内容热度一定会衰减到很低。

​	线性衰减：当新闻突然有大量用户点击阅读，获得极高热度分，就会持续排名靠前，会使用户感觉内容更新较慢

​	指数衰减：参考牛顿冷却定律，时间衰减因子应该是一个类似于指数函数：

​			**T(Time) = e ^ (k\*(T1 – T0))**

​			其中T0是新闻发布时间，T1是当前时间

而热度的发展最终是一个无限趋近于0热度的结果，最终算法调整为：

​			**Score = ( S0(Type) + S(Users) ) / T(Time)**



### 2.5 其它影响因素

“赞” “踩” “不推荐此类”等选项的存在

建议：把所有的调整指标均做成可配项，如：初始热度分，行为事件分，衰减因子等



## 3 个性化推荐

个性化推荐 一般常用的两种解决方案：一是基于内容的相关推荐，二是基于用户的协同过滤（对用户规模有较高要求）

### 3.1 基于内容的推荐算法

“新闻（内容）特征向量”来标示新闻的属性，以及用来对比内容之间的相似度；

​	新闻（内容）特征向量是由内容所包含的关键词所决定的；

​	把新闻（内容）看作所有关键词（标签）的合集；

​	两个新闻（内容）的关键词越类似，则两个内容是相关的可能性更高；

#### 3.1.1 分词

得到新闻（内容）特征向量的第一步， 就是要对新闻（内容）进行关键词级别的拆分。

- 分词
  - 正常词库：把内容拆解为词语的标准

停用词 主要是没有实际含义的，如“the” "that" "are"之类的助词，如"behind" "under" 之类的介词， 以及很多常用的高频但没有偏向性的动词"think" "give";

  - 停用词库：分词过程中需要首先去掉的内容

分词之前剔除停用词，对剩下的标准词库进行拆词，拆词方法包含正向匹配拆分，逆向匹配拆分，最少切分等常用算法

由于网络热词的频出，标准词库和停用词库也需要随之不断更新维护。



#### 3.1.2 关键词指标

- 关键词重合度
- 新闻（内容）内频率，TF（Term Frequency）
  - 衡量每个关键词在新闻（内容）里面是否高频
- 关键词在所有文档内出现的频率相反值，IDF（Inverse Document Frequency）
  - 如果一个关键词在某条新闻内出现的频率最大，在所有文档内出现频率小，则该关键词对这条新闻的特征标识作用越大

**TF-IDF模型**

每个关键词对新闻的作用衡量： 	**TFIDF = TF * IDF**



#### 3.1.3 相关性算法

每一份新闻（内容）的特征，即可用关键词的集合来标识：

![img](https://cdn.nlark.com/yuque/0/2018/png/153571/1542210840538-f319a86b-236b-40e6-8625-7cab674fd83a.png)

其中word0，1，2……n是新闻的所有关键词，tfidf0，1，2……n则是每个关键词的tfidf值



相关性计算：

![image-20190117100504112](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20190117100504112.png)



#### 3.1.4 用户特征

通过用户行为来获得，用户通过阅读、点赞、评论、分享来表达对新闻（内容）的喜爱；

 对用户的各种行为赋予一定的“喜爱分”，例如阅读1分，点赞2分，评论5分等；

新闻（内容）特征 与用户行为分结合，即可得到用户的特征分。



![image-20190117101005933](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20190117101005933.png)

随着用户阅读的新闻（内容）越来越多，该用户的标签也越来越多，并且越发精准；

当我们拿到新闻（内容）的特征后，就能与用户的关键词列表做匹配，得出用户阅读特征的匹配度，做出个性推荐。



#### 3.1.5 其他运用

除了个性推荐，基于内容的相关性，可精准的给出一篇相关推荐列表；



#### 3.1.6 优缺点

- 优点
   - 对用户数量没有要求，与日活无关，个性化推荐的早期一般可采用此方式；

   - 每个用户特征是由自己行为决定的，独立存在，不会相互干扰， 恶意刷阅读内容不会营销到推荐算法；

- 缺点
   - 确定性太强，推荐内容均由用户历史访问决定，无法挖掘用户潜在兴趣
   - 基于内容的推荐一般与其他推荐算法同时存在

### 3.2 基于用户的协同推荐

当具备内容协同过滤推荐后，推给用户的内容均为基于他们的阅读习惯来推荐，没能给用户“不期而遇”的感觉。

则，需要开始实现基于用户的协同过滤。

- 基于用户协同过滤推荐算法：

​	依据用户A的阅读喜好，为A找到与他兴趣最接近的群体； 即“人以群分”，把这个群体内其他人喜欢的，但A未阅读的推荐给A

#### 3.2.1 用户群体划分

##### 3.2.1.1 外部数据借用

​	使用第三方账户授权进入的，往往会包括性别、年龄、工作、甚至社交关系等

##### 3.2.1.2 产品内主动询问

​	产品首次启动时的弹窗询问，“职业” “性别”  对内容的冷启动提供帮助， 但性价比偏低

##### 3.2.1.3 对比用户特征

​	从内容的特征+用户的阅读数据 来得到用户特征，通过用户特征的相似性来划分群体



#### 3.2.2 内容推荐实施

A B C D E 5个用户

​	阅读  1分，

​	赞   2分，

​	收藏   3分，

​	评论   4分，

​	分享    5分

![image-20190117133645188](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20190117133645188.png)



各个用户的特征向量：

![image-20190117133715263](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20190117133715263.png)



多维向量的距离需要通过欧几里得距离公式来计算，数值越小，向量距离约接近。



![image-20190117133658566](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20190117133658566.png)





#### 3.2.3 内容选取

假设用户X在系统归属于群体A，这个群体有n个用户，分别为A0，A1，A2……An，这些用户的集合用S(X,n)表示。

1. 首先，我们需要把集合中所有用户交互过（阅读，评论等）的新闻提取出来；
2. 需要剔除掉用户X已经看过的新闻，这些就不用再推荐了，剩下的新闻集合有m条，用N(X,m)来表示；
3. 对余下的新闻进行评分和相似度加权的计算，计算包括两部分，一是用户X与S(X,n) 每一个用户的相似性，二是每个用户对新闻集N(X,m)中每条新闻的喜好，这样就能得到每条新闻相对于用户X的最终得分；
4. 将N(X,m)中的新闻列表按照得分高低的顺序推荐给用户。

#### 3.2.4 优缺点

- 优点
  - 对分词算法的精确度无较强的要求
  - 基于用户的行为数据去不断学习和完善
  - 能发现用户潜在阅读兴趣，能“制造惊喜”
- 缺点
  - 启动门槛高，用户量不够时几乎无法开展；
  - 学习量不够时，推荐结果较差


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>内容产品</category>
        <category>推荐</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
        <tag>内容产品</tag>
      </tags>
  </entry>
  <entry>
    <title>内容社区的产品选型与运营</title>
    <url>/2020/02/03/%E5%86%85%E5%AE%B9%E7%A4%BE%E5%8C%BA%E7%9A%84%E4%BA%A7%E5%93%81%E9%80%89%E5%9E%8B%E4%B8%8E%E8%BF%90%E8%90%A5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 内容社区的产品选型与运营

### 社区分类

社交网络

- facebook、微信朋友圈、QQ空间

社交媒体

- 微博、抖音、快手、微信公众号

垂直社区

- 懂球帝、小红书、汽车之家、豆瓣、知乎、美柚……



### 社区定义

以用户生产内容为核心的网络交流平台

### 社区的生命力

互联网流量红利消失，流量进入存量的争夺。 抢夺用户注意力和停留时长。

互联网流量的再分配



一个群体外部压力越大，内聚性就越强，就越容易形成社区。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>内容产品</category>
        <category>内容社区</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>运营</tag>
        <tag>内容产品</tag>
        <tag>内容社区</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么要做内容营销</title>
    <url>/2019/04/06/%E5%86%85%E5%AE%B9%E8%90%A5%E9%94%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 为什么要做内容营销

### 1、内容=让产品价值可触摸

- 大部分时间人都是在非理性决策
- 内容营销可产生“共情”效果
- 通过内容编织的故事、刻画的人物，将受众拖入一个情境世界，使人共情，相信这个世界发生的事。

### 2、内容=无限增长的流量入口

- 单纯的工具平台存在流量天花板，会出现瓶颈
- 用户单纯操作消费，使用户规模、停留时间、消费频次
- 内容丰富会制造更多访问动机

- 如看故事般看别人消费，访问变成kill time一样享受，将增加停留时长
- 一个个真实个体的消费故事就是一个个信任背书，促进购物欲望

- 内容营销是个没有天花板的流量入口
- 产生优质内容可打破流量封锁

### 3、内容=产品消费的第一动因

- 跨界营销

- 品牌集体患症“内容感缺失”
- 包装、广告、产品均没有温度
- 跨界实现对产品的一次赋能，让内容驱动消费

### 4、内容=隐形的竞争壁垒

- 能产出优质内容就是一种很强的竞争壁垒

# 如何做内容营销

企业如果想做好内容营销，核心是要有“成本意识”。

1. 金钱成本
2. 企业内部时间成本
3. 创意成本
4. 投资消费者的心智成本

### 1、选定内容赛道，持续投资

- 专注于某个内容领域，不断深耕，成为该领域的头部。

### 2、创造极致内容，而非内容

- 二八法则
- 提供极致内容，而非普通内容
- “爆款内容”，降低用户的时间成本，是受众觉得值得、赚到、强烈转发欲望，而不是“打发了时间”

### 3、降低生产门槛，标准化创意工艺

- 创意产业最大的问题-易逝性；但好内容可以打败时间
- 取消投入大产出小的内容营销模式
- 拆解内容营销的环节，让生产模式可复制

- 收集研究成功案例
- 建立高频词库
- 善用互联网工具
- 保持高密度的创意和执行

### 4、让内容沉淀，形成IP资产

- 消费者心智是一场投资
- 需将内容营销的成果形成可积累，可沉淀的，甚至形成一种IP化的资产
- 对营销IP进行微创新，呵护用户的新鲜感

### 5、优化消费者行为路径，降低转化成本

- 能产生市场增长的内容营销，就是好的内容营销
- 内容营销：内容为营销服务

### 6、不是让内容=广告，让是让内容=组织



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>营销</category>
        <category>内容营销</category>
      </categories>
      <tags>
        <tag>营销</tag>
        <tag>内容</tag>
        <tag>商业</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树demo</title>
    <url>/2020/12/31/%E5%86%B3%E7%AD%96%E6%A0%91demo/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 决策树

### 决策树的一个重要任务是为了数据中所蕴含的知识信息

- 决策树可以使用不熟悉的数据集合，并从中提取出一系列规则，在这些机器根据数据集创建规则时，就是机器学习的过程
- k-近邻算法可以完成很多分类任务，但是它最大的缺点就是无法给出数据的内在含义，决策树的主要优势就在于数据形式非常容易理解

#### 决策数的构造

- 优点：计算复杂度不高，输出结果易于理解，对中间值对缺失不敏感，可处理不相关特征数据
- 缺点：可能会产生过度匹配的问题
- 适用数据类型：数值型和 标称型

**构建决策树的第一个问题：当前数据集上哪个特征在划分数据分类时起决定性作用**

- 为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征。
- 完成测试之后，原始数据集就被划分为几个数据子集
- 这些数据子集会分布在第一个决策点的所有分支上。如果某个分支下的数据属于同一类型，则当前条件已经正确地划分数据分类， 无需进一步对数据集进行分割。
- 如果数据子集内的数据不属于同一类型，则需要重复划分数据子集的过程

**思路**
检测数据集中的每个子项是否属于同一分类: 
    If so return 类标签;
    Else
        寻找划分数据集的最好特征
        划分数据集
        创建分支节点
            for 每个划分的子集 
                调用函数createBranch并增加返回结果到分支节点中
        return 分支节点

**决策树的一般流程**

1. 收集数据：可使用任何方法
2. 准备数据：构造算法只适用于标称型数据， 因此数值型数据必须离散化
3. 分析数据：可使用任何方法，构造树完成后，应检查图形是否符合预期
4. 训练算法：构造树的数据结构
5. 测试算法：使用经验树计算错误概率
6. 使用算法：此步骤可以适用于任何监督学习算法，决策树可以更好地理解数据的内在含义

#### 信息增益(information gain)和香农熵/熵(entropy)

![image.png](attachment:b820e520-1b96-4c05-ad79-c74b7cbda53f.png)

另一个度量集合无序程度的方法是基尼不纯度1(Gini impurity)，简单地说就是从一个数据集中随机选取子项，度量其被错误分类到其他分组里的概率


```python
from math import log
import operator
```


```python
def calcShannonEnt(dataSet):
    numEntries = len(dataSet)
    # 为所有可能分类创建字典
    labelCounts= {}
    for featVec in dataSet:
        currentLabel = featVec[-1]
        if currentLabel not in labelCounts.keys():
            labelCounts[currentLabel] = 0
        labelCounts[currentLabel] += 1
    shannonEnt = 0.0
    for key in labelCounts:
        prob = float(labelCounts[key])/numEntries
        shannonEnt -= prob * log(prob,2)   # 以 2为底求对数
    return shannonEnt     
```

![image.png](attachment:5676c0e4-d930-4b1a-9c6d-afb2deaa6efc.png)


```python
def createDataSet():
    dataSet = [
        [1,1,'yes'],
        [1,1,'yes'],
        [1,0,'no'],
        [0,1,'no'],
        [0,1,'no']
    ]  
    labels = ['no surfacing','flippers']
    return dataSet ,labels
```


```python
myData, labels = createDataSet()
```


```python
myData
```




    [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]




```python
labels
```




    ['no surfacing', 'flippers']




```python
calcShannonEnt(myData)
```




    0.9709505944546686



熵越高，则混合的数据也越多


```python
myData[0][-1] = 'maybe'
myData
```




    [[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]




```python
 calcShannonEnt(myData)
```




    1.3709505944546687



#### 划分数据集

- 分类算法除了需要测量信息熵，还需要划分数据集， 度量划分数据集的熵，以便判断当前是否正确地划分了数据集
- 将对每个特征划分数 据集的结果计算一次信息熵，然后判断按照哪个特征划分数据集是最好的划分方式


```python
# 按照给定特征划分数据集
# 输入参数： 待划分待数据集、划分数据集的特征、需要返回的特征的值
def splitDataSet(dataSet,axis,value):
    retDataSet = []
    for featVec in dataSet:
        print("featVec",featVec)
        if featVec[axis] == value:
            print("axis",axis,"featVec[axis]",featVec[axis])
            reducedFeatVec = featVec[:axis]
            print("axis",axis,"reducedFeatVec:",reducedFeatVec)
            reducedFeatVec.extend(featVec[axis+1:])
            print("featVec[axis+1:]",featVec[axis+1:])
            print("axis",axis,"reducedFeatVec:",reducedFeatVec)
            retDataSet.append(reducedFeatVec)
    return retDataSet
```


```python
myData, labels = createDataSet()
```


```python
myData
```




    [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]




```python
labels
```




    ['no surfacing', 'flippers']




```python
splitDataSet(myData,0,1)
```

    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 0, 'no']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [0, 'no']
    axis 0 reducedFeatVec: [0, 'no']
    featVec [0, 1, 'no']
    featVec [0, 1, 'no']





    [[1, 'yes'], [1, 'yes'], [0, 'no']]




```python
splitDataSet(myData,0,0)
```

    featVec [1, 1, 'yes']
    featVec [1, 1, 'yes']
    featVec [1, 0, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']





    [[1, 'no'], [1, 'no']]




```python
# 测试
a = [1,2,3]
b = [4,5,6]
a.append(b)
a
```




    [1, 2, 3, [4, 5, 6]]




```python
# 测试
a = [1,2,3]
b = [4,5,6]
a.extend(b)
a
```




    [1, 2, 3, 4, 5, 6]




```python
len(myData[0])-1
```




    2




```python
# 选择最好的数据集划分方式
def chooseBestFeatureToSplit(dataSet):
    numFeatures = len(dataSet[0])-1  #特征的个数
    baseEntropy = calcShannonEnt(dataSet) # 基线熵
    print("baseEntropy:",baseEntropy)
    bestInfoGain = 0.0
    bestFeature = -1
    # 创建唯一的分类标签
    for i in range(numFeatures):
        featList = [example[i] for example in dataSet]
        print("featList:",featList)
        uniqueVals =  set(featList)
        print("uniqueVals:",uniqueVals)
        
        # 计算每种划分方式的信息熵
        newEntropy = 0.0
        for value in uniqueVals:
            subDataSet = splitDataSet(dataSet, i ,value)
            prob = len(subDataSet) / float(len(dataSet))
            newEntropy += prob * calcShannonEnt(subDataSet)
        infoGain = baseEntropy - newEntropy  # 计算信息增益
        print("baseEntropy",baseEntropy,"i:",i,"newEntropy",newEntropy,"infoGain",infoGain)
        if(infoGain > bestInfoGain):
            bestInfoGain = infoGain   # 计算最好的信息增益
            bestFeature = i
    return bestFeature
```

函数介绍：选取特征、划分数据集、计算得出最好的划分数据集的特征

- 第一个要求是，数据必须是一种由列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度;
- 第二个要求是，数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签
- 无需限定list中的数据类型，它们既可以是数字也可以是字符串，并不影响实际计算


```python
chooseBestFeatureToSplit(myData)
```

    baseEntropy: 0.9709505944546686
    featList: [1, 1, 1, 0, 0]
    uniqueVals: {0, 1}
    featVec [1, 1, 'yes']
    featVec [1, 1, 'yes']
    featVec [1, 0, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 0, 'no']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [0, 'no']
    axis 0 reducedFeatVec: [0, 'no']
    featVec [0, 1, 'no']
    featVec [0, 1, 'no']
    baseEntropy 0.9709505944546686 i: 0 newEntropy 0.5509775004326937 infoGain 0.4199730940219749
    featList: [1, 1, 0, 1, 1]
    uniqueVals: {0, 1}
    featVec [1, 1, 'yes']
    featVec [1, 1, 'yes']
    featVec [1, 0, 'no']
    axis 1 featVec[axis] 0
    axis 1 reducedFeatVec: [1]
    featVec[axis+1:] ['no']
    axis 1 reducedFeatVec: [1, 'no']
    featVec [0, 1, 'no']
    featVec [0, 1, 'no']
    featVec [1, 1, 'yes']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [1]
    featVec[axis+1:] ['yes']
    axis 1 reducedFeatVec: [1, 'yes']
    featVec [1, 1, 'yes']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [1]
    featVec[axis+1:] ['yes']
    axis 1 reducedFeatVec: [1, 'yes']
    featVec [1, 0, 'no']
    featVec [0, 1, 'no']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [0]
    featVec[axis+1:] ['no']
    axis 1 reducedFeatVec: [0, 'no']
    featVec [0, 1, 'no']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [0]
    featVec[axis+1:] ['no']
    axis 1 reducedFeatVec: [0, 'no']
    baseEntropy 0.9709505944546686 i: 1 newEntropy 0.8 infoGain 0.17095059445466854





    0



## 构建递归决策树

- 得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分。
- 第一次划分之后，数据将被向下传递到树分支的下一个节点，在这个节点上，我们可以再次划分数据。
- **因此我们可以采用递归的原则处理数据集**
- 递归结束的条件是：程序遍历完所有划分数据集的属性，或者每个分支下的所有实例都具有相同的分类

![image.png](attachment:d3b072f3-7a1b-4d05-b262-6a399d408f43.png)


```python
def majorityCnt(classList):
    classCount = {}
    for vote in classCount:
        if vote not in classCount.keys():
            classCount[vote] =0
        classCount[vote] += 1
    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse =True)
    return sortedClassCount[0][0]
```

**majorityCnt() 与投票表决代码非常类似**

1. 该函数使用分类名称的列表，
2. 然后创建键值为classList中唯一值的数据字典，字典对象存储了classList中每个类标签出现的频率
3. 最后利用operator操作键值排序字典，并返回出现次数最多的分类名称。


```python
myData[0]
```




    [1, 1, 'yes']




```python
# 创建决策树
def createTree(dataSet,labels):
    classList = [example[-1] for example in dataSet]
    print("labels:",labels)
    print("classList:",classList)
    print("classList[0]:",classList[0])
    print("classList.count(classList[0]):",classList.count(classList[0]))
    
    ## 类别相同则停止划分
    if classList.count(classList[0]) == len(classList):
        return classList[0]
    
    ## 遍历完所有特征时 返回出现次数最多的
    if len(dataSet[0]) == 1:
        return majorityCnt(classList)
    
    bestFeat = chooseBestFeatureToSplit(dataSet)
    bestFeatLabel = labels[bestFeat] 
    print("bestFeatLabel",bestFeatLabel)
    myTree = {bestFeatLabel:{}}
    print("myTree:::",myTree)
    del(labels[bestFeat])
    print("labels:",labels)
    featValues = [example[bestFeat] for example in dataSet]
    uniqueVals = set(featValues)
    for value in uniqueVals:
        subLabels = labels[:]
        print("subLabels:",subLabels)
        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)
    return myTree
```

**代码注释**

- 使用两个输入参数：数据集和标签列表

1. 首先创建了名为classList的列表变量，其中包含了数据集的所有类标签
2. 递归函数的第一个停止条件是所有的类标签完全相同，则直接返回该类标签
3. 递归函数的第二个停止条件是使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组
4. 字典变量myTree存储了树的所有信息，这对于其后绘制树形图非常重要。当前数据集选取的最好特征存储在变量bestFeat中，得到列表包含的所有属性值
5. 最后代码遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数
   createTree()，得到的返回值将被插入到字典变量myTree中


```python
myData,labels = createDataSet()
```


```python
createTree(myData,labels)
```

    labels: ['no surfacing', 'flippers']
    classList: ['yes', 'yes', 'no', 'no', 'no']
    classList[0]: yes
    classList.count(classList[0]): 2
    baseEntropy: 0.9709505944546686
    featList: [1, 1, 1, 0, 0]
    uniqueVals: {0, 1}
    featVec [1, 1, 'yes']
    featVec [1, 1, 'yes']
    featVec [1, 0, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 0, 'no']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [0, 'no']
    axis 0 reducedFeatVec: [0, 'no']
    featVec [0, 1, 'no']
    featVec [0, 1, 'no']
    baseEntropy 0.9709505944546686 i: 0 newEntropy 0.5509775004326937 infoGain 0.4199730940219749
    featList: [1, 1, 0, 1, 1]
    uniqueVals: {0, 1}
    featVec [1, 1, 'yes']
    featVec [1, 1, 'yes']
    featVec [1, 0, 'no']
    axis 1 featVec[axis] 0
    axis 1 reducedFeatVec: [1]
    featVec[axis+1:] ['no']
    axis 1 reducedFeatVec: [1, 'no']
    featVec [0, 1, 'no']
    featVec [0, 1, 'no']
    featVec [1, 1, 'yes']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [1]
    featVec[axis+1:] ['yes']
    axis 1 reducedFeatVec: [1, 'yes']
    featVec [1, 1, 'yes']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [1]
    featVec[axis+1:] ['yes']
    axis 1 reducedFeatVec: [1, 'yes']
    featVec [1, 0, 'no']
    featVec [0, 1, 'no']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [0]
    featVec[axis+1:] ['no']
    axis 1 reducedFeatVec: [0, 'no']
    featVec [0, 1, 'no']
    axis 1 featVec[axis] 1
    axis 1 reducedFeatVec: [0]
    featVec[axis+1:] ['no']
    axis 1 reducedFeatVec: [0, 'no']
    baseEntropy 0.9709505944546686 i: 1 newEntropy 0.8 infoGain 0.17095059445466854
    bestFeatLabel no surfacing
    myTree::: {'no surfacing': {}}
    labels: ['flippers']
    subLabels: ['flippers']
    featVec [1, 1, 'yes']
    featVec [1, 1, 'yes']
    featVec [1, 0, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    featVec [0, 1, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'no']
    axis 0 reducedFeatVec: [1, 'no']
    labels: ['flippers']
    classList: ['no', 'no']
    classList[0]: no
    classList.count(classList[0]): 2
    subLabels: ['flippers']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [1, 'yes']
    axis 0 reducedFeatVec: [1, 'yes']
    featVec [1, 0, 'no']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] [0, 'no']
    axis 0 reducedFeatVec: [0, 'no']
    featVec [0, 1, 'no']
    featVec [0, 1, 'no']
    labels: ['flippers']
    classList: ['yes', 'yes', 'no']
    classList[0]: yes
    classList.count(classList[0]): 2
    baseEntropy: 0.9182958340544896
    featList: [1, 1, 0]
    uniqueVals: {0, 1}
    featVec [1, 'yes']
    featVec [1, 'yes']
    featVec [0, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no']
    axis 0 reducedFeatVec: ['no']
    featVec [1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['yes']
    axis 0 reducedFeatVec: ['yes']
    featVec [1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['yes']
    axis 0 reducedFeatVec: ['yes']
    featVec [0, 'no']
    baseEntropy 0.9182958340544896 i: 0 newEntropy 0.0 infoGain 0.9182958340544896
    bestFeatLabel flippers
    myTree::: {'flippers': {}}
    labels: []
    subLabels: []
    featVec [1, 'yes']
    featVec [1, 'yes']
    featVec [0, 'no']
    axis 0 featVec[axis] 0
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['no']
    axis 0 reducedFeatVec: ['no']
    labels: []
    classList: ['no']
    classList[0]: no
    classList.count(classList[0]): 1
    subLabels: []
    featVec [1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['yes']
    axis 0 reducedFeatVec: ['yes']
    featVec [1, 'yes']
    axis 0 featVec[axis] 1
    axis 0 reducedFeatVec: []
    featVec[axis+1:] ['yes']
    axis 0 reducedFeatVec: ['yes']
    featVec [0, 'no']
    labels: []
    classList: ['yes', 'yes']
    classList[0]: yes
    classList.count(classList[0]): 2





    {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}



## 使用matplotlib注解绘制 树形图


```python
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
```


```python
simheifont = FontProperties(fname='../simhei.ttf')
```


```python
decisionNode = dict(boxstyle="sawtooth", fc="0.8")
leafNode = dict(boxstyle="round4", fc="0.8")
arrow_args = dict(arrowstyle="<-") def plotnode(nodetxt,centerpt,parentpt,nodetype): createplot.ax1.annotate(nodetxt,xy="parentPt," xycoords="axes fraction" , xytext="centerPt," textcoords="axes fraction" va="center" ,ha="center" ,bbox="nodeType," arrowprops="arrow_args," fontproperties="simheifont)" createplot(): fig="plt.figure(1," facecolor="white" ) fig.clf() createplot.ax1="plt.subplot(111,frameon=False)" plotnode("决策节点",(0.5,0.1),(0.1,0.5),decisionnode) plotnode("叶节点",(0.8,0.1),(0.3,0.8), leafnode) plt.show() ``` ```python createplot() ![png](c: users ysilhouette appdata local temp 360zip$temp 360( output_43_0.png) ### 构造注解树 **获得多少叶节点-- x轴的长度** **获得树有多少层-- y轴的高度** # 获取叶节点和树的层数 getnumleafs(mytree): numleafs="0" firststr="list(myTree.keys())[0]" seconddict="myTree[firstStr]" for key in seconddict.keys(): if type(seconddict[key]).__name__="=" 'dict': ## 测试节点的数据类型是否字典 +="getNumLeafs(secondDict[key])" else: return gettreedepth(mytree): maxdepth="0" thisdepth="1" gettreedepth(seconddict[key])> maxDepth:
            maxDepth = thisDepth
    return maxDepth
```


```python
def retrieveTree(i):
    listOfTrees = [
        {'no surfacing':{0:'no',1:{'flippers':{0:'no',1:'yes'}}}},
        {'no serfacing':{0:'no',1:{'flippers':{0:{'head':{0:'no',1:'yes'}},1:'no'}}}}
    ]
    return listOfTrees[i]
```


```python
retrieveTree(1)
```




    {'no serfacing': {0: 'no',
      1: {'flippers': {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'}}}}




```python
myTree = retrieveTree(0)
```


```python
list(myTree.keys())[0]
```




    'no surfacing'




```python
getNumLeafs(myTree)
```




    3




```python
getTreeDepth(myTree)
```




    2




```python
def plotMidText(cntrPt, parentPt, txtString):
    xMid = (parentPt[0] - cntrPt[0]) /2.0 + cntrPt[0]
    yMid = (parentPt[1] - cntrPt[1]) /2.0 + cntrPt[1]
    createPlot.ax1.text(xMid,yMid, txtString)

def plotTree(myTree, parentPt, nodeText):
    numLeafs = getNumLeafs(myTree)
    depth = getTreeDepth(myTree)
    
    firstStr = list(myTree.keys())[0]
    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs)) /2.0 / plotTree.totalW, plotTree.yOff)
    plotMidText(cntrPt, parentPt, nodeText)
    plotNode(firstStr, cntrPt, parentPt, decisionNode)
    
    secondDict = myTree[firstStr]
    plotTree.yOff = plotTree.yOff - 1.0 / plotTree.totalD
    for key in secondDict.keys():
        if type(secondDict[key]).__name__ == 'dict':
            plotTree(secondDict[key], cntrPt, str(key))
        else:
            plotTree.xOff = plotTree.xOff + 1.0 / plotTree.totalW
            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)
            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt,str(key))
    plotTree.yOff = plotTree.yOff + 1.0 / plotTree.totalD

def createPlot(inTree):
    fig = plt.figure(1, facecolor='white')
    fig.clf()
    axprops = dict(xticks=[], yticks=[])
    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)
    plotTree.totalW = float(getNumLeafs(inTree))
    plotTree.totalD = float(getTreeDepth(inTree))
    plotTree.xOff = - 0.5/ plotTree.totalW
    plotTree.yOff = 1.0
    plotTree(inTree,(0.5,1.0),'')
    plt.show()
```


```python
mytree = retrieveTree(0)
```


```python
mytree
```




    {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}




```python
createPlot(mytree)
```


![png](C:/Users/YSilhouette/AppData/Local/Temp/360zip$Temp/360(/output_56_0.png)



```python
mytree['no surfacing'][3]= 'maybe'
```


```python
mytree
```




    {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}, 3: 'maybe'}}




```python
createPlot(mytree)
```


![png](C:/Users/YSilhouette/AppData/Local/Temp/360zip$Temp/360(/output_59_0.png)



```python

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </-")>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>几种机器学习原理</title>
    <url>/2018/11/25/%E5%87%A0%E7%A7%8D%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 几种机器学习算法原理

#### 机器学习过程

#### 什么问题适合用机器学习解决

#### 几种常见的模型和算法

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>剪辑师-Premiere快捷键</title>
    <url>/2018/01/04/%E5%89%AA%E8%BE%91%E5%B8%88-Premiere%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 各种快捷键

基本快捷键操作技巧
Ctrl+Alt+N   新建项目
Ctrl+O 打开项目
Ctrl+shift+w  关闭项目
Ctrl + W  关闭
Ctrl + S 保存
Ctrl + shift+ S  另存为
Ctrl + I   导入
Ctrl + N  新建序列
Ctrl + Z  还原
Ctrl + X    剪切
Ctrl + C  复制
Ctrl + V    粘贴
Ctrl + A    全选
Ctrl + Shift + A  取消全选
Ctrl + F  查找
Ctrl + K  剪切
Ctrl + Shift + K  所有轨道剪切标记 
I 标记入点
O   标记出点
X 标记素材入出点
Shift + /  标记素材
Shift +   在项目窗口查看形式
Shift + *  返回媒体浏览
/  标记选择
Shift + I  跳转入点
Shift + O  跳转出点
Ctrl + Shift + I 清除入点
Ctrl + Shift + Q 清除出点
Ctrl + Shift + X  清除入出点
M  添加标记
Shift + M  转到下一个标记
Ctrl + Shift + M 转到上一个标记
Ctrl + Alt + M  清除当前标记
Ctrl + Alt + Shift + M清除所有标记剪辑操作技巧 
Delete                 删除素材
hift+Delete            单段素材删除，后面素材自动跟上 
C                      剃刀工具
Shift+C  全部轨道剪断
Ctrl+K  快速剪断素材
ctrl+shift+K           所有轨道快速剪切素材
W  删除本段素材时间线后面素材 
Q  删除本段素材时间线前面素材
Shift+Q              改变时间线前面剪辑点
Shift+W 改变时间线后面剪辑点
A   向前选择轨道工具
shift  向前选择单独选中单个轨道速度操作技巧
Alt键+滚动鼠标         放大素材显示
R  比率伸缩工具
Ctrl+R                 速度/持续时间
L  快进素材操作技巧
Shift+E                隐藏素材 
AIt+Ctrl+拖动         前后两段素材互换位置
回车键                 渲染红色时间线打好出入点项目窗口右键点击素材“设置标识帧”  
，                     插入素材 
.                     覆盖素材
Ctrl+L                 取消链接
Ctrl + G  编组
Ctrl + Shift + G 解组
Home                   回到第一帧的位置
End                    回到最后一帧的位置
ctrl+D                 默认交叉转场效果
Ctrl + Shift + D  默认音频转场
Shift + D   默认音视频转场
Ctrl + Alt + V                 粘贴属性
Alt+拖动  直接拖拽复制
Ctrl + Shift + V      粘贴插入  
窗口Shift + 1    项目
Shift + 2  源监视器
Shift + 3  时间轴
hift + 4  节目监视器
Shift + 5  特效控制台
Shift + 6  调音台
Shift + 7  效果
Shift + 8  媒体预览字幕 
Ctrl + T 新建字幕
Ctrl + Shift + L  左对齐
Ctrl + Shift + C  居中
Ctrl + Shift + R  右对齐
Ctrl + Shift + T  制表符设置
Ctrl + J  模板
Ctrl + Alt + ]  上一层的下一个对象
Ctrl + Alt + [  下一层的下一个对象
Ctrl + Shift + ]  放到最上层
Ctrl + ]  上移一层
Ctrl + Shift + [  放到最下层
Ctrl + [  下移一层


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>影视后期</category>
        <category>Premiere</category>
      </categories>
      <tags>
        <tag>剪辑师</tag>
        <tag>Premiere</tag>
      </tags>
  </entry>
  <entry>
    <title>单点破局十倍快速增长</title>
    <url>/2019/12/28/%E5%8D%95%E7%82%B9%E7%A0%B4%E5%B1%80%E5%8D%81%E5%80%8D%E5%BF%AB%E9%80%9F%E5%A2%9E%E9%95%BF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>电商</category>
      </categories>
      <tags>
        <tag>电商</tag>
      </tags>
  </entry>
  <entry>
    <title>基于seq2seq+attention实现文本摘要</title>
    <url>/2021/01/04/%E5%9F%BA%E4%BA%8Eseq2seq+attention%E5%AE%9E%E7%8E%B0%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 基于seq2seq+attention实现文本摘要

- **任务描述**: 自动摘要是指给出一段文本，我们从中提取出要点，然后再形成一个短的概括性的文本

![image.png](attachment:5f1f621e-0619-402f-b2b9-1827c3fb500b.png)

![image.png](attachment:7e378fd8-a713-4afa-9f79-a3059af5cd72.png)
https://github.com/pytorch/text/releases/tag/v0.9.0-rc5


```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import spacy
 
from torchtext.legacy.datasets import Multi30k
from torchtext.legacy.data import Field,Iterator,BucketIterator,TabularDataset

import pandas as pd
import numpy as np

import random
import math
import time
```



```python
# 全局初始化配置参数。 固定随机种子， 使得每次运行的结果相同
SEED = 22

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
```

## 数据准备
- 数据整理
- 数据说明
- 数据预处理

### 数据整理


```python
data_train_path = "./dataset/train.csv"
data_test_path = "./dataset/test.csv"
data_val_path = "./dataset/val.csv"
```

### 数据说明


```python
data_train = pd.read_csv(data_train_path,encoding="utf-8")
```


```python
data_train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>document</th>
      <th>summary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>jason blake of the islanders will miss the res...</td>
      <td>blake missing rest of season</td>
    </tr>
    <tr>
      <th>1</th>
      <td>the u.s. military on wednesday captured a wife...</td>
      <td>u.s. arrests wife and daughter of saddam deput...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>craig bellamy 's future at west ham appeared i...</td>
      <td>west ham drops bellamy amid transfer turmoil</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cambridge - when barack obama sought advice be...</td>
      <td>in search for expertise harvard looms large</td>
    </tr>
    <tr>
      <th>4</th>
      <td>wall street held on to steep gains on monday ,...</td>
      <td>wall street ends a three-day losing streak</td>
    </tr>
  </tbody>
</table>
</div>



### 数据预处理
- 构建分词函数
- 构建预处理格式
- 载入数据
- 构建数据迭代器
- 构建词表

#### 构建分词函数


```python
# 加载spacy的英文处理包
spacy_en = spacy.load('en_core_web_sm')
```


```python
# 构建分词函数， 返回文本里包含的所有词组的列表
def tokenize(text):
    return [tok.text for tok in spacy_en.tokenizer(text)]
```

#### 构建预处理格式

##### torchtext的Field函数可以构建预处理格式
- sequential：代表是否需要将数据序列化，大多数自然语言处理任务都是序列计算
- tokenize：需要传入分词函数，传入之前定义的tokenize函数
- lower：代表是否转换成小写，为了统一处理，把所有的字符转换成小写
- include_lengths：代表是否返回序列的长度，在gpu计算中，通常是对矩阵的运算，因此每个batch中，矩阵的长度为该batch中所有数据里最长的长度，其他长度不够的数据通常用pad字符补齐，这就会导致矩阵中有很多pad字符。为了后续的计算中把这些pad字符规避掉，我们需要返回每个数据的真实长度，这里的长度是指分词后每个文本中词组的数量
- init_token：传入起始符号，自然语言处理的任务中通常需要在文本的开头加入起始符号，作为句子的开始标记
- eos_token：传入结束符号，自然语言处理的任务中通常需要在文本的加入结束符号，作为句子的结束标记
- pad_token：传入pad符号，用来补全长度不够的文本，默认为  \<pad> 
- unk_token：传入unk符号，默认为 \<unk>。自然语言处理任务中，往往有一些词组不在我们构建的词表中，这种现场叫做00V（Out Of Vocabulary），用一个unk字符来表示这些字符。


```python
DOCUMENT = Field(sequential=True, 
                tokenize=tokenize,
                lower=True,
                include_lengths=True,
               init_token='<sos>',
               eos_token='<eos>')
```


```python
SUMMARY = Field(sequential=True, 
                tokenize=tokenize,
                lower=True,
                include_lengths=True,
               init_token='<sos>',
               eos_token='<eos>')
```

#### 载入数据


```python
fields = [("document",DOCUMENT),("summary",SUMMARY)]
```


```python
train = TabularDataset(path=data_train_path, format="csv", fields=fields, skip_header=True)
val = TabularDataset(path=data_val_path, format="csv", fields=fields, skip_header=True)
test = TabularDataset(path=data_test_path, format="csv", fields=fields, skip_header=True)
```

#### 构建数据迭代器
##### BucketIterator会自动将长度类似的文本归在一个batch，这样可以减少补全字符pad的数量，易于计算
- train：传入之前用TabularDataset载入的数据
- batch_size：传入每个批次包含的数据数量
- device：代表传入数据的设备，可以选择gpu或者cpu
- sort_within_batch：代表是否对一个批次内的数据排序
- sort_key：排序方式，由于要使用到pack_padded_sequence用来规避pad符号，而pack_padded_sequence需要数据以降序的形式排列，所以这里用document的长度进行降序。


```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```


```python
device
```




    device(type='cpu')




```python
BATCH_SIZE = 100 // 20
train_iter = BucketIterator(train, batch_size=BATCH_SIZE, device=device, sort_key = lambda x :len(x.document), sort_within_batch=True)
val_iter = BucketIterator(val,batch_size=BATCH_SIZE, device=device, sort_key = lambda x:len(x.document), sort_within_batch=True)
test_iter = BucketIterator(test,batch_size=BATCH_SIZE, device=device, sort_key = lambda x:len(x.document), sort_within_batch=True)
```

#### 构建词表
往往将字符转换成数字，需要构建词表，用以用数字表示每个词组，并用来训练embedding。
- 在训练集上构建词表，频次低于min_freq的词组会被过滤。
- 构建完词表后会自动将迭代器数据中的字符转换成单词在词表中的序号。

在这里，我们对document和summary分别单独构建了词表，也可以只构建一个词表，使document和summary共享词表。


```python
DOCUMENT.build_vocab(train,min_freq= 2)
SUMMARY.build_vocab(train,min_freq=2)
```


```python
DOCUMENT.vocab.itos[:100]
```




    ['<unk>',
     '<pad>',
     '<sos>',
     '<eos>',
     'the',
     '#',
     '.',
     ',',
     'a',
     'of',
     'to',
     'in',
     'and',
     'on',
     "'s",
     '-',
     'for',
     'said',
     'that',
     'with',
     'at',
     'an',
     '`',
     'as',
     'by',
     'from',
     'has',
     'his',
     'tuesday',
     'wednesday',
     'thursday',
     'its',
     'monday',
     'was',
     '<', '>',
     'unk',
     'is',
     'friday',
     'president',
     '-lrb-',
     '-rrb-',
     'after',
     'new',
     'will',
     'it',
     'two',
     'government',
     'their',
     'have',
     'u.s',
     'over',
     "''",
     'minister',
     'year',
     'china',
     'world',
     'first',
     'sunday',
     'he',
     'who',
     'saturday',
     'be',
     'here',
     'were',
     'against',
     'this',
     'people',
     'officials',
     'up',
     'are',
     'more',
     'country',
     'us',
     'united',
     'police',
     'percent',
     'one',
     'state',
     'reported',
     'into',
     'million',
     'last',
     'three',
     'official',
     'been',
     'than',
     'had',
     'not',
     'would',
     'but',
     'years',
     'about',
     'former',
     'prime',
     'states',
     'they',
     'international',
     'day',
     'week']



### 模型
- 模型概述
- 模型结构定义
- 模型实例化
- 查看模型

#### 模型该书
- seq2seq是一个Encoder–Decoder结构的网络，它的输入是一个序列，输出也是一个序列，seq2seq最早应用在翻译模型中，输入原文，输出为翻译后的译文。
- attention机制的用途是建立生成的译文中的每个单词和原文每个单词的联系，通过这种依赖关系，生成更精准的译文，seq2seq的结构如下图所示：
![image.png](attachment:7a9c3e26-c015-4bf8-b2dd-96f082617b03.png)

    - 左边为Encoder，是由rnn组成，顺序输入原文中单词的embedding，对于每个位置都输出一个hidden state $h_i$ 作为这个状态的表示，这个状态包含了之前所有单词的信息，待序列中所有的单词计算完后，Encoder输出一个变量 $h$ 作为整个序列的表示，这个变量可以直接是最后一个状态的表示，也可以对所有状态进行融合，将它们变换成一个固定维度的矩阵。
    -  右边是Decoder，它第一个状态的输入为Encoder的输出 $h$ 和 [单词的embedding; attention]，方括号内表示两个变量的连接，输出为 $s_j$ ，用[s_j; attention; embedding]预测这一步生成的单词，这里为了图像整体的简洁，没有画出attention对后面的状态的连接，实际上每一步生成都要连接attention。
    - Decoder和Encoder之间有一个attention，在最早的seq2seq模型中是没有attention的，Decoder直接接收Encoder的输出 $h$ ，这在生成译文单词的前期效果不错，但是随着生成单词的增多，rnn会逐渐遗忘掉 $h$ 的信息，这会导致生成的单词不够精准，而且无法建立原文和译文每个单词对应的关系，而attention由于在生成的每一步都会引入到生产过程中，并且每一步都计算Decoder的状态和Encoder每个状态的相似度用来建立关系，不仅使得生成效果更好，而且具有更强的可解释性，在很多翻译实验中，会把attention保存起来，建立一个attention的词表来观测不同语种单词之间的对应关系。

#### 模型结构定义
##### Encoder
![image.png](attachment:83f35c9b-6e96-448a-8b04-e70de555a8e4.png)

##### Decoder
- 这里为了获得上下文的语义表示，用了双向RNN，包含从sos向eos的前向RNN和从eos向sos的后向RNN，每个状态的表示变为前向RNN的输出和后向RNN的输出的连接 $[\vec{h_i}; \mathop{h_i} \limits ^{\leftarrow}]$，这样每个状态都包含了来自前文和后文的语义信息。
- Encoder的内部由RNN组成，RNN的形式为：
$h_i = RNN(h_{i-1},e(x_i))$
- 输入为前一个状态表示和这一步的单词的embedding。 $h_0$ 为一个全0矩阵，这里的RNN也可以替换成LSTM或者GRU。待所有的单词输入完毕后，Encoder会计算一个序列整体的表示，这里将前向RNN的最终输出和后向RNN输出的连接 $[\vec{h}; \mathop{h} \limits ^{\leftarrow}]$ 传入到一个全连接层进行变换，转换成Decoder输出的大小：
$hidden = tanh(w[\vec{h}; \mathop{h} \limits ^{\leftarrow}] + b )$
- Encoder函数构建一个encoder，内部RNN使用了torch内置的GRU，参数为：

  - input_dim：输入词表的大小
  - emb_dim：embedding的维度
  - enc_hid_dim：隐藏层的大小
  - dropout：dropout的概率
  
- forward参数：
  - doc：原文数据，是已经由词通过词表转换成序号的数据
  - doc_len：每个数据的真实长度，在计算RNN时，可以只计算相应长度的状态，不计算pad符号

- forword输出Encoder整体的输出，以及Encoder每个状态的输出。每个状态的输出用来计算后续的attention。
- 值得注意的是，为了规避掉后续计算attention时受到序列中存在pad符号的影响，这里应用了nn.utils的pad_paddad_sequence方法，可以去掉doc_len以后的pad符号，这里pad_packed_sequence的输入为单词序列的embedding和序列的真实长度，这样在计算序列时，就不会计算doc_len后的pad符号了。在计算完RNN后，为了形成一个矩阵方便GPU计算，会把每个doc_len < max_len 的序列填充起来，这里使用了pad_packed_sequence方法，输入为RNN计算后的序列packed_outputs，在后续的attention计算时，会把填充的信息规避掉。


```python
# encoder的输入为原文， 输出为hidden_state, size需设置
class Encoder(nn.Module):
    def __init__(self,input_dim,emb_dim,enc_hid_dim, dec_hid_dim,dropout):
        super().__init__()
    
        # 定义embedding层， 直接使用 torch.nn.Embedding函数
        self.embedding = nn.Embedding(input_dim,emb_dim)

        # 定义rnn层， 使用torch.nn.GRU
        self.rnn = nn.GRU(emb_dim,enc_hid_dim,bidirectional=True)

        # 定义一个 全连接层， 用来 将encoder的输出转换成 decoder输入的大小
        self.fc = nn.Linear(enc_hid_dim * 2 ,dec_hid_dim)

        # 定义dropout层， 防止过拟合
        self.dropout = nn.Dropout(dropout)
        
    def forward(self,doc,doc_len):
        embedded = self.dropout(self.embedding(doc))
        
        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,doc_len)
        
        # packed_outputs 包含了每个RNN中每个状态的输出，如图中的h1,h2,h3...hn
        # hidden只有最后的输出hn
        packed_outputs, hidden = self.rnn(packed_embedded)
        
        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)
        
        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]),dim=1)))
        
        return outputs,hidden
```

##### attention
- attention机制可以建立Decoder的状态 $s_i$ 和Encoder每个状态 $h_j$ 的关系，如下图所示：
![image.png](attachment:08055b25-8707-449b-8782-1cf18c9eaf3b.png)
这里计算 $s_2$ 和 Encoder中每个状态的关系，需要用到 $s_1$ 的信息，先计算Decoder中 $s_{i-1}$ 和 Encodr状态 $h_{j}$ 的相似度：
$e_{ij} = a(s_{i-1}, hj)$
将 $[s_{i-1};h_{j}]$ 传入至一个全连接层计算相似度。
然后将$s_{i-1}$ 和 Encoder中每个状态的相似度做一个softmax变化，得到每个Encoder中每个状态所占的权重，作为attention：
$\alpha_{ij} = \frac{exp(e_{ij})}{\sum^{T}_{k = 1}(exp(e_{ik}))}$
attention中的每个权重会用来计算context vector，即上下文的向量：
$c_i = \sum_{k = 1}^{T} \alpha_{ij} h_j$
这个context vector会在Decoder中作为一部分输入。

- 构建Attention类，参数：
  - enc_hid_dim：encoder每个位置输出的维度
  - dec_hid_dim：decoder每个位置输出的维度

- forward的参数：
  - hidden：decoder里rnn前一个状态的输出
  - encoder_outs：encoder里rnn的输出
  - mask：mask矩阵，里面存储的是0-1矩阵，0代表被规避的pad符号的位置

- forword的输出为attention中的每个权重，context vector的计算在下面的Decoder类


```python
class Attention(nn.Module):
    def __init__(self,enc_hid_dim,dec_hid_dim):
        super().__init__()
        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)
        self.v = nn.Linear(dec_hid_dim, 1, bias= False)
        
    def forward(self,hidden, encoder_outputs, mask):
        batch_size = encoder_outputs.shape[1]
        doc_len = encoder_outputs.shape[0]
        
        # 对decoder的状态重复doc_len次，用来计算和每个encoder状态的相似度
        hidden = hidden.unsqueeze(1).repeat(1,doc_len,1)
        
        encoder_outputs = encoder_outputs.permute(1,0,2)
        # 使用全连接层计算相似度
        energy = torch.tanh(self.attn(torch.cat((hidden,encoder_outputs), dim=2)))
        
        # 转换尺寸 [batch, doc_len]的形式作为 和每个encoder状态的相似度
        attention = self.v(energy).squeeze(2)
        
        # 规避encoder里的 pad符号， 将这些位置的权重值降到最低
        attention = attention.masked_fill(mask ==0, -1e10)
        
        # 返回权重
        return F.softmax(attention,dim=1)
```

#### decoder
- Decoder接收之前的状态信息、输入的单词和context vector，预测生成摘要的单词，结构如下所示：
![image.png](attachment:6a34d1b0-6c17-4fe1-9d24-e521610d0f76.png)
- Decoder的RNN与Encoder中的RNN有所不同，输入为[前一步生成单词的embedding;context vector]和前一步的状态 hi−1hi−1h_{i-1}，
- 目的是引入attention的信息：si=RNN([e(yi−1);c],si−1)si=RNN([e(yi−1);c],si−1)s_i = RNN([e(y_{i-1});c],s_{i-1})
- 在预测生成的单词时，将context vector、 RNN的输出状态、前一步生成单词的embedding连接起来输入至全连接层预测：yi=softmax(w[c;si;e(yi−1)]+b)yi=softmax(w[c;si;e(yi−1)]+b)y_i = softmax(w[c;s_i;e(y_{i-1})] + b)
- 构建Decoder类，参数为：
  - output_dim：输出的维度，为词表的长度
  - emb_dim：embedding的维度
  - enc_hid_dim：encoder每个位置输出的维度
  - dec_hid_dim：decoder每个位置输出的维度
  - dropout：dropout的概率
  - attention：需要传入attention类，用来计算decoder每个位置的输出和encoder每个位置的输出的关系
- forword参数：
  - input：输入单词的序号
  - hidden：上一步Decoder输出的状态
  - encoder_outputs：Encoder每个状态的输出，用来计算attention
  - mask：mask矩阵，用来在计算attention时，规避pad符号的影响
- forword输出为全连接层的输出、这一步Decoder的输出和attention的权重。这里输出的是预测时全连接层的输出，目的是计算后续的损失。


```python
class Decoder(nn.Module):
    def __init__(self,output_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout, attention):
        super().__init__()
        self.output_dim = output_dim
        self.attention = attention
        
        self.embedding = nn.Embedding(output_dim,emb_dim)
        
        self.rnn = nn.GRU((enc_hid_dim *2 )+ emb_dim, dec_hid_dim)
        
        self.fc_out = nn.Linear((enc_hid_dim * 2)+ dec_hid_dim + emb_dim , output_dim)
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self,input,hidden,encoder_outputs,mask):
        input = input.unsqueeze(0)
        
        embedded = self.dropout(self.embedding(input))
        
        a = self.attention(hidden,encoder_outputs,mask)
        
        a = a.unsqueeze(1)
        
        encoder_outputs = encoder_outputs.permute(1,0,2)
        
        weighted = torch.bmm(a,encoder_outputs)
        
        weighted = weighted.permute(1,0,2)
        
        rnn_input = torch.cat((embedded, weighted), dim=2)
        
        output,hidden = self.rnn(rnn_input, hidden.unsqueeze(0))
        
        assert (output == hidden).all()
        
        embedded = embedded.squeeze(0)
        output = output.squeeze(0)
        weighted = weighted.squeeze(0)
        
        prediction = self.fc_out(torch.cat((output,weighted,embedded), dim=1))
        
        return prediction,hidden.squeeze(0),a.squeeze(1)
```

#### seq2seq
- 构建一个seq2seq类将encoder、decoder和attention整合起来，参数：
  - encoder：encoder类
  - decoder：decoder类
  - doc_pad_idx：原文词典中pad符号的序号
  - device：需要传入的设备

- create_mask的参数：
  - doc：原文数据，create_mask会根据原文中pad符号的位置构建mask矩阵，这个mask矩阵会传入decoder，可以在计算attention时规避到pad符号的影响
- forward的参数：
  - doc：传入的一个批次的原文数据，是已经由词转换成序号的数据
  - doc_len：一个批次里每个数据的长度，用来生成mask矩阵
  - sum：摘要数据，同样已被转换成序号
  - teacher_forcing_ratio：teacher_forcing的概率，teacher_forcing是文本生成技术常用的技术，在训练时，如果一个词生成有误差，可能会影响到后面所有的词，所以以一定的概率选择生成的词还是标注的训练数据中相应位置的词，在验证测试时，不会用到teacher_forcing


```python
class Seq2Seq(nn.Module):
    def __init__(self,encoder,decoder,doc_pad_idx,device):
        super().__init__()
        
        self.encoder = encoder
        self.decoder = decoder
        self.doc_pad_idx = doc_pad_idx
        self.device = device
        
    def create_mask(self,doc):
        mask = (doc != self.doc_pad_idx).permute(1,0)
        return mask
    
    def forward(self,doc,doc_len,sum, teacher_forcing_ratio=0.5):
        batch_size = doc.shape[1]
        
#         print(type(sum))
#         print(sum)
        sum_len = sum[0].shape[0]
        sum_vocab_size= self.decoder.output_dim
        
        # 定义一个tensor来存储每一个生成的单词序号
        outputs = torch.zeros(sum_len,batch_size,sum_vocab_size).to(self.device)
        
        # encoder_outputs 是 encoder所有的输出状态
        # hidder是 encoder整体的输出
        encoder_outputs , hidden = self.encoder(doc,doc_len)
        
        # 输入的第一个字符为<sos>
        input = sum[0][0,:]
        
        # 构建一个mask矩阵， 包含训练数据原文中 pad符号的位置
        mask = self.create_mask(doc)
        
        for t in range(1, sum_len):
            try:
                # decoder 输入 前一步生成的单词embedding, 前一步状态hidden, encoder所有状态以及mask矩阵
                # 返回预测全连接层的输出和这一步的状态
                output,hidden,_ = self.decoder(input,hidden,encoder_outputs,mask)

                # 把output的信息存储在之前定义的 outputs里
                outputs[t] = output

                # 生成一个随机数， 来决定是否使用 teacher forcing
                teacher_force = random.random() < teacher_forcing_ratio

                # 获得可能性最高的单词序号 作为生成的单词
                top1 = output.argmax(1)

                # 如果使用teacher forcing则用训练数据相应位置的单词
                # 否则使用生成的单词 作为下一步的输入单词
                input = sum[t] if teacher_force else top1
            except Exception as e:
                pass
        return outputs      
```

### 模型实例化
利用定义好的模型结构实例化encoder和decoder。


```python
INPUT_DIM = len(DOCUMENT.vocab)
OUTPUT_DIM = len(SUMMARY.vocab)
ENC_EMB_DIM = 256//64
DEC_EMB_DIM = 256//64
ENC_HID_DIM = 512//64
DEC_HID_DIM = 512//64
ENC_DROPOUT = 0.5
DEC_DROPOUT = 0.5
DOC_PAD_IDX = DOCUMENT.vocab.stoi[DOCUMENT.pad_token]

attn = Attention(ENC_HID_DIM,DEC_HID_DIM)
enc = Encoder(INPUT_DIM,ENC_EMB_DIM,ENC_HID_DIM,DEC_HID_DIM,ENC_DROPOUT)
dec = Decoder(OUTPUT_DIM,DEC_EMB_DIM,ENC_HID_DIM,DEC_HID_DIM,DEC_DROPOUT,attn)

model = Seq2Seq(enc,dec,DOC_PAD_IDX,device).to(device)
```

#### 查看模型


```python
model
```




    Seq2Seq(
      (encoder): Encoder(
        (embedding): Embedding(16555, 4)
        (rnn): GRU(4, 8, bidirectional=True)
        (fc): Linear(in_features=16, out_features=8, bias=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (decoder): Decoder(
        (attention): Attention(
          (attn): Linear(in_features=24, out_features=8, bias=True)
          (v): Linear(in_features=8, out_features=1, bias=False)
        )
        (embedding): Embedding(9267, 4)
        (rnn): GRU(20, 8)
        (fc_out): Linear(in_features=28, out_features=9267, bias=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )



### 模型训练
- 使用之前处理的训练数据对模型训练，主要包括
  - 定义训练函数
  - 定义验证函数
  - 定义时间显示函数
  - 训练过程
  - 模型保存

#### 定义训练函数
定义训练一个 epoch的函数，并返回损失，参数
- model: 用以训练的模型
- iteration: 用以训练的数据迭代器
- optimizer: 训练模型使用的优化器
- criterion: 训练模型使用的损失函数
- clip: 梯度截断的值， 传入torch.nn.utils.clip_grad_norm_中，如果梯度超过这个clip，会使用clip对梯度进行截断，可以预防训练初期的梯度爆炸现象。

#### 定义验证函数
返回测试/验证数据的损失， 参数：
- model: 用以验证的模型
- iteration: 用以验证/测试的数据迭代器
- criterion: 验证/测试模型的损失函数


```python
def train(model,iterator,optimizer,criterion,clip):
    model.train()
    
    epoch_loss = 0
    
    for i,batch in enumerate(iterator):
        doc,doc_len = batch.document
        sum = batch.summary
#         print("****************这是train************************")
#         print(type(sum))
#         print(sum)
        optimizer.zero_grad()
        
        output = model(doc,doc_len,sum)
        
        output_dim = output.shape[-1]
        
        output = output[1:].view(-1,output_dim)
        sum = sum[0][1:].view(-1)
        
        loss = criterion(output,sum)
        
        loss.backward()
        
        torch.nn.utils.clip_grad_norm_(model.parameters(),clip)
        
        optimizer.step()
        
        epoch_loss += loss.item()
        if i>20:break
    return epoch_loss / len(iterator)
```


```python
def evaluate(model,iterator,criterion):
    model.eval()
    
    epoch_loss = 0
    with torch.no_grad():
        for i,batch in enumerate(iterator):
            doc,doc_len = batch.document
            sum = batch.summary
#             print("****************这是evaluate************************")
#             print(type(sum))
#             print(sum)
            output = model(doc,doc_len,sum,0)
            
            output_dim = output.shape[-1]
            
            output = output[1:].view(-1,output_dim)
            sum = sum[0][1:].view(-1)
            
            loss = criterion(output,sum)
            
            epoch_loss += loss.item()
            if i>20:break
    return epoch_loss / len(iterator)
```

#### 定义时间显示的函数


```python
def epoch_time(start_time,end_time):
    elapsed_time = end_time -start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time -(elapsed_mins * 60))
    return elapsed_mins,elapsed_secs
```

#### 训练过程
对整体的数据训练，分多个批次训练。
- 训练过程中，每个epoch后输出耗时、训练损失和验证损失。
  - 这里只训练了5个epoch，训练使用adam学习器，的学习率lr设置为0.001，weight decay设置为0.0001，CLIP设置为1。
  - 训练使用CrossEntropyLoss交叉熵损失，代表生成摘要每个位置单词和训练数据中相应位置的差异，如果训练数据中某个位置为pad符号，则计算损失时不计算生成摘要该位置的单词的损失。


```python
N_EPOCHS = 1
CLIP = 1
lr= 0.001
weight_decay = 0.0001
SUM_PAD_IDX = SUMMARY.vocab.stoi[SUMMARY.pad_token]

criterion = nn.CrossEntropyLoss(ignore_index=SUM_PAD_IDX)
optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)

# 训练
for epoch in range(N_EPOCHS):
    start_time = time.time()
    
    train_loss = train(model,train_iter, optimizer, criterion,CLIP)
    valid_loss = evaluate(model,val_iter,criterion)
    
    end_time = time.time()
    
    epoch_mins,epoch_secs = epoch_time(start_time,end_time)
    
    print(f'Epoch: {epoch + 1:02} | Time:{epoch_mins}m {epoch_secs}s')
    print(f'\tTrain Loss: {train_loss :.3f} | Tain PPL:{math.exp(train_loss):7.3f}')
    print(f'\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')
```

    Epoch: 01 | Time:0m 1s
    	Train Loss: 0.050 | Tain PPL:  1.052
    	 Val. Loss: 0.999 |  Val. PPL:   2.716


#### 模型保存


```python
torch.save(model.state_dict(),'model.pt')
```

### 模型预测
- 模型加载
- 构建预测函数
- 读取数据
- 预测

#### 模型加载


```python
model.load_state_dict(torch.load('model.pt'))
```




    <All keys matched successfully>



#### 构建预测函数
构建生成的函数，输入原文的字符串，输出生成摘要的字符串，参数为：
- doc_sentence:摘要的字符串
- doc_field:之前定义的针对document的预处理格式DOCUMENT
- sum_field:之前定义的针对summary的预处理格式SUMMARY
- model:训练的seq2seq模型
- device:数据存放的设备
- max_len:生成摘要的最长长度


```python
def generate_summary(doc_sentence,doc_field,sum_field,model,device,max_len=50):
    # 将模型部署为验证模式
    model.eval()
    
    # 对原文分词
    nlp = spacy.load('en_core_web_sm')
    
    tokens = [token.text.lower() for token in nlp(doc_sentence)]
    
    # 为原文加上起始符号<sos> 和结束符号<eos>
    tokens = [doc_field.init_token] + tokens + [doc_field.eos_token]
    
    # 将字符转换为序号
    doc_indexes = [doc_field.vocab.stoi[token] for token in tokens]
    
    # 转换成可以gpu计算的tensor
    doc_tensor = torch.LongTensor(doc_indexes).unsqueeze(1).to(device)
    
    doc_len = torch.LongTensor([len(doc_indexes)]).to(device)
    
    # 计算encoder
    with torch.no_grad():
        encoder_outputs,hidden = model.encoder(doc_tensor,doc_len)
        
    mask = model.create_mask(doc_tensor)
    
    # 生成摘要的一个单词<sos>
    sum_indexes = [sum_field.vocab.stoi[sum_field.init_token]]
    
    # 构建一个attention tensor，存储每一步的attention
    attentions = torch.zeros(max_len,1,len(doc_indexes)).to(device)
    
    for i in range(max_len):
        sum_tensor = torch.LongTensor([sum_indexes[-1]]).to(device)
        
        # 计算每一步的decoder
        with torch.no_grad():
            output,hidden,attention = model.decoder(sum_tensor, hidden, encoder_outputs,mask)
            
        attentions[i] = attention
        
        pred_token = output.argmax(1).item()
        
        # 如果出现了 <eos> 则直接结束计算
        if pred_token == sum_field.vocab.stoi[sum_field.eos_token]:
            break
        
        sum_indexes.append(pred_token)
        
    # 把序号转换成单词
    sum_tokens = [sum_field.vocab.itos[i] for i in sum_indexes]
    
    return sum_tokens[1:], attentions[:len(sum_tokens)-1]
```

#### 读取数据


```python
data_test = pd.read_csv("dataset/test.csv",encoding='utf-8')
data_test = data_test[:100]

doc_sentence_list = data_test['document'].tolist()
sum_sentence_list = data_test['summary'].tolist()
```

#### 预测


```python
# 使用generate_summary函数对测试集中所有的document生成摘要, 预测时，不能使用批次的方式预测，所有数据顺序预测，需要一定的时间。
generated_summary = []
for doc_sentence in doc_sentence_list:
    summary_words,attention = generate_summary(doc_sentence,DOCUMENT,SUMMARY,model,device,max_len=50)
    summary_sentence = (' ').join(summary_words)
    generated_summary.append(summary_sentence)
```


```python
# 输出一个生成的摘要
indices = random.sample(range(0,len(sum_sentence_list)),5)
for index in indices:
    print("******document******")
    print(doc_sentence_list[index])
    
    print("******generated summary:*******")
    print(generated_summary[index])
    
    print("*******reference summary:*******")
    print(sum_sentence_list[index])
    
    print("***************************")
```

    ******document******
    south african mining giant anglo american said on tuesday that it had agreed to sell the <unk> <unk> group for ### million dollars -lrb- ### million euros -rrb- in cash to private equity group advent international .
    ******generated summary:*******
    community pilgrims organizers qualifiers nt thailand descends number village village village village vie profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile replacement profile
    *******reference summary:*******
    anglo american sells <unk> <unk> for ### mln dlrs
    ***************************
    ******document******
    the patriots locked up super bowl hero adam vinatieri friday , removing the `` franchise player '' tag and signing him to a three-year deal , and now they will wait to see if there is any interest in a drew bledsoe deal at the owners ' meetings in orlando this upcoming week .
    ******generated summary:*******
    descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open
    *******reference summary:*******
    pats sign vinatieri to #-year deal
    ***************************
    ******document******
    greg oden was on a path to follow lebron james , a high school prodigy leaping directly to the national basketball association , but he now must wait until #### to seek professional riches .
    ******generated summary:*******
    descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open
    *******reference summary:*******
    nba hot prospect oden now looks to college first
    ***************************
    ******document******
    pedro astacio did n't allow a hit until geoff jenkins lined a single to left field with one out in the seventh inning saturday , and the new york mets beat the milwaukee brewers #-# .
    ******generated summary:*******
    descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open descends open
    *******reference summary:*******
    astacio nearly no-hits brewers as mets win #-#
    ***************************
    ******document******
    fighting spread saturday through the alleys of densely populated west bank refugee camps , where palestinian militants reportedly were handing out explosives-packed belts to residents willing to strap them on and challenge israeli soldiers .
    ******generated summary:*******
    replacement republican performance thailand descends thailand descends number village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village village
    *******reference summary:*******
    fighting spreads through palestinian refugee camps as death toll
    ***************************


### 模型评估
- 模型加载
- 损失评估
- 指标评估

#### 模型加载


```python
model.load_state_dict(torch.load('model.pt'))
```




    <All keys matched successfully>



#### 损失评估


```python
# 评估测试集的损失，输出损失。直接调用之前定义的evaluate函数，输入为测试数据的迭代器。
test_loss= evaluate(model,test_iter,criterion)
```


```python
print(f'| Test Loss:{test_loss:.3f} | Test PPL:{math.exp(test_loss):7.3f} |')
```

    | Test Loss:0.998 | Test PPL:  2.713 |


#### 指标评估

文本自动摘要的指标通常为ROUGE（Recall-Oriented Understudy for Gisting Evaluation），在2004年由Chin-Yew Lin提出。
![image.png](attachment:e4ae16be-a267-4f86-9401-d4284cb6223d.png)

- 分母是人工摘要（也就是数据中标注的摘要）中n-gram的个数，分子是人工摘要和机器生成的自动摘要共现（重合）的n-gram的个数。
- 可以看出，ROUGE与召回率（recall）的定义很相似。分母也可以是机器生成的摘要，这样就是准确率（precision），同时也可以计算F1指数。
- 通常情况下只用召回率，展示1-gram和2-gram的结果ROUGE-1和ROUGE-2。
- 除了ROUGE-1和ROUGE-2之外，还可以用人工摘要和机器生成的摘要的最长公共子序列(Longest Common Sequence)的长度和生成摘要或者标注摘要的长度之间的比例来评估摘要模型

![image.png](attachment:a96e27f2-6e52-47cf-bc06-9b18468f2e27.png)

- 第一个公式分母为标注的摘要长度，计算召回率。第二个公式分母为生成的摘要长度，计算准确率。第三个公式求 $F_\beta$ ， $\beta$ 的值通常大于1。
和ROUGE-1、ROUGE-2不同的是，ROUGE-L主要关注F指数。
- 目前用python计算评估ROUGE指标通常使用pyrouge，但是pyrouge的安装需要预先安装ROUGE工具，较为麻烦，我们这里直接使用rouge工具包进行ROUGE的评估，rouge可以直接使用pip install rouge安装。rouge输入生成的摘要和人工摘要，输出ROUGE-1、ROUGE-2、ROUGE-L的f指数、准确率和召回率。


```python
from rouge import Rouge
```


```python
rouge = Rouge()
scores = rouge.get_scores(generated_summary,sum_sentence_list,avg=True)
```


```python
print(scores)
```

    {'rouge-1': {'f': 0.0003508771714373667, 'p': 0.0002, 'r': 0.0014285714285714286}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.0024999999625000004, 'p': 0.005, 'r': 0.0016666666666666666}}


#### 存在如下问题
目前普遍使用seq2seq解决文本摘要问题，会出现以下问题：

1.OOV问题

源文档语料中的词的数量级通常会很大,但是经常使用的词数量则相对比较固定。因此通常会根据词的频率过滤掉一些词做成词表。这样的做法会导致生成摘要时会遇到UNK的词。


2.摘要的可读性。

通常使用贪心算法或者beamsearch方法来做decoding。这些方法生成的句子有时候会存在不通顺的问题。


3.摘要的重复性。

这个问题出现的频次很高。与2的原因类似，由于一些decoding的方法的自身缺陷，导致模型会在某一段连续timesteps生成重复的词。


4.长文本摘要生成难度大。

对于机器翻译来说，NLG的输入和输出的语素长度大致都在一个量级上，因此NLG在其之上的效果较好。但是对摘要来说，源文本的长度与目标文本的长度通常相差很大，此时就需要encoder很好的将文档的信息总结归纳并传递给decoder，decoder需要完全理解并生成句子。可想而知，这是一个很难的事情。


5.模型的训练目标与最终的评测指标不太一致。

这里牵扯到两个问题，一个是seq2seq的训练模式中，通常会使用teacher-forcing的方式，即在decoder上，将真实target的输入和模型在前一时刻生成的词一起送到下一个时刻的神经元中计算。但是在inference时，是不会有真实target的，因此存在一个gap；另一个问题就是通常模型训练的目标函数都是交叉熵损失函数。但是摘要的评测却不是以交叉熵来判断的，目前一些榜单通常以ROUGE、BLEU等方式评测，虽然这些评测也不是很完美，但是与交叉熵的评测角度均在较大差异。



优化思路
可以尝试如何利用深度无监督模型去做生成式摘要任务。

例如：以自编码器为主体架构，对其进行不同程度的改造，从压缩或者生成两个角度去无监督生成摘要文本，
同时为了提升效果，也会利用GPT,XLNET等预训练语言模型做finetune。

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </All></unk></unk></unk></unk></eos></sos></eos></sos></All></sos></',></eos></sos></pad></unk></eos></sos></eos></sos></unk></pad>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>基于贝叶斯决策理论的分类方法</title>
    <url>/2020/12/24/%E5%9F%BA%E4%BA%8E%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 基于贝叶斯决策理论的分类方法

**朴素贝叶斯是贝叶斯决策理论的一部分**
- 优点：在数据较少的情况下仍然有效，可以处理多类别问题
- 缺点：对于输入数据的准备方式较为敏感
- 适用数据类型：标称型数据

  *标称型：一般在有限的数据中取，而且只存在‘是’和‘否’两种不同的结果（一般用于分类）*
  *数值型：可以在无限的数据中取，而且数值比较具体化，例如4.02,6.23这种值（一般用于回归分析）*

#### **贝叶斯决策理论的核心思想，即选择具有最高概率的决策**
- 假设现在我们有一个数据集，它由两类数据组成，数据分布如图
![image.png](attachment:e36f25cc-1cec-4995-809d-c7812f629c99.png)
- 我们现在用p1(x,y)表示数据点(x,y)属于类别1（图中用圆点表示的类别）的概率，用p2(x,y)表示数据点(x,y)属于类别2（图中用三角形表示的类别）的概率，那么对于一个新数据点(x,y)，可以用下面的规则来判断它的类别：
 - 如果 p1(x,y) > p2(x,y)，那么类别为1
 - 如果 p2(x,y) > p1(x,y)，那么类别为2

- **计算分类的方法**
 - 使用kNN，进行1000次距离计算；
 - 使用决策树，分别沿x轴、y轴划分数据；
 - 计算数据点属于每个类别的概率，并进行比较

#### **条件概率**
![image.png](attachment:40d76e00-9bfb-4c92-af12-2257b8e49fc1.png)
- 计算从B桶中取到灰色石头的概率的办法，这就是所谓的条件概率（conditionalprobability）。假定计算的是从B桶取到灰色石头的概率，这个概率可以记作P(gray|bucketB)，
- 我们称之为“在已知石头出自B桶的条件下，取出灰色石头的概率”。不难得到，P(gray|bucketA)值为2/4，P(gray|bucketB) 的值为1/3。
![image.png](attachment:b6ba6689-3ad1-4a37-96c0-ccc2326b99a8.png)

## **使用条件概率分类**
- 之前贝叶斯决策理论要求计算两个概率p1(x, y)和p2(x, y)：
 - 如果p1(x, y) > p2(x, y)，那么属于类别1；
 - 如果p2(x, y) > p1(x, y)，那么属于类别2。

- 使用p1( )和p2( )只是为了尽可能简化描述，真正需要计算和比较的是p(c1|x, y)和p(c2|x, y)。这些符号所代表的具体意义是：
 - 给定某个由x、y表示的数据点，那么该数据点来自类别c1的概率是多少？
 - 数据点来自类别c2的概率又是多少？
![image.png](attachment:4ca58d34-234e-4fa6-b572-4b591bd36e18.png)
- 使用这些定义，可以定义贝叶斯分类准则为：
 - 如果P(c1|x, y) > P(c2|x, y)，那么属于类别c1。
 - 如果P(c1|x, y) < P(c2|x, y)，那么属于类别c2。

## **使用朴素贝叶斯进行文本分类**
- 朴素贝叶斯的一般过程
 - 收集数据：
 - 准备数据：需要数值型 或者布尔型数据
 - 分析数据：有大量特征时，绘制特征作用不大， 此时使用直方图效果更好
 - 训练算法：计算不同的独立特征的条件概率
 - 测试算法：计算错误率
 - 使用算法：一个常见的朴素贝叶斯应用是文档分类，可以任意的分类场景中使用朴素贝叶斯分类器

- 特征之间相互独立（independence）：指的是统计意义上的独立，即一个特征或者单词出现的可能性与它和其他单词相邻没有关系
- 每个特征同等重要

## **文本分类**

#### **准备数据：从文本中构建词向量**


```python
import sys
import numpy as np
print(sys.executable)
```

    /Users/gaozhiyong/Documents/pyenv/pyenv3.6/bin/python



```python
def loadDataSet():
    postingList = [
        ['my','dog','has','flea','problems','help','please'],
        ['maybe','not','take','him','to','dog','park','stupid'],
        ['my','dalmation','is','so','cute','I','love','him'],
        ['stop','posting','stupid','worthless','garbage'],
        ['mr','licks','ate','my','steak','how','to','stop','him'],
        ['quit','buying','worthless','dog','food','stupid']
    ]
    classVec = [0,1,0,1,0,1]
    return postingList,classVec
```


```python
def createVocabList(dataSet):
    vocabSet = set([])    #创建一个空集
    for document in dataSet:
#         print('document',document)
#         print("vocabSet之前",vocabSet)
        vocabSet = vocabSet | set(document)  #创建两个集合的并集
#         print("vocabSet之后",vocabSet)
    return list(vocabSet)
```


```python
def setOfWord2Vec(vocabList,inputSet):
    returnVec = [0] * len(vocabList)
    for word in inputSet:
        if word in vocabList:
            returnVec[vocabList.index(word)] = 1
        else:
            print("the word: %s is not in my Vocabulary!" % word )
    return returnVec
```


```python
listOPosts,listClasses = loadDataSet()
```


```python
listOPosts
```




    [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],
     ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],
     ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],
     ['stop', 'posting', 'stupid', 'worthless', 'garbage'],
     ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],
     ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]




```python
listClasses
```




    [0, 1, 0, 1, 0, 1]




```python
myVocabList = createVocabList(listOPosts)
```


```python
myVocabList
```




    ['stop',
     'dalmation',
     'park',
     'please',
     'my',
     'to',
     'problems',
     'posting',
     'flea',
     'steak',
     'him',
     'take',
     'ate',
     'is',
     'help',
     'how',
     'cute',
     'has',
     'maybe',
     'food',
     'buying',
     'stupid',
     'licks',
     'mr',
     'dog',
     'not',
     'love',
     'worthless',
     'I',
     'so',
     'quit',
     'garbage']




```python
listOPosts[0]
```




    ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please']




```python
setOfWord2Vec(myVocabList,listOPosts[0])
```




    [0,
     0,
     0,
     1,
     1,
     0,
     1,
     0,
     1,
     0,
     0,
     0,
     0,
     0,
     1,
     0,
     0,
     1,
     0,
     0,
     0,
     0,
     0,
     0,
     1,
     0,
     0,
     0,
     0,
     0,
     0,
     0]




```python
setOfWord2Vec(myVocabList,listOPosts[3])
```




    [1,
     0,
     0,
     0,
     0,
     0,
     0,
     1,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     0,
     1,
     0,
     0,
     0,
     0,
     0,
     1,
     0,
     0,
     0,
     1]



#### **训练算法：从词向量计算概率**
![image.png](attachment:40c1d39c-159e-4c7f-a811-45a728741340.png)
- 使用上述公式，对每个类计算该值，然后比较这两个概率值的大小。
- 如何计算呢？
 - 首先可以通过类别i（侮辱性留言或非侮辱性留言）中文档数除以总的文档数来计算概率p(ci)。
 - 接下来计算p(w|ci)，这里就要用到朴素贝叶斯假设。
   - 如果将w展开为一个个独立特征，那么就可以将上述概率写作p(w0,w1,w2..wN|ci)。
   - 这里假设所有词都互相独立，该假设也称作条件独立性假设，它意味着可以使p(w0|ci)p(w1|ci)p(w2|ci)...p(wN|ci)来计算上述概率

##### **代码逻辑**
- 计算每个类别中的文档数目
- 对每篇训练文档
 - 对每个类别
    - 如果词条出现在文档中 --- 增加该词条的计数值
    - 增加所有词条的计数值
 - 对每个类别
    - 对每个词条
       - 将 **该词条的数目** 除以 **总词数目** 得到 **条件概率**
 - 返回每个类别的条件概率


```python
def trainNB0(trainMatrix,trainCategory):
    numTrainDocs = len(trainMatrix)
    numWords = len(trainMatrix[0])
    pAbusive = sum(trainCategory) / float(numTrainDocs)
    p0Num = np.zeros(numWords) 
    p1Num = np.zeros(numWords)
    p0Denom = 0.0
    p1Denom = 0.0
    for i in range(numTrainDocs):
        try:
            if trainCategory[i] == 1:
                p1Num += trainMatrix[i]
                p1Denom += sum(trainMatrix[i])
            else:
                p0Num += trainMatrix[i]
                p0Denom += sum(trainMatrix[i])
        except:
            continue
    p1Vect = p1Num / p1Denom
    p0Vect = p0Num / p0Denom
    return p0Vect,p1Vect,pAbusive
```


```python
listOPosts,listClasses = loadDataSet()
```


```python
myVocabList = createVocabList(listOPosts)
```


```python
trainMat = []
for postinDoc in listOPosts:
    trainMat.append(setOfWord2Vec(myVocabList,postinDoc))
p0V,p1V,pAb = trainNB0(trainMat,listClasses)
```


```python
pAb
```




    0.5




```python
p0V
```




    array([0.04166667, 0.04166667, 0.        , 0.04166667, 0.125     ,
           0.04166667, 0.04166667, 0.        , 0.04166667, 0.04166667,
           0.08333333, 0.        , 0.04166667, 0.04166667, 0.04166667,
           0.04166667, 0.04166667, 0.04166667, 0.        , 0.        ,
           0.        , 0.        , 0.04166667, 0.04166667, 0.04166667,
           0.        , 0.04166667, 0.        , 0.04166667, 0.04166667,
           0.        , 0.        ])




```python
p1V
```




    array([0.05263158, 0.        , 0.05263158, 0.        , 0.        ,
           0.05263158, 0.        , 0.05263158, 0.        , 0.        ,
           0.05263158, 0.05263158, 0.        , 0.        , 0.        ,
           0.        , 0.        , 0.        , 0.05263158, 0.05263158,
           0.05263158, 0.15789474, 0.        , 0.        , 0.10526316,
           0.05263158, 0.        , 0.10526316, 0.        , 0.        ,
           0.05263158, 0.05263158])



#### **测试算法：根据现实情况修改分类器**


```python
def trainNB1(trainMatrix,trainCategory):
    numTrainDocs = len(trainMatrix)
    numWords = len(trainMatrix[0])
    pAbusive = sum(trainCategory) / float(numTrainDocs)
    p0Num = np.ones(numWords) 
    p1Num = np.ones(numWords)
    p0Denom = 2.0
    p1Denom = 2.0
    for i in range(numTrainDocs):
        try:
            if trainCategory[i] == 1:
                p1Num += trainMatrix[i]
                p1Denom += sum(trainMatrix[i])
            else:
                p0Num += trainMatrix[i]
                p0Denom += sum(trainMatrix[i])
        except:
            continue
    p1Vect = np.log(p1Num / p1Denom)
    p0Vect = np.log(p0Num / p0Denom)
    return p0Vect,p1Vect,pAbusive
```


```python
def classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):
    p1=sum(vec2Classify * p1Vec) + np.log(pClass1)
    p0= sum(vec2Classify * p0Vec) + np.log(1.0- pClass1)
    if p1>p0:
        return 1
    else:
        return 0
```


```python
def testingNB():
    listOPosts,listClasses = loadDataSet()
    myVocabList = createVocabList(listOPosts)
    trainMat = []
    for postinDoc in listOPosts:
        trainMat.append(setOfWord2Vec(myVocabList,postinDoc))
    p0V,p1V,pAb = trainNB1(np.array(trainMat), np.array(listClasses))
    testEntry1 = ['love','my','dalmation']
    thisDoc = np.array(setOfWord2Vec(myVocabList,testEntry1))
    print(testEntry1,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb))
    
    testEntry2 = ['stupid','garbage']
    thisDoc = np.array(setOfWord2Vec(myVocabList,testEntry2))
    print(testEntry2,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb))
```


```python
testingNB()
```

    ['love', 'my', 'dalmation'] classified as:  0
    ['stupid', 'garbage'] classified as:  1


#### **准备数据：文档词袋模型**
- 将每个词的出现与否作为一个特征，这可以被描述为词集模型(set-of-words model)。
- 如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表 达的某种信息，这种方法被称为词袋模型(bag-of-words model)


```python
def bagOfWords2VecMN(vocabList,inputSet):
    returnVec = [0] * len(vocabList)
    for word in inputSet:
        if word in vocabList:
            returnVec[vocabList.index[word]] += 1
    return returnVec
```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>朴素贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>基于矩阵分解实现电影推荐</title>
    <url>/2022/01/16/%E5%9F%BA%E4%BA%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 基于矩阵分解实现电影推荐

<iframe src="https://ocaeneyes.github.io/recommendPrj/%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90.html" width="100%" height="1080"></iframe>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>推荐</tag>
        <tag>矩阵分解</tag>
      </tags>
  </entry>
  <entry>
    <title>增长黑客最常见的6大误区</title>
    <url>/2018/11/04/%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2%E6%9C%80%E5%B8%B8%E8%A7%81%E7%9A%846%E5%A4%A7%E8%AF%AF%E5%8C%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 增长黑客最常见的6大误区

#### 误区一：“增长黑客和互联网营销没有区别，仅是注重低成本获客“

​	增长其实最关注的不是拉新，而是留存，留存的复利效应。

#### 误区二：“增长黑客是灵丹妙药，立刻就能见效”

​	增长不能临时抱佛脚--缺乏长期积累，实力再雄厚也无法从中受益

#### 误区三：“就算产品很烂，增长黑客也能把它推火”

​	真正的增长必须基于一个好的产品；如果把增长比作盖房子，那么优秀的产品功能/用户体验就是地基。

​	什么样的产品算的上好产品呢？

​	首先要通过最小可执行产品（MVP）/功能设计（MVD），检测用户对于产品/功能的真实需

求，从而找到产品-市场匹配（P/MF）只有达到PMF的产品，才能算合格的产品；真正的增长其实

是建立在PMF的基础上的。

​	**如果要维持长期的用户增长，首先必须要有一个好产品。**

#### 误区四：“增长黑客就是用一些小伎俩来走捷径”

​	·所谓的技巧和套路只是推动阶段性爆发的手段，而保持长期上升趋势则是需要依赖科学的战

略和增长流程。

**“增长黑客之父”肖恩.埃利斯的增长四步走理论：**

1. 掌握基本原理（principles）

   PMF如何优化；

   北极星指标如何制定；

   AB测试；

   数据分析；

   ……

2. 形成一套增长流程（growth process）

   增长目标>>聚焦领域>>（产生想法>>排列顺序>>>开发实验>>>分析数据>>>应用结果>>>产生想法）

3. 逐步积累对流量平台的认知（platform knowledge）

   借助某个成熟的流量体系来成长；如微信，微博，百度

4. 最后是“套路”（tactics）

   为了帮助高效实现北极星指标，而不是为了kpi去冲用户量

#### 误区五：“增长黑客凭借一己之力可以扭转局势”

​	再牛掰的增长黑客，也无法单打独斗，而是需要整个团队甚至全公司的配合。

**注意：**增长黑客不是一名狙击手，而是一只配合默契的正规军。这个团队可能包含数据分析师，内

容编辑，产品经理，设计师，广告投手和程序员，而大家的目标（KPI）是一致的，完成现阶段的

北极星指标。

#### 误区六：“增长黑客必须会写代码”

​	**增长黑客更多的是一种思维（mindset），而非技术（technical）。**能够学会写代码，是增长黑客提升自己段位的标志，但不是必要条件。

​	增长黑客的工作重心是以**业务发展**（完成阶段性指标）为导向，而不是技术开发为导向。

​	**不要重复发明轮子，要用别人的轮子，开自己的跑车。**



**增长本身是个实验驱动的思维模式，而黑客的意思是指用技术/技巧去爆破瓶颈，放大规模。**

实践思路：从用户的整个生命周期思考问题，帮助用户解决问题，创造价值。

实现方法：依靠实验和数据做好产品，靠低成本高粘性的渠道做营销。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>增长产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>增长黑客</tag>
      </tags>
  </entry>
  <entry>
    <title>基于LSTM+CRF的中文命名实体识别</title>
    <url>/2021/06/17/%E5%9F%BA%E4%BA%8ELSTM-CRF%E7%9A%84%E4%B8%AD%E6%96%87%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 基于LSTM+CRF的中文命名实体识别

- **任务描述**：命名实体识别是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。
  - 实现一个简单的命名实体识别方法，该方法通过BiLSTM+CRF模型预测出文本中文字所对应的标签，再根据标签提取出文本中的实体。
  - 从数据文件中加载数据并进行预处理、构建模型、训练模型、评估模型和测试模型。
    - 说明：目前本文档仅作为示例，为了加快训练速度模型较为简单，词向量维度也比较低，因此导致模型准确率较低。


```python
import tensorflow as tf
import numpy as np
import pandas as pd
```


```python
import tensorflow_addons as tfa
```

- tf 2.0 的新特性：eager execution

  - 可以用tf.executing_eargerly()查看Eager Execution当前的启动状态，返回True则是开启，False是关闭。
  - 可以用tf.compat.v1.enable_eager_execution()启动eager模式。
  - 关闭eager模式的函数是 tf.compat.v1.disable_eager_execution()


```python
tf.compat.v1.disable_eager_execution()
```

### 文本数准备

- 数据说明
- 数据整理
- 加载数据

#### 数据说明

- 数据集共包含约2.7万中文文本，其中包括约2.08万训练集，0.23万验证集和0.46万测试集。
- 数据集分别命名为example.train,example.dev,example.test,保存在datasets目录下。

  - 1.训练集：包含文本和对应的标签，用于模型训练。
  - 2.验证集：包含文本和对应的标签，用于模型训练和参数调试。
  - 3.测试集：包含文本和对应的标签，用于预测结果、验证效果。

- 数据集中标注有三种实体，分别为人名、地名、机构名，标注集合为{'O','B-PER','I-PER','B-ORG','I-ORG','B-LOC','I-LOC'}。
  - 其中'O'表示非实体，
  - 'B-'表示实体的首字，
  - 'I-'表示实体的其他位置的字，
  - 'PER'表示人名，
  - 'ORG'表示机构名，
  - 'LOC'表示地名。IOB（Inside–outside–beginning）是用于标记标志的通用标记格式。

#### 数据整理

根据数据集中的字符建立字典，并保存在datasets/vocab.txt中，
标签根据数据集中字符建立字典，并保存在datasets/.txt中


```python
def get_vocab_list(path_list):
    vocab_set = set()
    vocab_list = list()
    for path in path_list:
        with open(path,'r',encoding='utf-8') as f:
            for line in f:
                if len(line.strip()) == 0:
                    continue
                if line[0] not in vocab_set:
                    vocab_set.add(line[0])
                    vocab_list.append(line[0])
    return vocab_list

def save_vocab(path,vocab_list):
    output = ''.join([vocab + '\n' for vocab in vocab_list])
    with open(path,'w', encoding='utf-8') as f:
        f.write(output)
        
vocab_list = get_vocab_list(['./datasets/example.train','./datasets/example.dev','./datasets/example.test'])
save_vocab('./datasets/vocab.txt',vocab_list)
```


```python
vocab_list
```


    ['海',
     '钓',
     '比',
     '赛',
     '地',
     '点',
     '在',
     '厦',
     '门',
     '与',
     '金',
     '之',
     '间',
     '的',
     '域',
     '。',
     '这',
     '座',
     '依',
     '山',
     '傍',
     '水',
     '博',
     '物',
     '馆',
     '由',
     '国',
     '内',
     '一',
     '流',
     '设',
     '计',
     '师',
     '主',
     '持',
     '，',
     '整',
     '个',
     '建',
     '筑',
     '群',
     '精',
     '美',
     '而',
     '恢',
     '宏',
     '但',
     '作',
     '为',
     '共',
     '产',
     '党',
     '员',
     '、',
     '人',
     '民',
     '公',
     '仆',
     '应',
     '当',
     '胸',
     '怀',
     '宽',
     '阔',
     '真',
     '正',
     '做',
     '到',
     '“',
     '先',
     '天',
     '下',
     '忧',
     '后',
     '乐',
     '”',
     '淡',
     '化',
     '名',
     '利',
     '得',
     '失',
     '和',
     '宠',
     '辱',
     '悲',
     '喜',
     '把',
     '改',
     '革',
     '大',
     '业',
     '摆',
     '首',
     '位',
     '样',
     '才',
     '能',
     '超',
     '越',
     '自',
     '我',
     '脱',
     '世',
     '俗',
     '有',
     '所',
     '发',
     '达',
     '家',
     '急',
     '救',
     '保',
     '险',
     '十',
     '分',
     '普',
     '及',
     '已',
     '成',
     '社',
     '会',
     '障',
     '体',
     '系',
     '重',
     '要',
     '组',
     '部',
     '日',
     '俄',
     '两',
     '政',
     '局',
     '都',
     '充',
     '满',
     '变',
     '数',
     '尽',
     '管',
     '关',
     '目',
     '前',
     '是',
     '历',
     '史',
     '最',
     '佳',
     '时',
     '期',
     '其',
     '脆',
     '弱',
     '性',
     '不',
     '言',
     '明',
     '克',
     '马',
     '尔',
     '女',
     '儿',
     '让',
     '娜',
     '今',
     '年',
     '读',
     '五',
     '级',
     '她',
     '班',
     '上',
     '3',
     '0',
     '多',
     '同',
     '学',
     '该',
     '委',
     '1',
     '长',
     '参',
     '加',
     '步',
     '行',
     '男',
     '轻',
     '也',
     '中',
     '沙',
     '特',
     '队',
     '教',
     '练',
     '佩',
     '雷',
     '拉',
     '：',
     '支',
     '想',
     '胜',
     '因',
     '此',
     '出',
     '了',
     '努',
     '力',
     '种',
     '混',
     '乱',
     '面',
     '导',
     '致',
     '些',
     '使',
     '用',
     '者',
     '合',
     '法',
     '权',
     '益',
     '难',
     '以',
     '维',
     '护',
     '鲁',
     '宾',
     '确',
     '指',
     '对',
     '府',
     '控',
     '完',
     '全',
     '没',
     '事',
     '实',
     '根',
     '据',
     '向',
     '转',
     '敏',
     '感',
     '技',
     '术',
     '相',
     '总',
     '白',
     '于',
     '；',
     '众',
     '议',
     '院',
     '令',
     '非',
     '常',
     '望',
     '将',
     '商',
     '卫',
     '星',
     '受',
     '威',
     '胁',
     '竞',
     '争',
     '损',
     '害',
     '育',
     '场',
     '每',
     '早',
     '6',
     '至',
     '8',
     '免',
     '费',
     '开',
     '放',
     '游',
     '泳',
     '等',
     '则',
     '增',
     '综',
     '服',
     '务',
     '延',
     '采',
     '取',
     '灵',
     '活',
     '收',
     '再',
     '看',
     '容',
     '图',
     '文',
     '并',
     '茂',
     '简',
     '短',
     '字',
     '准',
     '反',
     '映',
     '六',
     '族',
     '风',
     '土',
     '情',
     '传',
     '统',
     '各',
     '讲',
     '很',
     '哥',
     '伦',
     '亚',
     '号',
     '航',
     '飞',
     '机',
     '宇',
     '边',
     '进',
     '验',
     '继',
     '续',
     '抢',
     '修',
     '故',
     '二',
     '氧',
     '碳',
     '清',
     '除',
     '装',
     '置',
     '从',
     '剥',
     '削',
     '阶',
     '劳',
     '动',
     '生',
     '率',
     '低',
     '况',
     '占',
     '限',
     '剩',
     '余',
     '品',
     '足',
     '豪',
     '华',
     '需',
     '量',
     '扩',
     '现',
     '资',
     '条',
     '件',
     '榨',
     '价',
     '值',
     '供',
     '身',
     '求',
     '外',
     '又',
     '本',
     '新',
     '雇',
     '佣',
     '私',
     '来',
     '料',
     '集',
     '代',
     '表',
     '澳',
     '别',
     '区',
     '筹',
     '备',
     '第',
     '次',
     '午',
     '北',
     '京',
     '堂',
     '幕',
     '副',
     '理',
     '任',
     '钱',
     '琛',
     '词',
     '工',
     '经',
     '启',
     '临',
     '紧',
     '迫',
     '们',
     '道',
     '远',
     '希',
     '齐',
     '心',
     '协',
     '平',
     '稳',
     '过',
     '渡',
     '顺',
     '交',
     '接',
     '贡',
     '献',
     '济',
     '程',
     '界',
     '深',
     '信',
     '观',
     '必',
     '须',
     '微',
     '基',
     '础',
     '病',
     '好',
     '颈',
     '背',
     '躯',
     '干',
     '殖',
     '器',
     '可',
     '见',
     '龄',
     '市',
     '柔',
     '县',
     '试',
     '遍',
     '觉',
     '四',
     '节',
     '课',
     '饥',
     '饿',
     '消',
     '川',
     '省',
     '江',
     '油',
     '丰',
     '选',
     '豆',
     '奶',
     '复',
     '营',
     '养',
     '素',
     '贫',
     '血',
     '降',
     '百',
     '照',
     '只',
     '．',
     '4',
     '宗',
     '旨',
     '决',
     '定',
     '奉',
     '甘',
     '愿',
     '吃',
     '亏',
     '苦',
     '享',
     '困',
     '危',
     '留',
     '给',
     '己',
     '方',
     '便',
     '安',
     '初',
     '央',
     '形',
     '势',
     '快',
     '速',
     '策',
     '立',
     '研',
     '究',
     '派',
     '就',
     '提',
     '许',
     '富',
     '意',
     '味',
     '论',
     '话',
     '题',
     '书',
     '记',
     '粟',
     '光',
     '断',
     '他',
     '亲',
     '兄',
     '弟',
     '签',
     '！',
     '熟',
     '悉',
     '运',
     '士',
     '说',
     '贷',
     '款',
     '旦',
     '被',
     '推',
     '迟',
     '几',
     '月',
     '甚',
     '更',
     '考',
     '虑',
     '伍',
     '义',
     '气',
     '原',
     '惠',
     '象',
     '估',
     '像',
     '疤',
     '痕',
     '笨',
     '拙',
     '手',
     '针',
     '线',
     '周',
     '恩',
     '那',
     '送',
     '株',
     '万',
     '古',
     '青',
     '友',
     '谊',
     '红',
     '杉',
     '吧',
     '巴',
     '谈',
     '问',
     '印',
     '声',
     '宣',
     '称',
     '何',
     '三',
     '介',
     '入',
     '久',
     '赴',
     '西',
     '老',
     '访',
     '广',
     '职',
     '积',
     '极',
     '企',
     '监',
     '督',
     '如',
     '居',
     '子',
     '倘',
     '若',
     '客',
     '环',
     '境',
     '钝',
     '迅',
     '判',
     '陷',
     '处',
     '碰',
     '壁',
     '然',
     '热',
     '解',
     '寻',
     '找',
     '联',
     '邦',
     '州',
     '予',
     '适',
     '具',
     '骤',
     '吸',
     '七',
     '团',
     '另',
     '龙',
     '口',
     '科',
     '投',
     '视',
     '息',
     '创',
     '跳',
     '跃',
     '式',
     '展',
     '强',
     '调',
     '高',
     '培',
     '训',
     '认',
     '识',
     '密',
     '结',
     '小',
     '九',
     '升',
     '或',
     '段',
     '少',
     '懂',
     '习',
     '互',
     '贵',
     '贱',
     '请',
     '注',
     '语',
     '构',
     '偏',
     '孝',
     '父',
     '母',
     '始',
     '票',
     '否',
     '制',
     '还',
     '缺',
     '乏',
     '际',
     '电',
     '影',
     '摄',
     '录',
     '音',
     '剪',
     '辑',
     '诸',
     '趋',
     '激',
     '烈',
     '造',
     '奇',
     '夺',
     '起',
     '直',
     '追',
     '医',
     '药',
     '李',
     '珍',
     '闻',
     '屡',
     '仕',
     '寄',
     '托',
     '八',
     '股',
     '兴',
     '趣',
     '酷',
     '爱',
     '召',
     '吴',
     '英',
     '司',
     '董',
     '德',
     '·',
     '葛',
     '夫',
     '邀',
     '席',
     '车',
     '闲',
     '防',
     '施',
     '配',
     '套',
     '存',
     '鹅',
     '洲',
     '源',
     '终',
     '连',
     '串',
     '井',
     '序',
     '顾',
     '犯',
     '罪',
     '讳',
     '审',
     '死',
     '刑',
     '笔',
     '融',
     '农',
     '假',
     '币',
     '知',
     '巧',
     '律',
     '规',
     '村',
     '秩',
     '『',
     '范',
     '茅',
     '迹',
     '览',
     '』',
     '磁',
     '球',
     '孩',
     '格',
     '散',
     '着',
     '独',
     '魅',
     '莱',
     '坞',
     '千',
     '模',
     '翻',
     '版',
     '？',
     '燃',
     '汽',
     '仅',
     '守',
     '—',
     '路',
     '易',
     '斯',
     '切',
     '迪',
     '阿',
     '塞',
     '瓦',
     '萨',
     '卡',
     '里',
     '罗',
     '弗',
     '哈',
     '丹',
     '尼',
     '扎',
     '胡',
     '埃',
     '索',
     '库',
     '纳',
     '吉',
     '莫',
     '帕',
     '锋',
     '米',
     '贝',
     '耶',
     '冈',
     '玻',
     '乌',
     '布',
     '苏',
     '念',
     '案',
     '罚',
     '较',
     '战',
     '略',
     '均',
     '贸',
     '拓',
     '5',
     '份',
     '去',
     '阅',
     '室',
     '刊',
     '晚',
     '智',
     '藏',
     '突',
     '破',
     '借',
     '架',
     '办',
     '沃',
     '盟',
     '昨',
     '约',
     '南',
     '举',
     '空',
     '军',
     '演',
     '示',
     '欢',
     '迎',
     '帮',
     '助',
     '7',
     '叫',
     '迈',
     '菲',
     '查',
     '奋',
     '剂',
     '通',
     '未',
     '勇',
     '曲',
     '绕',
     '桥',
     '绝',
     '《',
     '嫂',
     '》',
     '警',
     '魂',
     '片',
     '获',
     '房',
     '石',
     '香',
     '港',
     '朝',
     '蓬',
     '勃',
     '拼',
     '搏',
     '斗',
     '神',
     '写',
     '2',
     '春',
     '季',
     '招',
     '兵',
     '募',
     '既',
     '食',
     '预',
     '止',
     '癌',
     '症',
     '城',
     '引',
     '项',
     '懈',
     '液',
     '尾',
     '9',
     '％',
     '氢',
     '减',
     '污',
     '染',
     '双',
     '网',
     '抽',
     '封',
     '差',
     '亟',
     '待',
     '单',
     '麦',
     '果',
     '∶',
     '松',
     '赢',
     '测',
     '析',
     '迷',
     '叶',
     '钦',
     '岁',
     '刻',
     '哲',
     '思',
     '虽',
     '担',
     '负',
     '领',
     '责',
     '专',
     '却',
     '爸',
     '劲',
     '抗',
     '艰',
     '聘',
     '仍',
     '治',
     '洋',
     '尊',
     '庄',
     '志',
     '回',
     '忆',
     '淳',
     '朴',
     '报',
     '届',
     '张',
     '君',
     '秋',
     '剧',
     '角',
     '艺',
     '校',
     '坚',
     '质',
     '围',
     '侧',
     '缓',
     '财',
     '状',
     '聚',
     '渠',
     '逐',
     '靠',
     '优',
     '征',
     '稿',
     '截',
     '句',
     '晤',
     '纠',
     '纷',
     '朋',
     '坏',
     '它',
     '促',
     '岗',
     '标',
     '织',
     '践',
     '邓',
     '按',
     '署',
     '挥',
     '核',
     '●',
     '承',
     '键',
     '街',
     '巷',
     '横',
     '幅',
     '悬',
     '画',
     '头',
     '欣',
     '慰',
     ...]




```python
def get_label_list(path_list):
    label_set = set()
    label_list = list()
    for path in path_list:
        with open(path,'r',encoding='utf-8') as f:
            for line in f:
                if len(line.strip()) == 0:
                    continue
                if line[2:].strip() not in label_set:
                    label_set.add(line[2:].strip())
                    label_list.append(line[2:].strip())
    return label_list

def save_label(path,label_list):
    output = ''.join([label + '\n' for label in label_list])
    with open(path,'w', encoding='utf-8') as f:
        f.write(output)
        
label_list = get_label_list(['./datasets/example.train','./datasets/example.dev','./datasets/example.test'])
save_label('./datasets/label.txt',label_list)
```


```python
label_list
```




    ['O', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG']



#### 加载数据

分别获取vocab 和label与id的映射


```python
def get_string2id(path):    string2id = {}    id2string = []    with open(path,'r',encoding='utf-8') as f:        for line in f:             string2id[line.strip()] = len(string2id)            id2string.append(line.strip())    return id2string,string2idid2label,label2id = get_string2id("./datasets/label.txt")id2vocab,vocab2id = get_string2id("./datasets/vocab.txt")
```


```python
id2label
```




    ['O', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG']




```python
label2id
```




    {'O': 0,
     'B-LOC': 1,
     'I-LOC': 2,
     'B-PER': 3,
     'I-PER': 4,
     'B-ORG': 5,
     'I-ORG': 6}




```python
id2vocab
```




    ['海',
     '钓',
     '比',
     '赛',
     '地',
     '点',
     '在',
     '厦',
     '门',
     '与',
     '金',
     '之',
     '间',
     '的',
     '域',
     '。',
     '这',
     '座',
     '依',
     '山',
     '傍',
     '水',
     '博',
     '物',
     '馆',
     '由',
     '国',
     '内',
     '一',
     '流',
     '设',
     '计',
     '师',
     '主',
     '持',
     '，',
     '整',
     '个',
     '建',
     '筑',
     '群',
     '精',
     '美',
     '而',
     '恢',
     '宏',
     '但',
     '作',
     '为',
     '共',
     '产',
     '党',
     '员',
     '、',
     '人',
     '民',
     '公',
     '仆',
     '应',
     '当',
     '胸',
     '怀',
     '宽',
     '阔',
     '真',
     '正',
     '做',
     '到',
     '“',
     '先',
     '天',
     '下',
     '忧',
     '后',
     '乐',
     '”',
     '淡',
     '化',
     '名',
     '利',
     '得',
     '失',
     '和',
     '宠',
     '辱',
     '悲',
     '喜',
     '把',
     '改',
     '革',
     '大',
     '业',
     '摆',
     '首',
     '位',
     '样',
     '才',
     '能',
     '超',
     '越',
     '自',
     '我',
     '脱',
     '世',
     '俗',
     '有',
     '所',
     '发',
     '达',
     '家',
     '急',
     '救',
     '保',
     '险',
     '十',
     '分',
     '普',
     '及',
     '已',
     '成',
     '社',
     '会',
     '障',
     '体',
     '系',
     '重',
     '要',
     '组',
     '部',
     '日',
     '俄',
     '两',
     '政',
     '局',
     '都',
     '充',
     '满',
     '变',
     '数',
     '尽',
     '管',
     '关',
     '目',
     '前',
     '是',
     '历',
     '史',
     '最',
     '佳',
     '时',
     '期',
     '其',
     '脆',
     '弱',
     '性',
     '不',
     '言',
     '明',
     '克',
     '马',
     '尔',
     '女',
     '儿',
     '让',
     '娜',
     '今',
     '年',
     '读',
     '五',
     '级',
     '她',
     '班',
     '上',
     '3',
     '0',
     '多',
     '同',
     '学',
     '该',
     '委',
     '1',
     '长',
     '参',
     '加',
     '步',
     '行',
     '男',
     '轻',
     '也',
     '中',
     '沙',
     '特',
     '队',
     '教',
     '练',
     '佩',
     '雷',
     '拉',
     '：',
     '支',
     '想',
     '胜',
     '因',
     '此',
     '出',
     '了',
     '努',
     '力',
     '种',
     '混',
     '乱',
     '面',
     '导',
     '致',
     '些',
     '使',
     '用',
     '者',
     '合',
     '法',
     '权',
     '益',
     '难',
     '以',
     '维',
     '护',
     '鲁',
     '宾',
     '确',
     '指',
     '对',
     '府',
     '控',
     '完',
     '全',
     '没',
     '事',
     '实',
     '根',
     '据',
     '向',
     '转',
     '敏',
     '感',
     '技',
     '术',
     '相',
     '总',
     '白',
     '于',
     '；',
     '众',
     '议',
     '院',
     '令',
     '非',
     '常',
     '望',
     '将',
     '商',
     '卫',
     '星',
     '受',
     '威',
     '胁',
     '竞',
     '争',
     '损',
     '害',
     '育',
     '场',
     '每',
     '早',
     '6',
     '至',
     '8',
     '免',
     '费',
     '开',
     '放',
     '游',
     '泳',
     '等',
     '则',
     '增',
     '综',
     '服',
     '务',
     '延',
     '采',
     '取',
     '灵',
     '活',
     '收',
     '再',
     '看',
     '容',
     '图',
     '文',
     '并',
     '茂',
     '简',
     '短',
     '字',
     '准',
     '反',
     '映',
     '六',
     '族',
     '风',
     '土',
     '情',
     '传',
     '统',
     '各',
     '讲',
     '很',
     '哥',
     '伦',
     '亚',
     '号',
     '航',
     '飞',
     '机',
     '宇',
     '边',
     '进',
     '验',
     '继',
     '续',
     '抢',
     '修',
     '故',
     '二',
     '氧',
     '碳',
     '清',
     '除',
     '装',
     '置',
     '从',
     '剥',
     '削',
     '阶',
     '劳',
     '动',
     '生',
     '率',
     '低',
     '况',
     '占',
     '限',
     '剩',
     '余',
     '品',
     '足',
     '豪',
     '华',
     '需',
     '量',
     '扩',
     '现',
     '资',
     '条',
     '件',
     '榨',
     '价',
     '值',
     '供',
     '身',
     '求',
     '外',
     '又',
     '本',
     '新',
     '雇',
     '佣',
     '私',
     '来',
     '料',
     '集',
     '代',
     '表',
     '澳',
     '别',
     '区',
     '筹',
     '备',
     '第',
     '次',
     '午',
     '北',
     '京',
     '堂',
     '幕',
     '副',
     '理',
     '任',
     '钱',
     '琛',
     '词',
     '工',
     '经',
     '启',
     '临',
     '紧',
     '迫',
     '们',
     '道',
     '远',
     '希',
     '齐',
     '心',
     '协',
     '平',
     '稳',
     '过',
     '渡',
     '顺',
     '交',
     '接',
     '贡',
     '献',
     '济',
     '程',
     '界',
     '深',
     '信',
     '观',
     '必',
     '须',
     '微',
     '基',
     '础',
     '病',
     '好',
     '颈',
     '背',
     '躯',
     '干',
     '殖',
     '器',
     '可',
     '见',
     '龄',
     '市',
     '柔',
     '县',
     '试',
     '遍',
     '觉',
     '四',
     '节',
     '课',
     '饥',
     '饿',
     '消',
     '川',
     '省',
     '江',
     '油',
     '丰',
     '选',
     '豆',
     '奶',
     '复',
     '营',
     '养',
     '素',
     '贫',
     '血',
     '降',
     '百',
     '照',
     '只',
     '．',
     '4',
     '宗',
     '旨',
     '决',
     '定',
     '奉',
     '甘',
     '愿',
     '吃',
     '亏',
     '苦',
     '享',
     '困',
     '危',
     '留',
     '给',
     '己',
     '方',
     '便',
     '安',
     '初',
     '央',
     '形',
     '势',
     '快',
     '速',
     '策',
     '立',
     '研',
     '究',
     '派',
     '就',
     '提',
     '许',
     '富',
     '意',
     '味',
     '论',
     '话',
     '题',
     '书',
     '记',
     '粟',
     '光',
     '断',
     '他',
     '亲',
     '兄',
     '弟',
     '签',
     '！',
     '熟',
     '悉',
     '运',
     '士',
     '说',
     '贷',
     '款',
     '旦',
     '被',
     '推',
     '迟',
     '几',
     '月',
     '甚',
     '更',
     '考',
     '虑',
     '伍',
     '义',
     '气',
     '原',
     '惠',
     '象',
     '估',
     '像',
     '疤',
     '痕',
     '笨',
     '拙',
     '手',
     '针',
     '线',
     '周',
     '恩',
     '那',
     '送',
     '株',
     '万',
     '古',
     '青',
     '友',
     '谊',
     '红',
     '杉',
     '吧',
     '巴',
     '谈',
     '问',
     '印',
     '声',
     '宣',
     '称',
     '何',
     '三',
     '介',
     '入',
     '久',
     '赴',
     '西',
     '老',
     '访',
     '广',
     '职',
     '积',
     '极',
     '企',
     '监',
     '督',
     '如',
     '居',
     '子',
     '倘',
     '若',
     '客',
     '环',
     '境',
     '钝',
     '迅',
     '判',
     '陷',
     '处',
     '碰',
     '壁',
     '然',
     '热',
     '解',
     '寻',
     '找',
     '联',
     '邦',
     '州',
     '予',
     '适',
     '具',
     '骤',
     '吸',
     '七',
     '团',
     '另',
     '龙',
     '口',
     '科',
     '投',
     '视',
     '息',
     '创',
     '跳',
     '跃',
     '式',
     '展',
     '强',
     '调',
     '高',
     '培',
     '训',
     '认',
     '识',
     '密',
     '结',
     '小',
     '九',
     '升',
     '或',
     '段',
     '少',
     '懂',
     '习',
     '互',
     '贵',
     '贱',
     '请',
     '注',
     '语',
     '构',
     '偏',
     '孝',
     '父',
     '母',
     '始',
     '票',
     '否',
     '制',
     '还',
     '缺',
     '乏',
     '际',
     '电',
     '影',
     '摄',
     '录',
     '音',
     '剪',
     '辑',
     '诸',
     '趋',
     '激',
     '烈',
     '造',
     '奇',
     '夺',
     '起',
     '直',
     '追',
     '医',
     '药',
     '李',
     '珍',
     '闻',
     '屡',
     '仕',
     '寄',
     '托',
     '八',
     '股',
     '兴',
     '趣',
     '酷',
     '爱',
     '召',
     '吴',
     '英',
     '司',
     '董',
     '德',
     '·',
     '葛',
     '夫',
     '邀',
     '席',
     '车',
     '闲',
     '防',
     '施',
     '配',
     '套',
     '存',
     '鹅',
     '洲',
     '源',
     '终',
     '连',
     '串',
     '井',
     '序',
     '顾',
     '犯',
     '罪',
     '讳',
     '审',
     '死',
     '刑',
     '笔',
     '融',
     '农',
     '假',
     '币',
     '知',
     '巧',
     '律',
     '规',
     '村',
     '秩',
     '『',
     '范',
     '茅',
     '迹',
     '览',
     '』',
     '磁',
     '球',
     '孩',
     '格',
     '散',
     '着',
     '独',
     '魅',
     '莱',
     '坞',
     '千',
     '模',
     '翻',
     '版',
     '？',
     '燃',
     '汽',
     '仅',
     '守',
     '—',
     '路',
     '易',
     '斯',
     '切',
     '迪',
     '阿',
     '塞',
     '瓦',
     '萨',
     '卡',
     '里',
     '罗',
     '弗',
     '哈',
     '丹',
     '尼',
     '扎',
     '胡',
     '埃',
     '索',
     '库',
     '纳',
     '吉',
     '莫',
     '帕',
     '锋',
     '米',
     '贝',
     '耶',
     '冈',
     '玻',
     '乌',
     '布',
     '苏',
     '念',
     '案',
     '罚',
     '较',
     '战',
     '略',
     '均',
     '贸',
     '拓',
     '5',
     '份',
     '去',
     '阅',
     '室',
     '刊',
     '晚',
     '智',
     '藏',
     '突',
     '破',
     '借',
     '架',
     '办',
     '沃',
     '盟',
     '昨',
     '约',
     '南',
     '举',
     '空',
     '军',
     '演',
     '示',
     '欢',
     '迎',
     '帮',
     '助',
     '7',
     '叫',
     '迈',
     '菲',
     '查',
     '奋',
     '剂',
     '通',
     '未',
     '勇',
     '曲',
     '绕',
     '桥',
     '绝',
     '《',
     '嫂',
     '》',
     '警',
     '魂',
     '片',
     '获',
     '房',
     '石',
     '香',
     '港',
     '朝',
     '蓬',
     '勃',
     '拼',
     '搏',
     '斗',
     '神',
     '写',
     '2',
     '春',
     '季',
     '招',
     '兵',
     '募',
     '既',
     '食',
     '预',
     '止',
     '癌',
     '症',
     '城',
     '引',
     '项',
     '懈',
     '液',
     '尾',
     '9',
     '％',
     '氢',
     '减',
     '污',
     '染',
     '双',
     '网',
     '抽',
     '封',
     '差',
     '亟',
     '待',
     '单',
     '麦',
     '果',
     '∶',
     '松',
     '赢',
     '测',
     '析',
     '迷',
     '叶',
     '钦',
     '岁',
     '刻',
     '哲',
     '思',
     '虽',
     '担',
     '负',
     '领',
     '责',
     '专',
     '却',
     '爸',
     '劲',
     '抗',
     '艰',
     '聘',
     '仍',
     '治',
     '洋',
     '尊',
     '庄',
     '志',
     '回',
     '忆',
     '淳',
     '朴',
     '报',
     '届',
     '张',
     '君',
     '秋',
     '剧',
     '角',
     '艺',
     '校',
     '坚',
     '质',
     '围',
     '侧',
     '缓',
     '财',
     '状',
     '聚',
     '渠',
     '逐',
     '靠',
     '优',
     '征',
     '稿',
     '截',
     '句',
     '晤',
     '纠',
     '纷',
     '朋',
     '坏',
     '它',
     '促',
     '岗',
     '标',
     '织',
     '践',
     '邓',
     '按',
     '署',
     '挥',
     '核',
     '●',
     '承',
     '键',
     '街',
     '巷',
     '横',
     '幅',
     '悬',
     '画',
     '头',
     '欣',
     '慰',
     ...]




```python
vocab2id
```




    {'海': 0,
     '钓': 1,
     '比': 2,
     '赛': 3,
     '地': 4,
     '点': 5,
     '在': 6,
     '厦': 7,
     '门': 8,
     '与': 9,
     '金': 10,
     '之': 11,
     '间': 12,
     '的': 13,
     '域': 14,
     '。': 15,
     '这': 16,
     '座': 17,
     '依': 18,
     '山': 19,
     '傍': 20,
     '水': 21,
     '博': 22,
     '物': 23,
     '馆': 24,
     '由': 25,
     '国': 26,
     '内': 27,
     '一': 28,
     '流': 29,
     '设': 30,
     '计': 31,
     '师': 32,
     '主': 33,
     '持': 34,
     '，': 35,
     '整': 36,
     '个': 37,
     '建': 38,
     '筑': 39,
     '群': 40,
     '精': 41,
     '美': 42,
     '而': 43,
     '恢': 44,
     '宏': 45,
     '但': 46,
     '作': 47,
     '为': 48,
     '共': 49,
     '产': 50,
     '党': 51,
     '员': 52,
     '、': 53,
     '人': 54,
     '民': 55,
     '公': 56,
     '仆': 57,
     '应': 58,
     '当': 59,
     '胸': 60,
     '怀': 61,
     '宽': 62,
     '阔': 63,
     '真': 64,
     '正': 65,
     '做': 66,
     '到': 67,
     '“': 68,
     '先': 69,
     '天': 70,
     '下': 71,
     '忧': 72,
     '后': 73,
     '乐': 74,
     '”': 75,
     '淡': 76,
     '化': 77,
     '名': 78,
     '利': 79,
     '得': 80,
     '失': 81,
     '和': 82,
     '宠': 83,
     '辱': 84,
     '悲': 85,
     '喜': 86,
     '把': 87,
     '改': 88,
     '革': 89,
     '大': 90,
     '业': 91,
     '摆': 92,
     '首': 93,
     '位': 94,
     '样': 95,
     '才': 96,
     '能': 97,
     '超': 98,
     '越': 99,
     '自': 100,
     '我': 101,
     '脱': 102,
     '世': 103,
     '俗': 104,
     '有': 105,
     '所': 106,
     '发': 107,
     '达': 108,
     '家': 109,
     '急': 110,
     '救': 111,
     '保': 112,
     '险': 113,
     '十': 114,
     '分': 115,
     '普': 116,
     '及': 117,
     '已': 118,
     '成': 119,
     '社': 120,
     '会': 121,
     '障': 122,
     '体': 123,
     '系': 124,
     '重': 125,
     '要': 126,
     '组': 127,
     '部': 128,
     '日': 129,
     '俄': 130,
     '两': 131,
     '政': 132,
     '局': 133,
     '都': 134,
     '充': 135,
     '满': 136,
     '变': 137,
     '数': 138,
     '尽': 139,
     '管': 140,
     '关': 141,
     '目': 142,
     '前': 143,
     '是': 144,
     '历': 145,
     '史': 146,
     '最': 147,
     '佳': 148,
     '时': 149,
     '期': 150,
     '其': 151,
     '脆': 152,
     '弱': 153,
     '性': 154,
     '不': 155,
     '言': 156,
     '明': 157,
     '克': 158,
     '马': 159,
     '尔': 160,
     '女': 161,
     '儿': 162,
     '让': 163,
     '娜': 164,
     '今': 165,
     '年': 166,
     '读': 167,
     '五': 168,
     '级': 169,
     '她': 170,
     '班': 171,
     '上': 172,
     '3': 173,
     '0': 174,
     '多': 175,
     '同': 176,
     '学': 177,
     '该': 178,
     '委': 179,
     '1': 180,
     '长': 181,
     '参': 182,
     '加': 183,
     '步': 184,
     '行': 185,
     '男': 186,
     '轻': 187,
     '也': 188,
     '中': 189,
     '沙': 190,
     '特': 191,
     '队': 192,
     '教': 193,
     '练': 194,
     '佩': 195,
     '雷': 196,
     '拉': 197,
     '：': 198,
     '支': 199,
     '想': 200,
     '胜': 201,
     '因': 202,
     '此': 203,
     '出': 204,
     '了': 205,
     '努': 206,
     '力': 207,
     '种': 208,
     '混': 209,
     '乱': 210,
     '面': 211,
     '导': 212,
     '致': 213,
     '些': 214,
     '使': 215,
     '用': 216,
     '者': 217,
     '合': 218,
     '法': 219,
     '权': 220,
     '益': 221,
     '难': 222,
     '以': 223,
     '维': 224,
     '护': 225,
     '鲁': 226,
     '宾': 227,
     '确': 228,
     '指': 229,
     '对': 230,
     '府': 231,
     '控': 232,
     '完': 233,
     '全': 234,
     '没': 235,
     '事': 236,
     '实': 237,
     '根': 238,
     '据': 239,
     '向': 240,
     '转': 241,
     '敏': 242,
     '感': 243,
     '技': 244,
     '术': 245,
     '相': 246,
     '总': 247,
     '白': 248,
     '于': 249,
     '；': 250,
     '众': 251,
     '议': 252,
     '院': 253,
     '令': 254,
     '非': 255,
     '常': 256,
     '望': 257,
     '将': 258,
     '商': 259,
     '卫': 260,
     '星': 261,
     '受': 262,
     '威': 263,
     '胁': 264,
     '竞': 265,
     '争': 266,
     '损': 267,
     '害': 268,
     '育': 269,
     '场': 270,
     '每': 271,
     '早': 272,
     '6': 273,
     '至': 274,
     '8': 275,
     '免': 276,
     '费': 277,
     '开': 278,
     '放': 279,
     '游': 280,
     '泳': 281,
     '等': 282,
     '则': 283,
     '增': 284,
     '综': 285,
     '服': 286,
     '务': 287,
     '延': 288,
     '采': 289,
     '取': 290,
     '灵': 291,
     '活': 292,
     '收': 293,
     '再': 294,
     '看': 295,
     '容': 296,
     '图': 297,
     '文': 298,
     '并': 299,
     '茂': 300,
     '简': 301,
     '短': 302,
     '字': 303,
     '准': 304,
     '反': 305,
     '映': 306,
     '六': 307,
     '族': 308,
     '风': 309,
     '土': 310,
     '情': 311,
     '传': 312,
     '统': 313,
     '各': 314,
     '讲': 315,
     '很': 316,
     '哥': 317,
     '伦': 318,
     '亚': 319,
     '号': 320,
     '航': 321,
     '飞': 322,
     '机': 323,
     '宇': 324,
     '边': 325,
     '进': 326,
     '验': 327,
     '继': 328,
     '续': 329,
     '抢': 330,
     '修': 331,
     '故': 332,
     '二': 333,
     '氧': 334,
     '碳': 335,
     '清': 336,
     '除': 337,
     '装': 338,
     '置': 339,
     '从': 340,
     '剥': 341,
     '削': 342,
     '阶': 343,
     '劳': 344,
     '动': 345,
     '生': 346,
     '率': 347,
     '低': 348,
     '况': 349,
     '占': 350,
     '限': 351,
     '剩': 352,
     '余': 353,
     '品': 354,
     '足': 355,
     '豪': 356,
     '华': 357,
     '需': 358,
     '量': 359,
     '扩': 360,
     '现': 361,
     '资': 362,
     '条': 363,
     '件': 364,
     '榨': 365,
     '价': 366,
     '值': 367,
     '供': 368,
     '身': 369,
     '求': 370,
     '外': 371,
     '又': 372,
     '本': 373,
     '新': 374,
     '雇': 375,
     '佣': 376,
     '私': 377,
     '来': 378,
     '料': 379,
     '集': 380,
     '代': 381,
     '表': 382,
     '澳': 383,
     '别': 384,
     '区': 385,
     '筹': 386,
     '备': 387,
     '第': 388,
     '次': 389,
     '午': 390,
     '北': 391,
     '京': 392,
     '堂': 393,
     '幕': 394,
     '副': 395,
     '理': 396,
     '任': 397,
     '钱': 398,
     '琛': 399,
     '词': 400,
     '工': 401,
     '经': 402,
     '启': 403,
     '临': 404,
     '紧': 405,
     '迫': 406,
     '们': 407,
     '道': 408,
     '远': 409,
     '希': 410,
     '齐': 411,
     '心': 412,
     '协': 413,
     '平': 414,
     '稳': 415,
     '过': 416,
     '渡': 417,
     '顺': 418,
     '交': 419,
     '接': 420,
     '贡': 421,
     '献': 422,
     '济': 423,
     '程': 424,
     '界': 425,
     '深': 426,
     '信': 427,
     '观': 428,
     '必': 429,
     '须': 430,
     '微': 431,
     '基': 432,
     '础': 433,
     '病': 434,
     '好': 435,
     '颈': 436,
     '背': 437,
     '躯': 438,
     '干': 439,
     '殖': 440,
     '器': 441,
     '可': 442,
     '见': 443,
     '龄': 444,
     '市': 445,
     '柔': 446,
     '县': 447,
     '试': 448,
     '遍': 449,
     '觉': 450,
     '四': 451,
     '节': 452,
     '课': 453,
     '饥': 454,
     '饿': 455,
     '消': 456,
     '川': 457,
     '省': 458,
     '江': 459,
     '油': 460,
     '丰': 461,
     '选': 462,
     '豆': 463,
     '奶': 464,
     '复': 465,
     '营': 466,
     '养': 467,
     '素': 468,
     '贫': 469,
     '血': 470,
     '降': 471,
     '百': 472,
     '照': 473,
     '只': 474,
     '．': 475,
     '4': 476,
     '宗': 477,
     '旨': 478,
     '决': 479,
     '定': 480,
     '奉': 481,
     '甘': 482,
     '愿': 483,
     '吃': 484,
     '亏': 485,
     '苦': 486,
     '享': 487,
     '困': 488,
     '危': 489,
     '留': 490,
     '给': 491,
     '己': 492,
     '方': 493,
     '便': 494,
     '安': 495,
     '初': 496,
     '央': 497,
     '形': 498,
     '势': 499,
     '快': 500,
     '速': 501,
     '策': 502,
     '立': 503,
     '研': 504,
     '究': 505,
     '派': 506,
     '就': 507,
     '提': 508,
     '许': 509,
     '富': 510,
     '意': 511,
     '味': 512,
     '论': 513,
     '话': 514,
     '题': 515,
     '书': 516,
     '记': 517,
     '粟': 518,
     '光': 519,
     '断': 520,
     '他': 521,
     '亲': 522,
     '兄': 523,
     '弟': 524,
     '签': 525,
     '！': 526,
     '熟': 527,
     '悉': 528,
     '运': 529,
     '士': 530,
     '说': 531,
     '贷': 532,
     '款': 533,
     '旦': 534,
     '被': 535,
     '推': 536,
     '迟': 537,
     '几': 538,
     '月': 539,
     '甚': 540,
     '更': 541,
     '考': 542,
     '虑': 543,
     '伍': 544,
     '义': 545,
     '气': 546,
     '原': 547,
     '惠': 548,
     '象': 549,
     '估': 550,
     '像': 551,
     '疤': 552,
     '痕': 553,
     '笨': 554,
     '拙': 555,
     '手': 556,
     '针': 557,
     '线': 558,
     '周': 559,
     '恩': 560,
     '那': 561,
     '送': 562,
     '株': 563,
     '万': 564,
     '古': 565,
     '青': 566,
     '友': 567,
     '谊': 568,
     '红': 569,
     '杉': 570,
     '吧': 571,
     '巴': 572,
     '谈': 573,
     '问': 574,
     '印': 575,
     '声': 576,
     '宣': 577,
     '称': 578,
     '何': 579,
     '三': 580,
     '介': 581,
     '入': 582,
     '久': 583,
     '赴': 584,
     '西': 585,
     '老': 586,
     '访': 587,
     '广': 588,
     '职': 589,
     '积': 590,
     '极': 591,
     '企': 592,
     '监': 593,
     '督': 594,
     '如': 595,
     '居': 596,
     '子': 597,
     '倘': 598,
     '若': 599,
     '客': 600,
     '环': 601,
     '境': 602,
     '钝': 603,
     '迅': 604,
     '判': 605,
     '陷': 606,
     '处': 607,
     '碰': 608,
     '壁': 609,
     '然': 610,
     '热': 611,
     '解': 612,
     '寻': 613,
     '找': 614,
     '联': 615,
     '邦': 616,
     '州': 617,
     '予': 618,
     '适': 619,
     '具': 620,
     '骤': 621,
     '吸': 622,
     '七': 623,
     '团': 624,
     '另': 625,
     '龙': 626,
     '口': 627,
     '科': 628,
     '投': 629,
     '视': 630,
     '息': 631,
     '创': 632,
     '跳': 633,
     '跃': 634,
     '式': 635,
     '展': 636,
     '强': 637,
     '调': 638,
     '高': 639,
     '培': 640,
     '训': 641,
     '认': 642,
     '识': 643,
     '密': 644,
     '结': 645,
     '小': 646,
     '九': 647,
     '升': 648,
     '或': 649,
     '段': 650,
     '少': 651,
     '懂': 652,
     '习': 653,
     '互': 654,
     '贵': 655,
     '贱': 656,
     '请': 657,
     '注': 658,
     '语': 659,
     '构': 660,
     '偏': 661,
     '孝': 662,
     '父': 663,
     '母': 664,
     '始': 665,
     '票': 666,
     '否': 667,
     '制': 668,
     '还': 669,
     '缺': 670,
     '乏': 671,
     '际': 672,
     '电': 673,
     '影': 674,
     '摄': 675,
     '录': 676,
     '音': 677,
     '剪': 678,
     '辑': 679,
     '诸': 680,
     '趋': 681,
     '激': 682,
     '烈': 683,
     '造': 684,
     '奇': 685,
     '夺': 686,
     '起': 687,
     '直': 688,
     '追': 689,
     '医': 690,
     '药': 691,
     '李': 692,
     '珍': 693,
     '闻': 694,
     '屡': 695,
     '仕': 696,
     '寄': 697,
     '托': 698,
     '八': 699,
     '股': 700,
     '兴': 701,
     '趣': 702,
     '酷': 703,
     '爱': 704,
     '召': 705,
     '吴': 706,
     '英': 707,
     '司': 708,
     '董': 709,
     '德': 710,
     '·': 711,
     '葛': 712,
     '夫': 713,
     '邀': 714,
     '席': 715,
     '车': 716,
     '闲': 717,
     '防': 718,
     '施': 719,
     '配': 720,
     '套': 721,
     '存': 722,
     '鹅': 723,
     '洲': 724,
     '源': 725,
     '终': 726,
     '连': 727,
     '串': 728,
     '井': 729,
     '序': 730,
     '顾': 731,
     '犯': 732,
     '罪': 733,
     '讳': 734,
     '审': 735,
     '死': 736,
     '刑': 737,
     '笔': 738,
     '融': 739,
     '农': 740,
     '假': 741,
     '币': 742,
     '知': 743,
     '巧': 744,
     '律': 745,
     '规': 746,
     '村': 747,
     '秩': 748,
     '『': 749,
     '范': 750,
     '茅': 751,
     '迹': 752,
     '览': 753,
     '』': 754,
     '磁': 755,
     '球': 756,
     '孩': 757,
     '格': 758,
     '散': 759,
     '着': 760,
     '独': 761,
     '魅': 762,
     '莱': 763,
     '坞': 764,
     '千': 765,
     '模': 766,
     '翻': 767,
     '版': 768,
     '？': 769,
     '燃': 770,
     '汽': 771,
     '仅': 772,
     '守': 773,
     '—': 774,
     '路': 775,
     '易': 776,
     '斯': 777,
     '切': 778,
     '迪': 779,
     '阿': 780,
     '塞': 781,
     '瓦': 782,
     '萨': 783,
     '卡': 784,
     '里': 785,
     '罗': 786,
     '弗': 787,
     '哈': 788,
     '丹': 789,
     '尼': 790,
     '扎': 791,
     '胡': 792,
     '埃': 793,
     '索': 794,
     '库': 795,
     '纳': 796,
     '吉': 797,
     '莫': 798,
     '帕': 799,
     '锋': 800,
     '米': 801,
     '贝': 802,
     '耶': 803,
     '冈': 804,
     '玻': 805,
     '乌': 806,
     '布': 807,
     '苏': 808,
     '念': 809,
     '案': 810,
     '罚': 811,
     '较': 812,
     '战': 813,
     '略': 814,
     '均': 815,
     '贸': 816,
     '拓': 817,
     '5': 818,
     '份': 819,
     '去': 820,
     '阅': 821,
     '室': 822,
     '刊': 823,
     '晚': 824,
     '智': 825,
     '藏': 826,
     '突': 827,
     '破': 828,
     '借': 829,
     '架': 830,
     '办': 831,
     '沃': 832,
     '盟': 833,
     '昨': 834,
     '约': 835,
     '南': 836,
     '举': 837,
     '空': 838,
     '军': 839,
     '演': 840,
     '示': 841,
     '欢': 842,
     '迎': 843,
     '帮': 844,
     '助': 845,
     '7': 846,
     '叫': 847,
     '迈': 848,
     '菲': 849,
     '查': 850,
     '奋': 851,
     '剂': 852,
     '通': 853,
     '未': 854,
     '勇': 855,
     '曲': 856,
     '绕': 857,
     '桥': 858,
     '绝': 859,
     '《': 860,
     '嫂': 861,
     '》': 862,
     '警': 863,
     '魂': 864,
     '片': 865,
     '获': 866,
     '房': 867,
     '石': 868,
     '香': 869,
     '港': 870,
     '朝': 871,
     '蓬': 872,
     '勃': 873,
     '拼': 874,
     '搏': 875,
     '斗': 876,
     '神': 877,
     '写': 878,
     '2': 879,
     '春': 880,
     '季': 881,
     '招': 882,
     '兵': 883,
     '募': 884,
     '既': 885,
     '食': 886,
     '预': 887,
     '止': 888,
     '癌': 889,
     '症': 890,
     '城': 891,
     '引': 892,
     '项': 893,
     '懈': 894,
     '液': 895,
     '尾': 896,
     '9': 897,
     '％': 898,
     '氢': 899,
     '减': 900,
     '污': 901,
     '染': 902,
     '双': 903,
     '网': 904,
     '抽': 905,
     '封': 906,
     '差': 907,
     '亟': 908,
     '待': 909,
     '单': 910,
     '麦': 911,
     '果': 912,
     '∶': 913,
     '松': 914,
     '赢': 915,
     '测': 916,
     '析': 917,
     '迷': 918,
     '叶': 919,
     '钦': 920,
     '岁': 921,
     '刻': 922,
     '哲': 923,
     '思': 924,
     '虽': 925,
     '担': 926,
     '负': 927,
     '领': 928,
     '责': 929,
     '专': 930,
     '却': 931,
     '爸': 932,
     '劲': 933,
     '抗': 934,
     '艰': 935,
     '聘': 936,
     '仍': 937,
     '治': 938,
     '洋': 939,
     '尊': 940,
     '庄': 941,
     '志': 942,
     '回': 943,
     '忆': 944,
     '淳': 945,
     '朴': 946,
     '报': 947,
     '届': 948,
     '张': 949,
     '君': 950,
     '秋': 951,
     '剧': 952,
     '角': 953,
     '艺': 954,
     '校': 955,
     '坚': 956,
     '质': 957,
     '围': 958,
     '侧': 959,
     '缓': 960,
     '财': 961,
     '状': 962,
     '聚': 963,
     '渠': 964,
     '逐': 965,
     '靠': 966,
     '优': 967,
     '征': 968,
     '稿': 969,
     '截': 970,
     '句': 971,
     '晤': 972,
     '纠': 973,
     '纷': 974,
     '朋': 975,
     '坏': 976,
     '它': 977,
     '促': 978,
     '岗': 979,
     '标': 980,
     '织': 981,
     '践': 982,
     '邓': 983,
     '按': 984,
     '署': 985,
     '挥': 986,
     '核': 987,
     '●': 988,
     '承': 989,
     '键': 990,
     '街': 991,
     '巷': 992,
     '横': 993,
     '幅': 994,
     '悬': 995,
     '画': 996,
     '头': 997,
     '欣': 998,
     '慰': 999,
     ...}



#### 获取每个句子的长度，并得到最大长度


```python
def get_sequence_len(path):
    sequence_len = list()
    tmp_len = 0
    with open(path,'r',encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if len(line) == 0 :
#                 print(tmp_len)
                sequence_len.append(tmp_len)
                tmp_len = 0
            else:
                tmp_len +=1
    return np.array(sequence_len)
```


```python
train_sequence_len= get_sequence_len('./datasets/example.train')dev_sequence_len= get_sequence_len('./datasets/example.dev')test_sequence_len= get_sequence_len('./datasets/example.test')
```


```python
train_sequence_len,dev_sequence_len,test_sequence_len
```




    (array([18, 35, 88, ..., 53, 65, 41]), array([69, 35, 54, ..., 46, 38, 29]), array([40, 39, 43, ..., 42, 29, 52]))




```python
max_length = max(max(train_sequence_len),max(dev_sequence_len),max(test_sequence_len))
```


```python
max_length
```




    577



#### 读取数据，对不足最大长度的句子进行padding


```python
def read_data(path,vocab2id,label2id,max_len):    data_x = list()    data_y = list()    tmp_text = list()    tmp_label = list()        with open(path,'r', encoding='utf-8') as f:        for line in f:            line = line.strip()            if len(line) ==0:                # 数据集中以空行作为句子分隔符，说明前一个句子已经结束，tmp_text为vocab（id），tmp_label为label(id)                # padding 至max_len                tmp_text += [len(vocab2id)] * (max_len - len(tmp_text))                tmp_label += [0] * (max_len - len(tmp_label))                                # 保存已经结束的句子并清空tmp                data_x.append(tmp_text)                data_y.append(tmp_label)                tmp_text = list()                tmp_label = list()            else:                # 将字符和标签转换为相应的id放入tmp                # 根据数据格式，line[0]为vocab,line[1]为空格                # line[2:]为label                tmp_text.append(vocab2id[line[0]])                tmp_label.append(label2id[line[2:]])    print('{} include sequences {}'.format(path,len(data_x)))    return np.array(data_x), np.array(data_y)
```


```python
train_text,train_label = read_data("./datasets/example.train",vocab2id,label2id,max_length)dev_text,dev_label = read_data("./datasets/example.dev",vocab2id,label2id,max_length)test_text,test_label = read_data("./datasets/example.test",vocab2id,label2id,max_length)
```

    ./datasets/example.train include sequences 20864./datasets/example.dev include sequences 2318./datasets/example.test include sequences 4636



```python
train_text[0],train_label[0]
```




    (array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,
               8,   11,   12,   13,    0,   14,   15, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465, 4465,
            4465, 4465, 4465, 4465, 4465]),
     array([0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0]))



#### 讲数据通过tf.data.Dataset加载

Dataset可以看作是相同类型“元素”的有序列表，可以通过Iterator对其中的元素进行读取，通过初始化不同的initializer实现读取不同的数据


```python
train_dataset = tf.compat.v1.data.Dataset.from_tensor_slices((train_text,train_label,train_sequence_len))
train_dataset = train_dataset.batch(1)  #指定读取数据时的batch_size
```


```python
dev_dataset = tf.compat.v1.data.Dataset.from_tensor_slices((dev_text,dev_label,dev_sequence_len))dev_dataset = dev_dataset.batch(1)  #指定读取数据时的batch_size
```


```python
test_dataset = tf.compat.v1.data.Dataset.from_tensor_slices((test_text,test_label,test_sequence_len))test_dataset = test_dataset.batch(1)  #指定读取数据时的batch_size
```


```python
iterator = tf.compat.v1.data.Iterator.from_structure(train_dataset.output_types,                                                     train_dataset.output_shapes)
```

    WARNING:tensorflow:From <ipython-input-24-248b28ede763>:1: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.compat.v1.data.get_output_types(dataset)`.
    WARNING:tensorflow:From <ipython-input-24-248b28ede763>:2: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.compat.v1.data.get_output_shapes(dataset)`.



```python
#初始化不同的initializer，从X,Y,S读取的数据不同
train_initializer = iterator.make_initializer(train_dataset)
dev_initializer = iterator.make_initializer(dev_dataset)
test_initializer = iterator.make_initializer(test_dataset)
X,Y,S = iterator.get_next() #运行时每次读取一个batch_size的text,label和sequence_len
```

    WARNING:tensorflow:From c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py:336: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.compat.v1.data.get_output_types(iterator)`.
    WARNING:tensorflow:From c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py:337: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.compat.v1.data.get_output_shapes(iterator)`.
    WARNING:tensorflow:From c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py:339: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.compat.v1.data.get_output_classes(iterator)`.


### 命名实体识别模型构建

- 输入文本经过预处理后得到字符的id，
- 首先经过Embedding层得到字符向量，
- 然后经过BiLSTM层得到句子表示，
- 再经过CRF计算每个字符的标签得分，
- 对于每个字符，选取得分最高的标签作为该字符的类别。


```python
embedding_size = 5
hidden_dim = 4
```


```python
# embedding层
with tf.compat.v1.variable_scope('embedding'): #随机生成字符向量
    embedding = tf.compat.v1.Variable(
        tf.compat.v1.random_normal([len(vocab2id)+1, embedding_size]),
        dtype= tf.compat.v1.float32
    )
inputs = tf.compat.v1.nn.embedding_lookup(embedding,X) #将X中vocab的id转换为对应的字符向量
```


```python
# BiLSTM隐藏层
# 前向lstm
lstm_fw_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_dim,reuse = tf.compat.v1.AUTO_REUSE)
# 后向lstm
lstm_bw_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_dim,reuse = tf.compat.v1.AUTO_REUSE)
# 组合成双向lstm
(output,output_states) = tf.compat.v1.nn.bidirectional_dynamic_rnn(
    lstm_fw_cell,
    lstm_bw_cell,
    inputs,
    S,
    dtype=tf.compat.v1.float32
)
#list -> tensor [batch_size,max_len,hidden_dim * 2]
output = tf.stack(output,axis=1)
# -> [batch_size * max_len,hidden_dim * 2]
output = tf.reshape(output,[-1,hidden_dim *2])
```

    WARNING:tensorflow:From <ipython-input-28-215bd7d8a5e9>:12: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API
    WARNING:tensorflow:From c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\tensorflow\python\ops\rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use `keras.layers.RNN(cell)`, which is equivalent to this API
    WARNING:tensorflow:From c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\keras\layers\legacy_rnn\rnn_cell_impl.py:979: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
    Instructions for updating:
    Call initializer instance with the dtype argument instead of passing it to the constructor


    c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\keras\layers\legacy_rnn\rnn_cell_impl.py:901: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.
      warnings.warn("`tf.nn.rnn_cell.LSTMCell` is deprecated and will be "
    c:\users\ysilhouette\documents\pyenv\py_365_tf_2\lib\site-packages\keras\engine\base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
      warnings.warn('`layer.add_variable` is deprecated and '



```python
# BiLSTM输出层
with tf.compat.v1.variable_scope('output'):
    W = tf.compat.v1.Variable(
        tf.compat.v1.truncated_normal(
            shape=[hidden_dim *2 , len(label2id)],
            mean=0,
            stddev=0.1),
        dtype=tf.compat.v1.float32
    )
    B = tf.compat.v1.Variable(
        np.zeros(len(label2id)),
        dtype=tf.compat.v1.float32)
    #[batch_size * max_len,label_size]
    Y_out = tf.matmul(output,W) + B 
scores = tf.reshape(Y_out,[-1, max_length,len(label2id)])  #[batch_size,max_len,label_size]
```


```python
scores
```




    <tf.Tensor 'reshape_1:0' shape="(None," 577, 7) dtype="float32">




```python
Y
```




    <tf.Tensor 'iteratorgetnext:1' shape="(None," 577) dtype="int32">




```python
S
```




    <tf.Tensor 'iteratorgetnext:2' shape="(None,)" dtype="int32">




```python
# CRF层
with tf.compat.v1.variable_scope('crf',reuse=tf.compat.v1.AUTO_REUSE):
    trans_matrix = tf.compat.v1.get_variable('transition', [len(label2id),len(label2id)])
log_likelihood,_ =tfa.text.crf_log_likelihood(scores,Y,S,trans_matrix)
loss=tf.reduce_mean(-log_likelihood)
# optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)
# train_op =optimizer.minimize(loss)#梯度下降法，学习率0.1
train_op = tf.compat.v1.train.GradientDescentOptimizer(0.1).minimize(loss)#梯度下降法，学习率0.1
saver = tf.compat.v1.train.Saver() #用来保存和加载模型
min_Loss = int(1e8) #维护当前最小的Loss,初始化为一个较大的值
```

### 命名实体识别模型训练

- 通过训练集训练，并保存当前loss值最小的模型。
- 构建的模型抽象出来是一个包含计算和变量的图。定义变量时不会进行运算，也没有具体的值，变量在Session中进行初始化后才有值。
- 在Session中通过run可以执行图，进行相应的计算或取出对应的值。通过训练改变变量的值，最终可以得到模型需要的参数。
- 变量的值仅在一个Session中有效，通过saver保存变量后，可以在新的Session中通过saver加载变量，就无需再重新训练模型。


```python
sess = tf.compat.v1.Session() # 创建一个Session
sess.run(tf.compat.v1.global_variables_initializer()) # 初始化所有变量
for epoch in range(100):
    sess.run(train_initializer) #初始化训练集和initializer
    for step in range(10): #使用了10个batch的数据
        tf_train_scores,tf_trans_matrix,Loss,_ = sess.run(
            [scores,trans_matrix,loss,train_op]
        ) # 执行训练过程
        
    if Loss <min_Loss: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 saver.save(sess,'model my_model') # 保存当前loss最小的model min_loss="Loss" print("** epoch",epoch+1,"loss",loss) ``` ** epoch loss 58.72455 53.927124 50.51535 49.02472 50.43283 50.08667 46.792816 44.00418 42.740723 38.633057 34.638123 30.238342 31.892944 28.726074 27.086182 25.640747 24.253967 23.045715 22.389526 21.917236 21.551575 21.257202 21.010925 20.801147 20.622559 20.46753 20.330994 20.209717 20.09906 20.002686 19.913574 19.83197 19.756409 19.690308 19.62616 19.563904 19.511597 19.460754 19.409851 19.362366 19.32257 19.281921 19.241943 19.204895 19.17163 19.14154 19.10846 19.077393 19.050842 19.02295 18.999817 18.973328 18.948425 18.927612 18.903809 18.88678 18.864624 18.844116 18.824219 18.807495 18.79132 18.773804 18.757812 18.743103 18.72815 18.71283 18.69812 18.68335 18.670227 18.656555 18.646484 18.633667 18.621033 18.611145 18.603027 18.591614 18.577148 18.568176 18.558899 18.550049 18.5401 18.531128 18.52301 18.51294 18.504944 18.495544 18.486633 18.481384 18.473328 18.466125 18.459839 18.45227 18.444885 18.435303 18.432373 18.423462 18.418274 18.411194 18.403381 18.400818 ### 命名实体识别模型评估 #### 计算验证集f1_score并查看验证集预测结果。 - **精确率pression、召回率recall和f1_score** 对于结果仅包括“正负”的二分类问题， “预测为正，实际也为正”被称为真阳性，“预测为正，实际为负”被称为假阳性，“预测为负，实际为正”被称为假阴性， 精确率定义为$\frac {真阳性}{真阳性+假阳性}$，召回率定义为$\frac{真阳性}{真阳性+假阴性}$，f1_score可以看作是精确率和召回率的一种加权平均，定义为$ 2*\frac{精确率*召回率}{精确率+召回率}$。 对于多分类问题 既可以分别计算出每一类的精确率、召回率和f1_score 计算某一类时可认为该类为“正”，其他所有类为“负”，以此得到每一类的真阳性、假阳性和假阴性数量），再计算出f1_score的平均值，这种f1_score被称为macro-f1。 也可以计算出总的精确率和召回率 得到每一类的真阳性、假阳性和假阴性数量，分别求和得到总的数量），再计算出f1_score，这种f1_score被称为micro-f1 当预测结果未出现错误类别（即未包含在类别集合的类别）时，这种方式计算得到的精确率、召回率和f1_score都相等，值为$\frac{预测正确数量}{预测总数} $。 ```python sess.run(dev_initializer) 初始化验证集的 initializer tf_dev_scores,tf_trans_matrix,tf_dev_text,tf_dev_label,tf_dev_sequence_len="sess.run(" [scores,trans_matrix,x,y,s] ) viterbi_decode每次处理一个句子，这里因为我们设定的batch_size为1，可以直接通过reshape将该维去掉 同时去掉句子的padding部分 tf_dev_sequence_len="int(tf_dev_sequence_len)" tf_dev_text="tf_dev_text.reshape(max_length)[:tf_dev_sequence_len]" tf_dev_scores="tf_dev_scores.reshape(max_length,len(label2id))[:tf_dev_sequence_len]" tf_dev_label="tf_dev_label.reshape(max_length)[:tf_dev_sequence_len]" viterbi_decode传入的scores参数的shape应为[sequence_length,label_size],trans_matix应为[label_size，label_size] viterbi_sequence,_="tfa.text.viterbi_decode(tf_dev_scores,tf_trans_matrix)" correct_labels="np.sum(np.equal(viterbi_sequence,tf_dev_label))" 预测正确的标签数 print("f1_score:{}".format(correct_labels tf_dev_sequence_len)) print(viterbi_sequence) f1_score:0.463768115942029 [0, 0, 1, 2, 5, 6, 0] 命名实体识别模型预测 ##### 加载模型 sess="tf.compat.v1.Session()" saver.restore(sess,"model my_model") #加载模型参数 sess.run(test_initializer) 初始化测试集的initializer tf_test_scores,tf_test_matrix,tf_test_text,tf_test_label,tf_test_sequence_len="sess.run(" tf_test_sequence_len="int(tf_test_sequence_len)" tf_test_text="tf_test_text.reshape(max_length)[:tf_test_sequence_len]" tf_test_scores="tf_test_scores.reshape(max_length,len(label2id))[:tf_test_sequence_len]" tf_test_label="tf_test_label.reshape(max_length)[:tf_test_sequence_len]" example_test_text="[id2vocab[vocab]" for vocab in tf_test_text] id转换为vocab example_prediction_label="[id2label[label]" label viterbi_sequence] id转换为label print([id2vocab[tf_test_text[index]] + '' id2label[viterbi_sequence[index]] index range(len(tf_test_text))]) sess.close() info:tensorflow:restoring parameters from model my_model ['我i-org', '们i-org', '变i-org', '而o', '以o', '书o', '会o', '友o', '，o', '结o', '缘o', '把o', '欧o', '美o', '、o', '港o', '台o', '流b-org', '行i-org', '的i-org', '食i-org', '品i-org', '类i-org', '图i-org', '谱i-org', '、i-org', '画i-org', '册i-org', '工i-org', '具i-org', '书i-org', '汇i-org', '集i-org', '一i-org', '堂i-org', '。o'] ['我', '们', '变', '而', '以', '书', '会', '友', '，', '结', '缘', '把', '欧', '美', '、', '港', '台', '流', '行', '的', '食', '品', '类', '图', '谱', '画', '册', '工', '具', '汇', '集', '一', '堂', '。'] ['i-org', 'i-org', 'o', 'b-org', 'o'] 结果展示 exam_test_text="['我','们','变','而','以','书','会','友','，','以','书','结','缘','，'," '把','欧','美','、','港','台','流','行','的','食','品','类','图','谱','、', '画','册','、','工','具','书','汇','集','一','堂','。'] exam_prediction_label="['O','O','O','O','O','O','O','O','O','O','O','O','O','O'," 'o','b-loc','b-loc','o','b-loc','b-loc','o','o','o','o','o','o','o','o','o', 'o','o','o','o','o','o','o','o','o','o','o'] def get_named_entity(text,labels): named_entity_set="set()" #去重，同一个实体只记录一次 named_entity_list="list()" cur_type is_entity="False" tmp_named_entity range(len(text)): if or label[:2]="=" 'b-': 可能是前一个实体的结束 true: 一个实体的结束 not named_entity_set: named_entity_set.add(tmp_named_entity) named_entity_list.append({'text':tmp_named_entity,'type':cur_type}) 'o': continue 若为'b-',说明此时是回一个实体的开头 else: 'i-' return print(named_entity_list) [{'text': 'type': 'loc'}, {'text': 'loc'}] --- about me 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </min_Loss:></tf.Tensor></tf.Tensor></tf.Tensor></ipython-input-28-215bd7d8a5e9></ipython-input-24-248b28ede763></ipython-input-24-248b28ede763>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>NLP</tag>
        <tag>LSTM</tag>
        <tag>NER</tag>
        <tag>CRF</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>如何评估推荐系统的健康状况？</title>
    <url>/2020/02/05/%E5%A6%82%E4%BD%95%E8%AF%84%E7%BA%A7%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%81%A5%E5%BA%B7%E7%8A%B6%E5%86%B5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 如何评估推荐系统的健康状况？

## 推荐系统的常见指标

推荐系统的评价指标，要从解决实际问题的角度来思考。

好的推荐系统，不仅要保证自身系统的健壮度，好要满足服务平台、用户等多方面的需求。

### 用户角度

更方便更快速的发现自己喜欢的产品

#### 精准度

更多的为用户主观感受，评估的是推荐的物品是不是用户喜欢的

#### 惊喜度

推荐的物品让用户有心情跳动的惊喜感觉，比如发现多年前的记忆、耳目一新的内容、用户听过的但是不知名字的音乐，看过片段却不知道名字的电影、知道功能却不知道名字的商品

此类推荐和用户兴趣不一定相似，但是却给用户带来意外之喜，超出用户的预期

#### 新颖性

推荐用户没有接触过的东西，不一定是用户最喜欢的，但可以提升用户的探索欲望，从而获得更完整的用户兴趣

#### 多样性

推荐的更多的品类，可以挖掘用户潜在的兴趣点，拓展用户的兴趣范围来提升用户的推荐体验

### 平台角度

平台方为用户提供物品或信息。

不同平台的获利方式不同，比如有的靠会员模式、有的通过商品、大部分则通过广告

对多数平台来说商业目标是最重要的目标之一

#### 内容满意度

由于业务场景不同，内容满意的指标也会随之变化，主要是通过用户对产品的不同行为来衡量

- 资讯
  - 阅读-----阅读时长----分享评论
- 电商
  - 点击----浏览-----收藏购物车----购买-----好评----复购
- 短视频
  - 播放----播放时长-----分享、点赞、评论-----关注 ------跟拍
- 音乐
  - 播放-----播放时长-----分享、收藏、评论

#### 场景转化率

转化率指标更为直观，给用推荐内容，是希望用户对推荐的内容有所行动，比如点击行为、点赞行为

##### pv点击率（点击量/pv）

粗略的衡量转化效果，但如果少数用户贡献大量点击时，容易覆盖该指标的真实性

##### uv点击率（点击量/uv）

可记录用户在一个完整周期内的点击效果，不会因用户重复浏览某个内容而受影响

##### 曝光点击率（点击量/曝光次数）

更适合长页面、信息流等需要上拉、下拉翻页的产品，曝光次数随用户刷屏次数增加而变大，真实记录每一屏的转化效果

##### uv转化率（转化次数/点击量）

衡量用户转化情况，用户从一个场景转化到另一个场景去，用来评估用户的宽度

##### 人均点击次数（点击量/点击uv数）

每个用户的点击次数，可用来评价用户的深度



## 推荐系统的离线评估

推荐系统自身的评估，推荐系统从接受数据到产生推荐结果，再根据推荐结果的影响重新修正自身。

推荐算法训练--（离线评价）----模型上线----（在线评价）---推荐内容---（在线评价）------行为日志收集分析--->>迭代优化推荐算法

### 准确度

准确度评估主要是评估推荐算法模型的好坏，为选择合适的模型提供决策支持。

数据划分为训练集、测试集；

使用训练集学习训练模型；

使用测试集来衡量误差以及评估准确度；

根据推荐系统目的不同，准确度的衡量也不同：

#### 分类问题

比如点击、不点击； 喜欢、不喜欢；

- 精确度precision：推荐结果有多少是用户喜欢的

- 召回率recall：用户喜欢的产品，有多少个是推荐系统推荐的

通常希望两个指标都越大越好，但实际需平衡两个指标都关系，所以长远F-指标来作为平衡二者关系的计算方式

#### 评分预测

对产品惊醒评分，电影评分

- 均方根差RMSE
- MAE 平均绝对误差

用于描述与测评分与产品真实评分的差距

#### 排序问题

分类、评分只是把推荐产品晒出来，不包含展示顺序，而如果要把用户最可能消费的产品放在前面，则需要排序指标。

- AUC，随机挑选一个正样本，一个负样本，正样本排在负样本前的概率

  当算法能更好的把证样本排在前边的时候，就是一个好的算法模型

- MAP，推荐列表中和用户相关的产品在推荐列表中的位置得分，越靠前分越大

- MRR，按照跟用户相关的产品的排名的倒数作为精确度

- NDGC，推荐列表中每一个产品评分值的累加；同时考虑每个产品位置，最后进行归一化，在同一标准上评价不同的推荐列表

### 覆盖率

推荐出的产品占总产品的比例

### 多样性

用户兴趣不是一成不变的，统一用户的兴趣会受到时间段、心情、节日等多种因素影响。推荐时要尽量推荐更多的品类。

可通过对产品聚类，在推荐列表中插入不同类别产品类提高多样性

### 时效性

不同产品的时效性不同，比如电商产品时效性不是很高，但新闻、资讯、短视频之类的产品，就需要很高的时效性。

针对不同的产品，甚至产品下不同的类目，设置不同的时效性，也是提高推荐质量的途径之一。

## 推荐系统的在线评估

在线评估分为两个阶段：用户触发推荐服务、用户产生行为

### 触发推荐服务

#### 稳定性

系统稳定性对于用户体验至关重要，怎样针对不同场景持续稳定的提供推荐服务，是推荐系统的最重要的指标之一，提升推荐效果也要在保证系统稳定的前提下去进行优化

#### 高并发

当某个时间节点大量用户访问，或用户规模急速扩大时，系统能否扛住高并发的压力，也是个很大的挑战。

了解接口的高并发能力，做好充分的压力测试

#### 响应时间

衡量用户能否及时得到推荐反馈，response time 受多种因素影响，比如网络情况、服务器、数据库等，可通过监控请求的时长，接口监控，数据监控，做好报警措施

### 产生行为

用户产生行为，通过收集分析用户的行为日志进行相关指标的评价

**示例：**

1、推荐的曝光点击转化率

2、推荐的点击访问转化率

3、推荐的访问购买转化率

**示例：**

1、推荐曝光

2、点击 （曝光点击转化率）

3、阅读（点击阅读转化率）

4、分享（阅读分享转化率）

## AB测试

在线评估通常会结合AB测试

### 什么是AB测试

AB测试本质为对照实验，来源于医学的双盲测试，通过给两组病人不同的药物，来确定药物是否有效。

AB测试：将不同的算法/策略，在同一时间维度，分别在两组或者多组 组成成分相同的用户群体内容进行线上测试，分析各组用户的行为指标，得到可以真正全流量上线的算法和策略

### AB测试常见做法

**==核心：控制变量、分流测试、规则统一==**

#### 控制变量

AB测试必须是单变量的，变量太多会产生干扰，很难找到各个变量对结果的影响程度。

#### 分流测试

AB测试作为对照试验，自然要有 试验组和对照组。通常会对用户进行分流

- 用户ID
- 设备号
- 浏览器cookie
- 约定生成的伪随机数，0，1大数定律

#### 规则统一

在控制变量和分流测试的前提下，针对不同的流量，应制定相同的评价指标，才能得到准确的对比效果。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>推荐</category>
        <category>策略</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>推荐</tag>
        <tag>策略</tag>
      </tags>
  </entry>
  <entry>
    <title>常见描述性指标的python实现</title>
    <url>/2022/05/01/%E5%B8%B8%E8%A7%81%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1%E6%8C%87%E6%A0%87%E7%9A%84python%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 常见描述性指标的python实现

#### 集中趋势

##### 均值

$$
\mu=\frac{\displaystyle\sum\limits_{i=1}^N{X_i}}{N}
$$

##### 中位数

##### 众数

#### 离散程度

##### 极差

$$
R=\max{(X)}-\min{(X)}
$$

##### 方差

$$
\sigma^2=\frac{\displaystyle\sum\limits_{i=1}^N (X_i-\mu)^2}{N}
$$

##### 标准差

$$
\sigma =\sqrt{\sigma^2}
$$

##### 变异系数

$$
CV=\frac{\sigma}{\mu}
$$

#### 偏差程度

##### Z-分数

$$
Z_i=\frac{X_i-\mu}{\sigma}
$$

#### 相关程度

##### 协方差

$$
Cov(X,Y)=\frac{\displaystyle\sum\limits_{i=1}^N (X_i-\bar{X})(Y_i-\bar{Y})}{N}
$$

##### 相关系数

$$
r(X,Y)=\frac{Cov(X,Y)}{\sigma_X\sigma_Y}
$$

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/%E5%B8%B8%E8%A7%81%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1%E6%8C%87%E6%A0%87%E7%9A%84python%E5%AE%9E%E7%8E%B0.html" id="iframeid" frameborder="0" width="100%" height="1000">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>data analysis</category>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>pandas</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>学习如何为产品选择合适的推荐算法</title>
    <url>/2018/11/25/%E5%AD%A6%E4%B9%A0%E5%A6%82%E4%BD%95%E4%B8%BA%E4%BA%A7%E5%93%81%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 常见推荐机制/算法

#### 基础推荐机制

| **机制**           | **应用场景**                       | **原理概述**                                                 |
| ------------------ | ---------------------------------- | ------------------------------------------------------------ |
| 内容推荐           | 适用于冷启动                       |                                                              |
| 基于内容的协同过滤 | 数据量较大                         	|	 判断内容相似度，相似度高的内容；播放内容A的用户，也会对内容B感兴趣 |
| 基于用户的协同过滤 | 数据量较大，但数据量越大可信度越低 		| 把数据代入专门计算相似度的公式，获得不同用户（二者）口味的相似度；推测相似度高的用户，喜好的内容也类似，进而可以相互推荐 |
| 基于标签的推荐     | 适用于冷启动                       |                                                              |

- **协同过滤的风险**
  协同过滤技术在个性化推荐初期具有较好的效果，但随着产品结构、内容复杂度和用户人数的不断增加，协同过滤技术的缺点也一点一点的暴露出来了。

  - 稀疏性（sparity）
    大多数推荐系统中，每个用户涉及的信息量较为有限；用户数据最多不过评估到了百分分之一，造成评估矩阵数据相当稀疏，增加寻找相似用户集的难度，导致推荐效果大大降低
  - 扩展性（scalability）
	“最近邻居”算法的计算量虽则用户和项的增加而大大增加，对于百万之巨的数目，通常的算法将遭遇严重的扩展性问题
  - 精确性（accuracy）
	寻找相近用户来产生推荐集，在数据量较大的情况下，推荐的可信度也会降低



#### 经典算法

| 算法             | 应用机制         | 原理概述                                                     |
| ---------------- | ---------------- | ------------------------------------------------------------ |
| topN             | 基础算法         | 1、直接用List的sort方法进行排序处理 2、使用排序二叉树进行排序，然后取出前N名 3、使用最大堆排序，然后取出前N名 |
| 矩阵算法         | 基础算法         | 找到内容和内容之间相关性最高的，用topN的方式排序，就可以将内容相关性高的做推荐 |
| 内容关联算法     | 内容推荐         | 将item的基本属性、内容信息提取出来；抽出taglist，为每一个tag赋一个权重。不需要冷启动，时效高；但是对item需要解析，所以对音视频等不太友好；推出的内容缺乏惊喜，内容同质化严重 |
| 协同过滤算法     | 协同过滤         | 有惊喜，只依赖用户行为，不需要对内容完全解析；但是需要大量数据才能运转 |
| 神经网络矩阵分解 | 协同推荐基础算法 | 用户和内容之间自关联，用cf-nade建模为用户和内容评分，模型中可以用隐式反馈（动态指标）帮助克服评分稀疏的问题          【注：显示反馈-评分，评级；隐式反馈-操作行为等指标】 |
| slope one        | 基于内容协同过滤 | 通过评分之间的差值，推测另一个得分f(x) = x+b                 |
| 用户行为轨迹     |                  | 严格来说不算是一种算法，该逻辑的重点是依据单个用户的一条行为轨迹，对场景进行切分。 实现与场景匹配有助于提升推荐效果，能够提升用户的使用时长，以及用户活跃度 |

#### 混合合推荐算法：

没有哪种推荐技术敢说自己没有弊端, 往往一个好的推荐系统也不是只用一种推荐技术就解决问题, 往往都是相互结合来弥补彼此的不足, 常见的组合方式如下

1. 混合推荐技术: 同时使用多种推荐技术再加权取最优;
2. 切换推荐技术: 根据用户场景使用不同的推荐技术;
3. 特征组合推荐技术: 将一种推荐技术的输出作为特征放到另一个推荐技术当中;
4. 层叠推荐技术: 一个推荐模块过程中从另一个推荐模块中获取结果用于自己产出结果

综合所有的推荐策略和算法，大致可以分为以下常见的推荐策略：

1. 基于内容的推荐；
2. 协同过滤推荐；
3. 混合推荐；
4. 流行度推荐；
5. 其他更高级的；


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>推荐</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>推荐</tag>
      </tags>
  </entry>
  <entry>
    <title>常见的研究者认知偏误</title>
    <url>/2019/01/02/%E5%B8%B8%E8%A7%81%E7%9A%84%E7%A0%94%E7%A9%B6%E8%80%85%E8%AE%A4%E7%9F%A5%E5%81%8F%E8%AF%AF/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 常见的研究者认知偏误

**前言：**

认知偏误（Cognitive bias）是一种常见的现象，它是指当我们思考问题或做决策时，大脑会有一些固定的思维倾向。这个过程多是无意识的，有时也会带来正面作用，如帮助我们在纷繁复杂的环境中节省思考时间，更高效地做出决定但是在研究中，认知偏误易导致研究结果不准确，降低研究的价值。
我们都希望研究是客观、理性、反映真实情况的，了解常见的认知偏误可以帮助我们在工作中尽量规避它们，得出更准确的结论。
实际上每个人都会有认知偏误，包括用户研究者和用户。

今天我们就来说说研究者的常见认知偏误，下次有机会再谈谈用户的，敬请期待。



## 一、 确认偏误（Confirmation bias）


当人们本来就持有某种观点时，对这种观点的感知和注意度会被放大，会选择性地回忆或收集关于它的事例。人们对于自己原本就相信的观点会更容易接受，而把反面观点搁置在一旁。举个例子：有些人认为女司机不擅长开车，更容易造成事故，所以当新闻中的事故与女司机有关时，他们会觉得“果然如此”。而实际上男司机的事故率比女司机更高。

在用户研究中，当你的预设想法是用户对A设计的满意度比B设计更高时，在研究中你可能会更关注用户提到的A设计的优点、收集更多用户对于A设计的正面评价。当用户表示对A设计满意时，会觉得“果然是这样”。这种偏误会让你遗漏许多其它信息。





![img](https://cdn.nlark.com/yuque/0/2019/png/153571/1550218606789-da11792b-d68c-44c3-a328-6c98325dbba9.png)





## 二、 虚假一致性偏差（False consensus effect）


虚假一致性偏差是指人们很容易认为其他人跟自己有相同的想法，从而高估这些观点的普遍适用性。举个例子：有一种冷叫做“你妈觉得你冷”。妈妈感觉到了冬天的寒冷，担心我们也会冷，于是催促我们穿秋裤，但可能年轻人并没觉得冷。此时妈妈的想法就带有虚假一致性偏差。当年轻人吐槽父母朋友圈转的鸡汤文、养生文无用时，也是一种虚假一致性偏差。

在用户研究中，我们也很容易陷入虚假一致性偏差。比如，当你认为产品的某个方面比较好或者你对产品的某个方面不满意，可能会倾向于认为这也是许多其他用户的感受，但也许事实并非如此。在对海外产品做研究时尤其要注意这一点，研究者与用户的巨大文化背景差异可能会导致研究结果的严重失真。





![img](https://cdn.nlark.com/yuque/0/2019/png/153571/1550218606776-679c6dc9-fe1f-47c3-ac5c-84982fb5c03d.png)





## 三、 聚类错觉（Clustering Illusion） 

聚类错觉产生的原因是人们倾向于从随机事件中找出某种规律。举个例子：如果张三连着几次在群里抢红包都抢到最大份，他可能会觉得自己最近“手气特别旺”。这就是一种聚类错觉，人们试图将几次随机的结果联系起来，用某种规律进行解释。

在研究中，聚类错觉容易出现在小样本研究中，比如，我们在小样本中发现了被访者的某些共性，总结出某些规律，并期望它们在更大的群体中也适用，但这种共性可能只是源于随机，而非事实。我们应该谨慎对待在小样本研究中的发现，思考它们是否只是随机结果，最好用其它研究方法帮助验证或参考二手资料，避免出现聚类错觉。





![img](https://cdn.nlark.com/yuque/0/2019/png/153571/1550218606779-697362e9-ecb1-4e4e-a7a3-b6bce281fef1.png)





## 四、 知识的诅咒（Curse of knowledge）


培根说过，“知识就是力量”，它怎么会带来诅咒呢？知道的更多难道不好吗？知识的诅咒是指，人一旦知道了某件事，就没办法想象不知道的样子，也很难体会到不知者的感受。举个例子：

在某次考试之后的课堂上，
– 老师：“同学们，这是一道送分题啊，大家都做对了吧？只要先连一条辅助线，再……”
– 学生：“这是啥？这又是啥？这些都是啥？”

在用户研究中，知识的诅咒也会给我们带来许多困扰。比如，我们对自己的产品很熟悉，就很难想象新手用户是如何使用它的，使用感受如何。我们可能会惊讶地发现，即使在我们看起来操作十分简单的功能，新手用户使用起来也很吃力。再比如在设计问卷或者访谈脚本时，我们可能会不小心加入一些专业术语而不自知，让用户看的一头雾水。





![img](https://cdn.nlark.com/yuque/0/2019/png/153571/1550218606788-57f815ab-53a9-463c-8737-dd1b53dc7784.png)





***研究者的有些认知偏误还会直接影响到用户的行为和反应。***



## 五、 选择性偏差（Selection bias） 



选择性偏差是指过程或样本的非随机性导致结论的不准确。举个例子：假设张三想统计人们的工资水平，他拿着一份个税纳税名单开始了调查，结果发现，所有人的工资都在5000以上。这个结果当然是不准确的，因为5000是我国的个税起征点，工资超过5000的人才会出现在纳税名单上，张三的研究样本是有选择性偏差的，不能代表总体。

在用户研究中，选择性偏差不仅会出现在样本选择中，还可能会出现在研究设计中。比如在可用性测试中，我们设计了一系列的任务，研究结果自然就无法包含未选中的任务。而且这些任务也会让用户产生一种心理，既然它是设定好的任务，就一定是可以被完成的，他们也会耐心地多次尝试去完成任务，以期达成某种结果。当然我们也不会设置无法完成的任务。但在实际的使用情境中，用户并不知道哪些操作是有结果的，哪些没有，他们的行为和态度可能与可用性测试中不同。

## 六、 框架效应（Framing effect）


框架效应是指，对于同一个问题，当描述有所不同时，人们给出的选择也会有差异。举个例子：假如说“XX疾病的存活率达93%”，人们可能会觉得这种疾病没有很严重；但如果说“XX疾病的致死率达7%”，那么人们可能会觉得很严重。在用户研究中，我们也要避免框架效应带来的影响，不要设置引导性的问题，题目中不要用明显的正面或负面词汇，尽量用中立的语言描述。避免题目的描述干扰到用户的选择，而导致研究结果不准确。



## 七、 观察者期望效应（Observer-Expectancy Effect）


观察者期望效应是指，研究者有时可能会期望出现某种结果，他们无意识地操纵了试验过程，或者错误地解释实验结果，导致研究结果严重歪曲。一般来说，被观察者几乎无法不受观察行为的影响，当研究是针对人时，被试者会更容易感觉到研究者无意中透露的期望，从而做出相符的反应。

在用户研究中，研究者的表情、肢体语言等都可能会反映出自己所期待的结果，如果用户察觉到了这些，就可能做一些迎合研究者期望的反应。比如，如果研究者无意中透露出某个新功能是他们团队非常重视、投入巨大、报有很大期待的功能，用户可能会更倾向于对这个功能给出正向的评价，肯定该功能的市场前景。但这也许并非他真实的感觉。

**如何避免这些认知偏误呢？这里有一些建议：**
**1. 研究方案**：避免单一的研究方法和单一的样本渠道来源
多种研究方法的结果相互验证，多种样本渠道来源互做补充，帮助我们避免“聚类错觉”和“选择性偏差”，让我们的研究结果更准确。
**2. 研究准备期**：问卷试填、试访谈、预测试
找其他人进行试研究，帮我们在正式研究开始前发现问卷中是否含有引导性问题、专业术语、歧义用语等不便于用户理解的地方；访谈或测试中是否出现不适当的下意识行为等。避免因“知识的诅咒”、“框架效应”和“观察者期望效应”导致的研究结果不准确。
**3. 研究进行时**：多人合作研究、二手资料做参考、听取他人意见
多人共同参与研究和分析，有助于避免认知偏误。访谈时，每个研究员追问的点可能有所不同；走查评估时大家对问题的关注点也可能不一样。单个人的研究难免容易陷入“确认偏误”、“虚假一致性偏差”。综合大家的观点，会让研究结果更客观。
如果只能由单人完成研究，可以收集二手资料，阅读前人研究做参考。同时听取来自他人的意见，帮助拓展思路，包括用研同事和产品经理、设计师等非用研同事。
**4. 研究结束后**：复盘研究
研究结束后，反问自己，研究的过程是否客观？研究的结论是否可信？所有的结论都是有数据支撑、符合逻辑的吗？有哪些结论是带有偏误的吗？是否漏掉了一些很重要的结论？

是否与其他人的研究结果相似或相悖？相悖原因是什么？
下次研究将如何做改善?

***彩蛋：最后还有一个认知偏误介绍给大家。***



## 八、 偏见盲点（bias blind spot）



偏见盲点是指，我们都倾向于认为自己比别人更少受到认知偏误的影响。人们都有偏见盲点，更容易发现别人出现的认知偏误而忽略自己存在的认知偏误。举个例子：如果你看到这篇文章后觉得“这些都是别人容易遇到的，我可比他们客观多了”，那么你可能就陷入了偏见盲点。

**参考文献**：

1. Cognitive bias cheat sheet (https://betterhumans.coach.me/cognitive-bias-cheat-sheet-55a472476b18)
2. 20 cognitive biases that screw up your decisions
  (https://www.businessinsider.com.au/cognitive-biases-that-affect-decisions-2015-8)
3. 6 common cognitive biases UXers should know（https://medium.muz.li/6-common-cognitive-biases-uxers-should-know-750b8c7af1a8）
4. Cognitive biases in user research (https://blog.optimalworkshop.com/cognitive-biases-user-research)
5. Combating Bias in User Testing (https://blog.fullstory.com/combating-bias-in-user-testing/)
6. Don’t Let Your Brain Deceive You: Avoiding Bias In Your UX Feedback (https://www.smashingmagazine.com/2017/10/avoid-bias-ux-feedback/)
7. Overcoming bias in research and product design
  (https://medium.theuxblog.com/overcoming-bias-in-research-and-product-design-f35a0d92496d)
8. Overcoming Cognitive Bias in User Research (https://npr.design/overcoming-cognitive-bias-in-user-research-e4082f4506a)
9. User Research Bias: How It Hurts Your App And What You Can Do About It (https://usabilitygeek.com/user-research-bias/)

转载自 京东设计中心JDC 作者 @Sijia [原文地址](http://jdc.jd.com/archives/212946) 



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>小记</category>
      </categories>
      <tags>
        <tag>认知偏误</tag>
      </tags>
  </entry>
  <entry>
    <title>关于广告系统</title>
    <url>/2020/02/20/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F%E4%BA%A7%E5%93%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 关于广告系统

以把合适的内容推送给合适的受众为目的的商业交易过程，是一种最直接、透明的流量变现方式。

**广告平台提供流量分发的能力，同时提供广告创意，广告素材服务**进而服务于：

1、广告主：金主，有广告联盟和广告主两种形式

2、媒体：流量提供方

3、消费者：C端用户，广告和流量的使用者

![](广告系统产品/2.png)

### 广告系统模块

至少包含以下部分

#### 广告投放系统

承担广告内容管理和广告流量分发的功能，承前启后，是广告系统的核心部分

#### 商户后台系统

用于广告主和广告联盟自主接入的管理平台，主要包含：**广告需求承接 和广告效果数据、广告费用的展示**

#### 运营后台系统

广告平台方的运用后台，**主要用户广告审核、广告主管理和其他管理功能**

#### 广告素材设计系统

用于制作广告创意，根据广告位点要求支持不同尺寸、不同投放环境点创意设计

#### 数据统计系统

用户广告效果数据收集和分析

**各个系统模块的交互**

![](广告系统产品/1.png)

### 广告需求模型设计

把单个点广告需求称之为广告投放计划，广告需求是广告主的视角，其至少分为：

- 广告主
  - 广告点需求方，是广告效果和广告计费的统一收口方
  - 需要广告的投放目标，广告的投放时间、广告投放的定向和广告预算等内容进行配置

- 投放计划
  - 广告主名下往往有很多广告需求，将每个定制的广告需求称为投放计划

- 广告素材（创意）
  - 最小颗粒的广告素材（创意），每一个投放计划都可能包含多个广告素材的投放
  - 广告计费夜市根据广告素材的曝光、点击、展示时长等计费方式的数值进行计算的
  - banner横幅广告，文字链广告、视频广告、嵌入式社交广告

![](广告系统产品/3.png)

### 广告投放模型建立

广告系统需承接广告主的投放需求，并将大量的广告素材按照广告主偏好进行精准投放

![](广告系统产品/4.png)

#### 广告计费模型

##### CPA

cost per action，每次行为付费

##### CPM

cost per mile，每前次送达成本，互联网广告指千次曝光量的价格计费

##### CPT

cost per time，单位时长计费，是一种包断广告位的方式

##### CPC

cost per click , 每次点击的价格计费

##### CPS

### 广告投放流程

#### 广告投放计划

- 广告预算
- 投放定向
- 投放目标
- 计费方式

#### 投放流程

- 请求广告
  - 采用广告组件或者SDK等方式嵌入在广告位中，广告组件根据广告位的用户属性等信息，向广告投放系统请求广告资源
- 匹配广告位
  - 根据广告位不同，广告需要选择符合当前广告位投放目标的广告需求池
- 匹配投放计划
  - 将广告位的用户属性等信息与大数据标签进行匹配，获取用户画像标签。根据标签和广告投放计划的定向需求来进行匹配，并通过竞价选取对应的投放计划
- 匹配广告创意
  - 每个投放计划有多个素材，需要根据实时的广告效果来对广告素材进行评估，并选择转化率更高的广告素材进行投放
- 广告数据统计
  - 统计广告效果数据，如曝光量、点击量


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>广告产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>广告</tag>
      </tags>
  </entry>
  <entry>
    <title>态势感知与安全运营平台</title>
    <url>/2020/02/07/%E6%80%81%E5%8A%BF%E6%84%9F%E7%9F%A5%E4%B8%8E%E5%AE%89%E5%85%A8%E8%BF%90%E8%90%A5%E5%B9%B3%E5%8F%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 态势感知与安全运营平台

## 产品概述

针对各种网络安全数据进行分析处理，提供资产、危险、脆弱性的相关管理，并提供对危险的事前预警、事中发现、事后回溯功能，贯穿威胁的整个生命周期管理。

## 平台简介

### 产品组成

- 流量传感器
  - 采集网络中的流量数据，将原始的网络流量转化为安session方式记录的格式化流量日志，全流量日志会加密传输至分析平台存储用于后期分析
  - 内置流量检测引擎
    - web漏洞检测引擎
    - webshell 活动检测引擎
    - 网络入侵检测引擎
  - 常部署于需监听流量的网络节点旁，接受镜像流量
- 日志采集探针
  - 对网络内各业务应用系统、设备、服务器、终端等设备通过主动采集或被动接受等方式对日志进行采集和归一化处理，方便数据流后面的关联规则和数据分析快速使用
  - 兼具负责对内网资产进行扫描识别，收集资产数据
- 关联规则引擎
  - 负责对来自日志采集探针的大量日志信息进行实时流解析，并匹配关联规则，对异常行为产生关联告警
- 分析平台
  - 存储流量传感器和日志采集探针提交的流量日志、设备日志、系统日志
  - 分析平台底层对数据进行处理
- 文件威胁鉴定器
- 终端安全管理系统

### 产品架构



### 产品功能

#### 威胁管理



#### 资产管理



#### 拓扑管理



#### 漏洞管理



#### 日志搜索



#### 场景化分析



#### 工单



#### 调查分析



#### 知识库



#### 报表管理



#### 仪表展示



#### 态势感知



#### 级联管理



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>安全产品</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>安全产品</tag>
        <tag>运营平台</tag>
        <tag>平台产品</tag>
      </tags>
  </entry>
  <entry>
    <title>怎样进行产品提案？</title>
    <url>/2019/01/01/%E6%80%8E%E6%A0%B7%E8%BF%9B%E8%A1%8C%E4%BA%A7%E5%93%81%E6%8F%90%E6%A1%88%EF%BC%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 怎样进行产品提案？

### 1、产品的目的是什么？要解决什么问题？



### 2、 产品为谁解决问题？为什么他会有这样的问题？



### 3、解决这个问题，对公司有什么收益？



### 4、 现在市场上有哪些产品能解决这个问题？他们解决情况如何？



### 5、己方产品可以怎么解决这些问题？



### 6、为什么我们解决这个问题？ 有什么优势？



### 7、解决该问题，需要花费多少成本投入？



### 8、解决该问题 ，可能有什么风险？怎么规避和预防？



### 9、如果能验证这个产品能解决问题，未来如何规划解决更多问题？



### 10、第一版本产品方案的时间规划和上线方案是什么？


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>产品提案</category>
      </categories>
      <tags>
        <tag>用户体验</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐算法应该谨记的5个原则</title>
    <url>/2018/11/01/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E5%BA%94%E8%AF%A5%E8%B0%A8%E8%AE%B0%E7%9A%845%E4%B8%AA%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


#### 行业现象

- 资讯推荐算法

  ​	本意是帮人们找到可能感兴趣的更多内容

- 乱象

  ​	不管在专门的资讯推荐 App 还是社交媒体上，垃圾新闻、低俗资讯反而成为主力内容

- 原因

  ​	投机者们、垃圾内容的制造者们很快找到了推荐算法天然的缺陷，学会如何利用它来迎合人性的弱点，煽

  动情绪，刺激欲望

- 导致

  ​	推荐算法让垃圾内容的制造者占了上风，而真正的内容机构也不得不将自己的内容恶俗化，以迎合推荐

  算法。低俗内容越来越多，高品质内容越来越少。 

这不是算法的错，算法尽职尽责做了自己的工作，但算法的参数和控制指标需要重置，算法背后的人需要做出改变。 

### 推荐算法需谨记的5个原则

#### 真实性和准确性

​	人工干预，区分真假，将人工意见转为标签加入推荐算法内，监控和改进算法，放置算法被滥用。

#### 独立性

​	资讯推荐算法是为读者服务的，而不是为商业模式（营销推荐算法则偏向为商业模式），为广告主

​	资讯推荐算法容易让那些骗点击的标题党（clickbait）内容和广告凸显出来，正常的内容反而被打压；

​	目前网络内容最严重的问题——内容的权重，并不是根据内容是否对读者有益来判断的，而是为商业模型服

务的，让人们花更多时间沉浸在垃圾内容中，对这些公司的商业模型更有益。 

#### 公平和公正性

​	分歧和极端内容更受算法的青睐，也更容易引发读者的对立 ；

​	人工调整算法，呈现多角度不同的观点；

#### 人性

​	严格限制有害的内容被观看，及时调整推荐给平台上用户的内容 

#### 问责制

​	没有什么系统是完美的。

​	算法是互联网的基本组成，但算法并不是自己跑到服务器上的。是人创造了算法，所以人应该为算法的行

为负责任。 必须最小化假内容的传播，从而让高品质内容成为主流。 


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐算法理论与实践（一）</title>
    <url>/2018/12/20/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 电影推荐系统原理

##### 基于内容的推荐系统

![1550153370732](C:\Users\YSILHO~1\AppData\Local\Temp\1550153370732.png)

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>推荐算法</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>Machine Learning</tag>
        <tag>推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统常用算法</title>
    <url>/2018/09/01/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95%E3%80%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 一、基于内容推荐

基于内容的推荐（Content-based Recommendation）是信息过滤技术的延续与发展，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机 器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象 的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。 基于内容的用户资料是需要有用户的历史数据，用户资料模型可能随着用户的偏好改变而发生变化。

基于内容推荐方法的优点是：

1）不需要其它用户的数据，没有冷开始问题和稀疏问题。

2）能为具有特殊兴趣爱好的用户进行推荐。

3）能推荐新的或不是很流行的项目，没有新项目问题。

4）通过列出推荐项目的内容特征，可以解释为什么推荐那些项目。

5）已有比较好的技术，如关于分类学习方面的技术已相当成熟。

缺点是要求内容能容易抽取成有意义的特征，要求特征内容有良好的结构性，并且用户的口味必须能够用内容特征形式来表达，不能显式地得到其它用户的判断情况。

## 二、协同过滤推荐

协同过滤推荐（Collaborative Filtering Recommendation）技术是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后 利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。协同过滤最大优 点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。

协同过滤是基于这样的假设：为一用户找到他真正感兴趣的内容的好方法是首先找到与此用户有相似兴趣的其他用户，然后将他们感兴趣的内容推荐给此用户。其基本 思想非常易于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择。协同过滤正是把这一思想运用到电子商务推荐系统中来，基于其他用户对某一内 容的评价来向目标用户进行推荐。

基于协同过滤的推荐系统可以说是从用户的角度来进行相应推荐的，而且是自动的，即用户获得的推荐是系统从购买模式或浏览行为等隐式获得的，不需要用户努力地找到适合自己兴趣的推荐信息，如填写一些调查表格等。

和基于内容的过滤方法相比，协同过滤具有如下的优点：

1） 能够过滤难以进行机器自动内容分析的信息，如艺术品，音乐等。

2） 共享其他人的经验，避免了内容分析的不完全和不精确，并且能够基于一些复杂的，难以表述的概念（如信息质量、个人品味）进行过滤。

3） 有推荐新信息的能力。可以发现内容上完全不相似的信息，用户对推荐信息的内容事先是预料不到的。这也是协同过滤和基于内容的过滤一个较大的差别，基于内容的过滤推荐很多都是用户本来就熟悉的内容，而协同过滤可以发现用户潜在的但自己尚未发现的兴趣偏好。

4） 能够有效的使用其他相似用户的反馈信息，较少用户的反馈量，加快个性化学习的速度。
虽然协同过滤作为一种典型的推荐技术有其相当的应用，但协同过滤仍有许多的问题需要解决。最典型的问题有稀疏问题（Sparsity）和可扩展问题（Scalability）。

## 三、基于关联规则推荐

基于关联规则的推荐（Association Rule-based Recommendation）是以关联规则为基础，把已购商品作为规则头，规则体为推荐对象。关联规则挖掘可以发现不同商品在销售过程中的相关性，在零 售业中已经得到了成功的应用。管理规则就是在一个交易数据库中统计购买了商品集X的交易中有多大比例的交易同时购买了商品集Y，其直观的意义就是用户在购 买某些商品的时候有多大倾向去购买另外一些商品。比如购买牛奶的同时很多人会同时购买面包。

算法的第一步关联规则的发现最为关键且最耗时，是算法的瓶颈，但可以离线进行。其次，商品名称的同义性问题也是关联规则的一个难点。

## 四、基于效用推荐

基于效用的推荐（Utility-based Recommendation）是建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大 程度上是由系统所采用的效用函数决定的。基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性（Vendor Reliability）和产品的可得性（Product Availability）等考虑到效用计算中。

## 五、基于知识推荐

基于知识的推荐（Knowledge-based Recommendation）在某种程度是可以看成是一种推理（Inference）技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因 它们所用的功能知识不同而有明显区别。效用知识（Functional Knowledge）是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以 是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。

## 六、组合推荐

由于各种推荐方法都有优缺点，所以在实际中，组合推荐（Hybrid Recommendation）经常被采用。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法 去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通 过组合后要能避免或弥补各自推荐技术的弱点。

在组合方式上，有研究人员提出了七种组合思路：

1）加权（Weight）：加权多种推荐技术结果。

2）变换（Switch）：根据问题背景和实际情况或要求决定变换采用不同的推荐技术。

3）混合（Mixed）：同时采用多种推荐技术给出多种推荐结果为用户提供参考。

4）特征组合（Feature combination）：组合来自不同推荐数据源的特征被另一种推荐算法所采用。

5）层叠（Cascade）：先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。

6）特征扩充（Feature augmentation）：一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。

7）元级别（Meta-level）：用一种推荐方法产生的模型作为另一种推荐方法的输入。

## 七、主要推荐方法的对比

各种推荐方法都有其各自的优点和缺点，见表1。

![算法](http://image.woshipm.com/wp-files/2014/09/a87ff679a2f3e71d9181a67b7542122c3.png)


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建自然语言处理的开发环境</title>
    <url>/2019/03/01/%E6%90%AD%E5%BB%BA%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 自然语言处理开发环境介绍

- sublime

- vscode

- pycharm

- Anaconda3



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Natural Language Processing</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Natural Language Processing</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统-个性化内容分发</title>
    <url>/2020/02/08/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E4%B8%AA%E6%80%A7%E5%8C%96%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 什么是推荐系统？

**维基百科定义**

- 推荐系统是一种信息过滤系统，用语预测用户对物品的“评分”或“偏好”

**限定在电商购买决策过程的定义**

- 电商应用向客户提供商品信息和建议，帮助用户决定应该够买什么产品。

  ![img](https://pic3.zhimg.com/80/v2-f68d20fc587d680f178feedc2fb318d2_1440w.jpg)

- 这其中隐含了土建系统的2个重要的核心功能

  - 路径优化

    ![img](https://pic3.zhimg.com/80/v2-24981ed071de556fa72ef6106a42609a_1440w.jpg)

  - 兴趣发现

    ![img](https://pic2.zhimg.com/80/v2-d6494b2c04de2bff17231d5dfb4c3b61_1440w.jpg)

### 推荐概述

- 推荐目标：合适的才是最好的
- 实现手段：数据、算法、架构、
- 核心功能：链路优化、兴趣发现
- 评价：满意度（点击率，转化率，时长）、准确、覆盖率、多样性、新颖性、惊喜性、信任度、鲁棒性、实时性、商业目标
- 两过程：从学习到决策过程
- 核心问题：如何构建一个用户对商品的评价模型
- 宗旨：服务提供方和消费方双赢
- 演进：
- 与搜索的异同：推荐被动，搜索主动； 推荐不明确货找人， 搜索明确人找货

### 推荐的几大挑战

- 大数据，稀疏，长尾，噪音
- 用户行为模式的挖掘和利用（行为的复杂性）
- 冷启动（新用户/新商品）
- 多样性与精确性的两难困境
- 用户界面与用户体验（个性化体验的可解释性）

### 好的推荐产品

- 5W
  - when
  - where
  - who
  - what
  - why

![img](https://pic2.zhimg.com/80/v2-0acc89bd5a8812fcec86fc875f0df545_1440w.jpg)

![img](https://pic1.zhimg.com/80/v2-e0bc3333df76d907d3bb3ae39eab2f80_1440w.jpg)

![img](https://pic3.zhimg.com/80/v2-15462e7a78b08baef7862ed6b5717cb2_1440w.jpg)

![img](https://pic2.zhimg.com/80/v2-77e1b5a6b2f156ed7b130aaf84eb63ed_1440w.jpg)



## 推荐系统是怎么做到的？

### 上下文

- 当前定位
- 当前季节
- 用户年龄

### 用户画像

- 用户静态数据
- 用户动态数据

### 协同过滤

#### 基于用户

![img](https://pic2.zhimg.com/80/v2-61f42e1c94fe0092123ac7c9e5a2f079_1440w.jpg)

#### 基于内容

![img](https://pic4.zhimg.com/80/v2-f8308747d670f9c3d50e953c46977d1b_1440w.jpg)

#### 基于商品

![img](https://pic2.zhimg.com/80/v2-59276dea29eceb4c8b3267dd50ffb159_1440w.jpg)

#### 基于模型

![img](https://pic2.zhimg.com/80/v2-522b37b0343ff59d48c1091d0f1e299d_1440w.jpg)

#### 基于统计/知识

## 推荐系统的相似度评估

计算用户与用户， 商品与商品， 内容与内容的相似度

主要思想为，交集 / 并集

![img](https://pic1.zhimg.com/80/v2-027e7f8efad8f3576c557b3dec347ca8_1440w.jpg)

![img](https://pic2.zhimg.com/80/v2-529e00b279fc1b65af16c515836e45b9_1440w.jpg)

- 当交集与并集相等时，相似度为1
- 当交集为空时，相似度为 0

### 推荐的混合模型

#### 级联型

使用后一个推荐方法优化前一个

#### 特征递增

前一个做为后一个的输入

#### 特征组合

将来自不同推荐数据源的特征组合，然后由其他推荐技术使用

#### 元层次组合

将不同的推荐模型融合

#### 混合

将多种不同的推荐算法的结果混合在一起

#### 切换 

根据问题背景和实际情况采用不同的推荐技术

#### 加权融合

多种推荐类型的计算混合产生推荐

## 推荐系统的架构和模块

### 演进

![img](https://pic1.zhimg.com/80/v2-28e7d8a69370b9193b100c9dc594952c_1440w.jpg)

![img](https://pic4.zhimg.com/80/v2-262299acabf9486a52b3fee88b0475e3_1440w.jpg)

### 推荐系统架构

![img](https://pic3.zhimg.com/80/v2-1158150f45cea51bb628378b57c76282_1440w.jpg)

![img](https://pic3.zhimg.com/80/v2-063abc2abd313aa7df776b23b7977522_1440w.jpg)

![img](https://pic3.zhimg.com/80/v2-13b7da2172326c8392f3b232947d70c6_1440w.jpg)

### 推荐流量分发

- CVR (Click Value Rate): 转化率，衡量[CPA广告](https://www.baidu.com/s?wd=CPA广告&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)效果的指标

- CTR (Click Through Rate): 点击率

- CPC (Cost Per Click): 按点击计费

- CPA (Cost Per Action): 按成果数计费

- CPM (Cost Per Mille): 按千次展现计费

- PV (Page View): 流量

- PV单价: 每PV的收入，衡量页面[流量变现](https://www.baidu.com/s?wd=流量变现&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)能力的指标

- ADPV (Advertisement Page View): 载有广告的pageview流量

- ADimp (ADimpression): 单个广告的展示次数

- RPS (Revenue Per Search): 每搜索产生的收入，衡量搜索结果[变现能力](https://www.baidu.com/s?wd=变现能力&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)指标

- ROI：投资回报率(ROI)是指通过投资而应返回的价值，它涵盖了企业的获利目标。利润投入的经营所必备的财产相关，因为管理人员必须通过投资和现有财产获得利润。又称[会计收益率](https://www.baidu.com/s?wd=会计收益率&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)、投资利润率。
- GMV：通常称为网站成交金额，属于电商平台企业成交类指标，主要指拍下订单的总金额，包含付款和未付款两部分

**计算方式**

- ROI=订单额/消费量（即广告费用）=（单均额*转化量）/（CPA*转化量）=单均额/CPA

- CTR=点击量/展现量

- CVR=转化量/点击量

- CPM=（消费量/展现量）*1000

- CPA=消费量/转化量=（CPC*点击量）/（CVR*点击量）=CPC/CVR

- CPC=消费量/点击量

![img](https://pic4.zhimg.com/80/v2-c399cb49131fdc756c53df87fc75d357_1440w.jpg)

### 模型部署

![img](https://pic1.zhimg.com/80/v2-a7d81ac9ee10f14e7d06190259ac74b0_1440w.jpg)

![img](https://pic1.zhimg.com/80/v2-3176997f9da2fdc4c8dc7153275d3e38_1440w.jpg)

![img](https://pic3.zhimg.com/80/v2-bbf8e93ebb565d10053dd0120281121e_1440w.jpg)

## 推荐召回

### 召回分类

兼顾成本与性能

- user profile 标签索引列表
- 相似列表
  - 协同过滤
  - Content-Based
  - 基于图论的算法
  - knoledge-Based
  - Context-Aware
  - Hybrid-BAsed
- 热门列表
  - 分类热门
  - 运营人工推荐列表
- 召回的列表将作为推荐候选池

### 业界算法模型

![img](https://pic1.zhimg.com/80/v2-98232e9c4051988f7209dc9b81c40798_1440w.jpg)

![img](https://pic1.zhimg.com/80/v2-9bd8e6cb42d8d849a7b0c80292078ee4_1440w.jpg)

![img](https://pic4.zhimg.com/80/v2-b87e9115bccfa9143221d996aba68e17_1440w.jpg)

### 相似度计算注意点

- 在不丧失区分度的情况下，空间尽量稠密
- 经验目标：稀疏度> 1%
- 横向结合+纵向结合
- 相似度归一化
  - 提高推荐的准确度
- 时间因子
  - 对历史共现的数据和历史频次的数据进行降权
  - 要更加侧重于新数据的影响力

### 召回---关联推荐

![img](https://pic1.zhimg.com/80/v2-bed2819c1f3aa7637d38eeedebebdb90_1440w.jpg)

![img](https://pic1.zhimg.com/80/v2-c70800e9bf2ad2e3292132fbd15dda54_1440w.jpg)



![img](https://pic3.zhimg.com/80/v2-e8297116cce36f26c7de67d1972d42fe_1440w.jpg)

## 推荐排序

#### 问题抽象

![img](https://pic2.zhimg.com/80/v2-8b17939513726115c86590722f93ebb5_1440w.jpg)

#### 个性化/非个性化模型

![img](https://pic2.zhimg.com/80/v2-fcb69b1e3f904273f2a26ef1050c5fcd_1440w.jpg)

#### 目标变形

![img](https://pic4.zhimg.com/80/v2-b3ef26508d95239d9b710749b6aa34d3_1440w.jpg)

#### 预估流程与部署

![img](https://pic2.zhimg.com/80/v2-fc8612ddd48f5af5d5dd8b02514ab4c1_1440w.jpg)

#### 调试

![img](https://pic4.zhimg.com/80/v2-359a5eaf8855b9092ac7eaf07f737d8f_1440w.jpg)



![img](https://pic3.zhimg.com/80/v2-32fd09adc22679a9ca5730f97ea96b72_1440w.jpg)

## 用户画像

### 要素

用户行为= 商品/内容 +显性操作 （购买、关注、下载）+隐形操作（时长、跳过）

#### User profile 基础数据

**用户标签**

- 用户的历史行为
- 用户session行为
- 用户自身的标签

#### Item/Content profile基础数据

**内容标签**

- 内容的keyword
- 分类
- 热点标签
- 标题党
- ……

### 用户画像标签

![img](https://pic2.zhimg.com/80/v2-fb1939476538a7ffc5ddd846de94202d_1440w.jpg)

#### 用户画像应用-选人中心

![img](https://pic4.zhimg.com/80/v2-6c0c228787e88174d5a5e12a993483f7_1440w.jpg)

#### 用户画像应用-DMP

![img](https://pic3.zhimg.com/80/v2-3802a719644af111dd449d83acc80e6e_1440w.jpg)

#### 用户画像应用-Right Time 消费周期

![img](https://pic2.zhimg.com/80/v2-29abf4518c343d40bb0678effeb17575_1440w.jpg)



### 标签体系构建

![img](https://pic1.zhimg.com/80/v2-ba8e75e77794802fe92621938ac2335c_1440w.jpg)

### 标签建模

![img](https://pic3.zhimg.com/80/v2-7e8b921e78f6dfe34fb4a538aa8f8a12_1440w.jpg)

#### 性别模型

![img](https://pic3.zhimg.com/80/v2-70a2ab5f93c7e7b9d45f49b50cbc499a_1440w.jpg)

#### 购买力模型

![img](https://pic3.zhimg.com/80/v2-796093ed1186bbd3c359851c85b85eea_1440w.jpg)

#### 关键词偏好

![img](https://pic4.zhimg.com/80/v2-5ab2550a0063b8dad0dbc5d595eb469b_1440w.jpg)

#### 关键词模型

![img](https://pic4.zhimg.com/80/v2-d2a2d5f18624ed41a6cf2c7f6c096673_1440w.jpg)

### 画像与数据分析结合

![img](https://pic2.zhimg.com/80/v2-124a103f2e219804503fa089a56bc511_1440w.jpg)

![img](https://pic3.zhimg.com/80/v2-55c1eca9dbabf7c9ef553440a9219cae_1440w.jpg)

![img](https://pic2.zhimg.com/80/v2-8a6a2b8e65bbe753a7d8161ea65c1279_1440w.jpg)

## 特征工程

### 分类

- 用户特征
  - 人口统计学特征
  - 购物偏好
  - 用户群体标签
- 商品特征
  - 商品ID
  - 商品静态属性
  - 商品的关联卖家
  - 商品所在的店铺

![img](https://pic4.zhimg.com/80/v2-b1955438388f5b630c1dfbb2992450d3_1440w.jpg)

![img](https://pic3.zhimg.com/80/v2-13abad33462d724c18dbb2c2d47a88fa_1440w.jpg)

![img](https://pic2.zhimg.com/80/v2-bff1fd7d27d3c1b2c4e215c5e95f9121_1440w.jpg)

### 数据标注

- 样本关联
- 样本选择
- 样本采样
- 样本权重
- 负样本

![img](https://pic2.zhimg.com/80/v2-1e744c5f6e6f3791f05c378b0908beb1_1440w.jpg)

### 特征处理

- 特征离散化、ID类特征
  - 加快处理速度
  - 非线性
- 特征平滑
  - 威尔逊区间
  - PV越小，CTR的置信度越小
  - 防止低PV的商品占优势
- 特征组合
  - 非线性
  - PV+IPV组合，比CTR的信息更多

![img](https://pic4.zhimg.com/80/v2-4caed0fd81713f60bba02366960f9733_1440w.jpg)

百度百科：在[统计学](https://baike.baidu.com/item/统计学/1175)中，一个概率样本的**置信区间**（Confidence interval）是对这个样本的某个总体[参数](https://baike.baidu.com/item/参数)的[区间估计](https://baike.baidu.com/item/区间估计/6611490)。置信区间展现的是这个参数的真实值有一定[概率](https://baike.baidu.com/item/概率/828845)落在测量结果的周围的程度。置信区间给出的是被测量参数的测量值的可信程度，即前面所要求的“一定概率”。这个概率被称为**置信水平**。

### 特征聚合

- 特征降维
- 相似特征有相似权重
- 特征的权重近似于后验概率

![img](https://pic1.zhimg.com/80/v2-46e9dd415bd251b804ab088608a5baf4_1440w.jpg)

### 评估指标

![img](https://pic1.zhimg.com/80/v2-6ca5c99ea8e76ea02ba5ae2533acbba4_1440w.jpg)

![img](https://pic1.zhimg.com/80/v2-41a7a17a891d5a29b214cc40be2279b8_1440w.jpg)

## 回归

### 场景分类与推荐

![img](https://pic2.zhimg.com/80/v2-89a9e0870258f6a9eaa634544f249c85_1440w.jpg)

### 各类算法比较

![img](https://pic1.zhimg.com/80/v2-37ad55e090bcbe9ee42d9102dd110d70_1440w.jpg)

### 实时个性化

![img](https://pic3.zhimg.com/80/v2-ba19c9de4cb88e48096c7cce268d7b02_1440w.jpg)

### 意图计算

![img](https://pic4.zhimg.com/80/v2-d40c45b5d399dfb3933f16bbbf64a39b_1440w.jpg)

### E&E 个性化

![img](https://pic4.zhimg.com/80/v2-e3e28700c774d253ef4f9c89825d32c7_1440w.jpg)

### 可配置化

![img](https://pic3.zhimg.com/80/v2-623cb5d59687ec59a75fdc3fd5bac4ee_1440w.jpg)

### 分解

![img](https://pic2.zhimg.com/80/v2-2b5bace2d1ade91a61b2c915f0f2ad3d_1440w.jpg)

![img](https://pic2.zhimg.com/80/v2-5e2134edb61ad4d09981252e1ec52b69_1440w.jpg)


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>推荐</category>
        <category>个性化</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>推荐系统</tag>
        <tag>个性化</tag>
        <tag>内容分发</tag>
      </tags>
  </entry>
  <entry>
    <title>数字营销十大悖论</title>
    <url>/2019/04/03/%E6%95%B0%E5%AD%97%E8%90%A5%E9%94%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 悖论一：原生化与商业化

原生与商业化，不可兼得；怎样达到一个平衡点

- 想要不带利益的原生UGC内容，就很难做到优秀的商业化
- 好的商业化又会验证影响UGC的水准，掺杂了商业利益的内容，易被用户识别并唾弃

# 悖论二：隐私保护和数据应用

当前隐私保护和数据应用无法兼得的时代特征

- 数据从发生到蔑视全部需要隐私和安全的保护
- 怎么做到隐私保护的情况下，是数据获得应用造福人类

# 悖论三：“围墙花园”与“公域数据”

- 各个数据控制者为拒绝数据分享而高筑的壁垒–“围墙花园”

- 强化了强势媒体的垄断地位
- 削弱企业（广告主）在“公域数据”的能力
- 数据应用变得割裂，不得不与众多强势媒体合作，也变得彻底黑箱化
- 围墙花园、过于一刀切的隐私保护，抑制了行业的活力和创造力

# 悖论四：精准与规模

精准和规模很难兼得，只能尽量使二者达到一个可接受的平衡程度

- 外部流量红利是不能持续的
- 高浓度的目标人群的数量总是有限的，以及流量市场本身的竞争性降低了获得精准的概率
- 任何一个单一媒体的投放，即时在高精度技术水平下，也是一个不断衰减的规模曲线

# 悖论五：品牌和效果

- 品牌和效果是数字营销的两端，品效合一不太可能在一次营销campaign中发生
- 本质上只能有一个重要的核心目的

# 悖论六：作弊与反作弊

- 存在即合理。
- 作弊永远不可能被禁绝，也不可能被消灭。
- 规则本身是死的，而人是活的。

# 悖论七：AI和HI

人工智能（AI）非常依赖（HI）

- 在真正解放人的思考之前，AI需要大量人的思考参与其中
- AI在很多场景下死板的，但能补强人工效率低下的问题；故采取AI打前阵，HI再精细化处理
- AI的最大价值在于“学习”，但学习的成败，在于人告知机器“对”、“错”
- 监督学习，监督即为对AI处理成功与否的判断

# 悖论八：搜索和信息流

- 典型AI和HI结合的领域：信息流

- 判断人的行为数据、兴趣，主动提供信息
- 导致降低主动搜索需求，并降低搜索引擎的价值
- 搜索的出路

- 出路一：强化搜索体验，更容易找到真正有价值的最相关内容
- 出路二：搜索引擎信息流化，搜索的同时留住用户，花费用户其他时间

# 悖论九：Local Host 和 SaaS

- local host 带来“安全”感受，但并不是真正技术上的安全
- SaaS 易实施、且成本低廉、维护方便、能始终保持最新的状态

# 悖论十：营销和运营

- 运营究竟是什么？营销是否包含运营？反过来，营销又是否是运营的一部分？
- 互联网的世界已经不再是流量为王的世界，而是“有效流量”为王的世界。
- 为了营销而作的运营



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>营销</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>营销</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-matplotlib-基础</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-matplotlib-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化-matplotlib-基础

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/matplotlib%E5%9F%BA%E7%A1%80.html" width="100%" height="1200">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-matplotlib-常用图形</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-matplotlib-%E5%B8%B8%E7%94%A8%E5%9B%BE%E5%BD%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化-matplotlib-常用图形

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/matplotlib常用图形.html" width="100%" height="1200">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-matplotlib-统计图形实战</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-matplotlib-%E7%BB%9F%E8%AE%A1%E5%9B%BE%E5%BD%A2%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化-matplotlib-统计图形实战

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/matplotlib统计图形实战.html" width="100%" height="1200">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-plotly-绘制常见图形</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-plotly-%E7%BB%98%E5%88%B6%E5%B8%B8%E8%A7%81%E5%9B%BE%E5%BD%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化--plotly-绘制常见图形

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/plotly绘制常见图形.html" width="100%" height="1200">
</iframe></pre>

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
        <category>plotly</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-plotly-基础</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-plotly-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化--plotly-基础

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/plotly基础.html" width="100%" height="1200">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
        <category>plotly</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
        <tag>plotly</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-seaborn-基础</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-seaborn-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化-seaborn-基础

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/seaborn基础.html" width="100%" height="1200">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
        <category>seaborn</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title>数据可视化-seaborn-绘制常见统计图形</title>
    <url>/2022/05/02/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96-seaborn-%E7%BB%98%E5%88%B6%E5%B8%B8%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%9B%BE%E5%BD%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 数据可视化-seaborn-绘制常见统计图形

#### 具体实现

<pre>
<iframe src="https://ocaeneyes.github.io/recommendPrj/html/seaborn绘制常用统计图形.html" width="100%" height="1200">
</iframe></pre>


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>data visualization</category>
        <category>Python3</category>
        <category>matplotlib</category>
        <category>seaborn</category>
      </categories>
      <tags>
        <tag>pandas</tag>
        <tag>numpy</tag>
        <tag>data visualization</tag>
        <tag>matplotlib</tag>
        <tag>seaborn</tag>
      </tags>
  </entry>
  <entry>
    <title>数据思维打磨产品</title>
    <url>/2017/02/25/%E6%95%B0%E6%8D%AE%E6%80%9D%E7%BB%B4%E6%89%93%E7%A3%A8%E4%BA%A7%E5%93%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


什么是数据思维？

收集数据

做出决策

高效执行


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据思维</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据思维</tag>
      </tags>
  </entry>
  <entry>
    <title>数据统计产品常用的指标定义</title>
    <url>/2019/05/19/%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E4%BA%A7%E5%93%81%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8C%87%E6%A0%87%E5%AE%9A%E4%B9%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 一、用户类指标

1. **启动用户**：启动过该应用的用户（以独立设备为判断标准），通常也叫活跃用户。注：用户定义以独立设备为准，其中可能会用到包括imei、mac id、Android id、IDFA、IDFV等综合设备维度指标，生成长期有效彼此不冲突的唯一设备ID
2. **新用户**：首次下载安装并激活该应用的用户。在渠道或版本统计中，仅在第一次下载时被记为渠道新用户，后续重新下载或升级版本，不算新用户。（以独立设备为判断标准）
3. **老用户**：当日启动用户中，以前也启动过应用程序的用户
4. **日活跃用户**：当日启动过应用程序的用户（已去重）
5. **周活跃用户**：过去7天（含当日）启动过应用程序的用户（已去重）
6. **月活跃用户**：过去30天（含当日）启动过应用程序的用户（已去重）
7. **月沉默用户**：过去30天（含当日）没有启动过应用程序的用户
8. **留存用户**：所选考察时段的用户中，在留存时段再次启动应用的用户。包括新用户留存与活跃用户留存。
9. **流失用户**：过去60天（含当日）没有启动过应用程序的用户（已去重）
10. **分时用户**：每小时的启动用户数量（以独立设备为标准按小时去重）
11. **升级用户**： 从旧版本第一次升级到所选版本的用户为该版本的升级用户
12. **升级+新用户**： 该版本的全新用户加上升级用户
13. **本渠道新用户**： 第一次在该渠道下载APP并激活启动的用户，用户可能在其它渠道有过下载使用记录。
14. **启动次数**： 启动过应用程序的次数。“一次启动”是指用户从打开应用到退出应用（或离开应用界面，进入后台超过30分钟）为止。
15. **每次使用时长**： 平均每一次使用应用程序（session）的时间。
16. **每人使用时长**： 平均每个用户使用应用程序的时间。
17. **使用频率**： 所选时间段内单个用户的累计使用次数
18. **使用间隔**： 最近一次启动距离上一次启动的时间间隔，新用户的使用间隔为首次启动。

### 二、复合指标

1. **日活跃度**=当日启动用户/累计用户*100%
2. **周活跃度**=周活跃用户/累计用户*100%
3. **月活跃度**=月活跃用户/累计用户*100%
4. **月沉默率**=月沉默用户/累计用户*100%
5. **流失率**=流失用户/累计用户*100%
6. **日活/月活**=日活跃用户数/月活跃用户数*100%
7. **新用户留存率**=某日新用户中的留存用户/某日新用户*100%
8. **活跃用户留存率**=某日的活跃用户中的留存用户/某日活跃用户*100%
9. **新用户占比**=新用户/启动用户*100%
10. **老用户占比**=老用户/启动用户*100%

### 三、事件与页面指标

1. **事件数量（日均）**： 事件被触发的日均次数（数值向下取整）
2. **事件触发用户数（日均）**： 触发时间的独立用户数（当天内用户去重，跨天不去重，数值向下取整）
3. **事件平均使用时长**： 每一次事件触发的时长的平均值。
4. **页面访问次数**： 页面被打开的次数，同一页面的多次访问均会被计数。
5. **页面平均停留时长**： 每一次页面访问的停留时长的平均值
6. **页面跳出率**： 从当前页面离开应用的访次/该页面总访次*100%
7. **页面访问深度**： 一次启动过程中访问的页面数总和，同一个页面的重复访问均会被计数

### 四、Crash分析指标

1. **错误次数（日均）**： 该类错误出现的次数，如选择跨天的时间段，则取每天错误次数的平均值
2. **错误率**： 等于错误次数/累计启动次数*100%
3. **错误影响用户数**： 发生错误的独立设备数；仅对当天内的设备做去重处理，如选择跨天的时间段，则取每天影响用户数的平均值
4. **影响用户占比**： 某天的影响用户数占比=当天影响用户数/当天启动用户数*100%；如选择跨天的时间段，则取每天影响用户占比的平均值。

### 五、信息流分析指标

1. **信息展现次数**： 信息的曝光展现次数。信息区域展现超过50%即算做曝光
2. **信息点击次数**： 信息被用户点击的次数，多次点击均会被计数
3. **信息点击率**： 该信息被点击的次数占信息曝光展现次数的比例
4. **次均展现时长**： 每一次信息在列表页被曝光展现的时长的平均值
5. **次均浏览时长**： 每一次进入该信息详情页浏览时长的平均值
6. **短点击率**： 点击进入信息详情页阅读时长小于1s（可自定义）的点击次数占该信息总点击次数的比例



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据产品</category>
        <category>数据指标</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据指标</tag>
      </tags>
  </entry>
  <entry>
    <title>数据统计产品常用维度</title>
    <url>/2019/05/19/%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E4%BA%A7%E5%93%81%E5%B8%B8%E7%94%A8%E7%BB%B4%E5%BA%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


**1. 日期**

进行数据筛查的最基础维度，包含 月粒度、周粒度、天粒度和小时粒度。

**2.用户类型**

根据用户的历史启动行为划分，首次启动为“新用户”；历史上有过启动行为为“老用户”，新用户和老用户都是“活跃用户”（也叫启动用户）

**3. 品牌**

设备所属的品牌，如苹果、华为、三星等

**4. 设备型号**

单一机型的型号，如iPhoneX、华为P20等

**5. 操作系统**

设备的操作系统平台，主流平台有：Android、IOS等

**6. 分辨率**

设备屏幕的分辨率，当前主流分辨率有：1080 *1920、720* 1280、1440*2560等

**7. 运营商**

设备移动蜂窝网络的供应商，如国内三大运营商：中国移动、中国联通、中国电信

**8. APP版本**

设备所安装的APP的版本号

**9. 渠道**

该设备用户所安装的APP的渠道来源，如AppStore、百度手机助手、豌豆荚手机助手等。

**10. 地域**

用户启动APP时的IP地址匹配的地理位置，包含国家、省份、城市三层粒度。

**11. 页面**

APP内的页面层级，是用户浏览APP信息的主要载体，如首页、商品详情页等。在移动统计中，页面维度可以使用默认抓取的“页面路径”，也可手动编辑“页面备注名”

**12. 事件**

APP中的事件可以是一个元素控件的点击，也可以是启动app或进入到某个页面这种系统响应结果。通常可以通过对重要的节点进行事件埋点，再进一步分析 各个事件节点的转化漏斗。在移动统计中，事件维度可以用“事件ID”或“事件名称”表示，同时每一个事件也可添加“事件标签”

**13.信息标题**

信息标题是『信息流分析』功能自动抓取的文章或视频的标题

**14. 栏目**

栏目是『信息流分析』功能自动抓取的信息所属的栏目，典型如资讯类APP进入首页的『推荐』『社会』『体育』等频道，都可以算作一个栏目。



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据产品</category>
        <category>数据指标</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据指标</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习实战-笔记2-k-近邻算法概述</title>
    <url>/2020/12/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E7%AC%94%E8%AE%B02/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script># k-近邻算法概述
- 优点
  
   - 精度高、对异常值不敏感、无数据输入假定
- 缺点
  
   - 计算复杂度高、空间复杂度高
- 适用数据范围
   - 数值型和标称型  
   
     <!--标称型：标称型目标变量的结果只在有限目标集中取值，比如真与假(标称型目标变量主要用于分类)-->
   
     <!--数值型：数值型目标变量则可以从无限的数值集合中取值，如0.555，666.666等 (数值型目标变量主要用于回归分析)-->

### 工作原理
1. 样本数据集，每个数据都存在标签状态
2. 输入新的没有标签状态的数据，将新数据的每个特征与样本集中数据对应的特征比较
3. 算法提取样本集中特征最相似（最近邻）数据的标签； 一般选取样本数据集中前k个最相似的数据; k通常是不大于20的整数

### 一般流程
1. 收集数据：可以使用任何方法
2. 准备数据：距离计算索需要的数值，最好是结构化的数据格式
3. 分析数据：可以使用任何方法
4. 训练算法：不适用于k-近邻
5. 测试算法：计算错误率
6. 使用算法：首选需输入样本数据和结构化的输出结果， 然后运行k-近邻算法判定输入数据分别属于哪个分类， 最后应用对计算出的分类 执行后续的处理

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>k-近邻</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习实战-笔记1-基础</title>
    <url>/2020/12/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E7%AC%94%E8%AE%B01/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 机器学习实战-笔记1-基础

### 机器学习的主要任务

监督学习-必须知道预测什么，即目标变量的分类信息**

- 分类，将实例数据划分到核实的分类中
- 回归，用于预测数值型数据

监督学习的用途

- k-近邻算法
- 朴素贝叶斯算法
- 支持向量机
- 决策树
- 线性回归
- 局部加权线性回归
- Ridge回归
- Lasso最小回归系数估计

**无监督学习-没有类别信息，也没有目标值**

- 聚类，将数据集合分成类似的对象组成多个类的过程
- 密度估计，寻找描述数据统计值的过程

无监督学习的用途

- K-均值
- DBSCAN
- 最大期望算法
- Parzen窗设计

### 如何选择合适的算法

- 使用机器学习算法的目的，想要算法完成什么任务
  - 如果预测目标变量的值，则可选择监督学习算法
    - 目标变量类型如果是 离散型，如是/否、1/2/3等，则可使用分类算法
    - 目标变量类型如果是 连续型的数值，如1.0~100.0等，则可以使用回归算法
  - 如果不是预测目标变量的值，则可选择无监督学习算法
    - 如果只需要将数据分为离散的组，则使用聚类算法
    - 如果需要估计数据与每个分组的相似程度，则使用密度估计算法
- 需要分析或收集的数据是什么

### 开发机器学习应用程序的步骤

1. **收集数据**
2. **准备输入数据**
3. **分析输入数据**
4. **训练算法**
5. **测试算法**
6. **使用算法**


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习实战-笔记3-决策树</title>
    <url>/2020/12/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-%E7%AC%94%E8%AE%B03/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
### 决策树的一个重要任务是为了数据中所蕴含的知识信息
- 决策树可以使用不熟悉的数据集合，并从中提取出一系列规则，在这些机器根据数据集创建规则时，就是机器学习的过程
- k-近邻算法可以完成很多分类任务，但是它最大的缺点就是无法给出数据的内在含义，决策树的主要优势就在于数据形式非常容易理解

#### 决策数的构造
- 优点：计算复杂度不高，输出结果易于理解，对中间值对缺失不敏感，可处理不相关特征数据
- 缺点：可能会产生过度匹配的问题
- 适用数据类型：数值型和 标称型

**构建决策树的第一个问题：当前数据集上哪个特征在划分数据分类时起决定性作用**
- 为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征。
- 完成测试之后，原始数据集就被划分为几个数据子集
- 这些数据子集会分布在第一个决策点的所有分支上。如果某个分支下的数据属于同一类型，则当前条件已经正确地划分数据分类， 无需进一步对数据集进行分割。
- 如果数据子集内的数据不属于同一类型，则需要重复划分数据子集的过程

**思路**
检测数据集中的每个子项是否属于同一分类: 
    If so return 类标签;
    Else
        寻找划分数据集的最好特征
        划分数据集
        创建分支节点
            for 每个划分的子集 
                调用函数createBranch并增加返回结果到分支节点中
        return 分支节点

**决策树的一般流程**
1. 收集数据：可使用任何方法
2. 准备数据：构造算法只适用于标称型数据， 因此数值型数据必须离散化
3. 分析数据：可使用任何方法，构造树完成后，应检查图形是否符合预期
4. 训练算法：构造树的数据结构
5. 测试算法：使用经验树计算错误概率
6. 使用算法：此步骤可以适用于任何监督学习算法，决策树可以更好地理解数据的内在含义

##### 信息增益
**划分数据集的大原则是:将无序的数据变得更加有序**
*组织杂乱无章数据的一种方法就是使用信息论度量信息，可以在划分数据之前或之后使用信息论量化度量信息的内容*
**在划分数据集之前之后信息发生的变化称为信息增益(information gain)** 知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。 
**集合信息的度量方式称为香农熵或者简称为熵， 熵定义为信息的期望值**
##### 划分数据集
##### 递归构建决策树


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-NLP实现预测天气冷暖感知度</title>
    <url>/2019/03/01/%E6%A1%88%E4%BE%8B-NLP%E5%AE%9E%E7%8E%B0%E9%A2%84%E6%B5%8B%E5%A4%A9%E6%B0%94%E5%86%B7%E6%9A%96%E6%84%9F%E7%9F%A5%E5%BA%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 案例：NLP预测天气冷暖感知度

## 1、案例需求

> 根据吃冰淇淋和喝水的数量，判断成都天气冷热程度。
>
> 成都春熙路街头采访记录一些游客吃了多少冰淇淋，又喝了几瓶水，他觉得成都天气怎么样（这里只考虑二分类问题，假设只有‘非常热’和‘一般热’）
>
> 其中特征向量包括两个分别是冰激凌数t1和喝水数t2，户外活动时长t3:
>
> 对应的标签类别分别是非常热A和一般热B。

## 2、实验数据准备

- 构造模拟数据

| 人员 | 冰淇淋 | 喝水 | 户外活动时长 | 冷热程度 | 判断描述                                                  |
| ---- | ------ | ---- | ------------ | -------- | --------------------------------------------------------- |
| 小王 | 8      | 4    | 2            | A        | 小王吃了8个冰淇淋，喝了4瓶水，户外2小时，该地区天气非常热 |
| 小张 | 7      | 1    | 1            | A        | 小张吃了7个冰淇淋，喝了1瓶水，户外1小时，该地区天气非常热 |
| 小李 | 1      | 4    | 4            | B        | 小李吃了1个冰淇淋，喝了4瓶水，户外4小时，该地区天气一般热 |
| 小赵 | 3      | 0    | 5            | B        | 小赵吃了3个冰淇淋，喝了0瓶水，户外5小时，该地区天气一般热 |

- 代码构造数据集

  ```python
  #!/usr/bin/python
  # -*- coding:utf-8 -*-
  '''
      author:gzy
      date:20190301
      version:0.1.0
  '''
  import numpy as np
  import matplotlib.pyplot as plt
  from matplotlib.font_manager import FontProperties
  class Temperature():
      #设置字字体，避免汉字乱码
      siyuanyahei = FontProperties(fname="../SourceHanSans-Normal.otf")
  
      #创建数据集，返回数据集和类标签
      def create_dataset(self):
          # 数据集
          datasets = np.array([[8,4,2],[7,1,1],[1,4,4],[3,0,5]])
          #类标签
          labels = ['非常热','非常热','一般热','一般热']
          return datasets,labels
  
  ```

## 3、数据分析与可视化

- 可视化展示散点图

  ```python
   #可视化分析数据
      def analyze_data_plot(self,x,y):
          fig = plt.figure()
          # 将画布分隔为1行1列一块
          ax = fig.add_subplot(111)
          ax.scatter(x,y)
  
          #设置散点图的标题和横纵坐标
          plt.title('游客领热感知散点图',fontproperties=self.siyuanyahei)
          plt.xlabel('天热吃冰激凌数目',fontproperties=self.siyuanyahei)
          plt.ylabel('天热喝水的数目',fontproperties=self.siyuanyahei)
          plt.show()
  
  ```

## 4、算法模型及原理讲解

- KNN模型原理及欧式距离计算
  - 什么是KNN算法模型
  - KNN工作原理
  - KNN算法思想
  - KNN算法流程

### 4.1、KNN算法模型

​	k-近邻(KNN，k-NearestNeighbor)算法是一种基本分类与回归方法。*k-近邻假设设定一个训练数据集(先验知识)，其中的实例类别已定。分类时候，对新的实例数据，根据其K个最近邻的训练实例的类别，通过多数表决等方式进行预测。*

==K近邻算法属于有监督学习，实际上利用训练数据集对特征向量空间进行划分，并作为其分类的"模型"。K值的选择、距离度量、以及分类决策规则是K近邻算法的三个基本要素。==

在本案例中，仅讨论分类问题中的k-近邻算法；**输入值：**案例的特征向量(吃冰淇淋、喝水、活动时间)，对应特征空间的点；**输出值：**案例的类别(非常热、一般热、舒适、一般冷、非常冷)

### 4.2、KNN工作原理

- 假设一个带有标签的数据集(训练样本集)，包含每条数据与所属分类的对应关系
- 输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较
- 计算新数据与样本数据集 中每条数据的距离
- 对求得的所有距离进行排序(从小到大，越小表示越相似)
- 取前K(K<=20的奇数)个样本数据对应的分类标签 - 求k个数据中出现次数最多的分类标签作为新数据的分类 ### 4.3、knn算法思想 计算所有样本点 与 待分类样本之间的距离 计算完 样本距离进行排序 选取距离样本最近的k个点 针对这个k个点，统计各个类别分别有多少个 k个点钟某个类别最多，就将该样本划归该点 4.4、knn算法模型流程与实现 搜集数据 数据采集过程，分为：非机构化数据、半结构化数据、数据化数据 准备数据 格式化处理，对不同类别的数据进行统一的格式化处理 如：将pdf,word,excel,sql等统一转化为txt 分析数据 看数据特点，有无缺失值，数据是离散还是连续 训练数据 不适用与knn，但在其他一些监督学习中经常会用到 应用算法 针对完善的模型进行封装重构，进行实际应用 构造knn分类器 ```python #构造knn分类器 def knn_classifier(self,newv,datasets,labels,k): # 获取新样本的数据 获取样本库的数据 选择k值 计算样本数据与样本库数据之间的距离 根据距离进行排序 针对k个点，统计各个类别的数量 投票机制，少数服从多数原则 pass ``` 欧式距离计算 欧氏距离计算 #方式一 d^2="（x1-x2）^2" +(y1-y2)^2" computeeuclideandistance(self,x1,x2,y1,y2): d="math.sqrt(math.pow((x1-x2),2)+math.pow((y1-y2),2))" return 方式二 euclideandistance(self,instance1,instance2,length): for x in range(length): +="pow((instance1[x]-instance2[x]),2)" math.sqrt(d) --- about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</=20的奇数)个样本数据对应的分类标签>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Natural Language Processing</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Natural Language Processing</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-k-近邻-改进约会网站的配对效果</title>
    <url>/2020/12/29/%E6%A1%88%E4%BE%8B-%E4%BD%BF%E7%94%A8k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E6%94%B9%E8%BF%9B%E7%BA%A6%E4%BC%9A%E7%BD%91%E7%AB%99%E7%9A%84%E9%85%8D%E5%AF%B9%E6%95%88%E6%9E%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 思路
- 收集数据：提供文本数据
- 准备数据：解析文本数据
- 分析数据：使用matplotlib 二维扩散图
- 训练算法：不适用于k-近邻
- 测试算法：切分测试样本； 测试样本是已经完成分类的数据，如果预测分类与实际分类不同，则标记为错误
- 使用算法：程序执行，输入一些特征数据来判断是否为喜欢的类型
    - 三种类型：不喜欢的、一般的、喜欢的

### 准备数据


```python
import numpy as np
import matplotlib.pyplot as plt
import operator
```


```python
np.zeros((1000,3)).shape
```




    (1000, 3)




```python
def file2matrix(filename):
    with open (filename,'r') as f:
        arrayOLines = f.readlines()
#         print(arrayLines)
        numberOflines= len(arrayOLines)
#         print(numberOflines)
        returnMat = np.zeros((numberOflines,3)) # 创建numpy矩阵
#         print(returnMat)
        classLabelVector = []
        index= 0
        for line in arrayOLines:
            line = line.strip()
#             print(line)
            listFromLine = line.split('\t')
#             print(listFromLine)
            # x[:,n]表示在全部数组（维）中取第n个数据，直观来说，x[:,n]就是取所有集合的第n个数据, 
            # x[n,:]表示在n个数组（维）中取全部数据，直观来说，x[n,:]就是取第n集合的所有数据, 
        
            returnMat[index,:] = listFromLine[0:3]
#             print(returnMat)
            classLabelVector.append(int(listFromLine[-1]))
#             print(classLabelVector)
            index +=1
        return returnMat,classLabelVector
```


```python
# 每年获得的飞行常客里程数、玩视频游戏所耗时间的占比、每周消费的冰淇淋公升数
datingDataMat,datingLabels =file2matrix("./dataset/datingTestSet2.txt")
```


```python
datingDataMat
```




    array([[4.0920000e+04, 8.3269760e+00, 9.5395200e-01],
           [1.4488000e+04, 7.1534690e+00, 1.6739040e+00],
           [2.6052000e+04, 1.4418710e+00, 8.0512400e-01],
           ...,
           [2.6575000e+04, 1.0650102e+01, 8.6662700e-01],
           [4.8111000e+04, 9.1345280e+00, 7.2804500e-01],
           [4.3757000e+04, 7.8826010e+00, 1.3324460e+00]])




```python
datingLabels[0:20]
```




    [3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3]



### 分析数据


```python
fig=  plt.figure()
ax = fig.add_subplot(111)
# 第二列和第三列数据
ax.scatter(datingDataMat[:,1], datingDataMat[:,2])
plt.show()
```


![png](output_9_0.png)



```python
fig=  plt.figure()
ax = fig.add_subplot(111)
# 第二列和第三列数据
ax.scatter(datingDataMat[:,1], datingDataMat[:,2], 15.0*np.array(datingLabels) , 15.0*np.array(datingLabels))
plt.show()
```


![png](output_10_0.png)



```python
fig=  plt.figure()
ax = fig.add_subplot(111)
# 第二列和第三列数据
ax.scatter(datingDataMat[:,0], datingDataMat[:,1], 15.0*np.array(datingLabels) , 15.0*np.array(datingLabels))
plt.show()
```


![png](output_11_0.png)



```python
fig=  plt.figure()
ax = fig.add_subplot(111)
# 第二列和第三列数据
ax.scatter(datingDataMat[:,0], datingDataMat[:,2], 15.0*np.array(datingLabels) , 15.0*np.array(datingLabels))
plt.show()
```


![png](output_12_0.png)


### 准备数据：归一化数据

- 将数值归一化，如将取值范围 8 处理为0到1或者-1到1之间
newValue = (oldValue -min) / (max-min)


```python
def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals- minVals
    normDataSet = np.zeros(np.shape(dataSet))
    m = dataSet.shape[0] # 行数
#     print(m) 
    normDataSet = dataSet - np.tile(minVals , (m,1))
    normDataSet = normDataSet / np.tile(ranges,(m,1))  # 特征值相除
    return normDataSet,ranges,minVals
```

![image.png](attachment:8b397d01-55e2-4a32-a401-58859e3b2224.png)


```python
datingDataMat.shape
```




    (1000, 3)




```python
normMat , ranges, minVals = autoNorm(datingDataMat)
```

    1000



```python
normMat
```




    array([[0.44832535, 0.39805139, 0.56233353],
           [0.15873259, 0.34195467, 0.98724416],
           [0.28542943, 0.06892523, 0.47449629],
           ...,
           [0.29115949, 0.50910294, 0.51079493],
           [0.52711097, 0.43665451, 0.4290048 ],
           [0.47940793, 0.3768091 , 0.78571804]])




```python
normMat[10:20,:]
```




    array([[0.55045851, 0.17799301, 0.49030933],
           [0.69324992, 0.40086711, 0.9846361 ],
           [0.06101476, 0.23305864, 0.42936659],
           [0.55933299, 0.22372102, 0.36832056],
           [0.84769866, 0.73135976, 0.19487878],
           [0.47848761, 0.09032121, 0.11221162],
           [0.67231273, 0.35932065, 0.74836944],
           [0.76334732, 0.68067104, 0.15355464],
           [0.1716718 , 0.        , 0.73716817],
           [0.31211859, 0.50329267, 0.76942753]])




```python
datingDataMat.min(0).shape
```




    array([9.1273000e+04, 2.0919349e+01, 1.6943610e+00])




```python
minVals
```




    array([0.      , 0.      , 0.001156])




```python
def classify0(inX, dataSet, labels, k):
    # shape[0]：表示矩阵的行数
    # shape[1]：表示矩阵的列数
    dataSetSize = dataSet.shape[0]
#     print(dataSetSize)
    # 距离计算
    # np.tile(a,(2,1))第一个参数为Y轴扩大倍数，第二个为X轴行扩大倍数。
    # np.tile（a,(2)）函数的作用就是将函数将函数沿着X轴/行扩大两倍。如果扩大倍数只有一个，默认为X轴
    diffMat = np.tile(inX, (dataSetSize,1))-dataSet
    sqDiffMat = diffMat ** 2
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances ** 0.5
    sortedDistIndicies = distances.argsort()
#     print(sortedDistIndicies)
    # 选择距离最小的k个点
    classCount={}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        print("voteIlabel:",voteIlabel)
        classCount[voteIlabel]= classCount.get(voteIlabel,0) +1
        print("classCount[voteIlabel]:",classCount[voteIlabel])
        print("classCount:",classCount)
    # 排序
    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1), reverse=True)
    return sortedClassCount[0][0]
```

### 测试算法：作为完整程序验证分类器

- 通常使用90%作为训练样本来训练分类器，使用其余的10%数据去测试分类器


```python
def datingClassTest():
    hoRatio = 0.10
    datingDataMat ,datingLabels = file2matrix("./dataset/datingTestSet2.txt")
    normMat, ranges, minVals = autoNorm(datingDataMat)
    m = normMat.shape[0]
    numTestVecs = int(m * hoRatio)
    print(numTestVecs)
    errorCount = 0.0
    for i in range(numTestVecs):
        classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:], datingLabels[numTestVecs:m],3)
#         print("最近邻的结果",classifierResult,"realanswer", datingLabels[i])
        if (classifierResult != datingLabels[i]):
            errorCount +=1.0
    print("正确率",1.0-errorCount/float(numTestVecs))
```


```python
datingClassTest()
```

    1000
    100
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {2: 1, 3: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2, 3: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {3: 2, 1: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {3: 1, 2: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {3: 1, 2: 1, 1: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {3: 1, 1: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2, 1: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {3: 1, 2: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2, 2: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {3: 1, 2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {3: 1, 2: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {1: 2, 3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {3: 1, 1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {3: 1, 1: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {3: 1, 2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {3: 1, 2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {3: 2, 2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {3: 2, 1: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 2
    classCount[voteIlabel]: 3
    classCount: {2: 3}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 3
    classCount: {1: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {3: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 3
    classCount: {3: 3}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {2: 2, 3: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {2: 1, 1: 1}
    voteIlabel: 1
    classCount[voteIlabel]: 2
    classCount: {2: 1, 1: 2}
    voteIlabel: 1
    classCount[voteIlabel]: 1
    classCount: {1: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {1: 1, 3: 1}
    voteIlabel: 3
    classCount[voteIlabel]: 2
    classCount: {1: 1, 3: 2}
    正确率 0.95



```python
def classifyPerson():
    resultList=['not at all','in small doses','in large doses']
    percentTats = float(input("percentage of time spent playing video games?"))
    ffMiles = float(input("frequent flier miles per year?"))
    iceCream = float(input("liters of ice cream per week?"))
    datingDataMat, datingLabels = file2matrix("./dataset/datingTestSet2.txt")
    normMat ,ranges, minVals = autoNorm(datingDataMat)
    
    inArr=  np.array([ffMiles,percentTats,iceCream])
    classifierResult = classify0((inArr-minVals)/ranges , normMat, datingLabels ,3)
    print("probably result:",resultList[classifierResult-1])
```


```python
classifyPerson()
```

    percentage of time spent playing video games? 12
    frequent flier miles per year? 999
    liters of ice cream per week? 2


    1000
    1000
    voteIlabel 2
    voteIlabel 3
    voteIlabel 3
    probably result: in large doses



```python
classifyPerson()
```

    percentage of time spent playing video games? 10
    frequent flier miles per year? 10000
    liters of ice cream per week? 0.5


    1000
    voteIlabel: 2
    classCount[voteIlabel]: 1
    classCount: {2: 1}
    voteIlabel: 2
    classCount[voteIlabel]: 2
    classCount: {2: 2}
    voteIlabel: 3
    classCount[voteIlabel]: 1
    classCount: {2: 2, 3: 1}
    probably result: in small doses



```python

```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>k-近邻</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-基于朴素贝叶斯过滤垃圾邮件</title>
    <url>/2020/12/25/%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8E%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E8%BF%87%E6%BB%A4%E5%9E%83%E5%9C%BE%E9%82%AE%E4%BB%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 基于朴素贝叶斯过滤垃圾邮件

- 收集数据：提供文本文件
- 准备数据：将文本文件解析成词条向量
- 分析数据：检查词条确保解析的正确性
- 训练算法：使用trainNB1()函数
- 测试算法：使用classifyNB() 并且构建一个新的测试函数来计算文档集的错误率
- 使用算法：构建完整程序 对一组文档进行分类，并将错分的文档输出到屏幕

#### **准备数据：切分文本**


```python
mySent = 'this book is the best book on Python pr M.L I have ever laid eyes upon.'
```


```python
mySent.split()
```




    ['this',
     'book',
     'is',
     'the',
     'best',
     'book',
     'on',
     'Python',
     'pr',
     'M.L',
     'I',
     'have',
     'ever',
     'laid',
     'eyes',
     'upon.']




```python

```

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>朴素贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-k-近邻-手写字识别系统</title>
    <url>/2020/12/29/%E6%A1%88%E4%BE%8B-%E6%89%8B%E5%86%99%E5%AD%97%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
- 收集数据：提供文本文件
- 准备数据：编写函数classify0(), 将图像格式转换为分类器使用的list格式
- 分析数据：检查数据
- 训练算法：不适用于k-近邻算法
- 测试算法：编写函数切分测试样本； 测试样本是已经完成分类的数据，如果预测分类与实际分类不同，则标记为错误
- 使用算法：

###### Numpy中有两个常用数据类型，数组（array/ndarray）、矩阵（matrix）
- matrix是array的特殊形式，matrix只能表示2维的数据，而array可以表示任意维度数据，matrix相当于二维数组。
- 当matrix的某一维的维度为1时，即可称为向量（m，1）是列向量，（1，n)是行向量


```python
import numpy as np
import os
import operator
```

### 准备数据：将图像转换为测试向量


```python
# 将图像处理为向量
def img2vector(filename):
    returnVect = np.zeros((1,1024))
#     print(returnVect)
    with open(filename,'r') as f:
        for i in range(32):
            lineStr = f.readline()
#             print(lineStr)
            for j in range(32):
                returnVect[0,32*i+j] = int(lineStr[j])
        return returnVect
```


```python
testVector = img2vector("./dataset/testDigits/0_0.txt")
```

    [[0. 0. 0. ... 0. 0. 0.]]



```python
testVector[0,0:120]
```




    array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,
           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
           0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,
           0.])




```python
# kNN分类器
def classify0(inX, dataSet, labels, k):
    datsSetSize = dataSet.shape[0]  #行数
    diffMat = np.tile(inX, (datsSetSize,1)) -dataSet #将输入矩阵放大，求差
    sqDiffMat = diffMat ** 2
    sqDistances = sqDiffMat.sum(axis=1) #跨列，按行求和
    distances = sqDistances ** 0.5 # 欧式距离
    sortedDistIndicies = distances.argsort()  # 返回数组值从小到大的索引
    # 选择距离最小的k个点
    classCount={}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel]= classCount.get(voteIlabel,0) +1
    # 排序
    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1), reverse=True)
    return sortedClassCount[0][0]
```

### 测试算法：使用k-近邻算法识别手写数字


```python
def handwriteClassTest():
    hwLabels =[]
    trainingFileList = os.listdir('./dataset/trainingDigits')
    m = len(trainingFileList)
#     print(m)
    trainingMat = np.zeros((m,1024))
    for i in range(m):
        fileNameStr = trainingFileList[i]
#         print(fileNameStr)
        fileStr = fileNameStr.split('.')[0]
#         print(fileStr)
        classNum = int(fileStr.split('_')[0])
        hwLabels.append(classNum)
        trainingMat[i,:] = img2vector('./dataset/trainingDigits/%s' % fileNameStr)
        
        
    testFileList = os.listdir('./dataset/testDigits')
    errorCount =0.0
    mTest = len(testFileList)
    for j in range(mTest):
        fileNameStr = testFileList[j]
        fileStr = fileNameStr.split('.')[0]
        classNum = int(fileStr.split('_')[0])
        vectorTest = img2vector('./dataset/testDigits/%s' % fileNameStr)
        classifierResult = classify0(vectorTest, trainingMat, hwLabels, 3)
        print("classifierResult:",classifierResult, "real answer:",classNum)
        if (classifierResult != classNum):
            errorCount += 1.0
    print("正确率:",1.0-errorCount/float(mTest))
        
```


```python
handwriteClassTest()
```

    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 3 real answer: 3
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 9 real answer: 9
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 3 real answer: 8
    classifierResult: 9 real answer: 9
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 9 real answer: 9
    classifierResult: 3 real answer: 3
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 1 real answer: 1
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 9 real answer: 9
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 9 real answer: 9
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 9 real answer: 9
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 9 real answer: 9
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 9 real answer: 9
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 9 real answer: 9
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 6 real answer: 6
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 6 real answer: 6
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 8
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 6 real answer: 6
    classifierResult: 3 real answer: 3
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 7 real answer: 1
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 4 real answer: 4
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 3 real answer: 3
    classifierResult: 6 real answer: 6
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 8 real answer: 8
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 6 real answer: 6
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 0 real answer: 0
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 4 real answer: 4
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 6 real answer: 6
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 6 real answer: 6
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 6 real answer: 6
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 6 real answer: 6
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 4 real answer: 4
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 6 real answer: 6
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 1 real answer: 1
    classifierResult: 9 real answer: 9
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 6 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 3 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 1 real answer: 1
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 5 real answer: 5
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 1 real answer: 1
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 3 real answer: 3
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 8 real answer: 8
    classifierResult: 9 real answer: 9
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 9 real answer: 9
    classifierResult: 8 real answer: 8
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 1 real answer: 1
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 5 real answer: 5
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 1 real answer: 1
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 6 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 6 real answer: 6
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 3 real answer: 3
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 1 real answer: 1
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 5 real answer: 5
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    classifierResult: 4 real answer: 4
    classifierResult: 5 real answer: 5
    classifierResult: 1 real answer: 1
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 4 real answer: 4
    classifierResult: 0 real answer: 0
    classifierResult: 9 real answer: 9
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 3 real answer: 3
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 1 real answer: 1
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 6 real answer: 6
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 6 real answer: 6
    classifierResult: 1 real answer: 1
    classifierResult: 8 real answer: 8
    classifierResult: 1 real answer: 1
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 2 real answer: 2
    classifierResult: 2 real answer: 2
    classifierResult: 5 real answer: 5
    classifierResult: 5 real answer: 5
    classifierResult: 9 real answer: 9
    classifierResult: 3 real answer: 3
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 9 real answer: 9
    classifierResult: 0 real answer: 0
    classifierResult: 0 real answer: 0
    classifierResult: 4 real answer: 4
    classifierResult: 9 real answer: 9
    classifierResult: 7 real answer: 7
    classifierResult: 7 real answer: 7
    classifierResult: 1 real answer: 1
    classifierResult: 5 real answer: 5
    classifierResult: 4 real answer: 4
    classifierResult: 3 real answer: 3
    classifierResult: 3 real answer: 3
    正确率: 0.9883720930232558


#### 代码示意：
- 这段代码的主要功能是从os模块中导入函数listdir，它可以列 出给定目录的文件名。
- 将trainingDigits目录中的文件内容存储在列表中 ，然后可以得到目录中有多少文件，并将其存储在变量m中。
- 接着，代码创建一个m行1024列的训练矩阵，该矩阵的每行数 据存储一个图像。
- 我们可以从文件名中解析出分类数字 。该目录下的文件按照规则命名，如文件 9_45.txt的分类是9，它是数字9的第45个实例。
- 然后我们可以将类代码存储在hwLabels向量中，使 用前面讨论的img2vector函数载入图像。
- 在下一步中，我们对testDigits目录中的文件执行相似的操作，不同之处是我们并不将这个目录下的文件载入矩阵中，而是使用classify0()函数测试该 目录下的每个文件


```python

```



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>k-近邻</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习笔记——序言</title>
    <url>/2018/11/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%BA%8F%E8%A8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 序言

> 纸上得来终觉浅，绝知此事要躬行。
>

> 与其设计一个解决问题的程序，不如从最终需求入手来寻找一个解决方案。



### 核心思想：用数据编程

目前机器学习和深度学习应用共同的核心思想：用数据编程。

- 机器学习
  - 讨论各式各样适用于不同问题的函数形式
  - 如何使用数据来有效的获取函数参数具体价值
  - 深度学习是机器学习中的一类函数，形式通常为多层神经网络

- 深度学习处理复杂高纬度数据
  - 处理图像
  - 文本预料
  - 声音信号
  - ......



### 起源

自古以来，人类一直渴望从数据中分析出预知未来的窍门。

数据分析正是大部分自然科学的本质，从日常观测中提取规则，并找寻不确定性。



- 历史渊源
  - 雅各比·伯努利（1655–1705）提出了描述只有两种结果的随机过程（例如抛掷⼀枚
    硬币）的伯努利分布
  - 卡尔·弗里德里希·高斯（1777–1855）发明了今日仍广泛使用在从保险计算到医学诊断等领域的最小二乘法
  - 雅各比·科贝尔（1460–1533）的几何书中记载了使用16 名男子的平均脚长来估计男子的平均脚长
  - 罗纳德·费雪（1890–1962）对于统计学理论和统计学在基因学中的应⽤功不可没。他发明的许多算法和公式，例如线性判别分析和费雪信息仍经常被使用。即使是他在1936 年发布的Iris 数据集，仍然偶尔被用于演示机器学习算法
  - 克劳德·香农（1916–2001）的信息论以及阿兰·图灵（1912–1954）的计算理论也对机器学习有深远影响。图灵在他著名的论文《计算机器与智能》中提出了“机器可以思考吗？“
  - 唐纳德·赫布（1904–1985）在他开创性的著作《行为的组织》中，他提出神经是通过正向强化来学习的，即赫布理论。赫布理论是感知机学习算法的原型，并成为支撑今日深度学习的许许多多的随机梯度下降算法的基石：
    - 强化合意的行为、惩罚不合意的行为，最终获得优良的神经网络参数
  - 亚历山大·贝恩（1818–1903）和查尔斯·斯科特·谢灵顿（1857–1952）。研究者们尝试组建模仿神经元互动的计算电路。随着时间发展，神经网络的生物学解释被稀释，但仍保留了这个名字。时至今日，绝大多数神经网络都包含以下的核心原则：
    -  交替使用线性与非线性处理单元，经常被称为“层”
    - 使用链式法则（即反向传播）来更新网络的参数





### 发展



| 年代 | 数据样本个数         | 内存   | 每秒浮点计算数      |
| ---- | -------------------- | ------ | ------------------- |
| 1970 | 100（Iris）          | 1 KB   | 100 K（Intel 8080） |
| 1980 | 1 K（波士顿房价）    | 100 KB | 1 M（Intel 80186）  |
| 1990 | 10 K（手写字符识别） | 10 MB  | 10 M（Intel 80486） |
| 2000 | 10 M（网页）         | 100 MB | 1 G（Intel Core）   |
| 2010 | 10 G（广告）         | 1 GB   | 1 T（Nvidia C2050） |
| 2020 | 1 T（社交网络）      | 100 GB | 1 P（Nvidia DGX-2） |



很显然，存储容量没能跟上数据量增⻓的步伐。与此同时，计算力的增长盖过了数据量的增长。
这样的趋势使得统计模型可以在优化参数上投资更多的计算力量，但同时需要提高存储的利用效
率，例如使用非线性单元。这也相应导致了机器学习和统计学的最优选择从广义线性模型及核心
法变化为深度多层神经⽹络。这样的变化正是诸如多层感知机、卷积神经网络、长短期记忆循环
神经网络和Q- 学习等深度学习的支柱模型在过去十年从坐了数十年的冷板凳上站起来被“重新
发现”的原因。



###  特点



- 人工智能

  - 机器学习

    *研究范围*：如何利用既有的经验或知识使得计算机系统能够以更接近人类的方式处理问题

    *表征学习*：如何自动找出表示数据的合适方式，以便更好的将输入变换为正确的输出

    - 深度学习

      *具有多级表示的表征学习方法，由许多简单函数复合而成的函数，可以逐级表示越来越抽象的概念或模式*

      - 端到端的训练
      - 对非最优解的包容
      - 对非凸非线性优化的使用
      - 勇于尝试没有被证明过的方法



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈用户画像</title>
    <url>/2020/02/08/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 什么是用户画像？

**维基百科定义**

- A user profile is a visual display of personal data associated with a specific user, or a customized desktop environment
- 用户画像就是与该用户相关联的数据的可视化展现；即：用户信息标签化

**偏技术的定义**

- 海量的数据标签，根据用户的目标、行为和观点的差异区分为不同的类型

**常见的用户画像维度**

![img](https://pic1.zhimg.com/80/v2-ff0918f10a2ee07cfb6abed3045d5ae4_1440w.jpg)

**金融用户评级画像**

![img](https://pic3.zhimg.com/80/v2-5b729e6a291e558fdb9461feb7acddee_1440w.jpg)

**群体维度常见的画像-今日头条**

![img](https://pic2.zhimg.com/80/v2-8e062c70de9c41dd0d16aca01f83c731_1440w.jpg)

## 为什么要做用户画像？

### 宏观

#### 构建具象认知，构建战略、战术方向

- 为了在核心用户上达成统一 具象的认知，方便后期有的放矢
- 根据用户画像信息做产品设计，了解用户行为偏好

#### 探索用户足迹，用户市场导向

- 详细了解真实用户是如何 与产品及相关内容进行互动的
- 从业务场景出发，解决实际的业务问题，针对用户生命周期的不同状态进行产品设计

### 微观

#### 构建底层数据基础，服务上层应用

- 用户画像可作为推荐系统（广告、搜索系统）重要一环

#### 方便信息的处理

有了标签后计算机可以方便的处理各个量化需求

- 统计分类
- 数据挖掘

## 如何构建用户画像

### 构建用户静态/动态数据

#### 静态数据-评估价值

用户相对稳定的信息，此类信息自成标签，如果已有真实信息则无需过多的建模预测，更多的是数据清洗；如果静态信息不准或缺失则需要建模预测

- 人口属性
  - 性别
  - 年龄
  - 地域
- 商业属性
  - 收入
  - 职业
- 消费意向
  - 风险评估状态
- 生活型态
- CRM
  - 客户状态
  - 会员状态
  - 生命价值

![img](https://pic4.zhimg.com/80/v2-eae3496af324a1b8a06b2711c6a7e1e7_1440w.jpg)

#### 动态数据-循迹

用户不断变化的行为信息

- 场景
  - 访问设备
  - 访问时段
- 媒体
  - 访问媒体
  - 访问页面
  - 访问时长
  - 访问频次
- 路径
  - 流量来源
  - 流量去向

![img](https://pic2.zhimg.com/80/v2-b1d65ead43e546dc6ede2ba011bd4919_1440w.jpg)

### 标签与权重

用户画像的最终形态：通过分析用户行为，最终为每个用户打上标签，以及该标签的权重

#### 标签

表征了内容，用户对该内容有兴趣、偏好、需求等

#### 权重

表征了指数，用户的兴趣、偏好指数； 也可能表征用户的需求度

### 数据建模方法

标签= 用户标识 + 时间 + 行为类型 +接触点的聚合，某用户因为在什么时间、什么地点、做了什么事，所以会打上标签

#### 事件模型

收集用户行为，并结合上下文构建事件模型，5W

- who，唯一的用户标识
- when，时间因素
- where，地理位置
- what，交互的内容/商品
- which ，用户的行为（点击，浏览，购买，观看……）

#### 整体思考建模

用户标签的权重是会随着时间的增加而衰减

- 时间为衰减因子r，影响权重，每天衰减为昨天的r倍
- 行为类型、接触点决定权重
- 内容类型决定标签

用户偏好某内容的标签 = 衰减因子 * 行为类型权重 * 接触点权重

## 算法路线及常用算法模型

![img](https://pic2.zhimg.com/80/v2-e5938de15feb64394ed639785bf0ceb1_1440w.jpg)

## 算法处理评估流程图

![img](https://pic3.zhimg.com/80/v2-303e5268a3652315d147752bb17332f6_1440w.jpg)

## 算法架构图

![img](https://pic2.zhimg.com/80/v2-6a9b3eb0faa5d9bbfced5ff96820f8a9_1440w.jpg)

## 标签层级

![img](https://pic3.zhimg.com/80/v2-617bf8844eb1f75d3e50a5f49e10aad6_1440w.jpg)


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据</category>
        <category>用户画像</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据</tag>
        <tag>用户画像</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习笔记——线性回归的从零开始实现</title>
    <url>/2018/11/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%BA%BF%E5%BD%A2%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习笔记——线性回归</title>
    <url>/2018/11/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


*深度学习通过基于神经网络模型逐级表示越来越抽象的概念或模式*

**单层神经网络：线性回归、Softmax回归**

线性回归输出是一个连续值，适用于回归问题。

​	如：预测房屋价格、气温、销售额等连续值问题

Softmax回归适用于分类问题，分类问题中的模型最终输出是一个离散值。

​	如：图像分类、垃圾邮件识别、疾病检测等输出离散值

## 线性回归



### 线性回归基本要素

以房屋价格预测为例：假设价格只取决于  面积（平方米） 和房龄（年）

#### 模型

设房屋面积为x1 ,房龄为x2 ， 售出价格为y 。建立基于输入x1, x2来计算输出y的表达式，即——模型（Model）

线性回归假设输出与各个输入之间的线性关系：

y‘ = x1w1 + x2w2 + b;

其中w1;w2 是权重（weight），b 是偏差（bias），且均为标量;是线性回归模型的参数（parameter）；模型输出y'是线性回归对真实价格y的预测／估计 



#### 模型训练

模型训练（model training）：通过数据寻找特定的模型参数值，使得模型在数据上误差尽可能小。

##### 训练数据

- 训练数据集（training data set ）/ 训练集（training set）

  多栋房屋数据，真实出售价格 、面积、房龄

- 样本（sample）

  一栋房屋

- 标签（label）

  真实出售价格

- 特征（feature）

  预测标签的两个因素叫做特征；（面积、房龄）

  特征用来表征样本的特点



##### 损失函数

- 衡量价格测量值与真实值之间的误差
- 通常选取一个非负数作为误差，且数值越小表示误差越小

##### 优化算法

- 解析解（analytical solution）
  - 当模型和损失函数较为简单时，误差最小化问题的解可直接用公式表达出来
- 数值解（numerical solution）
  - 大多数深度学习模型没有解析解，只能通过优化算法有限次迭代模型参数 来尽可能降低损失函数的值
  - 常用：小批量随机梯度下降（ mini-batch stochastic gradient descent）
    - 选取一组模型参数的初始值
    - 对参数进行多次迭代，使得每次迭代都可能降低损失函数的值
    - 每次迭代流程
      - 先随机均匀采样 一个由固定数目训练数据样本所组成的小批量（mini-batch）B
      - 求小批量中数据样本的平均损失有关模型参数的导数（梯度）
      - 用此结果与 预先设定的一个 正数的乘积 作为模型参数在本次迭代的减小量

#### 模型预测

*模型预测、模型推断或模型测试*

 模型训练完成后，将模型参数w1;w2; b  在优化算法停⽌时的值分别记作^ w1; ^ w2;^b 。注意这⾥我们并不⼀定得到了最小化损失函数的最优解w1;w2; b ，而是对最优解的⼀个近似。

然后，就可以使⽤学出的线性回归模型x1 ^ w1 +x2 ^ w2 +^b 来估算训练数据集以外任意⼀栋⾯积（平⽅⽶）房屋的价格了。



### 线性回归的表示方法

线性回归与神经⽹络的联系，以及线性回归的⽮量计算表达式。

#### 神经网络图

#### 矢量计算表达式

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>渠道类指标详解</title>
    <url>/2019/05/19/%E6%B8%A0%E9%81%93%E7%B1%BB%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


**1)本渠道全新用户** 
**解释**：首次在该渠道下载APP并激活的新用户数，并且以前从未在其他渠道下载过此APP（与全部用户进行去重） 
**实例**：若用户第一次下载安装应用是通过A渠道，启动后弹出提示升级到新版本，于是用户选择升级新版本，但是升级包属于B渠道下载的，升级完成后再启动一次。那么，该用户在A渠道算作是该渠道的全新用户，但在B渠道就不算是全新用户了。启动数据会分别在A渠道和B渠道各增加一次。 
**2）激活** 
**解释**：用户下载安装APP之后，第一次启动应用算作激活 
**实例**：若用户只是下载并安装了APP而没有点击APP启动，不算作是激活 
**3）升级用户** 
**解释**：该版本累计新用户中，从历史版本中升级到所选版本的用户个数 
**实例**：若1个用户从3.0版本升级到3.1版本，1个用户从2.0版本升级到3.1版本，那么对于3.1版本中的升级用户数为2。原理是通过设备识别号来定位用户，比对用户当前版本号和历史版本号之间的差异。 
**4）某版本全新用户** 
**解释**：累计新用户数 – 升级用户数 
**实例**：某版本的累计新用户数若为100，该版本的升级用户数为30，那么该版本的全新用户数就为100-30=70人。 
**5）初始渠道URL** 
**解释**：渠道商提供给开发者的应用程序下载链接地址 
**实例**：这里说的应用程序下载地址是指能够精确到应用程序APK安装包的那个链接地址，而不是包含安装包的页面的链接地址。 
**6）生成渠道URL** 
**解释**：将初始URL输入“渠道来源管理”界面，然后点击由百度移动统计生成渠道URL，再将渠道URL提供给渠道商替换原始URL，即可对渠道来源进行细分统计了 
**7）渠道来源激活量** 
**解释**：所选时段内，可追溯渠道来源的激活量。激活意为下载并第一次启动 
**8）转化率** 
**算法**：激活量/去重点击量 
**实例**：若1月份内，可追溯到渠道来源的激活数量为50，经过去重的点击量为100，那么1月份的转化率为50/100=50%


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据产品</category>
        <category>数据指标</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据指标</tag>
      </tags>
  </entry>
  <entry>
    <title>用户体验地图</title>
    <url>/2019/01/06/%E7%94%A8%E6%88%B7%E4%BD%93%E9%AA%8C%E5%9C%B0%E5%9B%BE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>

## 概述

用户体验地图（User Experience Map），也被叫 User/CustomerJourney Map，它是用户增长策略体系的一部分，是产品优化的重要工具。

它从用户视角了解产品流程，可以帮助我们找到用户的痛点、发现产品存在问题的阶段，从而有的放矢地进行优化，因此它更适用于产品从1-∞的阶段（0-1阶段的产品的用户是虚拟的、数据是缺失的，因此整个体验地图可靠性低）。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-3.jpg)



△ Crash-Course-CX



## 组成

一个标准的用户体验地图一般包含以下三大组成部分：

- 用户：用户画像（persona）、用户目标（user goals/needs）；
- 用户和产品：用户行为（doing）、触点（touch point）、想法（thinking）、情绪曲线（feeling/experience）；
- 产品机会：痛点（pain point）、机会点（opportunities）。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-8.jpg)



△ 三大部分



如下图，raileurope体验地图，它的时间比较早，但因为非常全面和标准，包含体验地图相关的所有要素，至今仍然被各大公司当作参照的模板。

原版是英文，为了方便大家理解和参考，我把这个体验地图做了汉化。

因为完成体验地图整个步骤耗时长，时间成本和人力成本高。它比较适合用来梳理产品的整体流程线和主业务线。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-10.jpg)

△ 欧洲铁路体验地图-标准版

当然，上面的3大部分内容不一定都是必须的，体验地图也可以根据需求进行简化。它适用于周期短、团队人员有限、分析产品业务支线的需求。

就如同 Airtable 的这个体验地图，直接分析用户的痛点和情绪，直接梳理用户的痛点、接触点、情绪，以表格的形式呈现。



![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-7.jpg)

△ airtable体验地图-简化版

## 为什么要做用户体验地图？



- 避免产品设计者和决策者的管理员视角，真正考虑用户要什么，而不是有什么放什么。
- 能够帮助我们梳理场景中可能存在的问题，精准地找到用户的痛点，对产品优化更加有的放矢，提升用户体验。
- 创建一个共同视角，团队中各环节的同事都能参与进来，对用户行为、痛点等内容达成一致，认同感强。利于各个环节工作的协调，对产品的用户体验达成共识、有效沟通和协作。





![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-6.jpg)



△ 用户体验地图-模板



## 如何绘制用户体验地图？



### **1. 用户画像**

本次主要通过途家的案例来示范如何制作一个标准的用户体验地图。

在产品的1-∞阶段，通常团队内已经有构建好的用户画像，所以直接调用即可。

注意：如果产品的用户层跨度大，那么需要对不同的用户类型分别做体验地图。

### **2. 用户目标**

明确用户要完成的任务或者目标。在案例中，用户的目标就是在整个订房流程中，他的要求，或者说需求。列出用户目标，可以让我们真正考虑用户在每个环节，想要的是什么。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-5.jpg)

△ 明确用户目标

### **3. 提炼用户行为**

用户行为是用户在使用产品时采取的行为、操作，通常是根据用户调研、用户追踪的资料进行收集整理。用户行为讲述的是每一个阶段用户的执行细节。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-1.jpg)

△ 梳理用户行为

### **4. 用户想法和情绪曲线**

根据对应的阶段的用户行为，写下当时用户的思考和想法，可以将它们以便利贴的形式整理出来。

然后提炼用户每个节点的情绪，提炼情绪时，为了防止个人主观判断导致的误差，建议两个人一组用相同的数据进行提炼。





![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-9.jpg)



△ 绘制情绪曲线



### **5. 归纳痛点和机会点**

通过用户每个阶段的行为和情绪曲线，整理出每个阶段的痛点和问题，以及思考痛点背后的原因，此处是否可以采取什么措施，来满足用户的目标，提升用户的体验，这就是机会点。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-2.jpg)

△ 归纳痛点

### **6. 后续工作**

后续的工作首先是对体验地图进行整理和美化产出。然后整理出地图中的机会点，根据重要程度和难易程度排出优先级来安排执行。优化用户体验地图中的痛点，帮助用户实现目标，或者确立新的产品功能的方向。

![img](https://image.uisdc.com/wp-content/uploads/2019/01/uisdc-yh-20190103-4.jpg)

△ 用户体验地图示例-途家


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>用户体验</category>
      </categories>
      <tags>
        <tag>用户体验</tag>
      </tags>
  </entry>
  <entry>
    <title>案例-基于关联规则算法实现电影推荐系统</title>
    <url>/2021/01/02/%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8E%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


### 基于关联规则算法实现电影推荐系统

![image.png](attachment:8bf77266-511e-4e87-bcf0-a2b5340a7f20.png)

- 利用数据挖掘算法中的Apriori(关联规则)算法来实现一个电影推荐系统
  - 加载数据
  - 数据预处理
  - 生成频繁项集、关联规则
- 通过关联规则生成电影推荐的列表

### Apriori算法

- **案例：** 
  啤酒与尿布:  沃尔玛超市在分析销售记录时，发现了啤酒与尿布经常一起被购买，于是他们调整了货架将两者放在了一起，结果真的提升了啤酒的销量。  原因解释: 爸爸在给宝宝买尿布的时候，会顺便给自己买点啤酒？

- **概述：**
  Apriori算法是一种最有影响力的挖掘布尔关联规则的频繁项集的算法，其命名Apriori源于算法使用了频繁项集性质的先验(Prior)知识。
   接下来我们将以超市订单的例子理解关联分析相关的重要概念: Support(支持度)、Confidence(置信度)、Lift(提升度）。

  ![image.png](attachment:e0663e25-d0d7-4ee0-a2db-857a92930475.png)

  - Support(支持度)：指某事件出现的概率，在本例中即指某个商品组合出现的次数占总次数的比例。

  例：Support('Bread') = 4/5 = 0.8 Support('Milk') = 4/5 = 0.8
     Support('Bread+Milk') = 3/5 = 0.6  

  - Confidence(置信度)：本质上是个条件概率，即当购买了商品A的前提下，购买商品B的概率。

  例：Confidence('Bread'—> 'Milk') = Support('Bread+Milk')/ Support('Bread') = 0.6/0.8 = 0.75  

  - Lift(提升度）: 指商品A的出现，对商品B的出现的概率的提升程度。Lift(A->B) = Confidence(A, B) / Support(B)

  例：Lift('Bread'—> 'Milk') = 0.75/0.8 = 0.9375 

- **对于Lift(提升度）有三种情况：**

  - Lift(A->B)>1: 代表A对B的出现概率有提升。
  - Lift(A->B)=1: 代表A对B的出现概率没有提升，也没有下降。
  - Lift(A->B)<1: 代表a对b的出现概率有下降效果。 - **原理：** 该算法挖掘关联规则的过程，即是查找频繁项集(frequent itemset)的过程: 频繁项集：支持度大于等于最小支持度(min support)阈值的项集。 非频繁集：支持度小于最小支持度的项集。 **流程：** k="1," 计算k项集的支持度； 筛选掉小于最小支持度的项集； 如果项集为空，则对应k-1项集的结果为最终结果。否则k="K+1重复2-3步" ```python import pandas as pd matplotlib.pyplot plt mlxtend numpy np ``` #### 电影数据准备 movie_data_file="./movie_dataset/movies_metadata.csv" ratings_file="./movie_dataset/ratings_small.csv" movie_data_df="pd.read_csv(movie_data_file)" ratings_df="pd.read_csv(ratings_file)" c:\users\ysilhouette\documents\pyenv\py3.6.5\lib\site-packages\ipython\core\interactiveshell.py:3072: dtypewarning: columns (10) have mixed types.specify dtype option on or set low_memory="False." interactivity="interactivity," compiler="compiler," result="result)" movie_data_df.head(5) <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>adult</th>
      <th>belongs_to_collection</th>
      <th>budget</th>
      <th>genres</th>
      <th>homepage</th>
      <th>id</th>
      <th>imdb_id</th>
      <th>original_language</th>
      <th>original_title</th>
      <th>overview</th>
      <th>...</th>
      <th>release_date</th>
      <th>revenue</th>
      <th>runtime</th>
      <th>spoken_languages</th>
      <th>status</th>
      <th>tagline</th>
      <th>title</th>
      <th>video</th>
      <th>vote_average</th>
      <th>vote_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>
      <td>30000000</td>
      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>
      <td>http://toystory.disney.com/toy-story</td>
      <td>862</td>
      <td>tt0114709</td>
      <td>en</td>
      <td>Toy Story</td>
      <td>Led by Woody, Andy's toys live happily in his ...</td>
      <td>...</td>
      <td>1995-10-30</td>
      <td>373554033.0</td>
      <td>81.0</td>
      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>
      <td>Released</td>
      <td>NaN</td>
      <td>Toy Story</td>
      <td>False</td>
      <td>7.7</td>
      <td>5415.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>NaN</td>
      <td>65000000</td>
      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>
      <td>NaN</td>
      <td>8844</td>
      <td>tt0113497</td>
      <td>en</td>
      <td>Jumanji</td>
      <td>When siblings Judy and Peter discover an encha...</td>
      <td>...</td>
      <td>1995-12-15</td>
      <td>262797249.0</td>
      <td>104.0</td>
      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>
      <td>Released</td>
      <td>Roll the dice and unleash the excitement!</td>
      <td>Jumanji</td>
      <td>False</td>
      <td>6.9</td>
      <td>2413.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>False</td>
      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>
      <td>0</td>
      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>
      <td>NaN</td>
      <td>15602</td>
      <td>tt0113228</td>
      <td>en</td>
      <td>Grumpier Old Men</td>
      <td>A family wedding reignites the ancient feud be...</td>
      <td>...</td>
      <td>1995-12-22</td>
      <td>0.0</td>
      <td>101.0</td>
      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>
      <td>Released</td>
      <td>Still Yelling. Still Fighting. Still Ready for...</td>
      <td>Grumpier Old Men</td>
      <td>False</td>
      <td>6.5</td>
      <td>92.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>NaN</td>
      <td>16000000</td>
      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>
      <td>NaN</td>
      <td>31357</td>
      <td>tt0114885</td>
      <td>en</td>
      <td>Waiting to Exhale</td>
      <td>Cheated on, mistreated and stepped on, the wom...</td>
      <td>...</td>
      <td>1995-12-22</td>
      <td>81452156.0</td>
      <td>127.0</td>
      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>
      <td>Released</td>
      <td>Friends are the people who let you be yourself...</td>
      <td>Waiting to Exhale</td>
      <td>False</td>
      <td>6.1</td>
      <td>34.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>
      <td>0</td>
      <td>[{'id': 35, 'name': 'Comedy'}]</td>
      <td>NaN</td>
      <td>11862</td>
      <td>tt0113041</td>
      <td>en</td>
      <td>Father of the Bride Part II</td>
      <td>Just when George Banks has recovered from his ...</td>
      <td>...</td>
      <td>1995-02-10</td>
      <td>76578911.0</td>
      <td>106.0</td>
      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>
      <td>Released</td>
      <td>Just When His World Is Back To Normal... He's ...</td>
      <td>Father of the Bride Part II</td>
      <td>False</td>
      <td>5.7</td>
      <td>173.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>






```python
movie_data_df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>revenue</th>
      <th>runtime</th>
      <th>vote_average</th>
      <th>vote_count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>4.546000e+04</td>
      <td>45203.000000</td>
      <td>45460.000000</td>
      <td>45460.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.120935e+07</td>
      <td>94.128199</td>
      <td>5.618207</td>
      <td>109.897338</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.433225e+07</td>
      <td>38.407810</td>
      <td>1.924216</td>
      <td>491.310374</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000e+00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000e+00</td>
      <td>85.000000</td>
      <td>5.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000e+00</td>
      <td>95.000000</td>
      <td>6.000000</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.000000e+00</td>
      <td>107.000000</td>
      <td>6.800000</td>
      <td>34.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.787965e+09</td>
      <td>1256.000000</td>
      <td>10.000000</td>
      <td>14075.000000</td>
    </tr>
  </tbody>
</table>

</div>




```python
movie_data_df.info
```




    <bound 0 1 2 3 4 24 50 862 8844 11862 15602 31357 45461 45462 45463 45464 45465 67758 111109 227506 439050 461257 16000000 30000000 65000000 method dataframe.info of adult belongs_to_collection budget \ false {'id': 10194, 'name': 'toy story collection', ... nan 119050, 'grumpy old men collect... 96871, 'father the bride col... genres [{'id': 16, 'animation'}, 35, '... 12, 'adventure'}, 14, 10749, 'romance'}, 'comedy'}, 18, 'nam... 'comedy'}] 'drama'}, 10751, 'n... 'drama'}] 28, 'action'}, [] homepage id imdb_id http: toystory.disney.com toy-story tt0114709 tt0113497 tt0113228 tt0114885 tt0113041 www.imdb.com title tt6209470 tt2028550 tt0303758 tt0008536 tt6980792 original_language original_title en toy jumanji grumpier waiting to exhale father part ii fa رگ خواب tl siglo ng pagluluwal betrayal satana likuyushchiy queerama overview release_date led by woody, andy's toys live happily in his 1995-10-30 when siblings judy and peter discover an encha... 1995-12-15 a family wedding reignites ancient feud be... 1995-12-22 cheated on, mistreated stepped wom... just george banks has recovered from 1995-02-10 rising falling between man woman. artist struggles finish work while a... 2011-11-17 one her hits goes wrong, professiona... 2003-08-01 small town two brothers, minis... 1917-10-21 years after decriminalisation homosexual... 2017-06-09 revenue runtime spoken_languages 373554033.0 81.0 [{'iso_639_1': 'en', 'english'}] 262797249.0 104.0 'english'}, {'iso... 0.0 101.0 81452156.0 127.0 76578911.0 106.0 90.0 'fa', 'فارسی'}] 360.0 'tl', ''}] 87.0 75.0 status tagline released roll dice unleash excitement! still yelling. fighting. ready for... friends are people who let you be yourself... world is back normal... he's woman deadly game wits. video vote_average vote_count 7.7 5415.0 6.9 2413.0 6.5 92.0 6.1 34.0 5.7 173.0 subdue 4.0 1.0 century birthing 9.0 3.0 3.8 6.0 satan triumphant [45466 rows x columns]>




```python
movie_data_df.count()
```




    adult                    45466
    belongs_to_collection     4494
    budget                   45466
    genres                   45466
    homepage                  7782
    id                       45466
    imdb_id                  45449
    original_language        45455
    original_title           45466
    overview                 44512
    popularity               45461
    poster_path              45080
    production_companies     45463
    production_countries     45463
    release_date             45379
    revenue                  45460
    runtime                  45203
    spoken_languages         45460
    status                   45379
    tagline                  20412
    title                    45460
    video                    45460
    vote_average             45460
    vote_count               45460
    dtype: int64




```python
movie_data_df.columns
```




    Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',
           'imdb_id', 'original_language', 'original_title', 'overview',
           'popularity', 'poster_path', 'production_companies',
           'production_countries', 'release_date', 'revenue', 'runtime',
           'spoken_languages', 'status', 'tagline', 'title', 'video',
           'vote_average', 'vote_count'],
          dtype='object')




```python
ratings_df.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>31</td>
      <td>2.5</td>
      <td>1260759144</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1029</td>
      <td>3.0</td>
      <td>1260759179</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1061</td>
      <td>3.0</td>
      <td>1260759182</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1129</td>
      <td>2.0</td>
      <td>1260759185</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1172</td>
      <td>4.0</td>
      <td>1260759205</td>
    </tr>
  </tbody>
</table>

</div>




```python
ratings_df.columns
```




    Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')




```python
ratings_df.count()
```




    userId       100004
    movieId      100004
    rating       100004
    timestamp    100004
    dtype: int64




```python
ratings_df.shape
```




    (100004, 4)




```python
movie_data_df.shape
```




    (45466, 24)



#### 数据预处理

- 缺失值处理
- 数据去重
- 电影源信息 merge 电影评分信息


```python
movie_data_df_t=movie_data_df[['title','id']]
```


```python
movie_data_df_t.dtypes
```




    title    object
    id       object
    dtype: object




```python
ratings_df_s = ratings_df.drop(['timestamp'], axis=1)  #axis=0 跨列删除行 ，axis=1 跨行删除列
```


```python
ratings_df_s.dtypes
```




    userId       int64
    movieId      int64
    rating     float64
    dtype: object



##### 缺失值处理

- pandas中用NaN(Not a Number)表示浮点数和非浮点数数组中的缺失值，同时python中None值也被当作缺失值。


```python
# pd.to_numeric 将id列 的数据 由字符串转为数值类型， 不能转换的数据设置为NaN
pd.to_numeric(movie_data_df_t['id'],errors='coerce')
```




    0           862.0
    1          8844.0
    2         15602.0
    3         31357.0
    4         11862.0
               ...   
    45461    439050.0
    45462    111109.0
    45463     67758.0
    45464    227506.0
    45465    461257.0
    Name: id, Length: 45466, dtype: float64




```python
#np.where返回满足（）内条件的数据所在的位置
np.where(pd.to_numeric(movie_data_df_t['id'], errors='coerce').isna()) #返回缺失值的位置，其中isna() 对于NaN返回True，否则返回False
```




    (array([19730, 29503, 35587], dtype=int64),)



- **loc works on labels in the index.**
  - loc为Selection by Label函数，即为按标签取数据，标签是什么，就是上面的’0’~‘4’, ‘A’~‘B’。
  - 例如第一个参数选择index，第二个参数选择column 
  - ![image.png](attachment:32ceb63e-c986-499e-93f8-638b54d1359c.png)
  - 建议写df.loc[0, :]，这样可以清楚的看出为第0行的所有记录，同样如果取第’A’列的所有记录，可以写df.loc[:, ‘A’]，如下图：
  - ![image.png](attachment:6fdd7eed-bc5c-4fa4-8c63-9072c99b5340.png)
  - :表示所有，[]里边为先行后列
- **iloc works on the positions in the index (so it only takes integers).**
  - iloc函数为Selection by Position，即按位置选择数据，即第n行，第n列数据，只接受整型参数, 比如 0:2为左闭右开区间，即取0，1
  - ![image.png](attachment:328215b9-7799-4763-b611-8b27a8340c20.png)
  - 若要取第一列的所有数据，则为df.iloc[:, 0]，不接受’A’作为参数
  - ![image.png](attachment:3881dff3-57bd-45dd-a549-56af16b42ec5.png)


```python
movie_data_df_t.iloc[19730]
```




    title           NaN
    id       1997-08-20
    Name: 19730, dtype: object




```python
movie_data_df_t.iloc[[19730,29503,35587]]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19730</th>
      <td>NaN</td>
      <td>1997-08-20</td>
    </tr>
    <tr>
      <th>29503</th>
      <td>NaN</td>
      <td>2012-09-29</td>
    </tr>
    <tr>
      <th>35587</th>
      <td>NaN</td>
      <td>2014-01-01</td>
    </tr>
  </tbody>
</table>

</div>




```python
# 将格式转换后的数据 赋值给id列
movie_data_df_t['id'] = pd.to_numeric(movie_data_df_t['id'], errors='coerce')
```

    c:\users\ysilhouette\documents\pyenv\py3.6.5\lib\site-packages\ipykernel_launcher.py:2: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy


​    


```python
movie_data_df_t.info()
```

    <class 'pandas.core.frame.dataframe'>
    RangeIndex: 45466 entries, 0 to 45465
    Data columns (total 2 columns):
     #   Column  Non-Null Count  Dtype  
    ---  ------  --------------  -----  
     0   title   45460 non-null  object 
     1   id      45463 non-null  float64
    dtypes: float64(1), object(1)
    memory usage: 710.5+ KB



```python
movie_data_df_t.iloc[[19730,29503,35587]]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19730</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>29503</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>35587</th>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>

</div>




```python
movie_data_df_t.shape
```




    (45466, 2)




```python
movie_data_df_t.drop(np.where(movie_data_df_t['id'].isna())[0], inplace=True)
```

    c:\users\ysilhouette\documents\pyenv\py3.6.5\lib\site-packages\pandas\core\frame.py:4174: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      errors=errors,



```python
movie_data_df_t.shape
```




    (45463, 2)



##### 数据去重


```python
movie_data_df_t.duplicated(['id','title']).sum()
```




    30




```python
movie_data_df_t.drop_duplicates(['id'],inplace=True)
```

    c:\users\ysilhouette\documents\pyenv\py3.6.5\lib\site-packages\ipykernel_launcher.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      """Entry point for launching an IPython kernel.



```python
movie_data_df_t.shape
```




    (45433, 2)




```python
ratings_df_s.duplicated(['userId','movieId']).sum()
```




    0




```python
movie_data_df_t['id'] = movie_data_df_t['id'].astype(np.int64)
```

    c:\users\ysilhouette\documents\pyenv\py3.6.5\lib\site-packages\ipykernel_launcher.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      """Entry point for launching an IPython kernel.



```python
movie_data_df_t.dtypes
```




    title    object
    id        int64
    dtype: object




```python
ratings_df_s.dtypes
```




    userId       int64
    movieId      int64
    rating     float64
    dtype: object



### 数据合并


```python
# 左dataframe 和 右dataframe 根据 movieId 和 id进行合并
ratings_df_s = pd.merge(ratings_df_s,movie_data_df_t, left_on='movieId',right_on='id')
```


```python
ratings_df_s.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>title</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1371</td>
      <td>2.5</td>
      <td>Rocky III</td>
      <td>1371</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
      <td>1371</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
      <td>1371</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
      <td>1371</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
      <td>1371</td>
    </tr>
  </tbody>
</table>

</div>




```python
ratings_df_s.drop(['id'],axis=1,inplace=True)
```


```python
ratings_df_s
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1371</td>
      <td>2.5</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>44984</th>
      <td>652</td>
      <td>129009</td>
      <td>4.0</td>
      <td>Love Is a Ball</td>
    </tr>
    <tr>
      <th>44985</th>
      <td>653</td>
      <td>2103</td>
      <td>3.0</td>
      <td>Solaris</td>
    </tr>
    <tr>
      <th>44986</th>
      <td>659</td>
      <td>167</td>
      <td>4.0</td>
      <td>K-PAX</td>
    </tr>
    <tr>
      <th>44987</th>
      <td>659</td>
      <td>563</td>
      <td>3.0</td>
      <td>Starship Troopers</td>
    </tr>
    <tr>
      <th>44988</th>
      <td>665</td>
      <td>129</td>
      <td>3.0</td>
      <td>Spirited Away</td>
    </tr>
  </tbody>
</table>
<p>44989 rows × 4 columns</p>

</div>




```python
ratings_df_s.shape
```




    (44989, 4)




```python
# 有评分记录的电影的个数
len(ratings_df_s['title'].unique())
```




    2794




```python
ratings_df_s['title'].unique()
```




    array(['Rocky III', 'Greed', 'American Pie', ..., 'K-PAX',
           'Starship Troopers', 'Spirited Away'], dtype=object)




```python
ratings_df_s.groupby([ratings_df_s['title'],ratings_df_s['rating']]).count().reset_index()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>rating</th>
      <th>userId</th>
      <th>movieId</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>!Women Art Revolution</td>
      <td>3.0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>!Women Art Revolution</td>
      <td>3.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>'Gator Bait</td>
      <td>0.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>'Twas the Night Before Christmas</td>
      <td>3.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>'Twas the Night Before Christmas</td>
      <td>4.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>10263</th>
      <td>À nos amours</td>
      <td>4.0</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>10264</th>
      <td>À nos amours</td>
      <td>4.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10265</th>
      <td>À nos amours</td>
      <td>5.0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10266</th>
      <td>Ödipussi</td>
      <td>4.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10267</th>
      <td>Şaban Oğlu Şaban</td>
      <td>4.5</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>10268 rows × 4 columns</p>

</div>




```python
ratings_df_s.groupby(ratings_df_s['title']).count().reset_index()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>!Women Art Revolution</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>'Gator Bait</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>'Twas the Night Before Christmas</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>...And God Created Woman</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00 Schneider - Jagd auf Nihil Baxter</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2789</th>
      <td>xXx</td>
      <td>28</td>
      <td>28</td>
      <td>28</td>
    </tr>
    <tr>
      <th>2790</th>
      <td>¡Three Amigos!</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2791</th>
      <td>À nos amours</td>
      <td>14</td>
      <td>14</td>
      <td>14</td>
    </tr>
    <tr>
      <th>2792</th>
      <td>Ödipussi</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2793</th>
      <td>Şaban Oğlu Şaban</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>2794 rows × 4 columns</p>

</div>




```python
ratings_df_s_allcounts = ratings_df_s.groupby(ratings_df_s['title'])['userId'].count().reset_index()
```


```python
ratings_df_s_allcounts = ratings_df_s_allcounts.rename(columns = {'userId':'totalRatings'})
```


```python
ratings_df_s_allcounts
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>totalRatings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>!Women Art Revolution</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>'Gator Bait</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>'Twas the Night Before Christmas</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>...And God Created Woman</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00 Schneider - Jagd auf Nihil Baxter</td>
      <td>2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2789</th>
      <td>xXx</td>
      <td>28</td>
    </tr>
    <tr>
      <th>2790</th>
      <td>¡Three Amigos!</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2791</th>
      <td>À nos amours</td>
      <td>14</td>
    </tr>
    <tr>
      <th>2792</th>
      <td>Ödipussi</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2793</th>
      <td>Şaban Oğlu Şaban</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>2794 rows × 2 columns</p>

</div>




```python
ratings_df_s_allcounts.shape
```




    (2794, 2)




```python
ratings_df_s_allcounts['totalRatings'].describe()
```




    count    2794.000000
    mean       16.102004
    std        31.481795
    min         1.000000
    25%         1.000000
    50%         4.000000
    75%        15.750000
    max       324.000000
    Name: totalRatings, dtype: float64




```python
ratings_df_s_allcounts.hist()
```




    array([[<AxesSubplot:title={'center':'totalRatings'}>]], dtype=object)




![png](./案例-基于关联规则算法实现电影推荐系统/output_56_1.png)
    



```python
ratings_df_s_allcounts['totalRatings'].quantile(np.arange(0.6,1, 0.01)) #分位点
```




    0.60      7.00
    0.61      7.00
    0.62      7.00
    0.63      8.00
    0.64      8.00
    0.65      9.00
    0.66      9.00
    0.67     10.00
    0.68     10.00
    0.69     11.00
    0.70     12.00
    0.71     12.00
    0.72     13.00
    0.73     14.00
    0.74     14.00
    0.75     15.75
    0.76     17.00
    0.77     18.00
    0.78     19.00
    0.79     20.00
    0.80     21.00
    0.81     22.33
    0.82     24.00
    0.83     26.00
    0.84     27.00
    0.85     29.00
    0.86     31.00
    0.87     34.00
    0.88     37.00
    0.89     41.77
    0.90     45.00
    0.91     49.00
    0.92     52.56
    0.93     59.00
    0.94     64.42
    0.95     71.00
    0.96     83.28
    0.97     98.21
    0.98    119.14
    0.99    168.49
    Name: totalRatings, dtype: float64



- **从分位点数据分析可以看出，21%的电影 评分记录数超过20个**


```python
votes_count_threshold = 20
```


```python
ratings_df_s_top=ratings_df_s_allcounts.query('totalRatings > @votes_count_threshold').reset_index()
```


```python
ratings_df_s_top
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>title</th>
      <th>totalRatings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18</td>
      <td>20,000 Leagues Under the Sea</td>
      <td>89</td>
    </tr>
    <tr>
      <th>1</th>
      <td>19</td>
      <td>2001: A Space Odyssey</td>
      <td>87</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24</td>
      <td>24 Hour Party People</td>
      <td>22</td>
    </tr>
    <tr>
      <th>3</th>
      <td>26</td>
      <td>28 Days Later</td>
      <td>26</td>
    </tr>
    <tr>
      <th>4</th>
      <td>27</td>
      <td>28 Weeks Later</td>
      <td>47</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>575</th>
      <td>2770</td>
      <td>Young Adam</td>
      <td>34</td>
    </tr>
    <tr>
      <th>576</th>
      <td>2772</td>
      <td>Young Frankenstein</td>
      <td>29</td>
    </tr>
    <tr>
      <th>577</th>
      <td>2774</td>
      <td>Young and Innocent</td>
      <td>193</td>
    </tr>
    <tr>
      <th>578</th>
      <td>2781</td>
      <td>Zatoichi</td>
      <td>61</td>
    </tr>
    <tr>
      <th>579</th>
      <td>2789</td>
      <td>xXx</td>
      <td>28</td>
    </tr>
  </tbody>
</table>
<p>580 rows × 3 columns</p>

</div>




```python
ratings_df_s_top.drop(['index'],axis=1,inplace=True)
```


```python
ratings_df_s_top.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>totalRatings</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20,000 Leagues Under the Sea</td>
      <td>89</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2001: A Space Odyssey</td>
      <td>87</td>
    </tr>
    <tr>
      <th>2</th>
      <td>24 Hour Party People</td>
      <td>22</td>
    </tr>
    <tr>
      <th>3</th>
      <td>28 Days Later</td>
      <td>26</td>
    </tr>
    <tr>
      <th>4</th>
      <td>28 Weeks Later</td>
      <td>47</td>
    </tr>
  </tbody>
</table>

</div>




```python
ratings_df_s['title']
```




    0                Rocky III
    1                Rocky III
    2                Rocky III
    3                Rocky III
    4                Rocky III
                   ...        
    44984       Love Is a Ball
    44985              Solaris
    44986                K-PAX
    44987    Starship Troopers
    44988        Spirited Away
    Name: title, Length: 44989, dtype: object




```python
ratings_df_s_top['title']
```




    0      20,000 Leagues Under the Sea
    1             2001: A Space Odyssey
    2              24 Hour Party People
    3                     28 Days Later
    4                    28 Weeks Later
                       ...             
    575                      Young Adam
    576              Young Frankenstein
    577              Young and Innocent
    578                        Zatoichi
    579                             xXx
    Name: title, Length: 580, dtype: object




```python
ratings_df_s[ratings_df_s['title'].isin(ratings_df_s_top['title'])]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1371</td>
      <td>2.5</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>44507</th>
      <td>624</td>
      <td>3057</td>
      <td>4.0</td>
      <td>Frankenstein</td>
    </tr>
    <tr>
      <th>44781</th>
      <td>547</td>
      <td>97936</td>
      <td>3.0</td>
      <td>Sweet November</td>
    </tr>
    <tr>
      <th>44782</th>
      <td>624</td>
      <td>97936</td>
      <td>3.0</td>
      <td>Sweet November</td>
    </tr>
    <tr>
      <th>44909</th>
      <td>609</td>
      <td>1450</td>
      <td>5.0</td>
      <td>Blood: The Last Vampire</td>
    </tr>
    <tr>
      <th>44985</th>
      <td>653</td>
      <td>2103</td>
      <td>3.0</td>
      <td>Solaris</td>
    </tr>
  </tbody>
</table>
<p>34552 rows × 4 columns</p>

</div>




```python
ratings_df_s[ratings_df_s['title'].isin(ratings_df_s_top['title'])]  #得到评分数量大于20的
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1371</td>
      <td>2.5</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>44507</th>
      <td>624</td>
      <td>3057</td>
      <td>4.0</td>
      <td>Frankenstein</td>
    </tr>
    <tr>
      <th>44781</th>
      <td>547</td>
      <td>97936</td>
      <td>3.0</td>
      <td>Sweet November</td>
    </tr>
    <tr>
      <th>44782</th>
      <td>624</td>
      <td>97936</td>
      <td>3.0</td>
      <td>Sweet November</td>
    </tr>
    <tr>
      <th>44909</th>
      <td>609</td>
      <td>1450</td>
      <td>5.0</td>
      <td>Blood: The Last Vampire</td>
    </tr>
    <tr>
      <th>44985</th>
      <td>653</td>
      <td>2103</td>
      <td>3.0</td>
      <td>Solaris</td>
    </tr>
  </tbody>
</table>
<p>34552 rows × 4 columns</p>

</div>




```python
ratings_df_s[~ratings_df_s['title'].isin(ratings_df_s_top['title'])] # 得到评分数量小于20的
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1714</th>
      <td>2</td>
      <td>248</td>
      <td>3.0</td>
      <td>Pocketful of Miracles</td>
    </tr>
    <tr>
      <th>1715</th>
      <td>36</td>
      <td>248</td>
      <td>2.0</td>
      <td>Pocketful of Miracles</td>
    </tr>
    <tr>
      <th>1716</th>
      <td>110</td>
      <td>248</td>
      <td>4.0</td>
      <td>Pocketful of Miracles</td>
    </tr>
    <tr>
      <th>1717</th>
      <td>239</td>
      <td>248</td>
      <td>4.0</td>
      <td>Pocketful of Miracles</td>
    </tr>
    <tr>
      <th>1718</th>
      <td>242</td>
      <td>248</td>
      <td>3.0</td>
      <td>Pocketful of Miracles</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>44983</th>
      <td>652</td>
      <td>127728</td>
      <td>5.0</td>
      <td>8:46</td>
    </tr>
    <tr>
      <th>44984</th>
      <td>652</td>
      <td>129009</td>
      <td>4.0</td>
      <td>Love Is a Ball</td>
    </tr>
    <tr>
      <th>44986</th>
      <td>659</td>
      <td>167</td>
      <td>4.0</td>
      <td>K-PAX</td>
    </tr>
    <tr>
      <th>44987</th>
      <td>659</td>
      <td>563</td>
      <td>3.0</td>
      <td>Starship Troopers</td>
    </tr>
    <tr>
      <th>44988</th>
      <td>665</td>
      <td>129</td>
      <td>3.0</td>
      <td>Spirited Away</td>
    </tr>
  </tbody>
</table>
<p>10437 rows × 4 columns</p>

</div>




```python
ratings_df_s_cntD20 = ratings_df_s[ratings_df_s['title'].isin(ratings_df_s_top['title'])]
```


```python
ratings_df_s_cntX20 = ratings_df_s[~ratings_df_s['title'].isin(ratings_df_s_top['title'])]
```


```python
ratings_df_s_cntD20.shape
```




    (34552, 4)




```python
ratings_df_s_cntX20.shape
```




    (10437, 4)




```python
ratings_df_s_cntD20.isna().sum() #检查有无缺失值
```




    userId     0
    movieId    0
    rating     0
    title      0
    dtype: int64




```python
ratings_df_s_cntD20.duplicated(['userId','title']).sum()
```




    140




```python
ratings_df_s_cntD20=ratings_df_s_cntD20.drop_duplicates(['userId','title']) # 只保留每个用户对每个电影的一条评论记录
```


```python
ratings_df_s_cntD20
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1371</td>
      <td>2.5</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>3</th>
      <td>19</td>
      <td>1371</td>
      <td>4.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>4</th>
      <td>21</td>
      <td>1371</td>
      <td>3.0</td>
      <td>Rocky III</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>44506</th>
      <td>472</td>
      <td>3057</td>
      <td>3.0</td>
      <td>Frankenstein</td>
    </tr>
    <tr>
      <th>44507</th>
      <td>624</td>
      <td>3057</td>
      <td>4.0</td>
      <td>Frankenstein</td>
    </tr>
    <tr>
      <th>44782</th>
      <td>624</td>
      <td>97936</td>
      <td>3.0</td>
      <td>Sweet November</td>
    </tr>
    <tr>
      <th>44909</th>
      <td>609</td>
      <td>1450</td>
      <td>5.0</td>
      <td>Blood: The Last Vampire</td>
    </tr>
    <tr>
      <th>44985</th>
      <td>653</td>
      <td>2103</td>
      <td>3.0</td>
      <td>Solaris</td>
    </tr>
  </tbody>
</table>
<p>34412 rows × 4 columns</p>

</div>




```python
ratings_df_s_cntD20.duplicated(['userId','title']).sum()
```




    0




```python
# 将一个dataframe的记录数据整合成表格，而且是按照pivot(‘index=xx’,’columns=xx’,’values=xx’)来整合的。还有另外一种写法，就是pivot(‘索引列’，‘列名’，‘值’)。
ratings_df_s_cntD20_for_apriori = ratings_df_s_cntD20.pivot(index='userId',columns='title',values='rating')
```


```python
ratings_df_s_cntD20_for_apriori
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>title</th>
      <th>20,000 Leagues Under the Sea</th>
      <th>2001: A Space Odyssey</th>
      <th>24 Hour Party People</th>
      <th>28 Days Later</th>
      <th>28 Weeks Later</th>
      <th>300</th>
      <th>48 Hrs.</th>
      <th>5 Card Stud</th>
      <th>7 Virgins</th>
      <th>8 Women</th>
      <th>...</th>
      <th>Within the Woods</th>
      <th>X-Men Origins: Wolverine</th>
      <th>Y Tu Mamá También</th>
      <th>Yankee Doodle Dandy</th>
      <th>Yesterday</th>
      <th>Young Adam</th>
      <th>Young Frankenstein</th>
      <th>Young and Innocent</th>
      <th>Zatoichi</th>
      <th>xXx</th>
    </tr>
    <tr>
      <th>userId</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.5</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.5</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>667</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>668</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>669</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>670</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>671</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>671 rows × 580 columns</p>

</div>




```python
ratings_df_s_cntD20_for_apriori= ratings_df_s_cntD20_for_apriori.fillna(0) #缺失值 填充0
```


```python
def encode_units(x): # 有效评分规则， 1表示有效，0 表示无效
    if x <= 0 0: return if x>0:
        return 1
```


```python
ratings_df_s_cntD20_for_apriori = ratings_df_s_cntD20_for_apriori.applymap(encode_units)
```

### 计算频繁项集  和关联规则


```python
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
```


```python
ratings_df_s_cntD20_for_apriori.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>title</th>
      <th>20,000 Leagues Under the Sea</th>
      <th>2001: A Space Odyssey</th>
      <th>24 Hour Party People</th>
      <th>28 Days Later</th>
      <th>28 Weeks Later</th>
      <th>300</th>
      <th>48 Hrs.</th>
      <th>5 Card Stud</th>
      <th>7 Virgins</th>
      <th>8 Women</th>
      <th>...</th>
      <th>Within the Woods</th>
      <th>X-Men Origins: Wolverine</th>
      <th>Y Tu Mamá También</th>
      <th>Yankee Doodle Dandy</th>
      <th>Yesterday</th>
      <th>Young Adam</th>
      <th>Young Frankenstein</th>
      <th>Young and Innocent</th>
      <th>Zatoichi</th>
      <th>xXx</th>
    </tr>
    <tr>
      <th>userId</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 580 columns</p>

</div>




```python
ratings_df_s_cntD20_for_apriori.isna().sum() #检查是否有nan值
```




    title
    20,000 Leagues Under the Sea    0
    2001: A Space Odyssey           0
    24 Hour Party People            0
    28 Days Later                   0
    28 Weeks Later                  0
                                   ..
    Young Adam                      0
    Young Frankenstein              0
    Young and Innocent              0
    Zatoichi                        0
    xXx                             0
    Length: 580, dtype: int64




```python
frequent_itemsets = apriori(ratings_df_s_cntD20_for_apriori, min_support=0.10, use_colnames=True)  #生成符合条件的频繁项集
```


```python
frequent_itemsets.sort_values('support',ascending=False)  #support降序排列的频繁项集
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>support</th>
      <th>itemsets</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>111</th>
      <td>0.482861</td>
      <td>(Terminator 3: Rise of the Machines)</td>
    </tr>
    <tr>
      <th>130</th>
      <td>0.463487</td>
      <td>(The Million Dollar Hotel)</td>
    </tr>
    <tr>
      <th>105</th>
      <td>0.454545</td>
      <td>(Solaris)</td>
    </tr>
    <tr>
      <th>113</th>
      <td>0.433681</td>
      <td>(The 39 Steps)</td>
    </tr>
    <tr>
      <th>69</th>
      <td>0.408346</td>
      <td>(Monsoon Wedding)</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1613</th>
      <td>0.101341</td>
      <td>(Sleepless in Seattle, 5 Card Stud, The Tunnel)</td>
    </tr>
    <tr>
      <th>5455</th>
      <td>0.101341</td>
      <td>(Beauty and the Beast, Rain Man, Terminator 3:...</td>
    </tr>
    <tr>
      <th>5454</th>
      <td>0.101341</td>
      <td>(The Passion of Joan of Arc, Beauty and the Be...</td>
    </tr>
    <tr>
      <th>6769</th>
      <td>0.101341</td>
      <td>(The Million Dollar Hotel, The Hours, Three Co...</td>
    </tr>
    <tr>
      <th>3108</th>
      <td>0.101341</td>
      <td>(The Conversation, Men in Black II, The Millio...</td>
    </tr>
  </tbody>
</table>
<p>7327 rows × 2 columns</p>

</div>




```python
rules= association_rules(frequent_itemsets, metric="lift", min_threshold=1)  #生成关联规则，只保留lift>1的部分
rules
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>antecedents</th>
      <th>consequents</th>
      <th>antecedent support</th>
      <th>consequent support</th>
      <th>support</th>
      <th>confidence</th>
      <th>lift</th>
      <th>leverage</th>
      <th>conviction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(5 Card Stud)</td>
      <td>(48 Hrs.)</td>
      <td>0.298063</td>
      <td>0.298063</td>
      <td>0.108793</td>
      <td>0.365000</td>
      <td>1.224575</td>
      <td>0.019952</td>
      <td>1.105413</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(48 Hrs.)</td>
      <td>(5 Card Stud)</td>
      <td>0.298063</td>
      <td>0.298063</td>
      <td>0.108793</td>
      <td>0.365000</td>
      <td>1.224575</td>
      <td>0.019952</td>
      <td>1.105413</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(A Clockwork Orange)</td>
      <td>(48 Hrs.)</td>
      <td>0.152012</td>
      <td>0.298063</td>
      <td>0.102832</td>
      <td>0.676471</td>
      <td>2.269559</td>
      <td>0.057523</td>
      <td>2.169625</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(48 Hrs.)</td>
      <td>(A Clockwork Orange)</td>
      <td>0.298063</td>
      <td>0.152012</td>
      <td>0.102832</td>
      <td>0.345000</td>
      <td>2.269559</td>
      <td>0.057523</td>
      <td>1.294638</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(48 Hrs.)</td>
      <td>(A Nightmare on Elm Street)</td>
      <td>0.298063</td>
      <td>0.268256</td>
      <td>0.156483</td>
      <td>0.525000</td>
      <td>1.957083</td>
      <td>0.076526</td>
      <td>1.540513</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>75531</th>
      <td>(The Hours)</td>
      <td>(The Million Dollar Hotel, Terminator 3: Rise ...</td>
      <td>0.301043</td>
      <td>0.126677</td>
      <td>0.104322</td>
      <td>0.346535</td>
      <td>2.735585</td>
      <td>0.066187</td>
      <td>1.336449</td>
    </tr>
    <tr>
      <th>75532</th>
      <td>(Terminator 3: Rise of the Machines)</td>
      <td>(The Million Dollar Hotel, The Hours, Rain Man...</td>
      <td>0.482861</td>
      <td>0.114754</td>
      <td>0.104322</td>
      <td>0.216049</td>
      <td>1.882716</td>
      <td>0.048912</td>
      <td>1.129211</td>
    </tr>
    <tr>
      <th>75533</th>
      <td>(Rain Man)</td>
      <td>(The Million Dollar Hotel, The Hours, Terminat...</td>
      <td>0.295082</td>
      <td>0.120715</td>
      <td>0.104322</td>
      <td>0.353535</td>
      <td>2.928669</td>
      <td>0.068701</td>
      <td>1.360143</td>
    </tr>
    <tr>
      <th>75534</th>
      <td>(Sissi)</td>
      <td>(The Million Dollar Hotel, The Hours, Terminat...</td>
      <td>0.317437</td>
      <td>0.117735</td>
      <td>0.104322</td>
      <td>0.328638</td>
      <td>2.791347</td>
      <td>0.066949</td>
      <td>1.314143</td>
    </tr>
    <tr>
      <th>75535</th>
      <td>(Solaris)</td>
      <td>(The Million Dollar Hotel, The Hours, Terminat...</td>
      <td>0.454545</td>
      <td>0.113264</td>
      <td>0.104322</td>
      <td>0.229508</td>
      <td>2.026316</td>
      <td>0.052838</td>
      <td>1.150870</td>
    </tr>
  </tbody>
</table>
<p>75536 rows × 9 columns</p>

</div>




```python
rules.sort_values('lift',ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>antecedents</th>
      <th>consequents</th>
      <th>antecedent support</th>
      <th>consequent support</th>
      <th>support</th>
      <th>confidence</th>
      <th>lift</th>
      <th>leverage</th>
      <th>conviction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1473</th>
      <td>(Muxmäuschenstill)</td>
      <td>(Waiter)</td>
      <td>0.156483</td>
      <td>0.120715</td>
      <td>0.105812</td>
      <td>0.676190</td>
      <td>5.601529</td>
      <td>0.086922</td>
      <td>2.715438</td>
    </tr>
    <tr>
      <th>1472</th>
      <td>(Waiter)</td>
      <td>(Muxmäuschenstill)</td>
      <td>0.120715</td>
      <td>0.156483</td>
      <td>0.105812</td>
      <td>0.876543</td>
      <td>5.601529</td>
      <td>0.086922</td>
      <td>6.832489</td>
    </tr>
    <tr>
      <th>38208</th>
      <td>(Titanic, Big Fish)</td>
      <td>(Psycho, Rain Man)</td>
      <td>0.150522</td>
      <td>0.131148</td>
      <td>0.101341</td>
      <td>0.673267</td>
      <td>5.133663</td>
      <td>0.081601</td>
      <td>2.659215</td>
    </tr>
    <tr>
      <th>38209</th>
      <td>(Psycho, Rain Man)</td>
      <td>(Titanic, Big Fish)</td>
      <td>0.131148</td>
      <td>0.150522</td>
      <td>0.101341</td>
      <td>0.772727</td>
      <td>5.133663</td>
      <td>0.081601</td>
      <td>3.737705</td>
    </tr>
    <tr>
      <th>38238</th>
      <td>(Titanic, Big Fish)</td>
      <td>(Psycho, Solaris)</td>
      <td>0.150522</td>
      <td>0.134128</td>
      <td>0.102832</td>
      <td>0.683168</td>
      <td>5.093399</td>
      <td>0.082642</td>
      <td>2.732908</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>108</th>
      <td>(5 Card Stud)</td>
      <td>(Men in Black II)</td>
      <td>0.298063</td>
      <td>0.333830</td>
      <td>0.110283</td>
      <td>0.370000</td>
      <td>1.108348</td>
      <td>0.010781</td>
      <td>1.057413</td>
    </tr>
    <tr>
      <th>571</th>
      <td>(Bang, Boom, Bang)</td>
      <td>(The 39 Steps)</td>
      <td>0.260805</td>
      <td>0.433681</td>
      <td>0.125186</td>
      <td>0.480000</td>
      <td>1.106804</td>
      <td>0.012080</td>
      <td>1.089075</td>
    </tr>
    <tr>
      <th>570</th>
      <td>(The 39 Steps)</td>
      <td>(Bang, Boom, Bang)</td>
      <td>0.433681</td>
      <td>0.260805</td>
      <td>0.125186</td>
      <td>0.288660</td>
      <td>1.106804</td>
      <td>0.012080</td>
      <td>1.039159</td>
    </tr>
    <tr>
      <th>1137</th>
      <td>(Sissi)</td>
      <td>(License to Wed)</td>
      <td>0.317437</td>
      <td>0.301043</td>
      <td>0.102832</td>
      <td>0.323944</td>
      <td>1.076070</td>
      <td>0.007269</td>
      <td>1.033874</td>
    </tr>
    <tr>
      <th>1136</th>
      <td>(License to Wed)</td>
      <td>(Sissi)</td>
      <td>0.301043</td>
      <td>0.317437</td>
      <td>0.102832</td>
      <td>0.341584</td>
      <td>1.076070</td>
      <td>0.007269</td>
      <td>1.036675</td>
    </tr>
  </tbody>
</table>
<p>75536 rows × 9 columns</p>

</div>



- **结果说明：上述输出的即为所有关联规则的结果，每一行代表一个关联规则，其中行号1473所在的关联规则(Waiter->Muxmauschenstill)关联度最高(conviction值越大，代表antecedents与consequents的关联度越大）)。**

## 电影推荐

#### 推荐电影列表


```python
all_antecedents = [list(x) for x in rules['antecedents'].values]
```


```python
desired_indices = [i for i in range(len(all_antecedents)) if len(all_antecedents[i]) == 1 and all_antecedents[i][0] == 'Batman Returns'] 
```


```python
apriori_recommendations =rules.iloc[desired_indices,].sort_values(by=['lift'],ascending=False)
```


```python
apriori_recommendations.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>antecedents</th>
      <th>consequents</th>
      <th>antecedent support</th>
      <th>consequent support</th>
      <th>support</th>
      <th>confidence</th>
      <th>lift</th>
      <th>leverage</th>
      <th>conviction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>63981</th>
      <td>(Batman Returns)</td>
      <td>(The Hours, Monsoon Wedding, Silent Hill, Rese...</td>
      <td>0.298063</td>
      <td>0.107303</td>
      <td>0.102832</td>
      <td>0.345</td>
      <td>3.215208</td>
      <td>0.070849</td>
      <td>1.362897</td>
    </tr>
    <tr>
      <th>36084</th>
      <td>(Batman Returns)</td>
      <td>(Reservoir Dogs, Wag the Dog, Silent Hill)</td>
      <td>0.298063</td>
      <td>0.105812</td>
      <td>0.101341</td>
      <td>0.340</td>
      <td>3.213239</td>
      <td>0.069803</td>
      <td>1.354830</td>
    </tr>
    <tr>
      <th>63891</th>
      <td>(Batman Returns)</td>
      <td>(Monsoon Wedding, Silent Hill, Reservoir Dogs,...</td>
      <td>0.298063</td>
      <td>0.107303</td>
      <td>0.101341</td>
      <td>0.340</td>
      <td>3.168611</td>
      <td>0.069358</td>
      <td>1.352572</td>
    </tr>
    <tr>
      <th>63351</th>
      <td>(Batman Returns)</td>
      <td>(Monsoon Wedding, Silent Hill, Reservoir Dogs,...</td>
      <td>0.298063</td>
      <td>0.107303</td>
      <td>0.101341</td>
      <td>0.340</td>
      <td>3.168611</td>
      <td>0.069358</td>
      <td>1.352572</td>
    </tr>
    <tr>
      <th>36014</th>
      <td>(Batman Returns)</td>
      <td>(The Hours, Reservoir Dogs, Silent Hill)</td>
      <td>0.298063</td>
      <td>0.116244</td>
      <td>0.108793</td>
      <td>0.365</td>
      <td>3.139936</td>
      <td>0.074145</td>
      <td>1.391741</td>
    </tr>
  </tbody>
</table>

</div>




```python
apriori_recommendations_list = [list(x) for x in apriori_recommendations['consequents'].values]
```


```python
print("Apriori Recommendations for movie: Batman Returns\n")
for i in range(5):
    print("{0}:{1} with lift of {2}" .format(i+1, apriori_recommendations_list[i], apriori_recommendations.iloc[i,6]))
```

    Apriori Recommendations for movie: Batman Returns
    
    1:['The Hours', 'Monsoon Wedding', 'Silent Hill', 'Reservoir Dogs'] with lift of 3.215208333333333
    2:['Reservoir Dogs', 'Wag the Dog', 'Silent Hill'] with lift of 3.2132394366197183
    3:['Monsoon Wedding', 'Silent Hill', 'Reservoir Dogs', 'Sissi'] with lift of 3.168611111111111
    4:['Monsoon Wedding', 'Silent Hill', 'Reservoir Dogs', 'Rain Man'] with lift of 3.168611111111111
    5:['The Hours', 'Reservoir Dogs', 'Silent Hill'] with lift of 3.139935897435898


#### 推荐单部电影


```python
apriori_single_recommendations = apriori_recommendations.iloc[[x for x in range(len(apriori_recommendations_list)) if len(apriori_recommendations_list[x]) ==1],]
```


```python
apriori_single_recommendations_list = [list(x) for x in apriori_single_recommendations['consequents'].values]
```


```python
print("Apriori single-movie Recommendations for movie: Batman Returns\n")
for i in range(5):
    print("{0}: {1}, with lift of {2}".format(i+1,apriori_single_recommendations_list[i][0],apriori_single_recommendations.iloc[i,6]))
```

    Apriori single-movie Recommendations for movie: Batman Returns
    
    1: Reservoir Dogs, with lift of 2.6094444444444447
    2: Ariel, with lift of 2.5397663551401872
    3: Wag the Dog, with lift of 2.496744186046512
    4: To Kill a Mockingbird, with lift of 2.478125
    5: Romeo + Juliet, with lift of 2.4705000000000004


- **结果说明：我们约束consequents(后件)的长度为1，选出lift降序排列的前五个关联规则(关联规则格式为前件——>后件）。对于用户观看的电影记录《Batman Returns》，即antecedents(前件），我们根据规则按照推荐程度降序给出了单部电影推荐结果**

## **协同过滤**

#### 基于user的协同过滤

- 在海量的用户中发现一小部分和你品味比较相近的，在协同过滤中，这些用户称为邻居，然后根据他们喜欢的东西组织成一个排序的目录来推荐给你
  -  **重点就是怎样去寻找和你比较相似的用户，怎么将那些邻居的喜好组织成一个排序的目录给用户**
     - 在世纪钟给出一个数字K表示和你最为相似的用户。
     - 在计算相似度的时候，理论上要计算被推荐的用户与所有用户的相似度，但是当数据量比较大的时候，这样做是很费时间的 ，
     - 数据集中可能有很多用户和需要被推荐的用户是没有关系的， 在计算是完全是没有必要的，
     - 所以需要物品到用户的反查表，也就是没一件物品对应的用户信息，有了这个表，就可以过滤掉很多和你没有关系的用户，减少计算量。
     - ![image.png](attachment:c637faba-51f3-4a89-84f5-ede3ce337e4c.png)
  -  总结来说，推荐的过程就是先计算用户之间的相似度，根据相似度的高低选取前K个用户，在这K个用户中计算每一件物品的推荐程度。


```python
# 读取ratings_small.csv数据用于建模
ratings_small_path = "./movie_dataset/ratings_small.csv"
ratings_small_df = pd.read_csv(ratings_small_path)
```


```python
ratings_small_df.shape
```




    (100004, 4)




```python
ratings_small_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>31</td>
      <td>2.5</td>
      <td>1260759144</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1029</td>
      <td>3.0</td>
      <td>1260759179</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1061</td>
      <td>3.0</td>
      <td>1260759182</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1129</td>
      <td>2.0</td>
      <td>1260759185</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1172</td>
      <td>4.0</td>
      <td>1260759205</td>
    </tr>
  </tbody>
</table>

</div>




```python
# 原始的movieId 并非从0到1 的连续值， 为方便更贱user-item矩阵， 重新排列movie_id
movie_id = ratings_small_df['movieId'].drop_duplicates()
movie_id = pd.DataFrame(movie_id)
movie_id['movieid'] = range(len(movie_id))
```


```python
movie_id
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
      <th>movieid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>31</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1029</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1061</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1129</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1172</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99131</th>
      <td>64997</td>
      <td>9061</td>
    </tr>
    <tr>
      <th>99159</th>
      <td>72380</td>
      <td>9062</td>
    </tr>
    <tr>
      <th>99274</th>
      <td>129</td>
      <td>9063</td>
    </tr>
    <tr>
      <th>99678</th>
      <td>4736</td>
      <td>9064</td>
    </tr>
    <tr>
      <th>99820</th>
      <td>6425</td>
      <td>9065</td>
    </tr>
  </tbody>
</table>
<p>9066 rows × 2 columns</p>

</div>




```python
ratings_small_df = pd.merge(ratings_small_df, movie_id, on =['movieId'], how='left')
ratings_small_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>timestamp</th>
      <th>movieid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>31</td>
      <td>2.5</td>
      <td>1260759144</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1029</td>
      <td>3.0</td>
      <td>1260759179</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>1061</td>
      <td>3.0</td>
      <td>1260759182</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1129</td>
      <td>2.0</td>
      <td>1260759185</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>1172</td>
      <td>4.0</td>
      <td>1260759205</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>671</td>
      <td>6268</td>
      <td>2.5</td>
      <td>1065579370</td>
      <td>7005</td>
    </tr>
    <tr>
      <th>100000</th>
      <td>671</td>
      <td>6269</td>
      <td>4.0</td>
      <td>1065149201</td>
      <td>4771</td>
    </tr>
    <tr>
      <th>100001</th>
      <td>671</td>
      <td>6365</td>
      <td>4.0</td>
      <td>1070940363</td>
      <td>1329</td>
    </tr>
    <tr>
      <th>100002</th>
      <td>671</td>
      <td>6385</td>
      <td>2.5</td>
      <td>1070979663</td>
      <td>1331</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>671</td>
      <td>6565</td>
      <td>3.5</td>
      <td>1074784724</td>
      <td>2946</td>
    </tr>
  </tbody>
</table>
<p>100004 rows × 5 columns</p>

</div>




```python
ratings_small_df = ratings_small_df[['userId','movieid','rating','timestamp']]  #更新 movieId ----> movieid
ratings_small_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieid</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>2.5</td>
      <td>1260759144</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>3.0</td>
      <td>1260759179</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2</td>
      <td>3.0</td>
      <td>1260759182</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3</td>
      <td>2.0</td>
      <td>1260759185</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>4</td>
      <td>4.0</td>
      <td>1260759205</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>671</td>
      <td>7005</td>
      <td>2.5</td>
      <td>1065579370</td>
    </tr>
    <tr>
      <th>100000</th>
      <td>671</td>
      <td>4771</td>
      <td>4.0</td>
      <td>1065149201</td>
    </tr>
    <tr>
      <th>100001</th>
      <td>671</td>
      <td>1329</td>
      <td>4.0</td>
      <td>1070940363</td>
    </tr>
    <tr>
      <th>100002</th>
      <td>671</td>
      <td>1331</td>
      <td>2.5</td>
      <td>1070979663</td>
    </tr>
    <tr>
      <th>100003</th>
      <td>671</td>
      <td>2946</td>
      <td>3.5</td>
      <td>1074784724</td>
    </tr>
  </tbody>
</table>
<p>100004 rows × 4 columns</p>

</div>




```python
# 用户物品统计
# unique()是以 数组形式（numpy.ndarray）返回列的所有唯一值（特征的所有唯一值）
# nunique() Return number of unique elements in the object.即返回的是唯一值的个数

n_users = ratings_small_df.userId.nunique()
n_users
```




    671




```python
n_items = ratings_small_df.movieid.nunique()
n_items 
```




    9066




```python
# 拆分数据集
from sklearn.model_selection import train_test_split
#按照训练集70% 测试集30%的比例 对数据进行拆分
train_data,test_data = train_test_split(ratings_small_df,test_size= 0.3)
```


```python
train_data
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }

</style>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieid</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>69526</th>
      <td>481</td>
      <td>329</td>
      <td>4.0</td>
      <td>1437001087</td>
    </tr>
    <tr>
      <th>41670</th>
      <td>299</td>
      <td>917</td>
      <td>3.5</td>
      <td>1344188856</td>
    </tr>
    <tr>
      <th>49260</th>
      <td>358</td>
      <td>288</td>
      <td>2.0</td>
      <td>957480147</td>
    </tr>
    <tr>
      <th>39317</th>
      <td>287</td>
      <td>3582</td>
      <td>4.0</td>
      <td>1470168974</td>
    </tr>
    <tr>
      <th>35991</th>
      <td>262</td>
      <td>2094</td>
      <td>3.0</td>
      <td>1433899624</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6262</th>
      <td>33</td>
      <td>1095</td>
      <td>2.0</td>
      <td>1032769543</td>
    </tr>
    <tr>
      <th>8504</th>
      <td>56</td>
      <td>367</td>
      <td>2.0</td>
      <td>1467005360</td>
    </tr>
    <tr>
      <th>8540</th>
      <td>56</td>
      <td>1435</td>
      <td>4.0</td>
      <td>1467006577</td>
    </tr>
    <tr>
      <th>77937</th>
      <td>542</td>
      <td>1496</td>
      <td>1.0</td>
      <td>1424966216</td>
    </tr>
    <tr>
      <th>94226</th>
      <td>624</td>
      <td>476</td>
      <td>3.0</td>
      <td>1053249671</td>
    </tr>
  </tbody>
</table>
<p>70002 rows × 4 columns</p>

</div>




```python
# 训练集 用户-物品 矩阵
user_item_matrix = np.zeros((n_users,n_items))
user_item_matrix.shape
```




    (671, 9066)




```python
# iterrows() : 将DataFrame迭代成（index ,series）
# iteritems()： 将DataFrame迭代成（列名，series）
# itertuples()： 将DataFrame迭代成元组 
for line in train_data.itertuples():
    user_item_matrix[line[1]-1,line[2]]=line[3]
```


```python
user_item_matrix
```




    array([[0., 3., 3., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           ...,
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.],
           [0., 0., 0., ..., 0., 0., 0.]])




```python
user_item_matrix.shape
```




    (671, 9066)




```python
# 构建用户相似矩阵 ---采用余弦距离
from sklearn.metrics.pairwise import pairwise_distances
# 相似度计算 定义余弦距离
user_similarity_m = pairwise_distances(user_item_matrix,metric='cosine')  # 每个用户为1行数据，故此处不需要再进行转置
```

![image.png](attachment:580b16df-141a-4cce-a502-53a01d1ecb68.png)


```python
a=[[1,3],[2,2]]
a
```




    [[1, 3], [2, 2]]




```python
pairwise_distances(a,metric='euclidean')
```




    array([[0.        , 1.41421356],
           [1.41421356, 0.        ]])




```python
b = np.array([[1,2],[1,3],[2,1]])
b
```




    array([[1, 2],
           [1, 3],
           [2, 1]])




```python
pairwise_distances(b,metric='euclidean') #结果数组的第一行第二列表示 a[0]与a[1]的距离
```




    array([[0.        , 1.        , 1.41421356],
           [1.        , 0.        , 2.23606798],
           [1.41421356, 2.23606798, 0.        ]])




```python
pairwise_distances(b,metric='cosine')
```




    array([[0.        , 0.01005051, 0.2       ],
           [0.01005051, 0.        , 0.29289322],
           [0.2       , 0.29289322, 0.        ]])




```python
b.shape
```




    (3, 2)




```python
b[1]
```




    array([1, 3])




```python
b[0]
```




    array([1, 2])




```python
user_similarity_m.shape
```




    (671, 671)




```python
user_similarity_m[0:5,0:5].round(2)
```




    array([[0.  , 1.  , 1.  , 0.94, 0.97],
           [1.  , 0.  , 0.89, 0.93, 0.92],
           [1.  , 0.89, 0.  , 0.93, 0.93],
           [0.94, 0.93, 0.93, 0.  , 0.94],
           [0.97, 0.92, 0.93, 0.94, 0.  ]])




```python
user_similarity_m_triu = np.triu(user_similarity_m,k=1) #取得上三角数据
np.round(user_similarity_m_triu[user_similarity_m_triu.nonzero()],3)
```




    array([1.   , 1.   , 0.938, ..., 0.934, 0.919, 0.814])




```python
user_sim_nonzero = np.round(user_similarity_m_triu[user_similarity_m_triu.nonzero()],3)
```


```python
np.percentile(user_sim_nonzero,np.arange(0,101,10))
```




    array([0.316, 0.844, 0.885, 0.911, 0.93 , 0.947, 0.961, 0.976, 1.   ,
           1.   , 1.   ])



#### 训练集预测


```python
mean_user_rating = user_item_matrix.mean(axis=1)
mean_user_rating
```




    array([0.00297816, 0.0198544 , 0.01301566, 0.06265167, 0.03027796,
           0.01196779, 0.02404589, 0.03805427, 0.01114053, 0.0147805 ,
           0.01047871, 0.01301566, 0.01615928, 0.004743  , 0.33984116,
           0.01069932, 0.0991617 , 0.0147805 , 0.11780278, 0.02294286,
           0.0443415 , 0.04936025, 0.21111846, 0.00683874, 0.00617692,
           0.04031546, 0.00816236, 0.01555261, 0.00363997, 0.29643724,
           0.02625193, 0.01080962, 0.03684094, 0.05702625, 0.0025921 ,
           0.03000221, 0.01147143, 0.03838518, 0.0196338 , 0.01301566,
           0.0592323 , 0.0196338 , 0.02172954, 0.00694904, 0.00512905,
           0.01312597, 0.01069932, 0.14212442, 0.02371498, 0.01169204,
           0.01069932, 0.01941319, 0.00893448, 0.01384293, 0.00838297,
           0.14615045, 0.06254136, 0.01753805, 0.02090227, 0.02018531,
           0.04197   , 0.0172623 , 0.02454225, 0.00739025, 0.00694904,
           0.01544231, 0.02856828, 0.03331127, 0.02327377, 0.02856828,
           0.00794176, 0.05035297, 0.42096845, 0.01544231, 0.0394882 ,
           0.00573572, 0.07346128, 0.08234061, 0.00921024, 0.0100375 ,
           0.05283477, 0.01235385, 0.04555482, 0.03424884, 0.0247077 ,
           0.05084933, 0.00650783, 0.06281712, 0.02448709, 0.01577322,
           0.04671299, 0.02779616, 0.0444518 , 0.0497463 , 0.08769027,
           0.02288771, 0.03160159, 0.02332892, 0.0497463 , 0.00661813,
           0.0173726 , 0.1978822 , 0.02437679, 0.02360468, 0.13942202,
           0.01411869, 0.00656298, 0.00783146, 0.00628723, 0.04015001,
           0.09541143, 0.00650783, 0.00959629, 0.00827267, 0.01351202,
           0.00667328, 0.01389808, 0.05592323, 0.17185087, 0.03833002,
           0.02503861, 0.00882418, 0.00937569, 0.02415619, 0.0666777 ,
           0.01808957, 0.00573572, 0.09695566, 0.00595632, 0.09254357,
           0.01433929, 0.0297816 , 0.03518641, 0.10065078, 0.00529451,
           0.01637988, 0.02018531, 0.02024046, 0.02090227, 0.01213325,
           0.00816236, 0.01103022, 0.02365983, 0.01158173, 0.01455989,
           0.02134348, 0.01312597, 0.04081182, 0.06121774, 0.09557688,
           0.01654533, 0.05664019, 0.01698654, 0.00926539, 0.01279506,
           0.01604897, 0.08697331, 0.00562541, 0.04070152, 0.03132583,
           0.02702405, 0.00915508, 0.02007501, 0.02421134, 0.10870285,
           0.01422899, 0.00761085, 0.02790646, 0.03623428, 0.00590117,
           0.01588352, 0.0051842 , 0.01169204, 0.00639753, 0.03551732,
           0.05834988, 0.07059343, 0.03259431, 0.01080962, 0.00452239,
           0.01108537, 0.04301787, 0.01433929, 0.01125083, 0.05625414,
           0.0099272 , 0.1014229 , 0.02867858, 0.03320097, 0.02150893,
           0.00739025, 0.01687624, 0.01886168, 0.01367748, 0.10533863,
           0.02702405, 0.02051621, 0.01979925, 0.12221487, 0.05846018,
           0.03910214, 0.01831017, 0.01086477, 0.00871388, 0.05542687,
           0.00948599, 0.00672844, 0.01604897, 0.00452239, 0.00683874,
           0.01610413, 0.2176263 , 0.18409442, 0.06254136, 0.01753805,
           0.02465255, 0.03430399, 0.01433929, 0.03855063, 0.07842488,
           0.00501875, 0.02658284, 0.01158173, 0.02625193, 0.00827267,
           0.00921024, 0.00750055, 0.02349437, 0.00987205, 0.03347673,
           0.00937569, 0.20416942, 0.00871388, 0.03160159, 0.04858813,
           0.06507831, 0.01075447, 0.02432164, 0.0843812 , 0.07246856,
           0.0147805 , 0.14328259, 0.08151335, 0.02195014, 0.04268696,
           0.00739025, 0.07677035, 0.03595853, 0.0051842 , 0.05581293,
           0.03628943, 0.01147143, 0.05840503, 0.03739246, 0.04252151,
           0.00650783, 0.02768586, 0.01025811, 0.00926539, 0.01235385,
           0.01047871, 0.13710567, 0.03000221, 0.01091992, 0.054379  ,
           0.00959629, 0.01158173, 0.10324289, 0.00628723, 0.06176925,
           0.02029561, 0.01158173, 0.0296713 , 0.01114053, 0.06585043,
           0.00479815, 0.01808957, 0.0147805 , 0.01136113, 0.00838297,
           0.02509376, 0.03524156, 0.05333113, 0.01433929, 0.10302228,
           0.00915508, 0.0893448 , 0.02029561, 0.0049636 , 0.02090227,
           0.02553497, 0.08018972, 0.02217075, 0.25672844, 0.06849768,
           0.00634238, 0.03662034, 0.02647253, 0.11763733, 0.01389808,
           0.00551511, 0.00750055, 0.06243106, 0.03309067, 0.00595632,
           0.16997573, 0.02029561, 0.0148908 , 0.04594088, 0.00468784,
           0.23830796, 0.07290977, 0.08112729, 0.01169204, 0.01246415,
           0.03524156, 0.00573572, 0.01588352, 0.00595632, 0.01571807,
           0.02283256, 0.01323627, 0.00700419, 0.04180454, 0.00446724,
           0.00783146, 0.02073682, 0.04649239, 0.00584602, 0.02680344,
           0.00689389, 0.00816236, 0.02503861, 0.01086477, 0.007666  ,
           0.00816236, 0.00330907, 0.01323627, 0.02950585, 0.01384293,
           0.00595632, 0.05868079, 0.01114053, 0.04500331, 0.0619347 ,
           0.09055813, 0.00650783, 0.01621443, 0.00639753, 0.0495257 ,
           0.01378778, 0.02443194, 0.1039047 , 0.01544231, 0.09039268,
           0.00419148, 0.00948599, 0.15243768, 0.01483565, 0.0098169 ,
           0.01533201, 0.03071917, 0.05404809, 0.00909993, 0.0224465 ,
           0.0097066 , 0.05217295, 0.00628723, 0.01345687, 0.03055372,
           0.0446724 , 0.00849327, 0.06165895, 0.00838297, 0.00705934,
           0.01808957, 0.00645268, 0.03750276, 0.01990955, 0.28375248,
           0.02945069, 0.07654975, 0.01544231, 0.11973307, 0.03132583,
           0.02691374, 0.09276417, 0.22865652, 0.01246415, 0.03430399,
           0.02923009, 0.00617692, 0.0125193 , 0.04511361, 0.00683874,
           0.03540702, 0.01632473, 0.01544231, 0.00595632, 0.01676594,
           0.024818  , 0.09303993, 0.00783146, 0.0098169 , 0.11675491,
           0.0270792 , 0.10699316, 0.05978381, 0.01566292, 0.00799691,
           0.00882418, 0.05129054, 0.00650783, 0.01698654, 0.00893448,
           0.02724465, 0.04114273, 0.0494154 , 0.01643503, 0.02823737,
           0.0101478 , 0.0296713 , 0.09458416, 0.00799691, 0.01588352,
           0.06507831, 0.09458416, 0.04560997, 0.00457754, 0.09618354,
           0.09303993, 0.02013016, 0.06221046, 0.05382749, 0.00606662,
           0.02161924, 0.00683874, 0.00612177, 0.05779837, 0.01367748,
           0.03568277, 0.07572248, 0.01775866, 0.00441209, 0.00540481,
           0.00904478, 0.01808957, 0.00639753, 0.00871388, 0.03943305,
           0.01599382, 0.33085153, 0.02294286, 0.0101478 , 0.00821752,
           0.01660049, 0.14179351, 0.02272226, 0.00705934, 0.08283697,
           0.15784249, 0.0121884 , 0.13335539, 0.01058901, 0.01119568,
           0.0593426 , 0.02095742, 0.30228326, 0.0048533 , 0.01869623,
           0.0569711 , 0.24652548, 0.02614163, 0.01301566, 0.14284139,
           0.01114053, 0.00490845, 0.02774101, 0.03132583, 0.1185749 ,
           0.1435032 , 0.01819987, 0.03259431, 0.00573572, 0.004743  ,
           0.0398191 , 0.04037062, 0.01781381, 0.00672844, 0.0051842 ,
           0.01875138, 0.01941319, 0.02923009, 0.02415619, 0.00617692,
           0.03309067, 0.03419369, 0.0048533 , 0.01235385, 0.05741231,
           0.05658504, 0.03353188, 0.01334657, 0.004743  , 0.09927201,
           0.0051842 , 0.01125083, 0.01334657, 0.2351092 , 0.04367968,
           0.00948599, 0.00921024, 0.00584602, 0.1037944 , 0.00876903,
           0.03805427, 0.01411869, 0.19170527, 0.05619899, 0.03987426,
           0.01384293, 0.06083168, 0.04003971, 0.01968895, 0.03992941,
           0.00777631, 0.03171189, 0.03325612, 0.16804544, 0.02062652,
           0.03298037, 0.01384293, 0.0394882 , 0.08030002, 0.01378778,
           0.03011251, 0.10070593, 0.00739025, 0.01058901, 0.00551511,
           0.00683874, 0.01704169, 0.01544231, 0.09265387, 0.02713435,
           0.02178469, 0.63484447, 0.03562762, 0.00623208, 0.03353188,
           0.02360468, 0.00783146, 0.06358923, 0.01511141, 0.01831017,
           0.00959629, 0.01329142, 0.07224796, 0.04378998, 0.03253916,
           0.07798368, 0.07026252, 0.04616148, 0.52404589, 0.00871388,
           0.00777631, 0.01147143, 0.01180234, 0.02283256, 0.03634458,
           0.01577322, 0.02950585, 0.0101478 , 0.09022722, 0.14284139,
           0.01125083, 0.0917163 , 0.00805206, 0.00209574, 0.22887712,
           0.00595632, 0.03502096, 0.00821752, 0.06072138, 0.09728657,
           0.0150011 , 0.15938672, 0.01400838, 0.01047871, 0.02228105,
           0.00849327, 0.03904699, 0.02128833, 0.02514891, 0.05118023,
           0.14399956, 0.06243106, 0.07842488, 0.05757776, 0.01119568,
           0.01268476, 0.03926759, 0.03617913, 0.00330907, 0.11096404,
           0.0196338 , 0.12618575, 0.08879329, 0.02283256, 0.01913744,
           0.01080962, 0.01742775, 0.01560777, 0.02889918, 0.10225017,
           0.01069932, 0.01764836, 0.0100375 , 0.01257445, 0.04086698,
           0.02614163, 0.01185749, 0.03105008, 0.39383411, 0.02079197,
           0.04290757, 0.04500331, 0.0223362 , 0.00959629, 0.0075557 ,
           0.00937569, 0.01185749, 0.00772116, 0.00534966, 0.00750055,
           0.00739025, 0.00976175, 0.004743  , 0.01455989, 0.01191264,
           0.04059122, 0.01169204, 0.00490845, 0.01125083, 0.007666  ,
           0.05834988, 0.05162144, 0.07715641, 0.0245974 , 0.00827267,
           0.00595632, 0.08509817, 0.01753805, 0.20257004, 0.03353188,
           0.0445621 , 0.00419148, 0.01952349, 0.03827487, 0.02950585,
           0.00843812, 0.01742775, 0.00871388, 0.15927642, 0.1088683 ,
           0.00816236, 0.01687624, 0.00739025, 0.0098169 , 0.00716964,
           0.0347452 ])




```python
rating_diff = (user_item_matrix - mean_user_rating[:,np.newaxis])   # np.newaxis作用：为mean_user_rating增加一个维度，实现加减操作
rating_diff
```




    array([[-2.97816016e-03,  2.99702184e+00,  2.99702184e+00, ...,
            -2.97816016e-03, -2.97816016e-03, -2.97816016e-03],
           [-1.98544011e-02, -1.98544011e-02, -1.98544011e-02, ...,
            -1.98544011e-02, -1.98544011e-02, -1.98544011e-02],
           [-1.30156629e-02, -1.30156629e-02, -1.30156629e-02, ...,
            -1.30156629e-02, -1.30156629e-02, -1.30156629e-02],
           ...,
           [-9.81689830e-03, -9.81689830e-03, -9.81689830e-03, ...,
            -9.81689830e-03, -9.81689830e-03, -9.81689830e-03],
           [-7.16964483e-03, -7.16964483e-03, -7.16964483e-03, ...,
            -7.16964483e-03, -7.16964483e-03, -7.16964483e-03],
           [-3.47452019e-02, -3.47452019e-02, -3.47452019e-02, ...,
            -3.47452019e-02, -3.47452019e-02, -3.47452019e-02]])




```python
user_prediction = mean_user_rating[:,np.newaxis] + user_similarity_m.dot(rating_diff) / np.array([np.abs(user_similarity_m).sum(axis=1)]).T
# 处以np.array([np.abs(item_similarity_m).sum(axis=1)]是为了可以使评分在1~5之间，使1~5的标准化
```


```python
user_prediction
```




    array([[ 8.48587738e-02,  1.11549860e-01,  7.78496257e-02, ...,
            -3.30873704e-02, -3.59785123e-02, -3.59132569e-02],
           [ 9.36489784e-02,  1.35396758e-01,  1.04357090e-01, ...,
            -1.62815182e-02, -1.93136443e-02, -1.93247190e-02],
           [ 9.44428457e-02,  1.33314515e-01,  9.83052575e-02, ...,
            -2.28228892e-02, -2.58037344e-02, -2.59258365e-02],
           ...,
           [ 9.29750987e-02,  1.27902780e-01,  9.32275326e-02, ...,
            -2.60694824e-02, -2.89101875e-02, -2.87905826e-02],
           [ 8.62056229e-02,  1.26697599e-01,  9.17810994e-02, ...,
            -2.88942031e-02, -3.19119828e-02, -3.20590645e-02],
           [ 1.17342284e-01,  1.50739909e-01,  1.17908253e-01, ...,
            -7.69495365e-05, -2.99819315e-03, -3.02101562e-03]])




```python
# 只取数据集中有评分的数据集进行评估
from sklearn.metrics import mean_squared_error
from math import sqrt
```


```python
prediction_flatten = user_prediction[user_item_matrix.nonzero()]
prediction_flatten
```




    array([0.11154986, 0.07784963, 0.14877094, ..., 0.04236321, 0.01114962,
           0.02448394])




```python
user_item_matrix_flatten = user_item_matrix[user_item_matrix.nonzero()]
user_item_matrix_flatten
```




    array([3., 3., 2., ..., 4., 4., 4.])




```python
error_test = sqrt(mean_squared_error(prediction_flatten,user_item_matrix_flatten)) # 均方根误差计算
```


```python
error_test
```




    3.390138302832629


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
</=></AxesSubplot:title={'center':'totalRatings'}></class></bound></1:>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>推荐</tag>
        <tag>关联规则算法</tag>
      </tags>
  </entry>
  <entry>
    <title>用户基本指标详解</title>
    <url>/2019/05/19/%E7%94%A8%E6%88%B7%E5%9F%BA%E6%9C%AC%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


**1) 新用户** 
**定义**：历史上第一次启动应用的用户，需要按照设备号进行去重。 
**技术说明**：如果某一个用户之前安装过该应用又卸载，之后又二次安装，那么只要该用户的设备没有更换或重置，则两次视为同一个用户，即第二次安装不算作新增用户。按照设备号去重是指所有新开启的用户中，同一个设备号的新开启都算作一次新增用户，去重标准除了可以使用Android系统的MAC地址、IMEI号，IOS系统生成的广告ID之外，开发者还可以自行生成ID，例如百度移动统计自行生成的CUID。 
**涵义**：新增用户越多说明应用的成长越快，推广的效果越好。通常情况下，应用在发展初期的时候新增用户比例非常高，随着市场趋于稳健增长，新增用户比例逐渐下降。 
**2) 启动次数** 
**定义**：顾名思义，启动次数就是在规定时间段内，用户打开应用的次数。“一次启动”是指用户从打开APP开始，到退出APP（或离开应用界面，进入后台）为止。一次启动过程中可能浏览多个页面。 
**技术说明**：如果同一个用户在退出APP或离开应用界面进入后台，又在30秒之内再次启动应用，则两次启动算作一次。反之，如果用户在30秒之后再次启动应用，则启动次数算作两次。在百度移动统计SDK3.1版本以上中，开发者都可以对“30秒”这个业界标准根据应用自身情况进行调整设定。 
**涵义**：用户数是从规模上描述应用，而启动次数是从访客角度衡量访问质量的分析指标。如果一个应用的用户体验足够好，用户粘性足够高，同一个用户一天中会多次启动应用，那么启动次数就会明显大于访客数。 
**3) 每次使用时长** 
**定义**：平均每一次启动应用程序（session）的时长 
**算法**：每次session时间总和/session总次数； 
**4) 每人使用时长** 
**定义**：平均每个用户使用应用程序的时长 
**算法**：每次session时间总和/session用户数 
**5) 活跃用户** 
**定义**：指在规定的时间范围内，启动过应用的用户数，需要按照设备号去重。 
**涵义**：活跃用户通常都会有一个时间范围做约束的，例如日活跃用户、周活跃用户、活跃用户等。活跃用户指标是一个应用用户规模的体现，同样也是衡量一个应用质量的最基本指标，结合留存率、流失率、使用时长等指标还可以体现用户粘性。该指标也可以衡量渠道质量，排查渠道作弊。 
**6) 活跃度** 
**定义**：活跃用户除以累计启动用户 
**涵义**：这里的累计启动用户是指应用上线以来的全部去重后的启动用户，所以日活跃度<周活跃度<月活跃度，也会出现若某应用上线不满一个月，其月活跃度=100%的情况。 **7) 留存用户** **定义**：规定时间段（t1）内的新增用户中，在经过一段时间（t2）后，仍然使用程序的用户。其中t1和t2可以根据应用自身的实际情况进行设置。 **涵义**：留存用户主要用来衡量应用对用户的吸引程度、用户对应用的粘性、渠道用户质量及投放效果等。常用的留存指标有次日留存、三日留存和七日留存等。 **8) 留存率** **算法**：所选时段内的留存用户数 所选时段内的新增用户数 **实例**：若1月份的月留存用户数为50人，新增用户数为100人，则1月份的月留存率为50%。 **9) 自定义留存中月留存率** **解释**：昨日上月同期的新增用户中在过去7天（从上一日计起）启动过应用程序的用户数 昨日上月同期新增用户数 **实例**：若8月2日查看，则月留存用户数为7月1日0-24时所有新增用户中，在7月26~至8月1日这7天内至少启动过一次应用程序的用户数，比上7月1日0-24时所有新增用户数，即为自定义月留存率。 **10) 首次使用日 周 月留存用户** **解释**：某日 月的新增用户中，在第二天 月之后，每日 月启动过应用程序的用户 **实例**：如8月1日新增用户的日留存情况，是指8月1日所有新增用户中分别在8月2日之后每天启动过应用程序的用户数。如某用户8月1日为新增用户，分别在3号和4号两天各启动一次应用，那么3号和4号的日留存用户数各增加“1”。在下图的“漏斗”中，标蓝底色的为留存率超过20%的数据。 **11) 流失用户** **解释**：过去60天（含当日）没有启动过应用程序的用户（已去重） **实例**：若100个用户在1月1日启动过应用，之后这100人中有50人在未来60天内有过至少一次启动应用，另外50个在期间没有过启动的用户中，有25人在第65天启动了应用，那么在第61天查看流失用户数据为50人，在第65天查看流失用户数据为25人。 **12) 流失率** **算法**：流失用户数 累计启动用户数 **涵义**：累计启动用户数是指应用自开启统计以来的所有去重用户数量 --- ### about me ##### 👋 读书城南，🤔 在未来面前，我们都是孩子～ - 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~ social media 🛠️ blog: [http: oceaneyes.top](http: oceaneyes.top) ⚡ pm导航: [https: pmhub.oceangzy.top](https: pmhub.oceangzy.top) ☘️ cnblog: www.cnblogs.com oceaneyes-gzy ](https: ) 🌱 ai prj自己部署的一些算法demo: ai.oceangzy.top ](http: 📫 email: 1450136519@qq.com 💬 wechat: [oceangzy](https: oceaneyes.top img wechatqrcode.jpg) 公众号: [unclejoker-gzy](https: wechatgzh.jpeg) 加入小组~ <img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> </周活跃度<月活跃度，也会出现若某应用上线不满一个月，其月活跃度=100%的情况。>]]></content>
      <categories>
        <category>产品</category>
        <category>数据产品</category>
        <category>数据指标</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据指标</tag>
      </tags>
  </entry>
  <entry>
    <title>用户运营之6大用户分析增长模型</title>
    <url>/2019/04/20/%E7%94%A8%E6%88%B7%E8%BF%90%E8%90%A5%E4%B9%8B6%E5%A4%A7%E7%94%A8%E6%88%B7%E5%88%86%E6%9E%90%E5%A2%9E%E9%95%BF%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 用户运营之6大用户分析增长模型

六大用户分析方法论

- 行为事件分析
- 点击分析模型
- 用户行为路径分析
- 用户健康度分析
- 漏斗模型分析
- 用户画像分析

## 1、行为事件分析

行为事件分析法用于研究"某行为事件的发生对企业组织价值的影响以及影响程度"。

借此来追踪或记录用户行为及业务过程，如"注册，浏览商品，成功下单，退款等"，通过研究与事件发生关联的所有因素来挖掘用户行为事件背后的原因、交互影响。。

一般分为三大环节：事件定义，多维度下钻分析，解释与结论。

### 1.1、事件定义

**事件定义包括定义所关注的事件及事件窗口的长度，是 事件分析法最为核心和关键的步骤。**

**事件定义遵循5W原则：**

- Where
- Who
- When
- How
- What

一些经常性出现的名词：Path口径，Session口径，"访问次数"，"浏览深度"，"使用时长"，"停留时长"，"跳出率"，"页面退出率"等指标，都需要引入session。

**创建和管理session是事件定义的关键步骤。**

是个特定的时间概念，例如"用户从进入网站到关闭浏览器所经过的这段时间—用户浏览该网站所花费的时间"

### 1.2、多维度下钻分析

最为高效的行为事件分析要支持任意下钻和精细化条件筛选。

当行为事件分析合理配置追踪事件和属性，可以激发出事件分析的强大潜能，为企业回答关于变化趋势、维度对比、等各种细分问题。

"筛选条件"例如：地理位置、事件、广告系列媒介、操作系统、渠道来源、等

### 1.3、解释与结论

出具分析报告阶段。对分析结果进行合理的理论解释，判断数据分析结果是否与预期相符，如果相悖，则需要针对不足部分进行再分析与实证。

## 2、点击分析模型

点击分析模型在各行业内广泛应用。其中点击图是点击分析方法的效果呈现，在用户行为分析领域，点击分析包括"元素被点击次数、占比、发生点击的用户列表、按钮当前与历史内容等元素"

主要的解决问题点：

- 精准评估用户与产品交互背后的深层关系
- 实现产品的跳转路径分析，完成产品页面之间的深层次的关系需求挖掘
- 与其他分析模型配合，全面视角探索数据价值，深度感知用户体验，实现科学决策

主要应用场景：

- 官网
- 活动页面
- 产品频道／首页
- 详情页

常用的形式：

- 可视化：热力图呈现，根据点击密度进行判断用户的浏览喜好
- 固定埋点：

| 数据形式   | 热力图                                                       | 固定埋点                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 用户友好性 | 操作简单，可视化直观的将流量数据分布通过不同的颜色区块呈现，可快速判断点击分布 | 操作繁琐，须报出报表后进行加工分析，无法可视化取数           |
| 入手难度   | 简单，无需报告数据分析，无需页面分析经验                     | 入手稍难，需对埋点、数据统计维度有一定的数据分析经验         |
| 灵活性     | 灵活性强，可对页面任意位置进行数据监测                       | 灵活性弱，无法对任意位置进行数据监测；若页面变更数据麦地那则需要同步更改 |
| 长期取数   | 无法进行长期数据进行固定对比，形成报表性差，无法对页面定向区域进行定期取数分析 | 可进行长期数据进行固定对比，可对页面定向区域进行定期取数分析 |

## 3、用户行为路径分析

指用户在APP或网站中的访问行为路径。



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>运营</category>
      </categories>
      <tags>
        <tag>运营</tag>
        <tag>用户</tag>
      </tags>
  </entry>
  <entry>
    <title>用户行为类指标详解</title>
    <url>/2019/05/19/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E7%B1%BB%E6%8C%87%E6%A0%87%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


**1) 使用时长** 
**定义**：用户在应用程序上所停留的时间。主要分为平均使用时长和单次使用时长，平均使用时长是某一段时间内所有用户的全部访问时间的平均值。 
**涵义**：通过考量用户在应用上的停留时间，我们可以看出应用内容是否吸引用户，应用质量是否合格；还可以看出某个推广渠道到来的用户是否是深度使用用户，以此评判渠道质量。 
**2) 使用频率** 
**定义**：在一定时期内，同一个用户启动应用的次数。如在一天之内，同一个用户一共进行有效启动5次，那么该用户的日使用频率就是5次。 
**涵义**：使用频率和日启动次数类似，只是从另外一个角度衡量用户粘性，一个应用通常情况下用户粘性越高，那么用户的平均使用频率也就越高。 
**3) 使用间隔** 
**定义**：使用间隔是指同一用户相邻两次启动应用的时间间隔，例如某一用户第一次启动应用到第二次启动应用之间相隔2天，那么该用户的使用间隔即为2天。 
**涵义**：使用间隔也从侧面反映了应用的用户粘性，通常情况下使用间隔越短说明用户越依赖应用，也就是说应用的用户粘性越高。也可以据此来决定推送消息的时机和发版频率。 
**4) 访问深度** 
**定义**：我们将用户在一次启动应用过程中所到达的页面累计数量视为用户的访问深度， 例如某用户从启动APP到退出应用过程中，一共访问了12个页面，那么称该用户的访问深度为12。 
**涵义**：理论上来讲，访问深度越高，应用质量越好，用户对应用的依赖就越强 
**5)页面跳出率** 
**定义**：用户从当前页面离开应用程序的比例，离开指“退出或后台超过30秒” 
**涵义**：在“访问页面”报表中的参数，这里的离开指结束一次启动，比如某用户在当前页面接到电话，此时应用程序隐藏到后台运行，10秒钟后挂电话又回到了应用程序，这样的过程不算作是用户“离开”。如果超过30秒，才算作一次离开。


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>数据产品</category>
        <category>数据指标</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>数据指标</tag>
      </tags>
  </entry>
  <entry>
    <title>电商产品网站成交总额</title>
    <url>/2016/07/20/%E7%94%B5%E5%95%86%E4%BA%A7%E5%93%81%E7%BD%91%E7%AB%99%E6%88%90%E4%BA%A4%E6%80%BB%E9%A2%9D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 电商产品网站成交总额
- 用户数
  - 访客数
    - 自然流量
    - 营销流量
  - 转化率
    - 目的一 拉新
      - 品牌认知
        - 转入
      - 购买考虑
        - 实现
        - 转出
    - 目的二 促进复购
      - 购买尝试
        - 复购
        - 沉睡
        - 流失
      - 多次购买
        - 复购
        - 沉睡
        - 流失
      - 忠诚用户
        - 复购
        - 沉睡
        - 流失
    - 目的三 推荐代购
- 客单价
  - 产品单价
    - 前台价格
      - 智慧定价
    - 优惠价格
      - 促销建议
  - 关联产品数
    - 套装促销
      - 商品关联度
      - 商品热度



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>产品</category>
        <category>电商</category>
      </categories>
      <tags>
        <tag>电商</tag>
      </tags>
  </entry>
  <entry>
    <title>疫情之后，推动成交的核心方法</title>
    <url>/2020/02/18/%E7%96%AB%E6%83%85%E4%B9%8B%E5%90%8E%EF%BC%8C%E6%8E%A8%E5%8A%A8%E6%88%90%E4%BA%A4%E7%9A%84%E6%A0%B8%E5%BF%83%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 疫情之后的变化

#### 用户变化

- 没必要的都不买，更加在意==刚需、痛点、高频、场景、时机==

- 潜意识会更在意健康防护类产品

#### 面对萧条的五大对策

- 激活全员营销
- 重构产品及渠道
- 彻底消减成本
- 强化提升效率
- 重构内外关系



## 如何通过链路刺激与激活刚需

90%的用户在做购买决策是处于潜意识。

用户思维的本质：我关系你的关心。

### 需求驱动

先用情绪激活用户欲望，再切入场景，将产品转化为刚需

#### 需求动力

情绪激活

​	荷尔蒙刺激、多巴胺刺激

- 正面情绪
  - 快乐、乐观、自信
  - 欣赏、放松、从容
- 负面情绪
  - 恐惧、空虚、焦虑
  - 愤怒、悲伤、害怕
  - 孤独的另一个名字又叫找自己。

场景激活

### 信任驱动

- 人物信任
  - 知名度、资历、成功案例
- 企业信任
  - 影响力、行业地位

### 价值驱动

- 看点
- 亮点
- 记忆点

### 利益驱动

- 门槛要低
  - 尽量别让用户下载、注册、安装、关注，有门槛就会有难度，流失率就会增加
- 即时反馈
- 过程清晰
  - 用户天生多疑，活动是真的吗？一定要让他知道过程

### 服务驱动



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 

]]></content>
      <categories>
        <category>产品</category>
        <category>营销</category>
        <category>增长</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>营销</tag>
        <tag>增长</tag>
      </tags>
  </entry>
  <entry>
    <title>生活随笔</title>
    <url>/2015/07/20/%E7%99%BE%E5%B9%B4%E6%AD%8C%E8%87%AA%E8%8B%A6%EF%BC%8C%E6%9C%AA%E8%A7%81%E6%9C%89%E7%9F%A5%E9%9F%B3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


孤村落日残霞，轻烟老树寒鸦，一点飞鸿影下。 


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>杂谈</category>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>直播类产品全接触</title>
    <url>/2019/01/17/%E7%9B%B4%E6%92%AD%E7%B1%BB%E4%BA%A7%E5%93%81%E5%85%A8%E6%8E%A5%E8%A7%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


直播基础知识

- 直播基础知识

  - 直播为什么火
    - 基础条件成熟
      - 4G+wifi
      - 软硬件水平提升
      - 游戏行业的培养
      - 弹幕文化

    - 实时互动

      - 文字
      - 图片
      - 视频

    - 人性的驱动

      - 窥探欲
      - 炫耀
      - 虚荣
      - 色

  - 直播的特点

  - - 点播

      - 视频网站看电视剧
      - 文件存在服务器上
      - 指定节目播放

    - 直播

      - 直播网站看主播
      - 数据实时发送
      - 内容可以更改

  - 直播的流程

    - 推流端
      - 采集 8000**2*16*0.02 = bit /8 =         byte
        - 音频采集
          - 采样率
            - 模拟信号 转化为            数字的过程
            - 越大 音频质量越高
            - 例如 8kHz

          - 位宽

            - 一般8位
            - 例如 16bit

          - 声道数

            - 单/双
            - 例如：双

          - 音频帧

            - 2.5ms-60ms 约为一帧
            - 例如20ms

        - 图像采集

          - 分辨率
            - 长*宽

          - 采样频率 

          - 采集格式

          - 传输通道

        - 采集源

          - 摄像头
          - 屏幕录制
          - 文件推流

        - android采集

          - setPreviewCallback
          - MediaRecorder
          - 机型适配

        - ios采集

          - AVFoundation.framework

        - pc采集

          - mjpeg-streamer
          - 摄像头

      - 前处理

        - 视频处理
          - 美颜
            - 美白——算法识别皮肤轮廓，调整色值
            - 磨皮——模糊处理 均值模糊、高斯模糊、中值模糊

          - 滤镜

            - GPUImage

          - 水印

            - 图像与水印图片的合并

        - 音频处理

          - 混音
            - 伴奏
            - 音频信号的叠加，采样值溢出的处理

          - 降噪

            - 20Hz - 2000Hz
            - 傅里叶变换、滤波法

          - 特效

            - 变声
            - 改变音色、色调，            SoundTouch

      - 编码 

        - 必要性
          - 压缩数据
          - 减少传输时间

        - 编码原理

          - 空间冗余
            - 相邻元素之间的相关性

          - 时间冗余

            - 相邻图像之间的内容相似

          - 编码冗余

            - 像素值出现的概率不同

          - 视觉冗余

            - 视觉对细节的不敏感性

          - H264 编码

            - NALU:网络提取层单元
            - SPS：包括了一个图像序列的所有信息
            - PPS：包含了一个图像序列所有片的信息
            - I帧：帧内编码帧
            - P帧：前向预测编码帧
            - B帧：双向预测编码帧

          - AAC 音频

          - FLV，TS封装格式

      - 推流

        - 推流协议
          - RTMP
            - 优点
              - CDN支持良好
              - 协议简单易实现

            - 缺点

              - 基于TCP，传输成本高
              - 不支持浏览器推送
              - Adobe私有协议

          - WebRTC

            - W3C标准
            - 基于udp 
            - CDN支持较差

          - UDP自定义协议

            - 定制化空间大
            - 协议私有化
            - 开发成本高
            - CDN支持不太好

        - 推流优化思路

          - 保证音频的传输
          - 调整码率、FPS、分辨率
          - 减少传输的数据

    - 服务端

      - 转码
        - 适应不同网络带宽
        - 适应不同终端处理
        - 适应不同的用户需求
        - 为直播平台提供增值服务
        - 直播为实时转码，对图像计算要求较高，保证音画同步

      - 录制

      - 截图

        - 制作封面

      - 鉴黄

    - 播放端

      - 拉流
        - HTTP-FLV 即时性较高，互动性需求
        - HLS 回放需求，跨平台需求
        - RTMP 即时性较高，互动性需求

      - 解码

        - 编码的逆过程
        - 从音频数据提取原始数据

        - 硬解码

          - 速度快
          - 不易发热

        - 软解码

      - 渲染

        - 视频画面的显示
        - 声音的播放
        - 音画一致

    - 互动系统

      - 聊天
        - 弹幕

      - 礼物

        - 平台收入来源
        - 增加画面感，提高互动效果
        - 自定义消息

      - 关注

      - 点赞

  - 直播开发的辅助工具

    - 推流端OBS Studio
    - 播放端 CUTV测试工具

      - 流信息展示丰富
      - 可设置缓冲时间
      - 网页版

    - softe AAC Converter 转化为aac音频

    - H264BSAnalyzer 分析H264视频格式

    - FlvParse -分析FLV

    - yuvplayer -播放yuv文件


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>内容产品</category>
        <category>直播</category>
      </categories>
      <tags>
        <tag>直播</tag>
        <tag>视频</tag>
      </tags>
  </entry>
  <entry>
    <title>社区产品生命力顽强的原因究竟何在？</title>
    <url>/2020/02/04/%E7%A4%BE%E5%8C%BA%E5%9E%8B%E4%BA%A7%E5%93%81%E7%94%9F%E5%91%BD%E5%8A%9B%E9%A1%BD%E5%BC%BA%E7%9A%84%E5%8E%9F%E5%9B%A0%E7%A9%B6%E7%AB%9F%E4%BD%95%E5%9C%A8%EF%BC%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
## 社区产品生命力顽强的原因究竟何在？

### 一、导读

​		在中国互联网流量争夺异常激烈的今天，为什么社区这种古典互联网的典型产品，会有如此顽强的生命力？

​		社区有内容，有内容就意味着可以吸引更多的用户注意力，你能占据用户更多的访问时长，就更有可能实现基于内容的业务营销转化，取得更大的商业效益。

### 二、社区本质

核心定义：以用户创造内容为核心的网络交流平台。

悉数当前的各大独树一帜的产品

### 三、社区运营



### 四、社区产品



---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 

]]></content>
      <categories>
        <category>产品</category>
        <category>内容产品</category>
        <category>内容社区</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>内容</tag>
        <tag>社区</tag>
      </tags>
  </entry>
  <entry>
    <title>纯前端实现-tab卡片化样式切换</title>
    <url>/2019/03/01/%E7%BA%AF%E5%89%8D%E7%AB%AF%E5%AE%9E%E7%8E%B0-tab%E5%8D%A1%E7%89%87%E5%8C%96%E6%A0%B7%E5%BC%8F%E5%88%87%E6%8D%A2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 纯前端实现-tab卡片化样式切换

#### html内容

```html
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>选项卡切换</title>
    <link rel="stylesheet" type="text/css" href="./css/index.css">
  </head>
  <body>
    <div id="main">
      <div class="tabs">
        <div class="red active">选项一</div>
        <div class="green">选项二</div>
        <div class="blue">选项三</div>
        <div class="yellow">选项四</div>
      </div>
      <div id="content">
        <div id="one" class="active">
          <p>
            爱情要完结的时候自会完结，到时候，你不想画上句号也不行。爱情，原来是含笑饮毒酒。
          </p>
          <img src="/.top//1.jpeg">
        </div>
        <div id="two">
          <p>
            在这个光怪陆离的人间，没有谁可以将日子过的行云流水。但我始终相信，走过平湖山雨，岁月山河，那些历尽劫数，尝遍百味的人，会更加生动而干净。
          </p>
          <img src="/.top//2.jpeg">
        </div>
        <div id="three">
          <p>
            对于三十岁以后的人来说，十年八年不过是指缝间的事，而对于年轻人而言，三年五年就可以是一生一世。
          </p>
          <img src="/.top//3.jpeg">
        </div>
        <div id="four">
          <p>
            我要你知道，在这个世界上总有一个人是等着你的，不管在什么时候，不管在什么地方，反正你知道，总有这么个人。
          </p>
          <img src="/.top//4.jpeg">
        </div>
      </div>
    </div>
  </body>
  <script src="./js/index.js" type="text/javascript" charset="utf-8"></script>
</html>

```


#### css内容

```css
*{
			padding: 0;
			margin: 0;
      box-sizing: border-box;
		}
		body{
			background: #f5f5f5;
		}
    #main{
		width: 440px;
		margin: 30px auto;
		position: relative;
		height: 450px;
		
    }
		.tabs{
			width: 440px;
			height: 50px;
			line-height: 50px;
			display: flex;
			/* list-style: none; */
			/* text-align: left; */
			/* margin: 0; */
			/* padding: 0; */
			margin-bottom: -1px;
			position: absolute;
			top: 0;
			left: 0;
			z-index: 999;
		}
		.tabs div {
			text-align: center;
			cursor: pointer;
			width: 110px;
		}
		
		#content{
			position: absolute;
			width: 440px;
			height: 400px;
			overflow: hidden;
			margin: 49px auto;
		}
		#content div{
			position: absolute;
      width: 440px;
      height: 400px;
      overflow: hidden;
      background-color: white;
      border: 1px solid #dddddd;
      padding: 20px 30px;
      text-align: center;
		}
    #content img{
      display: inline-block;
      max-height: 240px;
      margin: 10px auto;
    }
    #content p{
      word-break: break-all;
      text-align: left;
      padding: 20px 0 10px 0;
    }
		.active{
			z-index: 99;
      background: white;
      border: 1px solid #dddddd;
      border-bottom: none;
		}
```


#### javascript内容

```javascript
// 实现选项卡功能
function init() {
  // TODO 待补充代码
  var tabs = document.querySelectorAll('.tabs>div');
  var contents = document.querySelectorAll('#content>div');
  console.log(tabs);

  console.log(contents);

  for (let i = 0; i < tabs.length; i++) {
    tabs[i].index =i;
    tabs[i].onclick = function () {
      for (let j = 0; j < tabs.length; j++) {
        tabs[j].classList.remove("active");
        contents[j].classList.remove("active");
      }
      tabs[i].classList.add("active");
      contents[i].classList.add("active");
    }
  }
}
init();
```


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>前端</category>
        <category>html</category>
        <category>css</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>html</tag>
        <tag>javascript</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理概述</title>
    <url>/2019/03/01/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 快速了解自然语言处理

- 什么是自然语言处理

  自然语言处理(Natural Language Processing，简称NLP)；主要包含自然语言的理解和生成；是人工智能和语言学领域的分支学科。

  自然语言理解：将自然语言转化为计算机更易于处理的形式，让电脑懂人类语言；

  自然语言生成：将计算数据转化为自然语言；

- 自然语言发展背景和历程

  - 1948年，香农把"熵"的概念引用到语言处理中
  - 1956年，乔姆斯基提出来上下文无关语法。[基于规则和概率]
  - 70年代，NLP研究进入低谷期
  - 80年代，有限状态模型和经验主义研究方法复苏
  - 90年代以后，计算机速度和存储量大幅增加，NLP商业化出现

- 自然语言涉及的学科领域

  - 语言学
  - 计算机科学(提供模型标识、算法设计、计算机实现)
  - 数学(数学模型)
  - 统计学(提供样本数据的预测统计技术)
  - 心理学
  - 哲学(提供人类思维和语言的更深层次处理)
  - 电子工程(信息论基础和语言信号处理技术)
  - 生物学(人类言语行为机制理论)

- 自然语言处理的技术体系

  ![image-20190423142659510](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20190423142659510.png)

- 自然语言处理工作原理

  过程：形式化描述——数学模型算法化——程序化——实用化

  - 形式化：研究的问题在语言上建立形式化模型，使其可以数学形式展示出来
  - 数学化：把数学模型标识为算法的过程，成为算法化
  - 程序化：根据算法计算机实现，建立各种自然语言处理系统
  - 实用化：对系统进行评测和改进，最终满足现实需求


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Natural Language Processing</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Natural Language Processing</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言处理基础知识</title>
    <url>/2019/12/28/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# Natural Language Processing

## 自然语言发展历程

- 谷歌翻译，2016年上线全新版本神经网络翻译系统，基于RNN
- Facebook的FAIR（Facebook AI Research）发布《**Convolutional Sequence to Sequence Learning**》， 基于CNN的端到端训练
- 谷歌2017年6月发布《Attention is All you Need》，提出Transformer模型
  - 自注意力 self-attention
  - 多头注意力 multi-head attention
  - 位置嵌入 positional encoding
- OpenAI 2018年发表《Improving Language Understanding by Generative Pre-Training》，提出GPT模型，基于transformer提取特征，跑12个任务，9个任务都达到了最佳
  - 单向语言模型
- AllenAI 2018年8月发表《Deep contextualized word representations》，提出模型ELMo
  - 双向LSTM语言模型
- 谷歌2018年10月，发表《Pre-training of Deep Bidirectional Transformers for Language Understanding》，提出BERT模型
- 百度的ERINE模型
- OpenAI 2019年2月提出GPT2.0，模型更深，训练数据更多，参数高达15亿
- 微软提出MASS模型，（Masked Sequence to Sequence Pre-training）
- 谷歌2019年6月提出XLNet
- Facebook2019年7月发表《RoBERTa: A Robustly Optimized BERT Pretraining Approach》，提出RoBERTa模型
- ……natural language processing

**没有最强，只有更强。。。。**

## 自然语言处理的任务应用

### 句法语义分析

对于给定的句子，进行分词、词性标记、命名实体识别和链接、句法分析、语义角色识别和多义词消歧

### 信息抽取

从给定文本中抽取重要信息，比如抽取：

- 时间
- 地点
- 人物
- 事件
- 原因
- 结果
- 数字
- 日期
- 货币
- 专有名词
- ……

旨在了解谁在什么时候、什么原因、对谁 、做了什么事、有什么结果，涉及到实体识别、时间抽取、因果关系抽取等关键技术

### 文本挖掘

文本聚类、分类、信息抽取、摘要、情感分析以及对挖掘的信息和知识等可视化、交互式的表达界面

### 机器翻译

将输入的源语言文本通过自动翻译获得另外一种语言的文本。

根据输入媒介不同，细分为：

- 文本翻译
- 语音翻译
- 手语翻译
- 图形翻译
- ……

### 信息检索

对大规模的文档进行索引，可简单的对文档中的词汇赋予不同的权重来建立索引，可利用1，2，3的技术来建立更深层的索引

### 问答系统

对一个自然语言表达的问题，由问答系统给出一个精准的答案

需要对自然语言查询语句进行某种程度的语义分析，包括实体链接、关系识别、形成逻辑表达式，然后在知识库中查找可能的候选答案并通过排序机制找出最佳答案

### 对话系统

系统通过一系列对话，跟用户进行聊天、回答、完成某一项任务

涉及到用户意图的理解、通过聊天引擎、问答引擎、对话管理技术，同时为体现和保证上下文的关联，需要具备多轮对话的能力

## 自然语言处理模型

### Seq2Seq模型

- encoder层
- decoder层

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190407193133441.gif)

1、在encode阶段，第一个节点输入一个词，之后的节点输入的是下一个词语前一个节点的 hidden state，最终encoder会输出一个context

2、这个context又作为decoder的输入，每经过一个decoder的节点就输出一个翻译后的词，并将decoder的 hidden state作为下一层的输入

该模型对短文本的翻译而言效果较好，但存在一定的缺点，如果文本稍长，就容易丢失文本的一些信息

### Attention

Attention是一种能让模型对重要信息进行重点关注并充分学习吸收的技术

Attention注意力，该模型在decoder阶段，会选择最适合当前节点的context作为输入

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190407193205893.gif)

1、encoder提供更多的数据给到decoder，encoder会把所有节点的hidden state提供给decoder，而不仅仅是encoder的最后一个节点的hidden state

2、decoder并不是直接吧所有的encoder提供的hidden state作为输入，而是采取一种选择机制，把最符合当前位置的hidden state选出来

- 确定哪个hidden state与当前节点关系最为密切
- 计算每一个hidden state的分值
- 对每个分数值做一个softmax的计算，使得相关性高的hidden state的分数值更大，相关性低的hidden state分数值更低

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190407193223473.gif)

1）把每一个encoder节点的hidden states的值  与decoder当前节点的上一个节点的hidden state相乘， 得到每个encoder节点的每个hidden state的分数

2）将得到的分数进行softmax计算，计算之后的值即为每一个encoder节点的 hidden states 对于当前节点的权重

3）将权重与原hidden states相乘并相加，得到的结果即为当前节点的hidden state

##### decoder层的工作原理

- 第一个decoder的节点初始化一个向量，并计算当前节点的hidden state

- 将得到的hidden state作为第一个节点的输入，经过RNN节点后得到一个新的hidden state与输出值

  区别：

  **seq2seq**是直接把输出值作为当前节点的输出

  **Attention**是把该值与hidden state做成一个链接，并把连接好的值作为context，送入一个前馈神经网络，最终当前节点的输出内容由该网络决定

- 把连接好的值作为context，送入一个前馈神经网络，最终当前节点的输出内容由该网络决定
- 重复以上步骤，直到把所有的 coder的节点都输出相应的内容

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190407193243788.gif)

Attention模型并不只是盲目地将输出的第一个单词与输入的第一个词对齐，实际在训练阶段学习了如何在语言中对齐单词。

**Attention函数的本质，可被描述为一个查询（query）到一系列（键key -值value）对的映射**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190625094348755.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW93b3Nob3V6aQ==,size_16,color_FFFFFF,t_70)

###### 计算attention的主要步骤

- 首先将query 和每个key进行相似度计算得到权重，常用的相似度函数又点积，拼接，感知机等
- 然后使用一个softmax函数对这些权重进行归一化
- 最后将权重和相应的键值value进行加权求和，得到最后的attention

目前在NLP研究中，key和value常常都是一个，key = value

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190625094424708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW93b3Nob3V6aQ==,size_16,color_FFFFFF,t_70)

### Transformer模型

**《Attention is all you need》**

1、不同于以往的主流机器翻译使用基于RNN的seq2seq模型框架，使用attention机制代替了RNN

2、提出多头注意力（Multi-headed attention）机制方法，在编码器和解码器内大量使用多头自注意力机制（Multi-headed self-attent）

#### Transformer总结结构

和Attention模型一样，Transformer也采用了encoder-的 coder架构，但其结构更加复杂，encoder层u由6个encoder组成， decoder层也由6个decoder组成

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190407193306430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW93b3Nob3V6aQ==,size_16,color_FFFFFF,t_70)

每个encoder和decoder的简版结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/2019040719332630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW93b3Nob3V6aQ==,size_16,color_FFFFFF,t_70)

- encoder
  - self-attention，帮助当前节点不仅仅只关注当前的词，从而能获取到上下文的语义
  - 前馈神经网络

**模型内部细节**

1、首先对输入的数据进行 embedding，降维，可以理解为类似word 2 vector 的操作

2、embedding结束之后，输入到encoder层

3、self-attention处理完数据之后把数据送给前馈神经网络

4、前馈神经网络可并行进行计算

5、将计算的输出 输入到下一个encoder

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190407193344547.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW93b3Nob3V6aQ==,size_16,color_FFFFFF,t_70)

- decoder
  - self-attention，帮助当前节点不仅仅只关注当前的词，从而能获取到上下文的语义
  - Encoder-Decoder Attention，帮助当前节点获取当前需要关注的重点内容
  - 前馈神经网络

#### self-attention

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>神经网络</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>神经网络</tag>
        <tag>RNN</tag>
        <tag>CNN</tag>
        <tag>DNN</tag>
      </tags>
  </entry>
  <entry>
    <title>网易云音乐突破红海的思考</title>
    <url>/2020/02/02/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E7%AA%81%E7%A0%B4%E7%BA%A2%E6%B5%B7%E7%9A%84%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 网易云音乐突破红海的思考

​		网易云音乐13年4月23日上线，看似错过音乐市场的先机，进入市场太晚，大部分的用户群体已经在长时间的使用某个音乐软件。

​		用户已经全面习惯了别人已有的音乐应用，它看上去似乎无法绝处逢生。

​		不过有趣的是，网易云音乐不但取得了自己的一席之地，甚至在短短几年后，快速占领市场，分的了音乐市场的一份蛋糕，成为了中国音乐平台第一梯队的选手，激发国内音乐软件市场一次大变革。

![image-20200215094449902](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215094449902.png)



### 一、云音乐吸引你使用的原因什么？

**绝大多数 的人的答案为：**

​		a)懂我

​		b)歌单

​		c)评论

**相信有些时候你会有这样的一种感觉**

​		你突然间遇到了一个毫无名气的小众音乐作品，而你听到的瞬间就红心种草。你把它推荐给你的朋友，死党，小伙伴，他们会觉得你脑子坏掉了。竟然喜欢这么怪的歌，难道你不觉得好难听吗？这是啥？民谣？不对呀，怎么感觉乱七八糟的？

​		然后你点开网易云的评论，一群和你拥有同样观点的人，早已经评论区言简意赅的表达出来你对这个首歌的感受，而且用词轻快简洁而又头头是道……

​		这个时候，你内心绝对是充满了赞同，只想大声呼喊好棒，说的太对了，点赞点赞，转发转发，英雄所见略同；就算大家都悟不到自己的感受，但是在这里你还是有一个音乐知己。

**相信有些时候你还会有这样的一种感觉**

​		你突然间遇到了一个毫无名气的小众音乐作品，而你听到的瞬间就红心种草。你把它推荐给你的朋友，死党，小伙伴，发在你的社群里，收获大量点赞、收听，你会发现“哇，还有这么多人也一样喜欢这首歌”，此刻的你仿佛一个音乐发现者，精品音乐潮人，内心满满的喜悦和满足感，同时还能因为有相同的音乐爱好，更进一步拉近与其他的人距离。

**人类是一种社会性、情感性动物**

​	人这一辈子，跟自己有共同喜好，共同梦想，共同价值观的人交谈或者惺惺相惜，有可能是一个人，也有可能是一群人。总之是件多么爽翻天的事呀～

​	人类是一种社会性、情感性动物，需要与别人交流，会存在情感的共鸣，需要情感化的寄托。依次对照马斯洛需求金字塔里面的各层级，不难发现这样一个有趣的现象：

![image-20200215100508263](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215100508263.png)

**内容的创作者**

​		音乐创作人、MLOG创作人、电台创作人，在这里输出音乐作品，收获到了用户的关注，响应，赞同，音乐作品被用户二次传播，N次传播，内容不停的增值变现。

**内容的消费者**

​		普通听众用户，在云村里触达到各类高质量的音乐作品，发表自己的音乐点评，生活故事，思想观点，收获更多的听众用户对话题的讨论，情感的共鸣；最早的接触到各类优质音乐作品，无形中为用户树立更潮更前卫的潜在心理快感。

创作者和消费者都在这里收获到了 **情感和归属需求、尊重需求、自我实现需求**的满足。

### 二、云音乐到底是个什么样产品？

我对它的的理解是：一个有情感共鸣的音乐内容生态平台。

1、通过UGC、算法、社交构建的音乐传播网络

2、领先的中国音乐人发布平台

![image-20200215113603410](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215113603410.png)

3、发力构建了音乐发行、传播、利润分配的新生态

![image-20200215113709610](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215113709610.png)



#### 云音乐三最

做到了最大的歌单

![image-20200215114311225](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215114311225.png)

做到了最火的评论

做到了最火的音乐推荐

![image-20200215114247663](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215114247663.png)

### 三、云音乐占领市场的切入点

**核心方法：细分+新兴**

细分又被称为后来者的机遇，先来者的挑战。

​		a) 深挖音乐产品的本质思考

​		b) 直指市场竞争的核心思考

​		c) 关于行业未来发展的洞察

#### 深挖音乐产品的本质思考

（1）音乐的特点

​		a) 时间短：一般3-5分钟

​		b) 数量多且长尾：全世界存在大量的音乐作品，由于数量极多而容易变的长尾

​		c) 不断的革新：每天都会新的音乐作品产生，每代人都会有不同的音乐风格

（2）中国人听音乐的现状 ：

​		a) 很少记得住歌，比如去KTV很少第一个站出来去点歌，反而是别人选择以后他人中途站出来接走别人的话题

​		b) 也很少接触到比较优质的音乐，经常的时候都是根据印象记忆里的信息，简单的搜索到几个

​		c) 音乐是无国界的，即使听不到歌词，但也能引起情感的共鸣

​		**国人为什么不能听到更好、更多的音乐？**

（3）当前互联网内容的一个信息对比

​		a) 电影、电视、小说、音乐的内容深度往往要大于图片、微博文字；

​		b) 图片、微博文字、音乐的数量广度又远远大于电影、电视、小说；

​		基于此，**音乐是一个能深度足够深、内容数量特别广的产品。**

​		**音乐短、多、快，而易变得长尾，优质音乐内容依赖发现；**

​		**对标其他内容产品内容深度和广度，优质音乐内容依赖推荐；**

（4）深挖听音乐用户的本质需求：

​		a) 好听

​		b) 情感连接

（5）独立音乐创作人的作品容易被深埋

​		a) 往往小众独立音乐人因资源、经费而无法快速进入大众视线

​		b) 优质的作品很难曝光给普通用户，市场的业态依旧被头部公司所把持

综上挖掘到了一个极其重要，但却一直未被满足的用户本质诉求：**让用户更多的听到他喜欢的音乐**。用户如同一个嗷嗷待哺的婴儿，对好听的音乐渴求不及。

#### 直指市场竞争的核心思考

（1）红海市场：

 		a) 巨头音乐软件的特点：曲库大、发现功能弱 

​			是一个曲库型的音乐播放器；但是用户却发现不了好音乐；

​			拥有大量的DAU，但是用户却发现不了好音乐；

​			完全依赖于用户自己主观的搜索和选择，对于认知、了解、文化不够充分的时候，用户却发现不了好音乐；		

​		 b) 小众音乐软件的特点：发现功能弱、产品无重心、体量小

（2）产业链结构

​		**内容产业上游（生产内容环节，艺人、词曲作者等） → 中间环节（发		行、演出、经纪公司等） → 内容产业下游（消费者）**

​		2.1) 音乐市场仍停留在**艺人-专辑-公司发行-在线播放-听众用户**的形态中

​		a) 市场所有的音乐软件都是在堆积曲库，收集专辑，搜索榜单

​		b) 所有音乐软件都是在作为音乐播放器来使用

​		2.2) 独立音乐创作人的作品容易被深埋

​		a) 往往小众独立音乐人因资源、经费而无法快速进入大众视线

​		b) 优质的作品很难曝光给普通用户，市场的业态依旧被头部公司所把持

​		c) 优质音乐人的作品，如果没有被音乐公司，品牌方制作宣传，很难进入曲库的最前方的位置，大众几乎无法捕捉到这些优质资源

**（3）市场竞争的切入点：**

 		a) 摆脱零和竞争: 红海市场的曲库型竞争;

 		b) 创造非零和市场: 赋予用户发现音乐的能力;

​			**网易云音乐发力点在曲库被用户发现的效率**

​		 c) 打破现有产业链结构，形成新的生态

​		产业链：三个环节逐渐融合，最终用户最大；

​		内容源：与用户直接互动；自主营销和传播，产生新的营收方式；

​		平台：使用户和内容源更加靠近；取代传统渠道，成为利益分配的平台；实现内容创作者和消费者及平台共赢

### 四、云音乐规模化增长

**用产品和口碑驱动增长**

#### 歌单促增长

(1) 实现歌单NO.1

​	a) 形成以歌单为核心的产品，围绕歌单进行发现、播放、管理、分享

​	b) 打造UGC循环，吸引热衷歌单创作、以歌单组合分享音乐作品的人

(2) 将歌单融入生活

​	a) 刷题的歌单、春天的歌单、抖腿的歌单，跑步的歌单……多种多样的歌单组合

​	b) 打破原有的语种、风格进行天马行空式的自由品类组合

​	c) 融合在生活场景内歌单组合得以在用户群体里快速传播

#### 推荐口碑促增长

(1) 音乐推荐NO.1

​	a) 以音乐推荐为核心的产品功能

​	b) 将推荐融入到所有“发现”类的应用场景

(2) 打造推荐的惊喜感

​	**国人有很多很多听过觉得很长好听，但却一直不知道名字的歌。**

​	而在云音乐恰好凸显了这个神奇的点，“恰好的推出来了，多年前的不知名的神奇音乐”。

​	a) 爬取音乐评论内的关键词，“记忆”，“不记得歌名”，“惊喜”，“想起来了”，捕捉到了初始的种子音乐

​	b) 基于算法去匹配与该种子音乐的相似度最高的音乐

​	c) 爬取用户在其他社交媒体的公开数据，收集用行为

​	d) 在云音乐内进一步推出相似结果

(3) 洞察用户需求本质：懂我

推荐音乐的本质：**不是让所有人都听到不通的音乐，而是让所有人都觉得好懂我。**

**推荐的懂我和惊喜感在千万人中引爆时，就会形成巨大的用户口碑效应。**

#### 评论促增长

(1) 洞察用户心理

​	a) 共鸣

​		青春、前男/女友、暗恋、回不去的童年、一代人的记忆、相通的感悟、未来的畅想……

​	b) 共鸣和记忆碎片连接

​		一段文字、一首歌、一个地点、一个小物件、一部电影、一张旧照片、一个定格画面……

​	c) 孤独感

​		当代青年人麻木不仁生活的格外的孤独，愈孤独愈需要感情共鸣和寄托；

​		需要情感的释放和表达；

​		人群的肯定与认可（点赞）；

![image-20200215143338411](/Users/gaozhiyong/Library/Application Support/typora-user-images/image-20200215143338411.png)

(2) 音乐推荐+评论+歌单，创造极致的音乐体验，彻底引爆口碑

​	a) 形成了一个极致的心的体验

​		打开云音乐听歌，看评论，循环往复，用户大量的碎片时间被沉淀在云音乐APP

收获到大量的核心品质用户，口口相传获得大量用户增长。

### 五、云音乐生态化打造

​		云音乐的快速发展，曲库、版权、原创内容、用户停留时长的日渐成为云音乐增长的制约性因素；故而云音乐一步一步打造起来的边际产品，渐成生态。

(1) 创作者中心，“入驻网易音乐人”|“电台中心” |"音乐达人"|“MLOG创作中心”

​		原创音乐是内容源头，而源头的作曲，作词却是收入的边缘人群，云音乐尝试打破已有的**内容产业上游（生产内容环节，艺人、词曲作者等） → 中间环节（发		行、演出、经纪公司等） → 内容产业下游（消费者）**结构，使的原创音乐创作者获得更大的变现空间，激发原创内容新血液。

(2) 云村，音乐与图片，音乐与短视频，音乐与热评的全方位融合

(3) 视频，扩展的视频信息流

​		移动端用户的注意力被大量的应用所侵占，云音乐发力构建内容社区，充分利用已有优势将音乐与评论，短视频创意组合，沉淀用户的停留时长。

​		有一群价值观趋同的人，为了一个共同的目的来到云村，云村使得这群人互相之间发生交互，从而让他们发现『哇~ 有这么多人跟我一样！』，从而形成连接，由此形成的往复循环。

逐步发力成为一个优质的音乐内容的生态平台

 a)产业链三个环节逐渐融合，最终用户最大；

 b)内容源：实现内容源与用户直接互动；自主营销和传播，产生新的营收方式；

 c)平台：用户和内容源更加靠近；取代传统渠道，成为利益分配的平台；

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>产品</category>
        <category>创新</category>
      </categories>
      <tags>
        <tag>产品</tag>
        <tag>创新</tag>
        <tag>行业</tag>
      </tags>
  </entry>
  <entry>
    <title>关于社群经济</title>
    <url>/2019/04/07/%E7%A4%BE%E7%BE%A4%E7%BB%8F%E6%B5%8E/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
现状：靠社群成功的组织，都在慢慢的去社群化。

# 如何理解社群

社群只是人与人之间的连接方式。

### 1、精神连接

### 2、现实连接

### 3、数字连接

一个社群的能量值=精神连接 * 现实连接 * 数字连接

# 如何理解社群经济

### 1、理论：1000铁粉和产销者

《失控：机器、社会与经济的新生物学》. 凯文.凯利（Kevin Kelly）

：一个创作者，例如作家、设计师、音乐家，只要永远1000铁粉，就可以借此谋生了。

#### 1）1000铁粉理论关键不在于1000，在于“铁”

- true fans
- 可以购买你任何产品的粉丝

#### 2）先有产品，后有商机

- 需要有足够好、足够多的产品，才能产生变现

#### 3）和粉丝直接对话

《第三次浪潮》.阿尔文.托夫勒—产销者概念

- 即是生产者，又是消费者

### 2、社群经济诞生背景：打破互联网的流量霸权

- 流量假、流量贵、流量转化低，成为全行业的痛点
- 2015年，内容公众号打开频率降低，为唤醒沉睡粉丝，自媒体打造群组，组织线下活动，试图于粉丝发保持更多维度、更高频次的连接
- 依靠人与人之间的连接欲望，就可以收获用户
- **社群，是一种零成本连接的商业模式**
- **社群经济最大的能量在于零成本完成原始积累**

### 3、案例：1000铁杆粉丝 + 产销者 = 真正的社群经济

- **形成社群经济的核心：社群内有没有真的“产销者”**

# 社群的特性

- 闭合性
- 自组织
- 隐秘性
- 强关系

### 1、闭合性：建造社群“围墙”

### 2、自组织：去运营化的社群，才是好社群

### 3、隐秘性：捕捉社群成员的精神诉求

### 4、强关系：建立社群的交叉连接

# 如何打造一个社群组织

### 1、图腾：找到一个终极意义

### 2、围墙：主动打造社群壁垒

### 3、教义：建立游戏规则

### 4、法老：赋能一个精神领袖

### 5、群贤：培育你的“产销者”

# 社群思维的商业应用

### 1、连接工具：零成本获客的最佳手段

### 2、多维变现：创造多维度的商业收割

### 3、产销一体：社群经济的终极追求

社群能量= 精神连接 * 数字连接 * 现实连接

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>营销</category>
        <category>社群经济</category>
      </categories>
      <tags>
        <tag>营销</tag>
        <tag>商业</tag>
      </tags>
  </entry>
  <entry>
    <title>自然语言的几个重要模型-学习记录</title>
    <url>/2020/12/25/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E9%BB%98%E5%86%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 自然语言的几个重要模型-学习记录

- 循环神经网络 (序列模型序列依赖问题)
- 双向循环神经网络（输入序列正向和反向依赖问题）
- 深度双向循环神经网络
- LSTM（梯度消失问题）
- GRU
- text CNN（一维卷积和池化）
- seq2seq（序列到序列问题）
- Attention（decoder对encoder输入序列注意力问题，从输入获取可用信息）
- Transform（对输入的序列分成q检索项 k键项 v值项进行计算，矩阵并行计算）
- 语言预训练方法ELMO （使用双向rnn组合中间层权重）
- 语言预训练方法BERT ERNIE （使用transform encoder部分无需标签，ERNIE主要处理中文场景按词mask）
- 语言预训练方法GPT （使用transform decoder部分）



### 1.循环神经网络

![img](https://pic2.zhimg.com/80/v2-6d3c95a028c3c39ef914578c28761f4d_720w.jpg)

- 使用隐藏层保留之前时间步的信息
- **梯度裁剪** 处理梯度爆炸问题，即超出阈值怎重置为阈值。因为在RNN中目标函数有关隐藏状态的梯度会因为时间步数较大或时间步较小而变大。

### 2.双向循环神经网络

![img](https://pic1.zhimg.com/80/v2-c867b8b44ac1523c5bcd57892d82c410_720w.jpg)

*（橘色的实线和虚线分别是前向传递和后向传递的过程 ）*

- 通常RNN输入序列是按顺序输入，但此时就会丢失从后往前的数据。双向RNN就是前后各有一个网络，对各自输出的向量进行整合。

### 3.深度双向循环神经网络

![img](https://pic4.zhimg.com/80/v2-f0cefee0daa2b03db7ab82d6041255db_720w.jpg)

- 叠加多层双向RNN

### 4.LSTM

![img](https://pic2.zhimg.com/80/v2-4722529b9d834e3f33d9c69c357a131d_720w.jpg)

![img](https://pic2.zhimg.com/80/v2-091d6c59f1470d69b02e5706c6e8826d_720w.jpg)

- 包含了三个门，输入门 输出门 遗忘门
- 缓解了梯度消失的问题

### 5.GRU

![img](https://pic3.zhimg.com/80/v2-1b198e023a6d37e62007f2194968345a_720w.jpg)

- 包含重置门和更新门
- 缓解了梯度消失的问题

### 6.textCNN

![img](https://pic3.zhimg.com/80/v2-018ad2fb5cedbac69995091a3382aa26_720w.jpg)

*如上图输入每个单词用5维词向量表示，即输入的通道是5. 输入宽度是7. 红色框卷积核宽是4 所以得到的输出向量长度是7-4+1=4，再对通道做池化得到最后的向量进行拼接 再使用全连接层进行业务逻辑处理例如分类*

- 使用一维卷积来捕获位置相近词的关联
- 时序最大池化层

### 7.seq2seq

![img](https://pic4.zhimg.com/80/v2-3d0a76f2a08c1e63a6b5e83363f449b7_720w.jpg)

- 序列到序列模型 使用Encoder编码器生成序列到向量。Decoder解码器从向量生成文本
- encoder的输出是c=f(h1, h2...)，在计算y输出时使用了相同的背景变量c。（但例如在翻译场景输出是关联到输入的某个词的，所以引入了带注意力机制的seq2seq）
- 输出y是一个概率模型（例如输出y1可能有 “越” 50%可能性、“跃”10%可能性、......）选择哪一个值有三种方式。
- 贪婪搜索 只取概率最大的 ，但是这种情况并非能取到全局最优解。因为前几个词选择直接影响到后面几个词。
- 穷举搜索 量太大了。。
- 束搜索 束宽k 每次取前k个 最后在候选取分最高得。

### 8.Attention注意力机制

![img](https://pic2.zhimg.com/80/v2-458a9f90e229afda50492fe07e820e25_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-d86bb49f50f76ffc04a0d35efb362358_720w.jpg)

- 如上图可以看出decoder的输出受到上一时刻输出、上一时刻隐含层变量和当前时间步背景向量影响。背景向量即所有编码器隐含层的加权平均得到。ci即为背景向量。
- ci最终是由解码器在i-1时刻的隐藏状态和编码器在j时刻的隐藏状态得到，具体怎么组合原文中提供了三种方法（第一种类似直接求内积..）：

![img](https://pic1.zhimg.com/80/v2-626705b15c5ecde49eb8423f380da928_720w.jpg)

- 得到了输入所需要得**上一时刻输出、上一时刻隐含层变量和当前时间步背景向量**后，接下来就是如何组合这三个输入得到输出。使用门控循环单元进行组合。

### 9.Transform

变换器模型不同于RNN的架构（下一步计算都依赖前一步的输出，无法并行）。使用矩阵运算得到计算效率更高的模型。

![img](https://pic4.zhimg.com/80/v2-6f091d417fdc6eeeafa7c520b5c8a8d7_720w.jpg)

最终的公式：

![img](https://pic1.zhimg.com/80/v2-d9060c49cb9fc6fca8d3dfe18e1ee460_720w.jpg)

- 由上图得到对于输入x分别通过三个不同的矩阵得到q（检索项）k（键值项）v（值项）。q1项分别与其他几个键值项点乘再得到所有q1计算得到的值求softmax，再和v值项相乘求和。同样得得到q2、q3、q4得出结果。该计算得过程是并行的。
- 多头注意力机制即每个x输入将会输出多组q k v如下图，计算规则基本一致。

![img](https://pic2.zhimg.com/80/v2-d62fd9134fd608aa3ca44883dadf84c1_720w.jpg)

- 通过上述描述可以看出在计算过程中没有词的位置信息。所以在进行x->a的变换过程中，将a增加位置信息编码。
- 完整Transform

![img](https://pic2.zhimg.com/80/v2-3d4f17d18143c6851357f27124bcab15_720w.jpg)

### 10.语言模型预训练方法ELMO

![img](https://pic2.zhimg.com/80/v2-7ff59c3d2c7f98cc8013d6ab12905ecd_720w.jpg)

- elmo使用双向rnn对文本进行训练得到中间层向量抽取后进行组合。组合的参数也是学出来了。原论文中r'n'n部分使用lstm实现

### 11.语言模型预训练方法BERT

- Bert使用transform的encoder部分，所以可以进行无标签学习
- bert训练方法一 有15%的字会被MASK隐藏，这样学出来的被遮挡的词就会有相似的词向量。

![img](https://pic2.zhimg.com/80/v2-faf5e9f13cb1c4335f51171ae2ddd1d1_720w.jpg)

- bert训练方法二 句子是否是相邻的判断。用SEP进行链接

![img](https://pic3.zhimg.com/80/v2-c86d61bb43209f2d2a109f7b7351624a_720w.jpg)

- ERNIE 由上述可以看出Bert是对字进行MASK，对于中文场景进行的词MASK更合理，如下图。目前百度paddlepaddle已经发布开源版本。

![img](https://pic4.zhimg.com/80/v2-5e91252408d0539d2090815f2084638f_720w.jpg)

### 12.语言模型预训练方法GPT

- 使用transform的decoder部分。
- 目前最大模型是1.5G 但是没有release最终版本

### 13.词向量计算相关模型word2vec和glove fasttext


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Natural Language Processing</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Natural Language Processing</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告-在线广告综述</title>
    <url>/2019/01/01/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A-%E5%9C%A8%E7%BA%BF%E5%B9%BF%E5%91%8A%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


# 计算广告-在线广告综述

> 广告不同于搜索或推荐，首先是一项商业活动，其次才是一项在互联网环境下需要技术优化的商业活动
>
> 在这一商业活动中，广告主、用户、媒体的利益都需要被考虑和满足，才能达到整个市场的平衡和不断发展。

## 1、广告的定义与目的

**广告定义**

​	广告由确定出资人，通过各种媒介进行的有关产品。 

​	有偿的、有组织的、综合的、劝服性的非人员的信息传播活动。

- 需求方（Demand）---广告主---出资人
- 供给方（Supply）---媒体
- 受众（Audience）

**广告分类**

- 品牌广告（Brand Awareness）

  借助媒体力量快速接触大量用户，以达到宣传品牌形象，提升中长期购买率与利润空间。

- 效果广告（Direct Response）

  利用广告手段马上获取到大量的购买行为。

**广告目的**

​	广告主通过媒体达到低成本的用户接触。

​	需要ROI（Return over Investment）投入产出比作为评价指标

## 2、在线广告类型

**条幅广告（Banner Ad）**

​	banner广告

**文字链广告（Textual Ad）**

​	搜索广告中的主流形式

**富媒体广告（Rich Media Ad）**

​	向用户侵入式的投送广告素材，有弹窗、对联、全屏，对用户体验影响页也较大

**视频广告（Video Ad）**

​	视频广告效果和创意类似线下的电视广告；除计算点击率，还采用观看时长来评估用户印象

​	根据插入位置分为

 - 前插片
   	- 短视频形式，冲击力和表现力远强于普通广告
	- 后插片
	- 暂停

**社交广告（Social Ad）**

​	社交广告， 并非“社交网络中的广告”；旨在通过用户的扩散式传播获得更大的影响力，以及更可信的口碑。

​	在信息流的交互中挖掘价值。

**移动设备广告（Mobile Ad）**

**邮件营销广告（EDM，Email Direct Marketing）**

​	通过邮件方式向目标用户传递价值信息。

##3、广告有效性原理

> 曝光（Exposure）

	>>> 关注（Attention）
	>>
	>>>> > 理解（Comprehension）
	>>>
	>>>> > > > 接收（Acceptance）
	>>>>
	>>>> >> > > > 保持（Retention）
	>>>> >
	>>>> >>> > > > > 决策（Decision）

**曝光阶段**

​	往往与广告位的物理属性有关，不同广告位效果区别较为明显。

​	==需考虑如何从算法上消除由于此带来的点击率预估偏差。==

**关注阶段**

​	受众从物理上接触到广告--->> 到意识到广告的过程

​	需着重考虑提高关注效率。

​	操作原则：

	- 尽量不打断用户的任务
	- 明确传达向用户推送此广告的原因
	- 内容符合用户的兴趣或需求（受众定向的原理基础）

**理解阶段**

​	受众意识到广告--->> 到理解广告传达的信息的过程

​	操作原则：

	- 广告内容要在用户理解的具体兴趣范围内
	- 注意设定与关注程度相匹配的理解门槛（比如电视广告讲个前奏故事；互联网广告强调主要诉求）

**接收阶段**

​	受众理解广告--->> 到接受广告的过程

​	广告的上下文环境对于广告的接受程度也有较大的影响；如何让合适的广告出现在合适的媒体上，（广告安全 Ad Safety）

**保持阶段**

**决策阶段**

​	带来转化行为

越靠前的阶段，效果的改善对点击率贡献越大；越靠后的阶段，效果的改善对转化率贡献越大；但是各阶段并非孤立绝对的，某项的调整也往往会影响其他几个阶段的效果。

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>广告产品</category>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>广告产品</tag>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告-基础</title>
    <url>/2019/01/02/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A-%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 计算广告-基础

## 1、在线广告技术特点

**技术和计算导向**

​	数字媒体的特点使在线广告可以精细的用户定向

​	技术又使广告决策和交易朝着计算驱动的方向发展

**效果的可衡量性**

​	在同一个时期，点击率的绝对值并没有那么重要；而在一个特定时期不同广告和算法表现出来的差异，才更有	意义

**创意和投放方式的标准化**

​	标准化的驱动力来自受众定向与程序购买

​	需求方更关心的是受众人群，创意尺寸的统一化与数据接口的标准化就变得更加重要

**媒体概念的多样化**

**数据驱动的投放决策**

​	互联网化的根本驱动力是数据的深入加工和利用

## 2、计算广告的核心问题

> 计算广告的核心问题，是为一系列用户与环境的组合，找到最合适的广告投放策略以优化整体的投入产出比（ROI）

### 2.1、在线广告计费模式

**CPM（Cost per Mile）**

​	按照千次展示计费

**CPC（Cost per Click）**

​	按照点击计费

**CPS（Cost per Sale）/ CPA（Cost per Action）/ROI**

​	按照销售订单数、转化行为数或投入产出比来计费

​	情况一：需求方只按照最后的转化效益来结算  

​	存在问题：

​			转化行为并非供给方能控制

​			存在广告主故意降低转化率，以低成本赚取大量曝光的可能

​	此方式只适合一些垂直广告网络（Vertical Network）

**CPT（Cost per Time）**

​	针对大品牌广告主特定的活动，将广告位以独占的方式交与某广告主，并按照独占的时间段进行收费

## 3、计算广告系统架构

通常有三个主体部分组成

- 在线的高并发投放引擎
- 离线的分布式数据处理平台
- 在线实时反馈的流式处理平台

按照功能划分模块

**广告投放机**

​	Ad Server，与其他模块交互，并将其串联，完成在线广告的投放。

**广告检索**

​	Ad Index 、Ad retrieval

​	接收广告投放信息，建立倒排索引，以及在线时根据用户与上下文标签从索引中查找广告候选。

​	检索技术也是大规模计算广告系统的基础。

**广告排序**

​	Ad ranking 、Click modeling

​	广告效果优化的关键。

​	关键技术，==在于离线分布式计算平台上的海量数据支持 点击率预测模型的训练。==

**数据高速公路**

​	Data highway

​	将在线投放的数据准实时传输到离线分布式计算平台 与 流式计算平台，供后续处理和建模使用。

**用户日志生成**

​	Session log generation

​	从个渠道收集日志

**商业智能**

​	Business Intelligence

​	包含ETL、dashboard 、cube

​	最终的数据处理和分析流程的总括。

**行为定向**

​	包含结构化标签库（Structural-label base）、Audience targeting 、以及User attributes的cache

​	挖掘用户日志，根据日志中的行为给用户打上结构化的标签

**上下文定向**

​	包括半在线页面抓去（Near-line page fetcher） 和 Page attributes的cache

​	与行为定向互相配合，负责为上下文打标签

**定制化用户划分**

​	Customized audience segmentation

​	根据广告主的需求逻辑划分用户群

**在线行为反馈**

​	一些需准实时完成的一些任务

​	短时用户行为标签、短时用户点击反馈

​	反作弊（Anti-spam） 与 计价（Billing）

**广告管理系统**

​	面向用户的产品，由广告的操作者进行配置

**实时竞价接口**

​	广告交易市场实时向DSP发起广告询价请求

---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>广告产品</category>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>广告产品</tag>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title>航空公司客户价值聚类分析</title>
    <url>/2021/02/17/%E8%88%AA%E7%A9%BA%E5%85%AC%E5%8F%B8%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>


## 航空公司客户价值聚类分析

- 特征工程
- K-means聚类
- RFM模型
- DBSCAN算法

#### 描述

信息时代的来临使得企业营销焦点从产品中心转变成客户中心。具体地，对不同的客户进行分类管理，给予不同类型的客户制定优化的个性化服务方案，采取不同的营销策略。将有限的营销资源集中于高价值的客户，实现企业利润最大化

1. 借助航空公司数据，对客户进行分类
2. 对不同类别的客户进行特征分析，比较不同类别客户的价值
3. 对不同价值的客户类别进行个性化服务，制定相应的营销策略

#### 思路

![image.png](01.png)

#### 数据

##### 数据集中字段含义

![image.png](02.png)
![image.png](03.png)

##### 数据预处理


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime
import sklearn.preprocessing
import sklearn.cluster
```


```python
air_data_path = "./dataset/air_data.csv"
air_data = pd.read_csv(air_data_path)
```


```python
air_data.shape
```


    (62988, 44)


```python
air_data.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MEMBER_NO</th>
      <th>FFP_DATE</th>
      <th>FIRST_FLIGHT_DATE</th>
      <th>GENDER</th>
      <th>FFP_TIER</th>
      <th>WORK_CITY</th>
      <th>WORK_PROVINCE</th>
      <th>WORK_COUNTRY</th>
      <th>AGE</th>
      <th>LOAD_TIME</th>
      <th>...</th>
      <th>ADD_Point_SUM</th>
      <th>Eli_Add_Point_Sum</th>
      <th>L1Y_ELi_Add_Points</th>
      <th>Points_Sum</th>
      <th>L1Y_Points_Sum</th>
      <th>Ration_L1Y_Flight_Count</th>
      <th>Ration_P1Y_Flight_Count</th>
      <th>Ration_P1Y_BPS</th>
      <th>Ration_L1Y_BPS</th>
      <th>Point_NotFlight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>54993</td>
      <td>2006/11/02</td>
      <td>2008/12/24</td>
      <td>男</td>
      <td>6</td>
      <td>.</td>
      <td>北京</td>
      <td>CN</td>
      <td>31.0</td>
      <td>2014/03/31</td>
      <td>...</td>
      <td>39992</td>
      <td>114452</td>
      <td>111100</td>
      <td>619760</td>
      <td>370211</td>
      <td>0.509524</td>
      <td>0.490476</td>
      <td>0.487221</td>
      <td>0.512777</td>
      <td>50</td>
    </tr>
    <tr>
      <th>1</th>
      <td>28065</td>
      <td>2007/02/19</td>
      <td>2007/08/03</td>
      <td>男</td>
      <td>6</td>
      <td>NaN</td>
      <td>北京</td>
      <td>CN</td>
      <td>42.0</td>
      <td>2014/03/31</td>
      <td>...</td>
      <td>12000</td>
      <td>53288</td>
      <td>53288</td>
      <td>415768</td>
      <td>238410</td>
      <td>0.514286</td>
      <td>0.485714</td>
      <td>0.489289</td>
      <td>0.510708</td>
      <td>33</td>
    </tr>
    <tr>
      <th>2</th>
      <td>55106</td>
      <td>2007/02/01</td>
      <td>2007/08/30</td>
      <td>男</td>
      <td>6</td>
      <td>.</td>
      <td>北京</td>
      <td>CN</td>
      <td>40.0</td>
      <td>2014/03/31</td>
      <td>...</td>
      <td>15491</td>
      <td>55202</td>
      <td>51711</td>
      <td>406361</td>
      <td>233798</td>
      <td>0.518519</td>
      <td>0.481481</td>
      <td>0.481467</td>
      <td>0.518530</td>
      <td>26</td>
    </tr>
    <tr>
      <th>3</th>
      <td>21189</td>
      <td>2008/08/22</td>
      <td>2008/08/23</td>
      <td>男</td>
      <td>5</td>
      <td>Los Angeles</td>
      <td>CA</td>
      <td>US</td>
      <td>64.0</td>
      <td>2014/03/31</td>
      <td>...</td>
      <td>0</td>
      <td>34890</td>
      <td>34890</td>
      <td>372204</td>
      <td>186100</td>
      <td>0.434783</td>
      <td>0.565217</td>
      <td>0.551722</td>
      <td>0.448275</td>
      <td>12</td>
    </tr>
    <tr>
      <th>4</th>
      <td>39546</td>
      <td>2009/04/10</td>
      <td>2009/04/15</td>
      <td>男</td>
      <td>6</td>
      <td>贵阳</td>
      <td>贵州</td>
      <td>CN</td>
      <td>48.0</td>
      <td>2014/03/31</td>
      <td>...</td>
      <td>22704</td>
      <td>64969</td>
      <td>64969</td>
      <td>338813</td>
      <td>210365</td>
      <td>0.532895</td>
      <td>0.467105</td>
      <td>0.469054</td>
      <td>0.530943</td>
      <td>39</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 44 columns</p>




```python
air_data.dtypes
```


    MEMBER_NO                    int64
    FFP_DATE                    object
    FIRST_FLIGHT_DATE           object
    GENDER                      object
    FFP_TIER                     int64
    WORK_CITY                   object
    WORK_PROVINCE               object
    WORK_COUNTRY                object
    AGE                        float64
    LOAD_TIME                   object
    FLIGHT_COUNT                 int64
    BP_SUM                       int64
    EP_SUM_YR_1                  int64
    EP_SUM_YR_2                  int64
    SUM_YR_1                   float64
    SUM_YR_2                   float64
    SEG_KM_SUM                   int64
    WEIGHTED_SEG_KM            float64
    LAST_FLIGHT_DATE            object
    AVG_FLIGHT_COUNT           float64
    AVG_BP_SUM                 float64
    BEGIN_TO_FIRST               int64
    LAST_TO_END                  int64
    AVG_INTERVAL               float64
    MAX_INTERVAL                 int64
    ADD_POINTS_SUM_YR_1          int64
    ADD_POINTS_SUM_YR_2          int64
    EXCHANGE_COUNT               int64
    avg_discount               float64
    P1Y_Flight_Count             int64
    L1Y_Flight_Count             int64
    P1Y_BP_SUM                   int64
    L1Y_BP_SUM                   int64
    EP_SUM                       int64
    ADD_Point_SUM                int64
    Eli_Add_Point_Sum            int64
    L1Y_ELi_Add_Points           int64
    Points_Sum                   int64
    L1Y_Points_Sum               int64
    Ration_L1Y_Flight_Count    float64
    Ration_P1Y_Flight_Count    float64
    Ration_P1Y_BPS             float64
    Ration_L1Y_BPS             float64
    Point_NotFlight              int64
    dtype: object




```python
air_data.describe().T
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MEMBER_NO</th>
      <td>62988.0</td>
      <td>31494.500000</td>
      <td>18183.213715</td>
      <td>1.00</td>
      <td>15747.750000</td>
      <td>31494.500000</td>
      <td>47241.250000</td>
      <td>62988.000000</td>
    </tr>
    <tr>
      <th>FFP_TIER</th>
      <td>62988.0</td>
      <td>4.102162</td>
      <td>0.373856</td>
      <td>4.00</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>4.000000</td>
      <td>6.000000</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>62568.0</td>
      <td>42.476346</td>
      <td>9.885915</td>
      <td>6.00</td>
      <td>35.000000</td>
      <td>41.000000</td>
      <td>48.000000</td>
      <td>110.000000</td>
    </tr>
    <tr>
      <th>FLIGHT_COUNT</th>
      <td>62988.0</td>
      <td>11.839414</td>
      <td>14.049471</td>
      <td>2.00</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>15.000000</td>
      <td>213.000000</td>
    </tr>
    <tr>
      <th>BP_SUM</th>
      <td>62988.0</td>
      <td>10925.081254</td>
      <td>16339.486151</td>
      <td>0.00</td>
      <td>2518.000000</td>
      <td>5700.000000</td>
      <td>12831.000000</td>
      <td>505308.000000</td>
    </tr>
    <tr>
      <th>EP_SUM_YR_1</th>
      <td>62988.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>EP_SUM_YR_2</th>
      <td>62988.0</td>
      <td>265.689623</td>
      <td>1645.702854</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>74460.000000</td>
    </tr>
    <tr>
      <th>SUM_YR_1</th>
      <td>62437.0</td>
      <td>5355.376064</td>
      <td>8109.450147</td>
      <td>0.00</td>
      <td>1003.000000</td>
      <td>2800.000000</td>
      <td>6574.000000</td>
      <td>239560.000000</td>
    </tr>
    <tr>
      <th>SUM_YR_2</th>
      <td>62850.0</td>
      <td>5604.026014</td>
      <td>8703.364247</td>
      <td>0.00</td>
      <td>780.000000</td>
      <td>2773.000000</td>
      <td>6845.750000</td>
      <td>234188.000000</td>
    </tr>
    <tr>
      <th>SEG_KM_SUM</th>
      <td>62988.0</td>
      <td>17123.878691</td>
      <td>20960.844623</td>
      <td>368.00</td>
      <td>4747.000000</td>
      <td>9994.000000</td>
      <td>21271.250000</td>
      <td>580717.000000</td>
    </tr>
    <tr>
      <th>WEIGHTED_SEG_KM</th>
      <td>62988.0</td>
      <td>12777.152439</td>
      <td>17578.586695</td>
      <td>0.00</td>
      <td>3219.045000</td>
      <td>6978.255000</td>
      <td>15299.632500</td>
      <td>558440.140000</td>
    </tr>
    <tr>
      <th>AVG_FLIGHT_COUNT</th>
      <td>62988.0</td>
      <td>1.542154</td>
      <td>1.786996</td>
      <td>0.25</td>
      <td>0.428571</td>
      <td>0.875000</td>
      <td>1.875000</td>
      <td>26.625000</td>
    </tr>
    <tr>
      <th>AVG_BP_SUM</th>
      <td>62988.0</td>
      <td>1421.440249</td>
      <td>2083.121324</td>
      <td>0.00</td>
      <td>336.000000</td>
      <td>752.375000</td>
      <td>1690.270833</td>
      <td>63163.500000</td>
    </tr>
    <tr>
      <th>BEGIN_TO_FIRST</th>
      <td>62988.0</td>
      <td>120.145488</td>
      <td>159.572867</td>
      <td>0.00</td>
      <td>9.000000</td>
      <td>50.000000</td>
      <td>166.000000</td>
      <td>729.000000</td>
    </tr>
    <tr>
      <th>LAST_TO_END</th>
      <td>62988.0</td>
      <td>176.120102</td>
      <td>183.822223</td>
      <td>1.00</td>
      <td>29.000000</td>
      <td>108.000000</td>
      <td>268.000000</td>
      <td>731.000000</td>
    </tr>
    <tr>
      <th>AVG_INTERVAL</th>
      <td>62988.0</td>
      <td>67.749788</td>
      <td>77.517866</td>
      <td>0.00</td>
      <td>23.370370</td>
      <td>44.666667</td>
      <td>82.000000</td>
      <td>728.000000</td>
    </tr>
    <tr>
      <th>MAX_INTERVAL</th>
      <td>62988.0</td>
      <td>166.033895</td>
      <td>123.397180</td>
      <td>0.00</td>
      <td>79.000000</td>
      <td>143.000000</td>
      <td>228.000000</td>
      <td>728.000000</td>
    </tr>
    <tr>
      <th>ADD_POINTS_SUM_YR_1</th>
      <td>62988.0</td>
      <td>540.316965</td>
      <td>3956.083455</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>600000.000000</td>
    </tr>
    <tr>
      <th>ADD_POINTS_SUM_YR_2</th>
      <td>62988.0</td>
      <td>814.689258</td>
      <td>5121.796929</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>728282.000000</td>
    </tr>
    <tr>
      <th>EXCHANGE_COUNT</th>
      <td>62988.0</td>
      <td>0.319775</td>
      <td>1.136004</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>46.000000</td>
    </tr>
    <tr>
      <th>avg_discount</th>
      <td>62988.0</td>
      <td>0.721558</td>
      <td>0.185427</td>
      <td>0.00</td>
      <td>0.611997</td>
      <td>0.711856</td>
      <td>0.809476</td>
      <td>1.500000</td>
    </tr>
    <tr>
      <th>P1Y_Flight_Count</th>
      <td>62988.0</td>
      <td>5.766257</td>
      <td>7.210922</td>
      <td>0.00</td>
      <td>2.000000</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>118.000000</td>
    </tr>
    <tr>
      <th>L1Y_Flight_Count</th>
      <td>62988.0</td>
      <td>6.073157</td>
      <td>8.175127</td>
      <td>0.00</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>8.000000</td>
      <td>111.000000</td>
    </tr>
    <tr>
      <th>P1Y_BP_SUM</th>
      <td>62988.0</td>
      <td>5366.720550</td>
      <td>8537.773021</td>
      <td>0.00</td>
      <td>946.000000</td>
      <td>2692.000000</td>
      <td>6485.250000</td>
      <td>246197.000000</td>
    </tr>
    <tr>
      <th>L1Y_BP_SUM</th>
      <td>62988.0</td>
      <td>5558.360704</td>
      <td>9351.956952</td>
      <td>0.00</td>
      <td>545.000000</td>
      <td>2547.000000</td>
      <td>6619.250000</td>
      <td>259111.000000</td>
    </tr>
    <tr>
      <th>EP_SUM</th>
      <td>62988.0</td>
      <td>265.689623</td>
      <td>1645.702854</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>74460.000000</td>
    </tr>
    <tr>
      <th>ADD_Point_SUM</th>
      <td>62988.0</td>
      <td>1355.006223</td>
      <td>7868.477000</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>984938.000000</td>
    </tr>
    <tr>
      <th>Eli_Add_Point_Sum</th>
      <td>62988.0</td>
      <td>1620.695847</td>
      <td>8294.398955</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>345.000000</td>
      <td>984938.000000</td>
    </tr>
    <tr>
      <th>L1Y_ELi_Add_Points</th>
      <td>62988.0</td>
      <td>1080.378882</td>
      <td>5639.857254</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>728282.000000</td>
    </tr>
    <tr>
      <th>Points_Sum</th>
      <td>62988.0</td>
      <td>12545.777100</td>
      <td>20507.816700</td>
      <td>0.00</td>
      <td>2775.000000</td>
      <td>6328.500000</td>
      <td>14302.500000</td>
      <td>985572.000000</td>
    </tr>
    <tr>
      <th>L1Y_Points_Sum</th>
      <td>62988.0</td>
      <td>6638.739585</td>
      <td>12601.819863</td>
      <td>0.00</td>
      <td>700.000000</td>
      <td>2860.500000</td>
      <td>7500.000000</td>
      <td>728282.000000</td>
    </tr>
    <tr>
      <th>Ration_L1Y_Flight_Count</th>
      <td>62988.0</td>
      <td>0.486419</td>
      <td>0.319105</td>
      <td>0.00</td>
      <td>0.250000</td>
      <td>0.500000</td>
      <td>0.711111</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Ration_P1Y_Flight_Count</th>
      <td>62988.0</td>
      <td>0.513581</td>
      <td>0.319105</td>
      <td>0.00</td>
      <td>0.288889</td>
      <td>0.500000</td>
      <td>0.750000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>Ration_P1Y_BPS</th>
      <td>62988.0</td>
      <td>0.522293</td>
      <td>0.339632</td>
      <td>0.00</td>
      <td>0.258150</td>
      <td>0.514252</td>
      <td>0.815091</td>
      <td>0.999989</td>
    </tr>
    <tr>
      <th>Ration_L1Y_BPS</th>
      <td>62988.0</td>
      <td>0.468422</td>
      <td>0.338956</td>
      <td>0.00</td>
      <td>0.167954</td>
      <td>0.476747</td>
      <td>0.728375</td>
      <td>0.999993</td>
    </tr>
    <tr>
      <th>Point_NotFlight</th>
      <td>62988.0</td>
      <td>2.728155</td>
      <td>7.364164</td>
      <td>0.00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>140.000000</td>
    </tr>
  </tbody>
</table>
##### 判断重复值：是否有重复的会员ID


```python
air_data['MEMBER_NO'].duplicated()
```


    0        False
    1        False
    2        False
    3        False
    4        False
             ...  
    62983    False
    62984    False
    62985    False
    62986    False
    62987    False
    Name: MEMBER_NO, Length: 62988, dtype: bool


```python
air_data[air_data['MEMBER_NO'].duplicated()]
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MEMBER_NO</th>
      <th>FFP_DATE</th>
      <th>FIRST_FLIGHT_DATE</th>
      <th>GENDER</th>
      <th>FFP_TIER</th>
      <th>WORK_CITY</th>
      <th>WORK_PROVINCE</th>
      <th>WORK_COUNTRY</th>
      <th>AGE</th>
      <th>LOAD_TIME</th>
      <th>...</th>
      <th>ADD_Point_SUM</th>
      <th>Eli_Add_Point_Sum</th>
      <th>L1Y_ELi_Add_Points</th>
      <th>Points_Sum</th>
      <th>L1Y_Points_Sum</th>
      <th>Ration_L1Y_Flight_Count</th>
      <th>Ration_P1Y_Flight_Count</th>
      <th>Ration_P1Y_BPS</th>
      <th>Ration_L1Y_BPS</th>
      <th>Point_NotFlight</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
<p>0 rows × 44 columns</p>


```python
air_data.isna().any()
```


    MEMBER_NO                  False
    FFP_DATE                   False
    FIRST_FLIGHT_DATE          False
    GENDER                      True
    FFP_TIER                   False
    WORK_CITY                   True
    WORK_PROVINCE               True
    WORK_COUNTRY                True
    AGE                         True
    LOAD_TIME                  False
    FLIGHT_COUNT               False
    BP_SUM                     False
    EP_SUM_YR_1                False
    EP_SUM_YR_2                False
    SUM_YR_1                    True
    SUM_YR_2                    True
    SEG_KM_SUM                 False
    WEIGHTED_SEG_KM            False
    LAST_FLIGHT_DATE           False
    AVG_FLIGHT_COUNT           False
    AVG_BP_SUM                 False
    BEGIN_TO_FIRST             False
    LAST_TO_END                False
    AVG_INTERVAL               False
    MAX_INTERVAL               False
    ADD_POINTS_SUM_YR_1        False
    ADD_POINTS_SUM_YR_2        False
    EXCHANGE_COUNT             False
    avg_discount               False
    P1Y_Flight_Count           False
    L1Y_Flight_Count           False
    P1Y_BP_SUM                 False
    L1Y_BP_SUM                 False
    EP_SUM                     False
    ADD_Point_SUM              False
    Eli_Add_Point_Sum          False
    L1Y_ELi_Add_Points         False
    Points_Sum                 False
    L1Y_Points_Sum             False
    Ration_L1Y_Flight_Count    False
    Ration_P1Y_Flight_Count    False
    Ration_P1Y_BPS             False
    Ration_L1Y_BPS             False
    Point_NotFlight            False
    dtype: bool




```python
air_data.isnull().any()
```


    MEMBER_NO                  False
    FFP_DATE                   False
    FIRST_FLIGHT_DATE          False
    GENDER                      True
    FFP_TIER                   False
    WORK_CITY                   True
    WORK_PROVINCE               True
    WORK_COUNTRY                True
    AGE                         True
    LOAD_TIME                  False
    FLIGHT_COUNT               False
    BP_SUM                     False
    EP_SUM_YR_1                False
    EP_SUM_YR_2                False
    SUM_YR_1                    True
    SUM_YR_2                    True
    SEG_KM_SUM                 False
    WEIGHTED_SEG_KM            False
    LAST_FLIGHT_DATE           False
    AVG_FLIGHT_COUNT           False
    AVG_BP_SUM                 False
    BEGIN_TO_FIRST             False
    LAST_TO_END                False
    AVG_INTERVAL               False
    MAX_INTERVAL               False
    ADD_POINTS_SUM_YR_1        False
    ADD_POINTS_SUM_YR_2        False
    EXCHANGE_COUNT             False
    avg_discount               False
    P1Y_Flight_Count           False
    L1Y_Flight_Count           False
    P1Y_BP_SUM                 False
    L1Y_BP_SUM                 False
    EP_SUM                     False
    ADD_Point_SUM              False
    Eli_Add_Point_Sum          False
    L1Y_ELi_Add_Points         False
    Points_Sum                 False
    L1Y_Points_Sum             False
    Ration_L1Y_Flight_Count    False
    Ration_P1Y_Flight_Count    False
    Ration_P1Y_BPS             False
    Ration_L1Y_BPS             False
    Point_NotFlight            False
    dtype: bool




```python
boolean_filter = air_data['SUM_YR_1'].notnull() & air_data['SUM_YR_2'].notnull()
```


```python
boolean_filter
```


    0         True1         True2         True3         True4         True         ...  62983     True62984     True62985     True62986     True62987    FalseLength: 62988, dtype: bool


```python
air_data = air_data[boolean_filter]
```


```python
filter1 = air_data['SUM_YR_1'] != 0filter2 = air_data['SUM_YR_2'] != 0
```


```python
air_data = air_data[filter1 | filter2]
```


```python
air_data.shape
```


    (62044, 44)



#### 特征工程

##### RFM模型

对于客户价值分析的一个经典模型是 RFM 模型。

- Recency: 最近消费时间间隔。
- Frequency: 客户消费频率。
- Monetary Value: 客户总消费金额。

##### 变体 - LRFMC 模型

- Length of Relationship: 客户关系时长，反映可能的活跃时长。
- Recency: 最近消费时间间隔，反映当前的活跃状态。
- Frequency: 客户消费频率，反映客户的忠诚度。
- Mileage: 客户总飞行里程，反映客户对乘机的依赖性。
- Coefficient of Discount: 客户所享受的平均折扣率，侧面反映客户价值高低。


```python
load_time = datetime.datetime.strptime('2014/03/31','%Y/%m/%d')
```


```python
load_time
```


    datetime.datetime(2014, 3, 31, 0, 0)


```python
ffp_dates = [datetime.datetime.strptime(ffp_date,'%Y/%m/%d') for ffp_date in air_data['FFP_DATE']]
```


```python
length_of_relationship  = [(load_time-ffp_date).days for ffp_date in ffp_dates]
```


```python
air_data['LEN_REL'] = length_of_relationship
```

##### 移除非重要列， 只保留LRFMC模型所需的属性


```python
features = ['LEN_REL','FLIGHT_COUNT','avg_discount','SEG_KM_SUM','LAST_TO_END']
data = air_data[features]

features = ['L','F','C','M','R']
data.columns = features
```


```python
data.shape
```


    (62044, 5)


```python
data.head()
```


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>L</th>
      <th>F</th>
      <th>C</th>
      <th>M</th>
      <th>R</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2706</td>
      <td>210</td>
      <td>0.961639</td>
      <td>580717</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2597</td>
      <td>140</td>
      <td>1.252314</td>
      <td>293678</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2615</td>
      <td>135</td>
      <td>1.254676</td>
      <td>283712</td>
      <td>11</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2047</td>
      <td>23</td>
      <td>1.090870</td>
      <td>281336</td>
      <td>97</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1816</td>
      <td>152</td>
      <td>0.970658</td>
      <td>309928</td>
      <td>5</td>
    </tr>
  </tbody>
</table>

```python
data.describe().T
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>L</th>
      <td>62044.0</td>
      <td>1488.691090</td>
      <td>847.880920</td>
      <td>365.000000</td>
      <td>735.000000</td>
      <td>1278.000000</td>
      <td>2182.000000</td>
      <td>3437.0</td>
    </tr>
    <tr>
      <th>F</th>
      <td>62044.0</td>
      <td>11.971359</td>
      <td>14.110619</td>
      <td>2.000000</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>15.000000</td>
      <td>213.0</td>
    </tr>
    <tr>
      <th>C</th>
      <td>62044.0</td>
      <td>0.722180</td>
      <td>0.184833</td>
      <td>0.136017</td>
      <td>0.613085</td>
      <td>0.712162</td>
      <td>0.809293</td>
      <td>1.5</td>
    </tr>
    <tr>
      <th>M</th>
      <td>62044.0</td>
      <td>17321.694749</td>
      <td>21052.728111</td>
      <td>368.000000</td>
      <td>4874.000000</td>
      <td>10200.000000</td>
      <td>21522.500000</td>
      <td>580717.0</td>
    </tr>
    <tr>
      <th>R</th>
      <td>62044.0</td>
      <td>172.532703</td>
      <td>181.526164</td>
      <td>1.000000</td>
      <td>29.000000</td>
      <td>105.000000</td>
      <td>260.000000</td>
      <td>731.0</td>
    </tr>
  </tbody>
</table>




### 标准化

让不同属性的取值范围一致，即数据的标准化。标准化方法有极大极小标准化、标准差标准化等方法。

- 对特征标准化，使得各特征的均值为0、方差为1


```python
((data -data.mean(axis=0)) /data.std(axis=0)).describe().T
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>L</th>
      <td>62044.0</td>
      <td>1.117739e-16</td>
      <td>1.0</td>
      <td>-1.325294</td>
      <td>-0.888911</td>
      <td>-0.248491</td>
      <td>0.817696</td>
      <td>2.297857</td>
    </tr>
    <tr>
      <th>F</th>
      <td>62044.0</td>
      <td>3.664717e-17</td>
      <td>1.0</td>
      <td>-0.706656</td>
      <td>-0.635788</td>
      <td>-0.352313</td>
      <td>0.214636</td>
      <td>14.246621</td>
    </tr>
    <tr>
      <th>C</th>
      <td>62044.0</td>
      <td>4.251071e-16</td>
      <td>1.0</td>
      <td>-3.171310</td>
      <td>-0.590233</td>
      <td>-0.054199</td>
      <td>0.471304</td>
      <td>4.208225</td>
    </tr>
    <tr>
      <th>M</th>
      <td>62044.0</td>
      <td>-5.863547e-17</td>
      <td>1.0</td>
      <td>-0.805297</td>
      <td>-0.591263</td>
      <td>-0.338279</td>
      <td>0.199537</td>
      <td>26.761154</td>
    </tr>
    <tr>
      <th>R</th>
      <td>62044.0</td>
      <td>1.465887e-16</td>
      <td>1.0</td>
      <td>-0.944948</td>
      <td>-0.790700</td>
      <td>-0.372027</td>
      <td>0.481844</td>
      <td>3.076511</td>
    </tr>
  </tbody>
</table>


```python
ss = sklearn.preprocessing.StandardScaler(with_mean=True,with_std=True)
```


```python
data = ss.fit_transform(data)
```


```python
data
```


    array([[ 1.43571897, 14.03412875,  1.29555058, 26.76136996, -0.94495516],       [ 1.30716214,  9.07328567,  2.86819902, 13.1269701 , -0.9119018 ],       [ 1.32839171,  8.71893974,  2.88097321, 12.65358345, -0.88986623],       ...,       [-0.14942206, -0.70666211, -2.68990622, -0.77233818, -0.73561725],       [-1.20618274, -0.70666211, -2.55464809, -0.77984321,  1.6056619 ],       [-0.47965977, -0.70666211, -2.39233833, -0.78668323,  0.60304353]])




```python
data = pd.DataFrame(data,columns=features)
```


```python
data.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>L</th>
      <th>F</th>
      <th>C</th>
      <th>M</th>
      <th>R</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.435719</td>
      <td>14.034129</td>
      <td>1.295551</td>
      <td>26.761370</td>
      <td>-0.944955</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.307162</td>
      <td>9.073286</td>
      <td>2.868199</td>
      <td>13.126970</td>
      <td>-0.911902</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.328392</td>
      <td>8.718940</td>
      <td>2.880973</td>
      <td>12.653583</td>
      <td>-0.889866</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.658481</td>
      <td>0.781591</td>
      <td>1.994730</td>
      <td>12.540723</td>
      <td>-0.416102</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.386035</td>
      <td>9.923716</td>
      <td>1.344346</td>
      <td>13.898848</td>
      <td>-0.922920</td>
    </tr>
  </tbody>
</table>
```python
data_db = data.copy()
```


```python
data_db.describe().T
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>L</th>
      <td>62044.0</td>
      <td>1.246004e-16</td>
      <td>1.000008</td>
      <td>-1.325304</td>
      <td>-0.888919</td>
      <td>-0.248493</td>
      <td>0.817703</td>
      <td>2.297875</td>
    </tr>
    <tr>
      <th>F</th>
      <td>62044.0</td>
      <td>5.863547e-17</td>
      <td>1.000008</td>
      <td>-0.706662</td>
      <td>-0.635793</td>
      <td>-0.352316</td>
      <td>0.214637</td>
      <td>14.246736</td>
    </tr>
    <tr>
      <th>C</th>
      <td>62044.0</td>
      <td>3.957894e-16</td>
      <td>1.000008</td>
      <td>-3.171335</td>
      <td>-0.590238</td>
      <td>-0.054200</td>
      <td>0.471308</td>
      <td>4.208258</td>
    </tr>
    <tr>
      <th>M</th>
      <td>62044.0</td>
      <td>-1.026121e-16</td>
      <td>1.000008</td>
      <td>-0.805303</td>
      <td>-0.591268</td>
      <td>-0.338282</td>
      <td>0.199539</td>
      <td>26.761370</td>
    </tr>
    <tr>
      <th>R</th>
      <td>62044.0</td>
      <td>4.397660e-17</td>
      <td>1.000008</td>
      <td>-0.944955</td>
      <td>-0.790706</td>
      <td>-0.372030</td>
      <td>0.481848</td>
      <td>3.076536</td>
    </tr>
  </tbody>
</table>



### 模型训练与 数据的预测

将客户群体细分为重要保持客户、重要发展客户、重要挽留客户、一般客户、低价值客户五类

#### K-means聚类算法

- 目标是把 $n$ 个观测样本划分成 $k$ 个群体（cluster），每个群体都有一个中心（mean）。
- 每个样本仅属于其中一个群体，即与这个样本距离最近的中心的群体。
- 符号: $S_{i}$ 是一个群体, $m_{i}$ 是群体 $S_{i}$ 里的样本的中心, $x_{i}$ 是一个样本点。
- Assignment step (expectation step): 把每个样本分配给距离最近的中心的群体
- Update step (maximization step): 根据当前的样本及其所属群体，重新计算各群体的中心


```python
num_clusters = 5  # 设置类别为5
km = sklearn.cluster.KMeans(n_clusters=num_clusters, n_jobs=4)  #模型加载
km.fit(data) # 模型训练
```

    /Users/gaozhiyong/Documents/pyenv/pyenv3.6/lib/python3.6/site-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).
      " removed in 1.0 (renaming of 0.25).", FutureWarning)
    
    KMeans(n_clusters=5, n_jobs=4)


```python
# 查看模型学习出来的5个群体的中心， 以及5哥群体所包含的样本个数
r1 = pd.Series(km.labels_).value_counts()
r2 = pd.DataFrame(km.cluster_centers_)
r = pd.concat([r2,r1],axis=1)
r.columns = list(data.columns) + ['counts']
r
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>L</th>
      <th>F</th>
      <th>C</th>
      <th>M</th>
      <th>R</th>
      <th>counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.482004</td>
      <td>2.478716</td>
      <td>0.298630</td>
      <td>2.420403</td>
      <td>-0.798959</td>
      <td>5338</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.155203</td>
      <td>-0.091881</td>
      <td>-0.150515</td>
      <td>-0.099938</td>
      <td>-0.373781</td>
      <td>15858</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.110721</td>
      <td>-0.189617</td>
      <td>2.353276</td>
      <td>-0.185116</td>
      <td>-0.015167</td>
      <td>3684</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.700396</td>
      <td>-0.164828</td>
      <td>-0.234397</td>
      <td>-0.165888</td>
      <td>-0.410842</td>
      <td>24970</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.315083</td>
      <td>-0.574115</td>
      <td>-0.162570</td>
      <td>-0.537185</td>
      <td>1.684579</td>
      <td>12194</td>
    </tr>
  </tbody>
</table>




```python
# 查看模型对每个样本预测的群体标签
km.labels_
```


    array([0, 0, 0, ..., 3, 4, 4], dtype=int32)

#### 尝试使用RFM模型


```python
data_rfm = data[['R','F','M']]
data_rfm.head()
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>R</th>
      <th>F</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.944955</td>
      <td>14.034129</td>
      <td>26.761370</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.911902</td>
      <td>9.073286</td>
      <td>13.126970</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.889866</td>
      <td>8.718940</td>
      <td>12.653583</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.416102</td>
      <td>0.781591</td>
      <td>12.540723</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.922920</td>
      <td>9.923716</td>
      <td>13.898848</td>
    </tr>
  </tbody>
</table>


```python
km.fit(data_rfm) # 模型对 只包含rfm数据集训练
```

    /Users/gaozhiyong/Documents/pyenv/pyenv3.6/lib/python3.6/site-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).
      " removed in 1.0 (renaming of 0.25).", FutureWarning)
    
    KMeans(n_clusters=5, n_jobs=4)


```python
km.labels_
```


    array([3, 3, 3, ..., 2, 1, 2], dtype=int32)


```python
r1 = pd.Series(km.labels_).value_counts()
r2 = pd.DataFrame(km.cluster_centers_)

rr = pd.concat([r2,r1],axis=1)
rr = pd.DataFrame(ss.fit_transform(rr))
rr.columns = list(data_rfm.columns) + ['counts']
rr
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>R</th>
      <th>F</th>
      <th>M</th>
      <th>counts</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.475915</td>
      <td>-0.389200</td>
      <td>-0.395668</td>
      <td>0.146242</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.958565</td>
      <td>-0.918959</td>
      <td>-0.893438</td>
      <td>0.118661</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.129480</td>
      <td>-0.846644</td>
      <td>-0.841995</td>
      <td>1.712033</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.727717</td>
      <td>1.772255</td>
      <td>1.795436</td>
      <td>-1.187639</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.625453</td>
      <td>0.382548</td>
      <td>0.335664</td>
      <td>-0.789296</td>
    </tr>
  </tbody>
</table>



#### 分析与决策

使用雷达图对模型学习出的5个群体特征进行可视化分析


```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Circle,RegularPolygon
from matplotlib.path import Path
from matplotlib.projections.polar import PolarAxes
from matplotlib.projections import register_projection
from matplotlib.spines import Spine
from matplotlib.transforms import Affine2D
```


```python
def radar_factory(num_vars,frame='circle'):
    # 计算得到 evenly-spaced axis angles
    theta = np.linspace(0,2*np.pi, num_vars, endpoint=False)
    
    class RadarAxes(PolarAxes):
        name= 'radar'
        # 使用1条线段连接指定点
        RESOLUTION = 1
        
        def __init__(self,*args,**kwargs):
            super().__init__(*args,**kwargs)
            # 旋转绘图，使第一个轴位于顶部
            self.set_theta_zero_location('N')
            
        def fill(self, *args, closed=True, **kwargs):
            """覆盖填充，以便默认情况下关闭该行"""
            return super().fill(closed=closed, *args, **kwargs)

        def plot(self, *args, **kwargs):
            """覆盖填充，以便默认情况下关闭该行"""
            lines = super().plot(*args, **kwargs)
            for line in lines:
                self._close_line(line)
                
        def _close_line(self, line):
            x, y = line.get_data()
            # FIXME: x[0], y[0] 处的标记加倍
            if x[0] != x[-1]:
                x = np.concatenate((x, [x[0]]))
                y = np.concatenate((y, [y[0]]))
                line.set_data(x, y)

        def set_varlabels(self, labels):
            self.set_thetagrids(np.degrees(theta), labels)

        def _gen_axes_patch(self):
            # 轴必须以（0.5，0.5）为中心并且半径为0.5
            # 在轴坐标中。
            if frame == 'circle':
                return Circle((0.5, 0.5), 0.5)
            elif frame == 'polygon':
                return RegularPolygon((0.5, 0.5), num_vars,
                                      radius=.5, edgecolor="k")
            else:
                raise ValueError("unknown value for 'frame': %s" % frame)
        
        def _gen_axes_spines(self):
            if frame == 'circle':
                return super()._gen_axes_spines()
            elif frame == 'polygon':
                # spine_type 必须是'left'/'right'/'top'/'bottom'/'circle'.
                spine = Spine(axes=self,
                              spine_type='circle',
                              path=Path.unit_regular_polygon(num_vars))
                # unit_regular_polygon 给出以1为中心的半径为1的多边形
                #（0，0），但我们希望以（0.5，
                #   0.5）的坐标轴。
                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)
                                    + self.transAxes)
                return {'polar': spine}
            else:
                raise ValueError("unknown value for 'frame': %s" % frame)
    register_projection(RadarAxes)
    return theta
```

#### LCRFM模型作图


```python
N = num_clusters
theta = radar_factory(N, frame='polygon')

data = r.to_numpy()
fig,ax = plt.subplots(figsize=(5,5), nrows = 1, ncols=1, subplot_kw=dict(projection='radar'))

fig.subplots_adjust(wspace=0.25,hspace=0.20,top=0.85,bottom=0.05)

# 去掉最后一列
case_data = data[:,:-1]
# 设置纵坐标不可见
ax.get_yaxis().set_visible(False)

# 图片标题
title = "Radar Chart for Different Means"
ax.set_title(title, weight='bold', size='medium', position=(0.5, 1.1),
             horizontalalignment='center', verticalalignment='center')
for d in case_data:
    # 画边
    ax.plot(theta, d)
    # 填充颜色
    ax.fill(theta, d, alpha=0.05)
# 设置纵坐标名称
ax.set_varlabels(features)

# 添加图例
labels = ["CustomerCluster_" + str(i) for i in range(1,6)]
legend = ax.legend(labels, loc=(0.9, .75), labelspacing=0.1)

plt.show()
```


​    
![png](C:\Users\YSilhouette\AppData\Local\Temp\360zip$Temp\360output_55_0.png\output_55_0.png)
​    


#### RFM模型作图


```python
theta = radar_factory(3, frame='polygon')

data = rr.to_numpy()

fig, ax = plt.subplots(figsize=(5, 5), nrows=1, ncols=1,
                         subplot_kw=dict(projection='radar'))
fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)

# 去掉最后一列
case_data = data[:, :-1]
# 设置纵坐标不可见
ax.get_yaxis().set_visible(False)
# 图片标题
title = "Radar Chart for Different Means"
ax.set_title(title, weight='bold', size='medium', position=(0.5, 1.1),
             horizontalalignment='center', verticalalignment='center')
for d in case_data:
    # 画边
    ax.plot(theta, d)
    # 填充颜色
    ax.fill(theta, d, alpha=0.05)
# 设置纵坐标名称
ax.set_varlabels(['R','F','M'])

# 添加图例
labels = ["CustomerCluster_" + str(i) for i in range(1,6)]
legend = ax.legend(labels, loc=(0.9, .75), labelspacing=0.1)

plt.show()
```


![png](output_57_0.png)
    


#### DBSCAN模型对LCRFM特征进行计算


```python
from sklearn.cluster import DBSCAN

# Kagging debug
db = DBSCAN(eps=10,min_samples=2).fit(data_db.sample(10000))

DBSCAN_labels = db.labels_
```


```python
DBSCAN_labels
```


    array([0, 0, 0, ..., 0, 0, 0])



#### 根据LCRFM结果进行分析

应实际业务对聚类结果进行分值离散转化，对应1-5分，其中属性值越大，分数越高：
![image.png](output_57_1.png)

1. 重要保持客户

平均折扣率高(C↑)，最近有乘机记录(R↓)，乘机次数高(F↑)或里程高(M↑)：
这类客户机票票价高，不在意机票折扣，经常乘机，是最理想的客户类型。
公司应优先将资源投放到他们身上，维持这类客户的忠诚度。

2. 重要发展客户

平均折扣率高(C↑)，最近有乘机记录(R↓)，乘机次数低(F↓)或里程低(M↓)：
这类客户机票票价高，不在意机票折扣，最近有乘机记录，但总里程低，具有很大的发展潜力。
公司应加强这类客户的满意度，使他们逐渐成为忠诚客户。

3. 重要挽留客户

平均折扣率高(C↑)，乘机次数高(F↑)或里程高(M↑)，最近无乘机记录(R↑)：
这类客户总里程高，但较长时间没有乘机，可能处于流失状态。
公司应加强与这类客户的互动，召回用户，延长客户的生命周期。

4. 一般客户

平均折扣率低(C↓)，最近无乘机记录(R↑)，乘机次数高(F↓)或里程高(M↓)，入会时间短(L↓)：
这类客户机票票价低，经常买折扣机票，最近无乘机记录，可能是趁着折扣而选择购买，对品牌无忠诚度。
公司需要在资源支持的情况下强化对这类客户的联系。

5. 低价值客户

平均折扣率低（C↓），最近无乘机记录（R↑），乘机次数高（F↓）或里程高（M↓），入会时间短（L↓）：
这类客户与一般客户类似，机票票价低，经常买折扣机票，最近无乘机记录，可能是趁着折扣而选择购买，对品牌无忠诚度。

#### 结果分析

- 群体1的L属性最大
- 群体2的L、C属性最小
- 群体3的C属性上最大
- 群体4的M、F属性属性最大，R属性最小
- 群体5的R属性最大，F、M属性最小

- 其中每项指标的实际业务意义为：
  - L：加入会员的时长。越大代表会员资历越久
  - R：最近一次乘机时间。越大代表越久没乘机
  - F：乘机次数。越大代表乘机次数越多
  - M：飞行总里程。越大代表总里程越多
  - C：平均折扣率。越大代表折扣越弱，0表示0折免费机票，10代表无折机票

重要保持客户：客户群4

重要发展客户：客户群3

重要挽留客户：客户群1

一般客户：客户群2

低价值客户：客户群5

#### 决策

- 重要发展客户、重要保持客户、重要挽留客户这三类客户其实也对应着客户生命周期中的发展期、稳定器、衰退期三个时期。
- 从客户生命周期的角度讲，也应重点投入资源召回衰退期的客户。
- 一般而言，数据分析最终的目的是针对分析结果提出并开展一系列的运营/营销策略，以期帮助企业发展。在本实例中，运营策略有三个方向：
  - 提高活跃度：提高一般客户、低价值客户的活跃度。将其转化为优质客户
  - 提高留存率：与重要挽留客户互动，提高这部分用户的留存率
  - 提高付费率：维系重要保持客户、重要发展客户的忠诚度，保持企业良好收入
  - 每个方向对应不同的策略，如会员升级、积分兑换、交叉销售、发放折扣券等手段


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> 
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
        <category>Machine Learning</category>
        <category>Algorithm</category>
        <category>K-means</category>
        <category>DBSCAN</category>
        <category>RFM</category>
        <category>用户画像</category>
        <category>聚类分析</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>用户画像</tag>
        <tag>K-means</tag>
        <tag>DBSCAN</tag>
        <tag>RFM</tag>
        <tag>聚类分析</tag>
      </tags>
  </entry>
  <entry>
    <title>计算广告-知识储备</title>
    <url>/2019/01/02/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A-%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script>
# 计算广告-知识储备

## 1、信息检索

#### 1.1、倒排索引

​	核心目的，将从大量文档中查找包含某些词的文档集合，用O(1)的时间复杂度完成。

​	基本操作：

​			1、向索引中加入一个新文档

​			2、给定一个有多个关键词组成的查询时，返回对应的文档集合

#### 1.2、向量空间模型

​	向量空间模型（Vector Space Model ，VSM），信息检索中最基础且最重要的文档相似度度量方法之一。

​	核心：

​	1、文档的表示方法

​	用各个关键词（term）在文档中强度组成的矢量来表示该文档	
$$
D=(X_1,X_2,...X_m)^T
$$


​	2、相似度计算方法

## 2、最优化方法

#### 2.1、下降单纯型法



#### 2.2、梯度方法



#### 2.3、拟牛顿方法



#### 2.4、Trust-Region方法



#### 2.5、带约束 优化和拉格朗日法



## 3、统计机器学习

#### 3.1、最大熵原理



#### 3.2、指数族分布



#### 3.3、混合模型和EM算法



#### 3.4、贝叶斯学习



#### 3.5、共轭先验



#### 3.6、经验贝叶斯



#### 3.7、变分法


---


### About ME
##### 👋 读书城南，🤔 在未来面前，我们都是孩子～

- 📙 一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~

##### 👋 Social Media

- 🛠️ Blog: [http://oceaneyes.top](http://oceaneyes.top)
- ⚡ PM导航: [https://pmhub.oceangzy.top](https://pmhub.oceangzy.top)
- ☘️ CNBLOG: [https://www.cnblogs.com/oceaneyes-gzy/](https://www.cnblogs.com/oceaneyes-gzy/)
- 🌱 AI PRJ自己部署的一些算法demo: [http://ai.oceangzy.top/](http://ai.oceangzy.top/)
- 📫 Email: 1450136519@qq.com
- 💬 WeChat: [OCEANGZY](https://oceaneyes.top/img/wechatqrcode.jpg)

- 💬 公众号: [UncleJoker-GZY](https://oceaneyes.top/img/wechatgzh.jpeg)

##### 👋 加入小组~
<img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"> 

##### 👋 感谢打赏~
<img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"> ]]></content>
      <categories>
        <category>广告产品</category>
        <category>计算广告</category>
      </categories>
      <tags>
        <tag>广告产品</tag>
        <tag>计算广告</tag>
      </tags>
  </entry>
</search>
