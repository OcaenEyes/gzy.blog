<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>基于PyTorch实现图像去模糊-学习 | OCAEN.GZY读书城南</title><meta name="author" content="OCEAN.GZY"><meta name="copyright" content="OCEAN.GZY"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="基于PyTorch实现图像去模糊-学习 任务描述  相机的抖动、快速运动的物体都会导致拍摄出模糊的图像，景深变化也会使图像进一步模糊。 对于传统方法来说，要想估计出每个像素点对应的 “blur kernel” 几乎是不可行的。因此，传统方法常常需要对模糊源作出假设，将 “blur kernel” 参数化。显然，这类方法不足以解决实际中各种复杂因素引起的图像模糊。 卷积神经网络能够从图像中提取出复杂">
<meta property="og:type" content="article">
<meta property="og:title" content="基于PyTorch实现图像去模糊-学习">
<meta property="og:url" content="http://oceaneyes.top/2021/11/19/pytorch%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%A8%A1%E7%B3%8A/index.html">
<meta property="og:site_name" content="OCAEN.GZY读书城南">
<meta property="og:description" content="基于PyTorch实现图像去模糊-学习 任务描述  相机的抖动、快速运动的物体都会导致拍摄出模糊的图像，景深变化也会使图像进一步模糊。 对于传统方法来说，要想估计出每个像素点对应的 “blur kernel” 几乎是不可行的。因此，传统方法常常需要对模糊源作出假设，将 “blur kernel” 参数化。显然，这类方法不足以解决实际中各种复杂因素引起的图像模糊。 卷积神经网络能够从图像中提取出复杂">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2021-11-19T15:19:00.000Z">
<meta property="article:modified_time" content="2022-09-30T06:56:37.182Z">
<meta property="article:author" content="OCEAN.GZY">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Algorithm">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="CV">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://oceaneyes.top/2021/11/19/pytorch%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%A8%A1%E7%B3%8A/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '基于PyTorch实现图像去模糊-学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-30 14:56:37'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">166</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">114</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">91</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="OCAEN.GZY读书城南"><span class="site-name">OCAEN.GZY读书城南</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">基于PyTorch实现图像去模糊-学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-11-19T15:19:00.000Z" title="发表于 2021-11-19 23:19:00">2021-11-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-30T06:56:37.182Z" title="更新于 2022-09-30 14:56:37">2022-09-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Artificial-Intelligence/">Artificial Intelligence</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Artificial-Intelligence/Machine-Learning/">Machine Learning</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Artificial-Intelligence/Machine-Learning/Algorithm/">Algorithm</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Artificial-Intelligence/Machine-Learning/Algorithm/CV/">CV</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="基于PyTorch实现图像去模糊-学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="基于pytorch实现图像去模糊-学习">基于PyTorch实现图像去模糊-学习</h2>
<h2 id="任务描述">任务描述</h2>
<ul>
<li>相机的抖动、快速运动的物体都会导致拍摄出模糊的图像，景深变化也会使图像进一步模糊。</li>
<li>对于传统方法来说，要想估计出每个像素点对应的 “blur kernel”
几乎是不可行的。因此，传统方法常常需要对模糊源作出假设，将 “blur kernel”
参数化。显然，这类方法不足以解决实际中各种复杂因素引起的图像模糊。</li>
<li>卷积神经网络能够从图像中提取出复杂的特征，从而使得模型能够适应各种场景。<br>
</li>
<li>本教程以 CVPR2017 的 《Deep Multi-scale Convolutional Neural Network
for Dynamic Scene Deblurring》 为例，来完成图像去模糊的任务。</li>
</ul>
<h3 id="方法概述">方法概述</h3>
<ul>
<li>利用pytorch深度学习工具实现一个端到端的图像去模糊模型，通过参数设置、加载数据、构建模型、训练模型和测试用例依次实现一个图像去模糊工具，在训练和预处理过程中通过可视化监督训练过程。</li>
<li>模型采用了残差形式的CNN，输入和输出都采用高斯金字塔（Gaussian
pyramid）的形式。</li>
<li>整个网络结构由三个相似的CNN构成，分别对应输入金字塔中的每一层。网络最前面是分辨率最低的子网络（coarest
level network），在这个子网络最后，是“upconvolution
layer”，将重建的低分辨率图像放大为高分辨率图像，然后和高一层的子网络的输入连接在一起，作为上层网络的输入。</li>
</ul>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120221821489.png" alt="image-20211120221821489">
<figcaption aria-hidden="true">image-20211120221821489</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs python">%config Completer.use_jedi = <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!pip install pytorch_msssim -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="hljs-comment"># !jupyter nbextension enable --py widgetsnbextension</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> torchsummary <span class="hljs-keyword">import</span> summary<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> lr_scheduler<br><span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> tqdm.notebook <span class="hljs-keyword">import</span> tqdm<br><br><br><span class="hljs-keyword">import</span> pytorch_msssim <span class="hljs-comment"># 用于计算指标 ssim 和 mssim</span><br><br>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="参数设置">参数设置</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Config</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,name=<span class="hljs-string">&quot;Configs&quot;</span></span>):<br>        <span class="hljs-comment"># train set</span><br>        self.data_dir = <span class="hljs-string">&#x27;datasets/train&#x27;</span> <span class="hljs-comment"># 训练集目录</span><br>        self.patch_size = <span class="hljs-number">256</span>  <span class="hljs-comment"># 输入模型的patch的尺寸</span><br>        self.batch_size= <span class="hljs-number">2</span> <span class="hljs-comment">#16 # 训练时每个batch中的样本个数</span><br>        self.n_threads = <span class="hljs-number">1</span> <span class="hljs-comment"># 用于加载数据的线程数</span><br>        <br>        <span class="hljs-comment"># test set</span><br>        self.test_data_dir = <span class="hljs-string">&#x27;datasets/test&#x27;</span> <span class="hljs-comment"># 测试集目录</span><br>        self.test_batch_size=<span class="hljs-number">1</span> <span class="hljs-comment"># 测试时的 batch_size</span><br>        <br>        <span class="hljs-comment"># model</span><br>        self.multi = <span class="hljs-literal">True</span> <span class="hljs-comment"># 模型采用多尺度方法True</span><br>        self.skip = <span class="hljs-literal">True</span> <span class="hljs-comment"># 模型采用滑动连接方法</span><br>        self.n_resblocks = <span class="hljs-number">3</span> <span class="hljs-comment">#9  # resblock的个数</span><br>        self.n_feats = <span class="hljs-number">8</span> <span class="hljs-comment">#64  #feature map的个数</span><br>        <br>        <span class="hljs-comment"># optimization </span><br>        self.lr = <span class="hljs-number">1e-4</span>  <span class="hljs-comment"># 初始学习率</span><br>        self.epochs =<span class="hljs-number">5</span> <span class="hljs-comment">#800 # 训练epoch的数目</span><br>        self.lr_step_size = <span class="hljs-number">600</span> <span class="hljs-comment">#采用步进学习率策略所用的 step_size</span><br>        self.lr_gamma = <span class="hljs-number">0.1</span> <span class="hljs-comment">#每 lr_step_size后，学习率变成 lr * lr_gamma</span><br>        <br>        <span class="hljs-comment"># global</span><br>        self.name = name <span class="hljs-comment">#配置的名称</span><br>        self.save_dir = <span class="hljs-string">&#x27;temp/result&#x27;</span>  <span class="hljs-comment"># 保存训练过程中所产生数据的目录</span><br>        self.save_cp_dir = <span class="hljs-string">&#x27;temp/models&#x27;</span>  <span class="hljs-comment"># 保存 checkpoint的目录</span><br>        self.imgs_dir = <span class="hljs-string">&#x27;datasets/pictures&#x27;</span>  <span class="hljs-comment"># 此 notebook所需的图片目录</span><br>        <br>        <br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(self.save_dir):<br>            os.makedirs(self.save_dir)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(self.save_cp_dir):<br>            os.makedirs(self.save_cp_dir)<br><span class="hljs-comment">#         if not os.path.exists(self.data_dir):</span><br><span class="hljs-comment">#             os.makedirs(self.data_dir)</span><br><span class="hljs-comment">#         if not os.path.exists(self.test_data_dir):</span><br><span class="hljs-comment">#             os.makedirs(self.test_data_dir)</span><br><br>args =  Config(name=<span class="hljs-string">&quot;image-deblurring&quot;</span>)<br></code></pre></td></tr></table></figure>
<h2 id="数据准备">数据准备</h2>
<ul>
<li>数据集展示</li>
<li>数据增强</li>
<li>构造 dataset类</li>
<li>数据加载 dataloader</li>
</ul>
<h3 id="数据集展示">数据集展示</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">sample_idx = <span class="hljs-number">1</span> <span class="hljs-comment"># 样本编号</span><br>blur_path = os.path.join(args.imgs_dir,<span class="hljs-string">f&quot;blur/test<span class="hljs-subst">&#123;sample_idx&#125;</span>.png&quot;</span>)  <span class="hljs-comment"># 模糊图片</span><br>sharp_path = os.path.join(args.imgs_dir,<span class="hljs-string">f&quot;sharp/test<span class="hljs-subst">&#123;sample_idx&#125;</span>.png&quot;</span>) <span class="hljs-comment"># 去模糊图片</span><br>blur_img = plt.imread(blur_path)<br>sharp_img = plt.imread(sharp_path)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">4</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>plt.imshow(blur_img)<br>plt.subplot(<span class="hljs-number">122</span>)<br>plt.imshow(sharp_img)<br>plt.show()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120221933618.png" alt="image-20211120221933618">
<figcaption aria-hidden="true">image-20211120221933618</figcaption>
</figure>
<h3 id="数据增强">数据增强</h3>
<p>为了防止过拟合，需要对数据集进行数据增强，增强方式如下所示，对每一个输入图像，都将其进行随机角度旋转，旋转的角度在
[0, 90, 180, 270] 中随机选取。除此之外，考虑到图像质量下降，对 HSV
颜色空间的饱和度乘以 0.8 到 1.2 内的随机数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">augment</span>(<span class="hljs-params">img_input, img_target</span>):<br>    degree = random.choice([<span class="hljs-number">0</span>,<span class="hljs-number">90</span>,<span class="hljs-number">180</span>,<span class="hljs-number">270</span>])<br>    img_input = transforms.functional.rotate(img_input,degree)<br>    img_target = transforms.functional.rotate(img_target,degree)<br>    <br>    <span class="hljs-comment"># color augmentation</span><br>    img_input = transforms.functional.adjust_gamma(img_input,<span class="hljs-number">1</span>)<br>    img_target = transforms.functional.adjust_gamma(img_target,<span class="hljs-number">1</span>)<br>    sat_factor = <span class="hljs-number">1</span> + (<span class="hljs-number">0.2</span> - <span class="hljs-number">0.4</span>* np.random.rand())<br>    img_input = transforms.functional.adjust_saturation(img_input,sat_factor)<br>    img_target = transforms.functional.adjust_saturation(img_target,sat_factor)<br>    <br>    <span class="hljs-keyword">return</span> img_input,img_target<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">img_input = Image.<span class="hljs-built_in">open</span>(blur_path)<br>img_target = Image.<span class="hljs-built_in">open</span>(sharp_path)<br><br>img_aug_input,img_aug_target = augment(img_input,img_target)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>))<br>plt.subplot(<span class="hljs-number">121</span>)<br>plt.imshow(img_aug_input)<br>plt.subplot(<span class="hljs-number">122</span>)<br>plt.imshow(img_aug_target)<br>plt.show()<br></code></pre></td></tr></table></figure>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120221955392.png" alt="image-20211120221955392">
<figcaption aria-hidden="true">image-20211120221955392</figcaption>
</figure>
<h3 id="构造-dataset类">构造 dataset类</h3>
<p>对每一个输入图像，对齐进行随机裁剪，得到patch_size大小的输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">getPatch</span>(<span class="hljs-params">img_input,img_target,patch_size</span>):<br>    w,h = img_input.size<br>    p = patch_size<br>    x = random.randrange(<span class="hljs-number">0</span>,w-p +<span class="hljs-number">1</span>)<br>    y = random.randrange(<span class="hljs-number">0</span>,h -p +<span class="hljs-number">1</span>)<br>    <br>    img_input = img_input.crop((x,y,x+p,y+p))<br>    img_target = img_target.crop((x,y,x+p,y+p))<br>    <br>    <span class="hljs-keyword">return</span> img_input,img_target<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ImgMission</span>(data.Dataset):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,data_dir, patch_size=<span class="hljs-number">256</span>, is_train= <span class="hljs-literal">False</span>, multi=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(ImgMission,self).__init__()<br>        <br>        self.is_train = is_train  <span class="hljs-comment">#是否是训练集</span><br>        self.patch_size = patch_size <span class="hljs-comment"># 训练时 patch的尺寸</span><br>        self.multi = multi  <span class="hljs-comment"># 是否采用多尺度因子，默认采用</span><br>        <br>        self.sharp_file_paths = []<br>        sub_folders = os.listdir(data_dir)<br>        <span class="hljs-built_in">print</span>(sub_folders)<br>        <br>        <span class="hljs-keyword">for</span> folder_name <span class="hljs-keyword">in</span> sub_folders:<br>            sharp_sub_folder = os.path.join(data_dir,folder_name,<span class="hljs-string">&#x27;sharp&#x27;</span>)<br>            sharp_file_names = os.listdir(sharp_sub_folder)<br>            <span class="hljs-comment"># print(sharp_file_names)</span><br>            <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> sharp_file_names:<br>                sharp_file_path = os.path.join(sharp_sub_folder,file_name)<br>                <span class="hljs-comment"># print(sharp_file_path)</span><br>                self.sharp_file_paths.append(sharp_file_path)<br>                <br>        self.n_samples = <span class="hljs-built_in">len</span>(self.sharp_file_paths)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_img_pair</span>(<span class="hljs-params">self,idx</span>):<br>        sharp_file_path = self.sharp_file_paths[idx]<br>        blur_file_path = sharp_file_path.replace(<span class="hljs-string">&quot;sharp&quot;</span>,<span class="hljs-string">&quot;blur&quot;</span>)<br>        <span class="hljs-comment"># print(blur_file_path)</span><br>        img_input = Image.<span class="hljs-built_in">open</span>(blur_file_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>        img_target = Image.<span class="hljs-built_in">open</span>(sharp_file_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>        <br>        <span class="hljs-keyword">return</span> img_input,img_target<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self,idx</span>):<br>        img_input,img_target = self.get_img_pair(idx)<br>        <br>        <span class="hljs-keyword">if</span> self.is_train:<br>            img_input,img_target = getPatch(img_input,img_target, self.patch_size)<br>            img_input,img_target=  augment(img_input,img_target)<br>            <br>            <br>        <span class="hljs-comment"># 转换为 tensor类型</span><br>        input_b1 = transforms.ToTensor()(img_input)<br>        target_s1 = transforms.ToTensor()(img_target)<br>        <br>        H = input_b1.size()[<span class="hljs-number">1</span>]<br>        W= input_b1.size()[<span class="hljs-number">2</span>]<br>        <br>        <span class="hljs-keyword">if</span> self.multi:<br>            input_b1 = transforms.ToPILImage()(input_b1)<br>            target_s1 = transforms.ToPILImage()(target_s1)<br>            <br>            input_b2 = transforms.ToTensor()(transforms.Resize([<span class="hljs-built_in">int</span>(H/<span class="hljs-number">2</span>), <span class="hljs-built_in">int</span>(W/<span class="hljs-number">2</span>)])(input_b1))<br>            input_b3 = transforms.ToTensor()(transforms.Resize([<span class="hljs-built_in">int</span>(H/<span class="hljs-number">4</span>), <span class="hljs-built_in">int</span>(W/<span class="hljs-number">4</span>)])(input_b1))<br>            <br>            <span class="hljs-comment"># 只对训练集进行数据增强</span><br>            <span class="hljs-keyword">if</span> self.is_train:<br>                target_s2 = transforms.ToTensor()(transforms.Resize([<span class="hljs-built_in">int</span>(H/<span class="hljs-number">2</span>), <span class="hljs-built_in">int</span>(W/<span class="hljs-number">2</span>)])(target_s1))<br>                target_s3 = transforms.ToTensor()(transforms.Resize([<span class="hljs-built_in">int</span>(H/<span class="hljs-number">4</span>), <span class="hljs-built_in">int</span>(W/<span class="hljs-number">4</span>)])(target_s1))<br>            <span class="hljs-keyword">else</span>:<br>                target_s2 = []<br>                target_s3 = []<br>                <br>            input_b1 = transforms.ToTensor()(input_b1)<br>            target_s1 = transforms.ToTensor()(target_s1)<br>            <br>            <span class="hljs-keyword">return</span> &#123;<br>                <span class="hljs-string">&#x27;input_b1&#x27;</span>: input_b1, <span class="hljs-comment"># 参照下文的网络结构，输入图像的尺度 1</span><br>                <span class="hljs-string">&#x27;input_b2&#x27;</span>: input_b2, <span class="hljs-comment"># 输入图像的尺度 2</span><br>                <span class="hljs-string">&#x27;input_b3&#x27;</span>: input_b3, <span class="hljs-comment"># 输入图像的尺度 3</span><br>                <span class="hljs-string">&#x27;target_s1&#x27;</span>: target_s1, <span class="hljs-comment"># 目标图像的尺度 1</span><br>                <span class="hljs-string">&#x27;target_s2&#x27;</span>: target_s2, <span class="hljs-comment"># 目标图像的尺度 2</span><br>                <span class="hljs-string">&#x27;target_s3&#x27;</span>: target_s3 <span class="hljs-comment"># 目标图像的尺度 3</span><br>            &#125;<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;input_b1&#x27;</span>: input_b1, <span class="hljs-string">&#x27;target_s1&#x27;</span>: target_s1&#125;<br>            <br>        <br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.n_samples<br></code></pre></td></tr></table></figure>
<h3 id="数据加载-dataloader">数据加载 dataloader</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataset</span>(<span class="hljs-params">data_dir,patch_size=<span class="hljs-literal">None</span>, </span><br><span class="hljs-params">                batch_size=<span class="hljs-number">1</span>, n_threads=<span class="hljs-number">1</span>, </span><br><span class="hljs-params">                is_train=<span class="hljs-literal">False</span>,multi=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-comment"># Dataset实例化</span><br>    <br><span class="hljs-comment">#     print(data_dir)</span><br><span class="hljs-comment">#     print(patch_size)</span><br><span class="hljs-comment">#     print(is_train)</span><br><span class="hljs-comment">#     print(multi)</span><br><br>    dataset = ImgMission(data_dir,patch_size=patch_size,<br>                    is_train=is_train,multi=multi)<br>    <br>    <span class="hljs-comment"># print(dataset)</span><br>    <span class="hljs-comment"># 利用封装好的 dataloader 接口定义训练过程的迭代器</span><br>    <span class="hljs-comment"># 参数num_workers表示进程个数，在jupyter下改为0</span><br>    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,<br>                                            drop_last=<span class="hljs-literal">True</span>, shuffle=is_train,<br>                                             num_workers = <span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> dataloader<br></code></pre></td></tr></table></figure>
<ul>
<li>将训练时的dataloader实例化</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">data_loader = get_dataset(args.data_dir,<br>                          patch_size=args.patch_size,<br>                          batch_size= args.batch_size,<br>                          n_threads= args.n_threads,<br>                          is_train=<span class="hljs-literal">True</span>,<br>                          multi = args.multi<br>                         )<br></code></pre></td></tr></table></figure>
<div class="code-wrapper"><pre><code class="hljs">[&#39;GOPR0372_07_00&#39;, &#39;GOPR0372_07_01&#39;, &#39;GOPR0374_11_00&#39;, &#39;GOPR0374_11_01&#39;, &#39;GOPR0374_11_02&#39;, &#39;GOPR0374_11_03&#39;, &#39;GOPR0378_13_00&#39;, &#39;GOPR0379_11_00&#39;, &#39;GOPR0380_11_00&#39;, &#39;GOPR0384_11_01&#39;, &#39;GOPR0384_11_02&#39;, &#39;GOPR0384_11_03&#39;, &#39;GOPR0384_11_04&#39;, &#39;GOPR0385_11_00&#39;, &#39;GOPR0386_11_00&#39;, &#39;GOPR0477_11_00&#39;, &#39;GOPR0857_11_00&#39;, &#39;GOPR0868_11_01&#39;, &#39;GOPR0868_11_02&#39;, &#39;GOPR0871_11_01&#39;, &#39;GOPR0881_11_00&#39;, &#39;GOPR0884_11_00&#39;]</code></pre></div>
<h2 id="模型构建">模型构建</h2>
<ul>
<li>模型介绍</li>
<li>模型定义</li>
<li>实例化模型</li>
<li>损失函数和优化器</li>
</ul>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222025823.png" alt="image-20211120222025823">
<figcaption aria-hidden="true">image-20211120222025823</figcaption>
</figure>
<p>CONV 表示卷积层， ResBlock 表示残差模块， Upconv
表示上采样（也可以用反卷积代替）。 从图中可以看出，该模型使用了
“multi-scale” 的结构， 在输入和输出部分都都采用了高斯金字塔（Gaussian
pyramid）的形式（即对原图像进行不同尺度的下采样，从而获得处于不同分辨率的图像）</p>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222042862.png" alt="image-20211120222042862">
<figcaption aria-hidden="true">image-20211120222042862</figcaption>
</figure>
<h3 id="模型定义">模型定义</h3>
<ul>
<li>default_conv 是模型采用的默认卷积层，</li>
<li>UpConv 用于上采样卷积，</li>
<li>ResidualBlock 是模型使用的残差模块，</li>
<li>SingleScaleNet 是单个尺度网络，</li>
<li>MultiScaleNet 将几个 SingleScaleNet
整合成了最终的多尺度网络模型</li>
</ul>
<p><em>具体作用</em></p>
<ul>
<li>default_conv : 网络中默认采用的卷积层，定义之后，避免重复代码</li>
<li>UpConv : 上卷积，对应上图中的 Up
Conv，将图像的尺度扩大，输入到另一个单尺度网络</li>
<li>ResidualBlock :
残差模块，网络模型中采用的残差模块，之所以采用残差模块，是因为网络“只需要需要模糊图像与去模糊图像之间的差异即可”</li>
<li>SingleScaleNet : 单尺度模型，一个尺度对应一个单尺度模型实例</li>
<li>MultiScaleNet :
多尺度模型，将多个单尺度模型实例组合即可得到上图所示的多尺度去模糊网络</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">default_conv</span>(<span class="hljs-params">in_channels,out_channels, kernel_size, bias</span>):<br>    <span class="hljs-keyword">return</span> nn.Conv2d(in_channels,<br>                    out_channels,<br>                    kernel_size,<br>                    padding=(kernel_size // <span class="hljs-number">2</span>),<br>                    bias=bias)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">UpConv</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(UpConv, self).__init__()<br>        self.body = nn.Sequential(default_conv(<span class="hljs-number">3</span>,<span class="hljs-number">12</span>,<span class="hljs-number">3</span>,<span class="hljs-literal">True</span>),<br>                                 nn.PixelShuffle(<span class="hljs-number">2</span>),<br>                                 nn.ReLU(inplace=<span class="hljs-literal">True</span>))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>            <span class="hljs-keyword">return</span> self.body(x)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResidualBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n_feats</span>):<br>        <span class="hljs-built_in">super</span>(ResidualBlock,self).__init__()<br>        <br>        modules_body = [<br>            default_conv(n_feats, n_feats, <span class="hljs-number">3</span>, bias=<span class="hljs-literal">True</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            default_conv(n_feats,n_feats,<span class="hljs-number">3</span>,bias=<span class="hljs-literal">True</span>)<br>        ]<br>        <br>        self.body = nn.Sequential(*modules_body)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        res= self.body(x)<br>        res += x<br>        <span class="hljs-keyword">return</span> res<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SingleScaleNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n_feats,n_resblocks, is_skip, n_channels=<span class="hljs-number">3</span></span>):<br>        <span class="hljs-built_in">super</span>(SingleScaleNet, self).__init__()<br>        self.is_skip = is_skip<br>        <br>        modules_head = [<br>            default_conv(n_channels,n_feats,<span class="hljs-number">5</span>,bias=<span class="hljs-literal">True</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        ]<br>        <br>        modules_body = [ResidualBlock(n_feats) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_resblocks)]<br>        modules_tail = [default_conv(n_feats, <span class="hljs-number">3</span>,<span class="hljs-number">5</span>,bias=<span class="hljs-literal">True</span>)]<br>        <br>        self.head = nn.Sequential(*modules_head)<br>        self.body = nn.Sequential(*modules_body)<br>        self.tail = nn.Sequential(*modules_tail)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x= self.head(x)<br>        res= self.body(x)<br>        <span class="hljs-keyword">if</span> self.is_skip:<br>            res += x<br>        <br>        res = self.tail(res)<br>        <span class="hljs-keyword">return</span> res<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiScaleNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,n_feats, n_resblocks ,is_skip</span>):<br>        <span class="hljs-built_in">super</span>(MultiScaleNet,self).__init__()<br>        <br>        self.scale3_net = SingleScaleNet(n_feats,<br>                                         n_resblocks,<br>                                         is_skip,<br>                                         n_channels=<span class="hljs-number">3</span>)<br>        self.upconv3 = UpConv()<br>        self.scale2_net = SingleScaleNet(n_feats,<br>                                         n_resblocks,<br>                                         is_skip,<br>                                         n_channels=<span class="hljs-number">6</span>)<br>        self.upconv2 = UpConv()<br>        <br>        self.scale1_net = SingleScaleNet(n_feats,<br>                                        n_resblocks,<br>                                        is_skip,<br>                                        n_channels=<span class="hljs-number">6</span>)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,mulscale_input</span>):<br>        input_b1, input_b2,input_b3 = mulscale_input<br>        <br>        output_l3 = self.scale3_net(input_b3)<br>        output_l3_up = self.upconv3(output_l3)<br>        <br>        output_l2 = self.scale2_net(torch.cat((input_b2,output_l3_up),<span class="hljs-number">1</span>))<br>        output_l2_up = self.upconv2(output_l2)<br>        <br>        output_l1 = self.scale2_net(torch.cat((input_b1,output_l2_up),<span class="hljs-number">1</span>))<br>        <br>        <span class="hljs-keyword">return</span> output_l1,output_l2,output_l3<br></code></pre></td></tr></table></figure>
<h3 id="模型实例化">模型实例化</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> args.multi:<br>    my_model = MultiScaleNet(n_feats=args.n_feats,<br>                            n_resblocks = args.n_resblocks,<br>                            is_skip= args.skip)<br><span class="hljs-keyword">else</span>:<br>    my_model = SingleScaleNet(n_feats=args.n_feats,<br>                             n_resblocks=args.n_resblocks,<br>                             is_skip = args.skip)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    my_model.cuda()<br>    loss_function = nn.MSELoss().cuda()<br><span class="hljs-keyword">else</span>:<br>    loss_function = nn.MSELoss()<br>    <br>optimizer = optim.Adam(my_model.parameters(),lr=args.lr)<br><span class="hljs-built_in">print</span>(my_model)<br><span class="hljs-built_in">print</span>(loss_function)<br></code></pre></td></tr></table></figure>
<div class="code-wrapper"><pre><code class="hljs">MultiScaleNet(
  (scale3_net): SingleScaleNet(
    (head): Sequential(
      (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace=True)
    )
    (body): Sequential(
      (0): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (tail): Sequential(
      (0): Conv2d(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
  (upconv3): UpConv(
    (body): Sequential(
      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PixelShuffle(upscale_factor=2)
      (2): ReLU(inplace=True)
    )
  )
  (scale2_net): SingleScaleNet(
    (head): Sequential(
      (0): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace=True)
    )
    (body): Sequential(
      (0): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (tail): Sequential(
      (0): Conv2d(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
  (upconv2): UpConv(
    (body): Sequential(
      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): PixelShuffle(upscale_factor=2)
      (2): ReLU(inplace=True)
    )
  )
  (scale1_net): SingleScaleNet(
    (head): Sequential(
      (0): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
      (1): ReLU(inplace=True)
    )
    (body): Sequential(
      (0): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (1): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): ResidualBlock(
        (body): Sequential(
          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU(inplace=True)
          (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (tail): Sequential(
      (0): Conv2d(8, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
  )
)
MSELoss()</code></pre></div>
<h3 id="损失函数和优化器">损失函数和优化器</h3>
<ul>
<li>Adam 优化器，初始学习率为 lr，其相对于
SGD，更自动化，实际中需要调整的参数较少，但需要注意的是，其使用内存也比
SGD 要高。</li>
<li>损失函数使用最常见的均方损失函数（MSELoss）: <img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222105417.png" alt="image-20211120222105417"> 其中 <span class="math inline">\(f^{\prime}(i,j)\)</span> 和 <span class="math inline">\(f(i,j)\)</span>
分别为模型输出结果图和非模糊图上坐标为 <span class="math inline">\((i,j)\)</span>
的像素，M,N分别表示图片的长与宽。</li>
<li>具体的，本文所用的多尺度损失函数为： <img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222124809.png" alt="image-20211120222124809"> <span class="math inline">\(f^{\prime}_k\)</span> 和 <span class="math inline">\(f_k\)</span> 分别表示第 <span class="math inline">\(k\)</span> 个尺度上的输出结果图和非模糊图。</li>
</ul>
<h2 id="模型训练">模型训练</h2>
<ol type="1">
<li>训练策略</li>
<li>训练模型</li>
<li>训练过程可视化</li>
</ol>
<h3 id="训练策略">训练策略</h3>
<ul>
<li>在模型训练过程中，随着训练的进行，更新网络参数的步进（学习率）应该越来越小，整体训练过程应该满足
“先粗调后细调”，这就是常说的学习率策略。</li>
<li>本次训练采用的学习率优化策略为 lr_scheduler.StepLR，步进为
lr_step_size，学习率每隔 lr_step_size 个 epoch 乘以 lr_gamma</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">scheduler = lr_scheduler.StepLR(optimizer,args.lr_step_size,args.lr_gamma)<br><br>scheduler<br></code></pre></td></tr></table></figure>
<div class="code-wrapper"><pre><code class="hljs">&lt;torch.optim.lr_scheduler.StepLR at 0x290378a0198&gt;</code></pre></div>
<h3 id="训练模型">训练模型</h3>
<p>在训练开始之前，要先创建一个
SummaryWriter，用来记录和可视化训练过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">writer = SummaryWriter(os.path.join(args.save_dir,<span class="hljs-string">&quot;temp/logs/&quot;</span>))<br><br>writer<br></code></pre></td></tr></table></figure>
<div class="code-wrapper"><pre><code class="hljs">&lt;tensorboardX.writer.SummaryWriter at 0x290378d6e10&gt;</code></pre></div>
<ul>
<li>在命令行运行 tensorboard --logdir=experiment/logs
来启动tensorboard。</li>
<li>在训练模型时，每训练完一个 epoch
将模型的参数保存下来，防止训练被意外中断以及方便测试，如果需要不断更新最新的一次训练的参数，可以取消最后一行的注释。</li>
<li>训练过程中，使用 tqdm 的进度条来观察训练过程</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python">bar_format = <span class="hljs-string">&#x27;&#123;desc&#125;&#123;percentage:3.0f&#125;% | [&#123;elapsed&#125;&lt;&#123;remaining&#125;,&#123;rate_fmt&#125;]&#x27;</span> <span class="hljs-comment"># 进度条格式</span><br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(args.epochs):<br>    total_loss = <span class="hljs-number">0</span><br>    batch_bar =  tqdm(data_loader, bar_format=bar_format) <span class="hljs-comment"># 利用tqdm动态显示训练过程</span><br>    <span class="hljs-keyword">for</span> batch,images <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(batch_bar):<br>        my_model.train()<br>        curr_batch = epoch * data_loader.__len__() + batch <span class="hljs-comment"># 当前batch在整个训练过程中的索引</span><br><br>        input_b1 = images[<span class="hljs-string">&#x27;input_b1&#x27;</span>].to(device) <span class="hljs-comment"># 原始输入图像</span><br>        target_s1 = images[<span class="hljs-string">&#x27;target_s1&#x27;</span>].to(device) <span class="hljs-comment"># 目标非模糊图片</span><br><br>        <span class="hljs-keyword">if</span> args.multi:<br>            input_b2 = images[<span class="hljs-string">&#x27;input_b2&#x27;</span>].to(device)  <span class="hljs-comment"># level-2 尺度</span><br>            target_s2 = images[<span class="hljs-string">&#x27;target_s2&#x27;</span>].to(device)<br><br>            input_b3 = images[<span class="hljs-string">&#x27;input_b3&#x27;</span>].to(device)  <span class="hljs-comment"># level-3 尺度</span><br>            target_s3 = images[<span class="hljs-string">&#x27;target_s3&#x27;</span>].to(device)<br>            output_l1, output_l2, output_l3 = my_model((input_b1,input_b2,input_b3))<br><br>            <span class="hljs-comment"># 损失函数</span><br>            loss = (loss_function(output_l1,target_s1) + loss_function(output_l2,target_s2) + loss_function(output_l3, target_s3)) /<span class="hljs-number">3</span> <br><br>        <span class="hljs-keyword">else</span>:<br>            output_l1 = my_model(input_b1)<br>            loss = loss_function(output_l1,target_s1)<br><br>        my_model.zero_grad()<br>        loss.backward()  <span class="hljs-comment">#反向传播</span><br>        optimizer.step() <span class="hljs-comment"># 更新权值</span><br>        total_loss += loss.item()<br><br><br>        print_str = <span class="hljs-string">&quot;|&quot;</span>.join([<br>            <span class="hljs-string">&quot;epoch:%3d/%3d&quot;</span> % (epoch + <span class="hljs-number">1</span>, args.epochs),<br>            <span class="hljs-string">&quot;batch:%3d/%3d&quot;</span> % (batch + <span class="hljs-number">1</span>, data_loader.__len__()),<br>            <span class="hljs-string">&quot;loss:%.5f&quot;</span> % (loss.item()),<br>        ])<br>        batch_bar.set_description(print_str,refresh=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 更新进度条</span><br><br>        writer.add_scalar(<span class="hljs-string">&#x27;train/batch_loss&#x27;</span>, loss.item(), curr_batch)<br><br>    batch_bar.close()<br>    scheduler.step() <span class="hljs-comment">#调整学习率</span><br>    loss = total_loss / (batch +<span class="hljs-number">1</span>)<br><br>    writer.add_scalar(<span class="hljs-string">&#x27;train/batch_loss&#x27;</span>,loss,epoch)<br>    torch.save(my_model.state_dict(),os.path.join(args.save_cp_dir, <span class="hljs-string">f&#x27;Epoch_<span class="hljs-subst">&#123;epoch&#125;</span>.pt&#x27;</span>)) <span class="hljs-comment"># 保存每个 epoch 的参数</span><br><span class="hljs-comment">#     torch.save(my_model.state_dict(),os.path.join(args.save_cp_dir, f&#x27;Epoch_lastest.pt&#x27;)) # 保存最新的参数</span><br></code></pre></td></tr></table></figure>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222241087.png" alt="image-20211120222241087">
<figcaption aria-hidden="true">image-20211120222241087</figcaption>
</figure>
<h2 id="模型评估">模型评估</h2>
<ol type="1">
<li>指标介绍</li>
<li>指标实现</li>
</ol>
<h3 id="指标介绍">指标介绍</h3>
<p>为了评估模型的效果如何，我们通过计算 峰值信噪比（Peak Signal-to-Noise
Ratio, PSNR）， 结构相似性（Structural Similarity, SSIM）和 多尺度的
SSIM（Multi-Scale SSIM，MSSIM）三个指标来对结果进行分析</p>
<h5 id="psnr">PSNR</h5>
<p>PSNR 的定义如下： <img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222352850.png" alt="image-20211120222352850"> 其中，<span class="math inline">\(M A
X_{I}\)</span>表示图像点颜色的最大数值，如果每个采样点用 8
位表示，则最大数值为 255，<span class="math inline">\(MSE\)</span>是两个图像之间的均方误差。
PSNR值越大代表模糊图像与参考图像越接近，即去模糊效果越好。</p>
<h5 id="ssim">SSIM</h5>
<p>SSIM也是衡量两幅图片相似性的指标，其定义如下： <img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222344621.png" alt="image-20211120222344621"> SSIM由模型输出图像 <span class="math inline">\(x\)</span> 和参考图像 <span class="math inline">\(y\)</span> 之间的亮度对比（$ l(, )<span class="math inline">\(）、对比度对比（\)</span>c(, )<span class="math inline">\(）和结构对比（\)</span>s(, ) <span class="math inline">\(）三部分组成，\)</span><span class="math inline">\(，\)</span>$ 和 <span class="math inline">\(\gamma\)</span>是各自的权重因子，一般都取为 1：
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222325752.png" alt="image-20211120222325752"> 其中，<span class="math inline">\(C_{1}\)</span>，<span class="math inline">\(C_{2}\)</span>和<span class="math inline">\(C_{3}\)</span>为常数，是为了避免分母接近于0时造成的不稳定性。<span class="math inline">\(\mu_{x}\)</span> 和 <span class="math inline">\(\mu_{y}\)</span>
分别为模型输出图像和参考图像的均值。<span class="math inline">\(\sigma_{x}\)</span> 和 <span class="math inline">\(\sigma_{y}\)</span>
分别为模型输出图像和参考图像的标准差。通常取 <span class="math inline">\(C1=(K1*L)^2\)</span>，<span class="math inline">\(C2=(K2*L)^2\)</span>，<span class="math inline">\(C3=C2/2\)</span>，一般地<span class="math inline">\(K1=0.01\)</span>， <span class="math inline">\(K2=0.03\)</span>, <span class="math inline">\(L=255\)</span>（ <span class="math inline">\(L\)</span>是像素值的动态范围，一般都取为255）。
输出图片和目标图片的结构相似值越大，则表示相似性越高，图像去模糊效果越好。
SSIM是一种符合人类直觉的图像质量评价标准。从名字上我们不难发现，这种指标是在致力于向人类的真实感知看齐，详细细节可以参考<a target="_blank" rel="noopener" href="https://www.cns.nyu.edu/pub/lcv/wang03-preprint.pdf">原论文</a></p>
<h5 id="mssim">MSSIM</h5>
<p>MSSIM相当于是在多个尺度上来进行SSIM指标的测试，相对于SSIM，其能更好的衡量图像到观看者的距离、像素信息密集程度等因素对观看者给出的主观评价所产生的影响。
论文中给出的一个例子是，观看者给一个分辨率为1080p的较为模糊的画面的评分可能会比分辨率为720p的较为锐利的画面的评分高。因此在评价图像质量的时候不考虑尺度因素可能会导致得出片面的结果。
MSSIM提出在不同分辨率（尺度）下多次计算结构相似度后综合结果得到最终的评价数值。其计算过程框图如下所示
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222301708.png" alt="image-20211120222301708"></p>
<p>MSSIM 的详细细节可以参考<a target="_blank" rel="noopener" href="https://ece.uwaterloo.ca/~z70wang/publications/msssim.pdf">原论文</a></p>
<h3 id="指标实现">指标实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># class PSNR(nn.Module):</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PSNR</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,img1,img2</span>):<br>        mse = ((img1 - img2) ** <span class="hljs-number">2</span>).mean() <span class="hljs-comment"># 输出图像和参考图像的 MSE</span><br>        psnr = <span class="hljs-number">10</span> * torch.log10(<span class="hljs-number">1.0</span> * <span class="hljs-number">1.0</span> / (mse + <span class="hljs-number">10</span> ** (-<span class="hljs-number">10</span>)))<br>        <span class="hljs-keyword">return</span> psnr<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># SSIM 和 MSSIM 的计算较为复杂，在这里，我们直接调用 pytorch-msssim 的接口来进行计算</span><br>ssim = pytorch_msssim.SSIM(data_range=<span class="hljs-number">1.0</span>, size_average=<span class="hljs-literal">True</span>, channel=<span class="hljs-number">3</span>)<br>mssim = pytorch_msssim.MS_SSIM(data_range=<span class="hljs-number">1.0</span>, size_average=<span class="hljs-literal">True</span>, channel=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 实例化</span><br>ssim = pytorch_msssim.SSIM(data_range=<span class="hljs-number">1.0</span>, size_average=<span class="hljs-literal">True</span>, channel=<span class="hljs-number">3</span>)<br>mssim = pytorch_msssim.MS_SSIM(data_range=<span class="hljs-number">1.0</span>, size_average=<span class="hljs-literal">True</span>, channel=<span class="hljs-number">3</span>)<br>psnr = PSNR()<br></code></pre></td></tr></table></figure>
<h2 id="模型预测">模型预测</h2>
<ol type="1">
<li>绘图函数定义</li>
<li>模型加载</li>
<li>数据加载</li>
<li>模型预测与指标分析</li>
<li>结果展示与保存</li>
</ol>
<h3 id="绘图函数定义">绘图函数定义</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_tensor</span>(<span class="hljs-params">tensor</span>):<br>    <span class="hljs-keyword">if</span> tensor.dim() == <span class="hljs-number">4</span>:<br>        tensor = tensor.squeeze(<span class="hljs-number">0</span>)<br>    ret = transforms.ToPILImage()(tensor.squeeze(<span class="hljs-number">0</span>))<br>    plt.imshow(ret)<br>    <span class="hljs-keyword">return</span><br></code></pre></td></tr></table></figure>
<h3 id="模型加载">模型加载</h3>
<p>训练过程中我们保存了多个 checkpoint
，现在对其进行加载和测试。这里我们提供了两种选择 checkpoint
的方式，一种是选择指定 checkpoint，一种是选择最新的
checkpoint。在这里我们以最新的 checkpoint 为例进行测试</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># option-A ：测试指定epoch</span><br><span class="hljs-comment"># best_epoch = 100 </span><br><span class="hljs-comment"># best_cp = f&quot;&#123;args.save_cp_dir&#125;/Epoch_&#123;best_epoch&#125;.pt&quot;</span><br><br><span class="hljs-comment"># option-B ：测试最终epoch</span><br><span class="hljs-comment"># best_cp = f&quot;&#123;args.save_cp_dir&#125;/Epoch_lastest.pt&quot;</span><br>best_cp = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;args.save_cp_dir&#125;</span>/Epoch_3.pt&quot;</span><br><br>my_model.to(<span class="hljs-string">&quot;cuda&quot;</span>).load_state_dict(torch.load(best_cp))<br>my_model = my_model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>
<h3 id="数据加载">数据加载</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 由于此模型采用的是多尺度训练，因此对于单张输入图像，需要对其进行处理，定义加载图像的函数 load_images 为</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_images</span>(<span class="hljs-params">blur_img_path,multi</span>):<br>    target_s1 = <span class="hljs-literal">None</span><br>    sharp_img_path = blur_img_path.replace(<span class="hljs-string">&quot;blur&quot;</span>,<span class="hljs-string">&quot;sharp&quot;</span>)<br>    <span class="hljs-keyword">if</span> os.path.exists(sharp_img_path):<br>        img_target = Image.<span class="hljs-built_in">open</span>(sharp_img_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>        target_s1 = transforms.ToTensor()(img_target).unsqueeze(<span class="hljs-number">0</span>)<br>        <br>    img_input = Image.<span class="hljs-built_in">open</span>(blur_img_path).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)  <span class="hljs-comment"># 转换为image类型 方便进行resize</span><br>    input_b1 = transforms.ToTensor()(img_input)<br>    <br>    <span class="hljs-keyword">if</span> multi:<br>        H = input_b1.size()[<span class="hljs-number">1</span>]<br>        W = input_b1.size()[<span class="hljs-number">2</span>]<br>        <br>        input_b1 = transforms.ToPILImage()(input_b1)<br>        input_b2 = transforms.ToTensor()(transforms.Resize([<span class="hljs-built_in">int</span>(H/<span class="hljs-number">2</span>), <span class="hljs-built_in">int</span>(W/<span class="hljs-number">2</span>)])(input_b1)).unsqueeze(<span class="hljs-number">0</span>)<br>        input_b3 = transforms.ToTensor()(transforms.Resize([<span class="hljs-built_in">int</span>(H/<span class="hljs-number">4</span>), <span class="hljs-built_in">int</span>(W/<span class="hljs-number">4</span>)])(input_b1)).unsqueeze(<span class="hljs-number">0</span>)<br>        <br>        input_b1 = transforms.ToTensor()(input_b1).unsqueeze(<span class="hljs-number">0</span>)<br>        <br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;input_b1&#x27;</span>:input_b1, <span class="hljs-string">&#x27;input_b2&#x27;</span>:input_b2, <span class="hljs-string">&#x27;input_b3&#x27;</span>:input_b3, <span class="hljs-string">&#x27;target_s1&#x27;</span>:target_s1&#125;<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;input_b1&#x27;</span>:unsqueeze(<span class="hljs-number">0</span>), <span class="hljs-string">&#x27;target_s1&#x27;</span>:target_s1&#125;<br></code></pre></td></tr></table></figure>
<h2 id="模型预测与指标分析">模型预测与指标分析</h2>
<h3 id="模型预测-1">模型预测</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#目录一</span><br><span class="hljs-comment"># idx = 1</span><br><span class="hljs-comment"># blur_img_path = f&quot;datasets/pictures/blur/test&#123;idx&#125;.png&quot;  </span><br><br><span class="hljs-comment"># 目录二</span><br>idx=<span class="hljs-string">&#x27;000001&#x27;</span><br>blur_img_path =<span class="hljs-string">f&quot;datasets/test/GOPR0384_11_00/blur/<span class="hljs-subst">&#123;idx&#125;</span>.png&quot;</span><br>item = load_images(blur_img_path,args.multi)<br><br>input_b1 = item[<span class="hljs-string">&#x27;input_b1&#x27;</span>].to(device) <br>input_b2 = item[<span class="hljs-string">&#x27;input_b2&#x27;</span>].to(device) <br>input_b3 = item[<span class="hljs-string">&#x27;input_b3&#x27;</span>].to(device) <br>target_s1 = item[<span class="hljs-string">&#x27;target_s1&#x27;</span>].to(device) <br><br>output_l1,_,_ = my_model((input_b1,input_b2,input_b3))<br></code></pre></td></tr></table></figure>
<h3 id="指标分析">指标分析</h3>
<p>原始模糊图片与不模糊图片之间的指标计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">blur_psnr = psnr(input_b1,target_s1)<br>blur_ssim = ssim(input_b1,target_s1)<br>blur_mssim = mssim(input_b1,target_s1)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;原始模糊图片:PSNR=<span class="hljs-subst">&#123;blur_psnr.<span class="hljs-built_in">float</span>()&#125;</span>, SSIM=<span class="hljs-subst">&#123;blur_ssim.<span class="hljs-built_in">float</span>()&#125;</span>, MSSIM=<span class="hljs-subst">&#123;blur_mssim.<span class="hljs-built_in">float</span>()&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<div class="code-wrapper"><pre><code class="hljs">原始模糊图片:PSNR=24.050003051757812, SSIM=0.716961145401001, MSSIM=0.840461015701294</code></pre></div>
<p>去模糊图片与不模糊的图片之间的指标计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">output_psnr = psnr(output_l1,target_s1)<br>output_ssim = ssim(output_l1,target_s1)<br>output_mssim = mssim(output_l1,target_s1)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;网络输出图片:PSNR=<span class="hljs-subst">&#123;output_psnr.<span class="hljs-built_in">float</span>()&#125;</span>, SSIM=<span class="hljs-subst">&#123;output_ssim.<span class="hljs-built_in">float</span>()&#125;</span>, MSSIM=<span class="hljs-subst">&#123;output_mssim.<span class="hljs-built_in">float</span>()&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<div class="code-wrapper"><pre><code class="hljs">网络输出图片:PSNR=24.012224197387695, SSIM=0.7089502811431885, MSSIM=0.8413411974906921</code></pre></div>
<h3 id="结果展示">结果展示</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">6</span>,<span class="hljs-number">10</span>))<br>plt.subplot(<span class="hljs-number">311</span>)<br>plot_tensor(input_b1)<br>plt.subplot(<span class="hljs-number">312</span>)<br>plot_tensor(output_l1)<br>plt.subplot(<span class="hljs-number">313</span>)<br>plot_tensor(target_s1)<br></code></pre></td></tr></table></figure>
<figure>
<img src="/.top//Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20211120222412395.png" alt="image-20211120222412395">
<figcaption aria-hidden="true">image-20211120222412395</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将结果保存</span><br>save_name = blur_img_path.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>]<br>save_path = os.path.join(args.save_dir,save_name)<br>save_img = transforms.ToPILImage()(output_l1.squeeze(<span class="hljs-number">0</span>))<br>save_img.save(save_path)<br></code></pre></td></tr></table></figure>
<hr>
<h3 id="about-me">About ME</h3>
<h5 id="读书城南-在未来面前我们都是孩子">👋 读书城南，🤔
在未来面前，我们都是孩子～</h5>
<ul>
<li>📙
一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~</li>
</ul>
<h5 id="social-media">👋 Social Media</h5>
<ul>
<li><p>🛠️ Blog: <a href="http://oceaneyes.top">http://oceaneyes.top</a></p></li>
<li><p>⚡ PM导航: <a target="_blank" rel="noopener" href="https://pmhub.oceangzy.top">https://pmhub.oceangzy.top</a></p></li>
<li><p>☘️ CNBLOG: <a target="_blank" rel="noopener" href="https://www.cnblogs.com/oceaneyes-gzy/">https://www.cnblogs.com/oceaneyes-gzy/</a></p></li>
<li><p>🌱 AI PRJ自己部署的一些算法demo: <a target="_blank" rel="noopener" href="http://ai.oceangzy.top/">http://ai.oceangzy.top/</a></p></li>
<li><p>📫 Email: 1450136519@qq.com</p></li>
<li><p>💬 WeChat: <a href="https://oceaneyes.top/img/wechatqrcode.jpg">OCEANGZY</a></p></li>
<li><p>💬 公众号: <a href="https://oceaneyes.top/img/wechatgzh.jpeg">UncleJoker-GZY</a></p></li>
</ul>
<h5 id="加入小组">👋 加入小组~</h5>
<p><img src="https://oceaneyes.top/img/zhishigroup.jpg" title="加入组织" alt width="240"></p>
<h5 id="感谢打赏">👋 感谢打赏~</h5>
<p><img src="https://oceaneyes.top/img/alipay.jpg" title="支付宝打赏" alt width="140">
<img src="https://oceaneyes.top/img/wechatpay.jpg" title="微信打赏" alt width="140"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://oceaneyes.top">OCEAN.GZY</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://oceaneyes.top/2021/11/19/pytorch%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%A8%A1%E7%B3%8A/">http://oceaneyes.top/2021/11/19/pytorch%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%A8%A1%E7%B3%8A/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://oceaneyes.top" target="_blank">OCAEN.GZY读书城南</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a><a class="post-meta__tags" href="/tags/Algorithm/">Algorithm</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a><a class="post-meta__tags" href="/tags/CV/">CV</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/15/item2vec%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/" title="训练item2vec实现电影推荐"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">训练item2vec实现电影推荐</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/01/bert-tf2-6/" title="Bert-TF-2.6修改-自调适配版"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Bert-TF-2.6修改-自调适配版</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2018/10/01/Algorithm%E5%85%A5%E9%97%A8%E8%A7%A3%E8%AF%BB/" title="Algorithm入门解读"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-10-01</div><div class="title">Algorithm入门解读</div></div></a></div><div><a href="/2021/01/03/NLP-Bert%E8%AF%AD%E4%B9%89%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/" title="NLP-Bert语义情感分类"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-03</div><div class="title">NLP-Bert语义情感分类</div></div></a></div><div><a href="/2022/01/15/item2vec%E5%AE%9E%E7%8E%B0%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/" title="训练item2vec实现电影推荐"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-15</div><div class="title">训练item2vec实现电影推荐</div></div></a></div><div><a href="/2021/03/28/ctr-predict/" title="广告投放中的CTR预估模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-28</div><div class="title">广告投放中的CTR预估模型</div></div></a></div><div><a href="/2021/03/01/lstm/" title="LSTM"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-01</div><div class="title">LSTM</div></div></a></div><div><a href="/2021/01/01/%E4%BD%BF%E7%94%A8%E5%86%B3%E7%AD%96%E6%A0%91%E9%A2%84%E6%B5%8B%E9%9A%90%E6%80%A7%E7%9C%BC%E9%95%9C%E7%B1%BB%E5%9E%8B/" title="案例-使用决策树预测隐性眼镜类型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-01</div><div class="title">案例-使用决策树预测隐性眼镜类型</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">OCEAN.GZY</div><div class="author-info__description">This is MyBlog Notes.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">166</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">114</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">91</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Epytorch%E5%AE%9E%E7%8E%B0%E5%9B%BE%E5%83%8F%E5%8E%BB%E6%A8%A1%E7%B3%8A-%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">基于PyTorch实现图像去模糊-学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E6%8F%8F%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">任务描述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">方法概述</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.</span> <span class="toc-text">参数设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">4.</span> <span class="toc-text">数据准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B1%95%E7%A4%BA"><span class="toc-number">4.1.</span> <span class="toc-text">数据集展示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">4.2.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E9%80%A0-dataset%E7%B1%BB"><span class="toc-number">4.3.</span> <span class="toc-text">构造 dataset类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD-dataloader"><span class="toc-number">4.4.</span> <span class="toc-text">数据加载 dataloader</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA"><span class="toc-number">5.</span> <span class="toc-text">模型构建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89"><span class="toc-number">5.1.</span> <span class="toc-text">模型定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%AE%9E%E4%BE%8B%E5%8C%96"><span class="toc-number">5.2.</span> <span class="toc-text">模型实例化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">5.3.</span> <span class="toc-text">损失函数和优化器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">6.</span> <span class="toc-text">模型训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5"><span class="toc-number">6.1.</span> <span class="toc-text">训练策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.</span> <span class="toc-text">训练模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">7.</span> <span class="toc-text">模型评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E4%BB%8B%E7%BB%8D"><span class="toc-number">7.1.</span> <span class="toc-text">指标介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#psnr"><span class="toc-number">7.1.0.1.</span> <span class="toc-text">PSNR</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ssim"><span class="toc-number">7.1.0.2.</span> <span class="toc-text">SSIM</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#mssim"><span class="toc-number">7.1.0.3.</span> <span class="toc-text">MSSIM</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E5%AE%9E%E7%8E%B0"><span class="toc-number">7.2.</span> <span class="toc-text">指标实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">8.</span> <span class="toc-text">模型预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%98%E5%9B%BE%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="toc-number">8.1.</span> <span class="toc-text">绘图函数定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8A%A0%E8%BD%BD"><span class="toc-number">8.2.</span> <span class="toc-text">模型加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="toc-number">8.3.</span> <span class="toc-text">数据加载</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E4%B8%8E%E6%8C%87%E6%A0%87%E5%88%86%E6%9E%90"><span class="toc-number">9.</span> <span class="toc-text">模型预测与指标分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B-1"><span class="toc-number">9.1.</span> <span class="toc-text">模型预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%87%E6%A0%87%E5%88%86%E6%9E%90"><span class="toc-number">9.2.</span> <span class="toc-text">指标分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA"><span class="toc-number">9.3.</span> <span class="toc-text">结果展示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#about-me"><span class="toc-number">9.4.</span> <span class="toc-text">About ME</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E4%B9%A6%E5%9F%8E%E5%8D%97-%E5%9C%A8%E6%9C%AA%E6%9D%A5%E9%9D%A2%E5%89%8D%E6%88%91%E4%BB%AC%E9%83%BD%E6%98%AF%E5%AD%A9%E5%AD%90"><span class="toc-number">9.4.0.1.</span> <span class="toc-text">👋 读书城南，🤔
在未来面前，我们都是孩子～</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#social-media"><span class="toc-number">9.4.0.2.</span> <span class="toc-text">👋 Social Media</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A0%E5%85%A5%E5%B0%8F%E7%BB%84"><span class="toc-number">9.4.0.3.</span> <span class="toc-text">👋 加入小组~</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%84%9F%E8%B0%A2%E6%89%93%E8%B5%8F"><span class="toc-number">9.4.0.4.</span> <span class="toc-text">👋 感谢打赏~</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><div class="content"><a class="title" href="/2023/03/04/AI%E4%BA%A7%E5%93%81%E8%A7%86%E8%A7%92%E4%B8%8B%E7%9A%84ChatGPT/" title="AI产品视角下的ChatGPT">AI产品视角下的ChatGPT</a><time datetime="2023-03-04T14:58:39.000Z" title="发表于 2023-03-04 22:58:39">2023-03-04</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%85%AD%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/" title="Python设计模式-六大设计原则">Python设计模式-六大设计原则</a><time datetime="2022-06-01T15:50:00.000Z" title="发表于 2022-06-01 23:50:00">2022-06-01</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B/" title="Python设计模式-结构型">Python设计模式-结构型</a><time datetime="2022-06-01T15:33:00.000Z" title="发表于 2022-06-01 23:33:00">2022-06-01</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B/" title="Python设计模式-行为型">Python设计模式-行为型</a><time datetime="2022-06-01T15:31:00.000Z" title="发表于 2022-06-01 23:31:00">2022-06-01</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2022/06/01/python%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B/" title="Python设计模式-创建型">Python设计模式-创建型</a><time datetime="2022-06-01T15:30:00.000Z" title="发表于 2022-06-01 23:30:00">2022-06-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By OCEAN.GZY</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>